{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import glob\n",
    "import sys\n",
    "sys.path.append('../pytorch-image-models')\n",
    "import timm\n",
    "from torch.utils.data.sampler import WeightedRandomSampler\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "from torch.nn import Sequential, Linear, Dropout\n",
    "from utils import stratify_split, make_holdout_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16881, 18187)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df = pd.read_csv('data/train_cleaned-0.5.csv', engine='python') \n",
    "data_df, holdout_df = make_holdout_df(data_df, seed=123)\n",
    "folds_df = stratify_split(data_df, 5, 123, 'label')\n",
    "folds1 = pd.read_csv('trained-models/sgd_coswarm_bnf_bitemp_smooth_weighted_t1=0.3_t2=1.0_89-53/folds.csv')\n",
    "len(folds_df.image_id), len(folds1.image_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = []\n",
    "\n",
    "a = [1,2,3,4]\n",
    "b = [0.1, 0.2, 0.3, 0.4]\n",
    "preds.extend(list(x) for x in zip(a, b))\n",
    "npa = np.array(preds)\n",
    "print(npa[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [[[1, 0.2], [2, 0.3]], \n",
    "     [[2, 0.1], [4, 0.9]]]\n",
    "a = np.array(a)\n",
    "b = a[:,:,0]\n",
    "print(b)\n",
    "np.mean(b, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = timm.create_model('skresnext50d_32x4d', pretrained=False)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ckpt = torch.load('trained-models/adabound_coswarm_bnf_bitemp_smooth_weighted_t1=0.3_t2=1.0_89-1/tf_efficientnet_b4_ns_bitempered_smooth=0.05_val_loss=0.104_val_acc=0.884_fold2.ckpt')\n",
    "print(ckpt['callbacks'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = timm.create_model('tf_efficientnet_b4_ns', pretrained=True)\n",
    "model.classifier = Sequential(\n",
    "                Dropout(p=0.3),\n",
    "                Linear(model.classifier.in_features, 5)\n",
    "            )\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "torch.hub.list('rwightman/pytorch-image-models')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WeightedRandomSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "s = np.array(list(WeightedRandomSampler([0.1, 0.9, 0.4, 3.0, 0.6], 20000, replacement=True)))\n",
    "counter = Counter(s)\n",
    "print(counter)\n",
    "for k,v in counter.items():\n",
    "    counter[k] = v/20000\n",
    "for i in range(0, 5):\n",
    "    print(i, counter[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folds = pd.read_csv('./trained-models/sgd_onecycle_bnfrozen_smoothed/folds.csv')\n",
    "values = folds.label.values\n",
    "\n",
    "classcounts = Counter(values)\n",
    "classcounts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = folds.iloc[folds[folds.fold != 0].index].reset_index(drop=True)\n",
    "print(len(train_df))\n",
    "target = train_df.label.values\n",
    "print('target classes', np.unique(target))\n",
    "\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "w = compute_class_weight({0:3,\n",
    "                          1:2.,\n",
    "                          2:2.3,\n",
    "                          4:2.3}, np.unique(target), target)\n",
    "\n",
    "\n",
    "class_sample_count = np.unique(target, return_counts=True)[1]\n",
    "print(class_sample_count)\n",
    "class_sample_count[0] *= 3\n",
    "class_sample_count[1] *= 2\n",
    "class_sample_count[2] *= 2.3\n",
    "class_sample_count[4] *= 2.3\n",
    "\n",
    "print(class_sample_count)\n",
    "\n",
    "weight = 1. / class_sample_count\n",
    "print('w', weight)\n",
    "samples_weight = weight[target] # unpacks\n",
    "print(len(samples_weight))\n",
    "samples_weight = torch.from_numpy(samples_weight)\n",
    "\n",
    "sampler = WeightedRandomSampler(samples_weight, len(samples_weight), replacement=True)\n",
    "\n",
    "sampled = np.array(list(sampler))\n",
    "sampled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# smooth cross entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([[1,2,3],\n",
    "             [4,5,6]])\n",
    "a.sum(axis=0), a.sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor([[0.5, 0.25, 0.75],\n",
    "                  [0.2, 0.7, 0.1],\n",
    "                  [0.1, 0.1, 0.8]])\n",
    "target = torch.tensor([0,2,1])\n",
    "\n",
    "weight = torch.zeros_like(x)\n",
    "smooth = 0.0\n",
    "confidence = 1-smooth\n",
    "\n",
    "weight.fill_(smooth / (3 - 1))\n",
    "print(weight) # defaults\n",
    "\n",
    "# randomly scatter self.confidence at indexes across each col dimension\n",
    "print(weight.scatter_(1, target.unsqueeze(1), confidence))\n",
    "\n",
    "# each row contains confidences for the given sample\n",
    "# each column is  a class\n",
    "\n",
    "dist_lsm_input = -weight * x\n",
    "torch.mean(torch.sum(dist_lsm_input, dim=1)) # sum across the columns (each sample's predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from loss_functions import bi_tempered_logistic_loss \n",
    "\n",
    "device = \"cpu\"\n",
    "\n",
    "activations = torch.FloatTensor([[-0.5,  0.1,  2.0],\n",
    "                                [0.1,2,3]]).to(device)\n",
    "labels = torch.FloatTensor([[0.2, 0.5, 0.3],\n",
    "                           [0.1,0.2,0.3]]).to(device)\n",
    "\n",
    "# The standard logistic loss is obtained when t1 = t2 = 1.0\n",
    "loss = bi_tempered_logistic_loss(activations=activations, labels=labels, t1=1.0, t2=1.0)\n",
    "print(\"Loss, t1=1.0, t2=1.0: \", loss)\n",
    "\n",
    "loss = bi_tempered_logistic_loss(activations=activations, labels=labels, t1=0.7, t2=1.3)\n",
    "print(\"Loss, t1=0.7, t2=1.3: \", loss)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
