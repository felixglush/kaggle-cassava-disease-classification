{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import errno\n",
    "import glob\n",
    "import json\n",
    "import os\n",
    "import re\n",
    "from types import SimpleNamespace\n",
    "import torch\n",
    "import warnings\n",
    "from lightning_objects import LightningModel\n",
    "warnings.filterwarnings('ignore')\n",
    "from config import Configuration\n",
    "import pandas as pd\n",
    "from common_utils import stratify_split, make_holdout_df, set_seeds\n",
    "from train_manager import TrainManager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 2, 3],\n",
       "       [1, 2, 3],\n",
       "       [4, 5, 6]])"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "a = np.array([1,2,3])\n",
    "b = np.array([1,2,3])\n",
    "c = np.array([4,5,6])\n",
    "predictions = np.vstack((a, b))\n",
    "predictions = np.vstack((predictions, c))\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "out = []\n",
    "out = out.append(a)\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[1, 2, 3]]), array([2., 3., 4.]))"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.stats import stats\n",
    "stats.mode(predictions, axis=0)[0], np.round(np.mean(predictions, axis=0), decimals=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "m = LightningModel(Configuration(), None, lr=0.1, fold=3,\n",
    "                 fc_nodes=0, pretrained=True)\n",
    "# frozen batch norm parameters\n",
    "for name, p in m.named_parameters():\n",
    "    print(name, p.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def main(experiment_name: str, config: Configuration, resume=False):\n",
    "    experiment_dir = os.path.abspath(config.save_dir + f'/{experiment_name}')\n",
    "    print('Experiment directory', experiment_dir)\n",
    "    try:\n",
    "        # -------- SETUP --------\n",
    "        # if resuming, get checkpoint parameters\n",
    "        checkpoint_params = get_checkpoint_params(experiment_dir, resume)\n",
    "\n",
    "        if not checkpoint_params:\n",
    "            make_experiment_directory(experiment_dir)\n",
    "\n",
    "            # -------- LOAD DATA FROM TRAIN FILE --------\n",
    "            data_df = pd.read_csv(config.data_dir + '/train.csv', engine='python')\n",
    "            data_df, holdout_df = make_holdout_df(data_df, seed=config.seed)\n",
    "            folds_df = stratify_split(data_df, config.fold_num, config.seed, config.target_col)\n",
    "\n",
    "            # -------- SAVE FILES (for experiment state) --------\n",
    "            folds_df.to_csv(experiment_dir + '/folds.csv', index=False)\n",
    "            # save holdout to a csv file for final inference (so we don't run inference on training examples)\n",
    "            holdout_df.to_csv(experiment_dir + '/holdout.csv', index=False)\n",
    "            # save the settings for this experiment to its directory\n",
    "            with open(experiment_dir + '/experiment_config.json', 'w') as f:\n",
    "                json.dump(config.__dict__, f)\n",
    "        else:\n",
    "            print('resuming...')\n",
    "            # LOAD DATA FROM SAVED FILES\n",
    "            with open(experiment_dir + '/experiment_config.json', 'r') as f:\n",
    "                config = json.load(f, object_hook=lambda d: SimpleNamespace(**d))\n",
    "            folds_df = pd.read_csv(experiment_dir + '/folds.csv', engine='python')\n",
    "            holdout_df = pd.read_csv(experiment_dir + '/holdout.csv', engine='python')\n",
    "\n",
    "        trainer = TrainManager(experiment_name=experiment_name, experiment_dir=experiment_dir,\n",
    "                               folds_df=folds_df, holdout_df=holdout_df,\n",
    "                               checkpoint_params=checkpoint_params, config=config)\n",
    "        trainer.run()\n",
    "    finally:\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "def make_experiment_directory(basename):\n",
    "    try:\n",
    "        os.makedirs(basename)\n",
    "    except FileExistsError as e:\n",
    "        print('Experiment already exists. Be sure to resume training appropriately or start a new experiment.')\n",
    "        if e.errno == errno.EEXIST: raise\n",
    "\n",
    "\n",
    "def get_checkpoint_params(basename, resume):\n",
    "    \"\"\"\n",
    "    We can restart from the middle of a fold or start from the beginning of a fold.\n",
    "\n",
    "    checkpoint_params: {\"restart_from\": fold, \"start_beginning_of\": fold, \"checkpoint_file_path\": file}\n",
    "        restart_from (int): start from middle of a fold - typically used when a training session was cancelled mid fold\n",
    "            checkpoint_file_path (str) is required in this case\n",
    "        start_beginning_of (int): train a particular fold\n",
    "    \"\"\"\n",
    "\n",
    "    checkpoint_params = None\n",
    "    if resume:\n",
    "        checkpoint_params = {}\n",
    "        model_filenames = glob.glob(basename + '/*fold*.ckpt')\n",
    "        trained_folds = [re.findall(r'fold\\d+', f)[0][len('fold'):] for f in model_filenames]\n",
    "        most_recent_fold = int(max(trained_folds)) if len(trained_folds) > 0 else 0\n",
    "\n",
    "        checkpoint_params['restart_from'] = most_recent_fold\n",
    "        checkpoint_params['checkpoint_file_path'] = f'{basename}/{config.model_arch}_fold{most_recent_fold}.pth'\n",
    "    return checkpoint_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    try:\n",
    "        debug = False\n",
    "        print('Running in debug mode:', debug)\n",
    "        config = Configuration()\n",
    "        set_seeds(config.seed)\n",
    "        config.debug = debug\n",
    "        main(experiment_name='exp8_sgd_frozen_batch_norm', resume=False, config=config)\n",
    "    except KeyboardInterrupt:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
