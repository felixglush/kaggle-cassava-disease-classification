{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import errno\n",
    "import glob\n",
    "import json\n",
    "import os\n",
    "import re\n",
    "import torch\n",
    "from config import ConstantConfig, DynamicConfig\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from common_utils import read_csv, create_holdout_loader, stratify_split, make_holdout_df\n",
    "\n",
    "from logger import init_logger\n",
    "from train_utilities.trainer import Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(experiment_name, config, resume=False, train_fold=None):\n",
    "    experiment_dir = config.save_dir + f'/{experiment_name}'\n",
    "\n",
    "    try:\n",
    "        # -------- SETUP --------\n",
    "        # if resuming, get checkpoint parameters\n",
    "        checkpoint_params = get_checkpoint_params(experiment_dir, resume, train_fold)\n",
    "        logger = init_logger()\n",
    "        tb_writer = SummaryWriter(f'./runs/{experiment_name}')\n",
    "        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "        if not checkpoint_params:\n",
    "            make_experiment_directory(experiment_dir)\n",
    "\n",
    "            # -------- LOAD DATA FROM TRAIN FILE --------\n",
    "            data_df = read_csv(config.data_dir + '/train.csv', config.debug)\n",
    "            holdout_df = make_holdout_df(data_df)\n",
    "            folds_df = stratify_split(data_df, config.fold_num, config.seed, config.target_col)\n",
    "\n",
    "            # -------- SAVE FILES (for experiment state) --------\n",
    "            folds_df.to_csv(experiment_dir + '/folds.csv', index=False)\n",
    "            # save holdout to a csv file for final inference (so we don't run inference on training examples)\n",
    "            holdout_df.to_csv(experiment_dir + '/holdout.csv', index=False)\n",
    "            # save the settings for this experiment to its directory\n",
    "            with open(experiment_dir + '/experiment_config.json', 'w') as f:\n",
    "                json.dump(config.__dict__, f)\n",
    "        else:\n",
    "            # LOAD DATA FROM SAVED FILES\n",
    "            with open(experiment_dir + '/experiment_config.json', 'r') as f:\n",
    "                config = json.load(f)\n",
    "            folds_df = read_csv(experiment_dir + '/folds.csv', config.debug)\n",
    "            holdout_df = read_csv(experiment_dir + '/holdout.csv', config.debug)\n",
    "\n",
    "        holdout_loader, holdout_targets = create_holdout_loader(holdout_df, config.train_img_dir)\n",
    "\n",
    "        trainer = Trainer(experiment_dir=experiment_dir,\n",
    "                          folds_df=folds_df, holdout_loader=holdout_loader,\n",
    "                          logger=logger, tensorboard_writer=tb_writer,\n",
    "                          device=device, checkpoint_params=checkpoint_params,\n",
    "                          config=config,)\n",
    "        trainer.fit()\n",
    "    finally:\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "def make_experiment_directory(basename):\n",
    "    try:\n",
    "        os.makedirs(basename)\n",
    "    except OSError as e:\n",
    "        print('Experiment already exists. Be sure to resume training appropriately or start a new experiment.')\n",
    "        if e.errno != errno.EEXIST: raise\n",
    "\n",
    "\n",
    "def get_checkpoint_params(basename, resume, train_fold):\n",
    "    \"\"\"\n",
    "    We can restart from the middle of a fold or start from the beginning of a fold.\n",
    "\n",
    "    checkpoint_params: {\"restart_from\": fold, \"start_beginning_of\": fold, \"checkpoint_file_path\": file}\n",
    "        restart_from (int): start from middle of a fold - typically used when a training session was cancelled mid fold\n",
    "            checkpoint_file_path (str) is required in this case\n",
    "        start_beginning_of (int): train a particular fold\n",
    "    \"\"\"\n",
    "\n",
    "    checkpoint_params = None\n",
    "    if resume:\n",
    "        model_filenames = glob.glob(basename + '/*.pth')\n",
    "        trained_folds = [re.findall(r'fold\\d+', f)[0][len('fold'):]\n",
    "                         for f in model_filenames]\n",
    "        if train_fold is not None:\n",
    "            assert train_fold not in trained_folds\n",
    "            checkpoint_params['start_beginning_of'] = train_fold\n",
    "        else:\n",
    "            most_recent_fold = max(trained_folds)\n",
    "            checkpoint_params['restart_from'] = most_recent_fold\n",
    "            checkpoint_params['checkpoint_file_path'] = basename + f'/{config.settings.model_arch}_fold{most_recent_fold}.pth'\n",
    "    return checkpoint_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    try:\n",
    "        debug = True\n",
    "        print('Running in debug mode:', debug)\n",
    "        config = Configuration()\n",
    "        config.debug = debug\n",
    "        main(experiment_name='test1', resume=False, config=config)\n",
    "    except KeyboardInterrupt:\n",
    "        pass"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}