{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from datetime import datetime, timedelta\n",
    "import time\n",
    "import glob\n",
    "\n",
    "# My modules\n",
    "from config import Config\n",
    "from logger import init_logger\n",
    "from common_utils import set_seeds, create_holdout_loader, get_valid_transforms\n",
    "from train_loop_functions import ensemble_inference\n",
    "from cassava_dataset import CassavaDataset\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_seeds(Config.seed)\n",
    "LOGGER = init_logger() # uses Python's logging framework"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./trained-models/exp1_88_Adam/tf_efficientnet_b4_ns_fold0.pth\n",
      "./trained-models/exp1_88_Adam/tf_efficientnet_b4_ns_fold1.pth\n",
      "./trained-models/exp1_88_Adam/tf_efficientnet_b4_ns_fold2.pth\n",
      "./trained-models/exp1_88_Adam/tf_efficientnet_b4_ns_fold3.pth\n",
      "Loaded 4 models\n"
     ]
    }
   ],
   "source": [
    "experiment_name_dirs = ['exp1_88_Adam']\n",
    "model_states = []\n",
    "for experiment in experiment_name_dirs:\n",
    "    base = Config.save_dir + f'/{experiment}'\n",
    "    # find all files that end in \"pth\"\n",
    "    model_filenames = glob.glob(base + '/*.pth')\n",
    "    for f in model_filenames:\n",
    "        print(f)\n",
    "        checkpoint = torch.load(f)\n",
    "        model_states.append(checkpoint['model_state'] if 'model_state' in checkpoint else checkpoint['model'])\n",
    "\n",
    "print(f'Loaded {len(model_states)} models')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_inference(model_states, model_arch, kaggle):\n",
    "    LOGGER.info('========== Running inference ==========')\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    loader, targets, df = None, None, None\n",
    "    num_samples = 0    \n",
    "    \n",
    "    if not kaggle: \n",
    "        # read holdout set from csv... \n",
    "        df = pd.read_csv('./trained-models/exp6_sgd/holdout.csv', engine='python')\n",
    "        loader, targets = create_holdout_loader(df, Config.train_img_dir)\n",
    "    else: \n",
    "        df = pd.DataFrame()\n",
    "        df['image_id'] = list(os.listdir(Config.test_img_dir))\n",
    "        test_dataset = CassavaDataset(df, Config.test_img_dir, \n",
    "                                      transform=get_valid_transforms(Config.img_size),\n",
    "                                      output_label=False)\n",
    "        loader = DataLoader(test_dataset, batch_size=Config.valid_bs)\n",
    "    num_samples = len(df)\n",
    "\n",
    "    inference_start = time.time()\n",
    "    \n",
    "    predictions = ensemble_inference(model_states, model_arch, \n",
    "                            Config.num_classes, loader, num_samples, device, mode='vote', kaggle=kaggle)\n",
    "    \n",
    "    inference_elapsed = time.time() - inference_start\n",
    "    \n",
    "    LOGGER.info(f\"Inference time: {str(timedelta(seconds=inference_elapsed))}\")\n",
    "\n",
    "    if not kaggle:\n",
    "        holdout_accuracy = accuracy_score(y_true=targets, y_pred=predictions)\n",
    "        LOGGER.info(f\"Ensemble model holdout accuracy: {holdout_accuracy}\")\n",
    "    else: # make submission file\n",
    "        submission = pd.DataFrame()\n",
    "        submission['image_id'] = df['image_id']\n",
    "        submission['label'] = predictions\n",
    "        submission.to_csv('submission.csv', index=False)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "========== Running inference ==========\n",
      "100%|██████████| 4/4 [00:02<00:00,  1.84it/s]\n",
      "Inference time: 0:00:02.170352\n"
     ]
    }
   ],
   "source": [
    "run_inference(model_states, Config.model_arch, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}