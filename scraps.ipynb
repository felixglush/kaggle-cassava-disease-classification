{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WeightedRandomSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({3: 11859, 1: 3642, 4: 2423, 2: 1623, 0: 453})\n",
      "0 0.02265\n",
      "1 0.1821\n",
      "2 0.08115\n",
      "3 0.59295\n",
      "4 0.12115\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data.sampler import WeightedRandomSampler\n",
    "import numpy as np\n",
    "s = np.array(list(WeightedRandomSampler([0.1, 0.9, 0.4, 3.0, 0.6], 20000, replacement=True)))\n",
    "from collections import Counter\n",
    "counter = Counter(s)\n",
    "print(counter)\n",
    "for k,v in counter.items():\n",
    "    counter[k] = v/20000\n",
    "for i in range(0, 5):\n",
    "    print(i, counter[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({3: 11167, 4: 2206, 1: 1838, 2: 2028, 0: 948})"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "folds = pd.read_csv('./trained-models/sgd_onecycle_bnfrozen_smoothed/folds.csv')\n",
    "values = folds.label.values\n",
    "\n",
    "classcounts = Counter(values)\n",
    "classcounts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14549\n",
      "target classes [0 1 2 3 4]\n",
      "[ 758 1470 1623 8933 1765]\n",
      "[2274 2940 3732 8933 4059]\n",
      "w [0.00043975 0.00034014 0.00026795 0.00011194 0.00024637]\n",
      "14549\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/favordata/anaconda3/envs/kaggle/lib/python3.7/site-packages/sklearn/utils/validation.py:70: FutureWarning: Pass classes=[0 1 2 3 4], y=[3 4 4 ... 4 1 3] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 8970,  7042,  2124, ...,  2022, 13297,   599])"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = folds.iloc[folds[folds.fold != 0].index].reset_index(drop=True)\n",
    "print(len(train_df))\n",
    "target = train_df.label.values\n",
    "print('target classes', np.unique(target))\n",
    "\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "w = compute_class_weight({0:3,\n",
    "                          1:2.,\n",
    "                          2:2.3,\n",
    "                          4:2.3}, np.unique(target), target)\n",
    "\n",
    "\n",
    "class_sample_count = np.unique(target, return_counts=True)[1]\n",
    "print(class_sample_count)\n",
    "class_sample_count[0] *= 3\n",
    "class_sample_count[1] *= 2\n",
    "class_sample_count[2] *= 2.3\n",
    "class_sample_count[4] *= 2.3\n",
    "\n",
    "print(class_sample_count)\n",
    "\n",
    "weight = 1. / class_sample_count\n",
    "print('w', weight)\n",
    "samples_weight = weight[target] # unpacks\n",
    "print(len(samples_weight))\n",
    "samples_weight = torch.from_numpy(samples_weight)\n",
    "\n",
    "sampler = WeightedRandomSampler(samples_weight, len(samples_weight), replacement=True)\n",
    "\n",
    "sampled = np.array(list(sampler))\n",
    "sampled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# smooth cross entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([5, 7, 9]), array([ 6, 15]))"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.array([[1,2,3],\n",
    "             [4,5,6]])\n",
    "a.sum(axis=0), a.sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0250, 0.0250, 0.0250],\n",
      "        [0.0250, 0.0250, 0.0250],\n",
      "        [0.0250, 0.0250, 0.0250]])\n",
      "tensor([[0.9500, 0.0250, 0.0250],\n",
      "        [0.0250, 0.0250, 0.9500],\n",
      "        [0.0250, 0.9500, 0.0250]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(-0.2450)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.tensor([[0.5, 0.25, 0.75],\n",
    "                  [0.2, 0.7, 0.1],\n",
    "                  [0.1, 0.1, 0.8]])\n",
    "target = torch.tensor([0,2,1])\n",
    "\n",
    "weight = torch.zeros_like(x)\n",
    "weight.fill_(0.05 / (3 - 1))\n",
    "print(weight) # defaults\n",
    "\n",
    "# randomly scatter self.confidence at indexes across each col dimension\n",
    "print(weight.scatter_(1, target.unsqueeze(1), 0.95))\n",
    "\n",
    "# each row contains confidences for the given sample\n",
    "# each column is  a class\n",
    "\n",
    "dist_lsm_input = -weight * x\n",
    "torch.mean(torch.sum(dist_lsm_input, dim=1)) # sum across the columns (each sample's predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3]) torch.Size([2, 1])\n",
      "torch.Size([2])\n",
      "Loss, t1=1.0, t2=1.0:  tensor([0.6287, 0.1883])\n",
      "logt torch.Size([2, 1])\n",
      "point torch.Size([2, 1])\n",
      "torch.Size([2, 3]) torch.Size([2, 1])\n",
      "torch.Size([2])\n",
      "Loss, t1=0.7, t2=1.3:  tensor([0.2630, 0.0919])\n"
     ]
    }
   ],
   "source": [
    "from loss_functions import bi_tempered_logistic_loss \n",
    "\n",
    "device = \"cpu\"\n",
    "\n",
    "activations = torch.FloatTensor([[-0.5,  0.1,  2.0],\n",
    "                                [0.1,2,3]]).to(device)\n",
    "labels = torch.FloatTensor([[0.2, 0.5, 0.3],\n",
    "                           [0.1,0.2,0.3]]).to(device)\n",
    "\n",
    "# The standard logistic loss is obtained when t1 = t2 = 1.0\n",
    "loss = bi_tempered_logistic_loss(activations=activations, labels=labels, t1=1.0, t2=1.0)\n",
    "print(\"Loss, t1=1.0, t2=1.0: \", loss)\n",
    "\n",
    "loss = bi_tempered_logistic_loss(activations=activations, labels=labels, t1=0.7, t2=1.3)\n",
    "print(\"Loss, t1=0.7, t2=1.3: \", loss)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
