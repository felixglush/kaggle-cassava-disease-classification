{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import errno\n",
    "import glob\n",
    "import json\n",
    "import os\n",
    "import re\n",
    "import shutil\n",
    "from types import SimpleNamespace\n",
    "import cv2\n",
    "import torch\n",
    "import warnings\n",
    "from lightning_objects import LightningModel\n",
    "warnings.filterwarnings('ignore')\n",
    "from config import Configuration\n",
    "import pandas as pd\n",
    "from utils import stratify_split, make_holdout_df, set_seeds\n",
    "from train_manager import TrainManager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def main(experiment_name: str, debug, resume=False,\n",
    "         finetune=False, freeze_bn=True, freeze_feature_extractor=False):\n",
    "\n",
    "    experiment_dir = os.path.abspath(f'trained-models/{experiment_name}')\n",
    "    print('Experiment directory', experiment_dir)\n",
    "\n",
    "    try:\n",
    "        # -------- SETUP --------\n",
    "        checkpoint_params = None\n",
    "        finetune_model_fnames = None\n",
    "        folds_df, holdout_df = None, None\n",
    "\n",
    "        if not resume and not finetune: # totally new experiment\n",
    "            make_experiment_directory(experiment_dir)\n",
    "            config = Configuration()\n",
    "            config.debug = debug\n",
    "            set_seeds(config.seed)\n",
    "\n",
    "            # -------- LOAD DATA FROM TRAIN FILE --------\n",
    "            data_df = pd.read_csv(config.data_dir + '/train.csv', engine='python')\n",
    "            data_df, holdout_df = make_holdout_df(data_df, seed=config.seed)\n",
    "            folds_df = stratify_split(data_df, config.fold_num, config.seed, config.target_col)\n",
    "\n",
    "            # -------- SAVE FILES (experiment state: things like resuming, fine tuning, and inference on holdout) --------\n",
    "            folds_df.to_csv(experiment_dir + '/folds.csv', index=False)\n",
    "            holdout_df.to_csv(experiment_dir + '/holdout.csv', index=False)\n",
    "            with open(experiment_dir + '/experiment_config.json', 'w') as f:\n",
    "                json.dump(config.__dict__, f)\n",
    "        elif resume or finetune:\n",
    "            # LOAD DATA FROM SAVED FILES\n",
    "            with open(experiment_dir + '/experiment_config.json', 'r') as f:\n",
    "                config = json.load(f, object_hook=lambda d: SimpleNamespace(**d))\n",
    "                set_seeds(config.seed)\n",
    "                config.debug = debug\n",
    "\n",
    "            folds_df = pd.read_csv(experiment_dir + '/folds.csv', engine='python')\n",
    "            holdout_df = pd.read_csv(experiment_dir + '/holdout.csv', engine='python')\n",
    "\n",
    "            if finetune and not resume:\n",
    "                print('finetuning...')\n",
    "                # verify there are checkpoints to fine tune\n",
    "                finetune_model_fnames = glob.glob(experiment_dir + '/*fold*.ckpt')\n",
    "                assert len(finetune_model_fnames) > 0\n",
    "                finetune_model_fnames.sort()\n",
    "\n",
    "                # make new directory for tuning experiment with files from training run 1\n",
    "                make_experiment_directory(experiment_dir + '_tune')\n",
    "                for f in os.listdir(experiment_dir):\n",
    "                    print(f\"copying {f} to {experiment_dir + '_tune'}\")\n",
    "                    shutil.copy2(experiment_dir + '/' + f, experiment_dir + '_tune')\n",
    "                experiment_dir += '_tune'\n",
    "                experiment_name += '_tune'\n",
    "            else:\n",
    "                print('resuming from last checkpoint...')\n",
    "                checkpoint_params = get_checkpoint_params(experiment_dir, resume, config.model_arch)\n",
    "\n",
    "        assert holdout_df is not None, 'holdout_df is None'\n",
    "        assert folds_df is not None, 'folds_df is None'\n",
    "\n",
    "        # cv2 multithreading seems to go into deadlock with PyTorch data loaders\n",
    "        if config.num_workers > 0:\n",
    "            cv2.setNumThreads(0)\n",
    "\n",
    "        trainer = TrainManager(experiment_name=experiment_name, experiment_dir=experiment_dir,\n",
    "                               folds_df=folds_df, holdout_df=holdout_df,\n",
    "                               checkpoint_params=checkpoint_params, config=config,\n",
    "                               finetune=finetune, freeze_bn=freeze_bn,\n",
    "                               freeze_feature_extractor=freeze_feature_extractor,\n",
    "                               finetune_model_fnames=finetune_model_fnames)\n",
    "        trainer.run()\n",
    "    finally:\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "def make_experiment_directory(name):\n",
    "    try:\n",
    "        os.makedirs(name)\n",
    "    except FileExistsError as e:\n",
    "        print('Experiment already exists. Be sure to resume training appropriately or start a new experiment.')\n",
    "        if e.errno == errno.EEXIST: raise\n",
    "\n",
    "\n",
    "def get_checkpoint_params(basename, resume, model_arch):\n",
    "    checkpoint_params = None\n",
    "    if resume:\n",
    "        checkpoint_params = {}\n",
    "        model_filenames = glob.glob(basename + '/*fold*.ckpt')\n",
    "        model_filenames.sort()\n",
    "        trained_folds = [re.findall(r'fold\\d+', f)[0][len('fold'):] for f in model_filenames]\n",
    "        most_recent_fold = int(max(trained_folds)) if len(trained_folds) > 0 else 0\n",
    "\n",
    "        checkpoint_params['restart_from'] = most_recent_fold\n",
    "        checkpoint_params['checkpoint_file_path'] = model_filenames[-1]\n",
    "\n",
    "    return checkpoint_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: None, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Using native 16bit precision.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running in debug mode: False\n",
      "Experiment directory /opt/favordata/AI/Felix/kaggle-cassava/trained-models/tf_efficientnet_b4_ns_sgd_onecycle_smoothing=0.05_weighted_bitempered_t1=0.8_t2=1\n",
      "folds_df len 18187, holdout_df len 3210\n",
      "Training fold 0\n",
      "Class sample counts [ 758 1470 1623 8933 1765]\n",
      "After class sample counts [2274 2940 3732 8933 4765]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name           | Type           | Params\n",
      "--------------------------------------------------\n",
      "0 | valid_accuracy | Accuracy       | 0     \n",
      "1 | test_accuracy  | Accuracy       | 0     \n",
      "2 | criterion      | BiTemperedLoss | 0     \n",
      "3 | model          | EfficientNet   | 17.6 M\n",
      "--------------------------------------------------\n",
      "17.4 M    Trainable params\n",
      "125 K     Non-trainable params\n",
      "17.6 M    Total params\n",
      "\n",
      "Finding best initial lr:   0%|          | 0/100 [00:00<?, ?it/s]\u001b[A\n",
      "Finding best initial lr:   1%|          | 1/100 [00:00<00:30,  3.24it/s]\u001b[A\n",
      "Finding best initial lr:   2%|▏         | 2/100 [00:01<01:18,  1.24it/s]\u001b[A\n",
      "Finding best initial lr:   3%|▎         | 3/100 [00:02<01:33,  1.04it/s]\u001b[A\n",
      "Finding best initial lr:   4%|▍         | 4/100 [00:03<01:40,  1.04s/it]\u001b[A\n",
      "Finding best initial lr:   5%|▌         | 5/100 [00:04<01:42,  1.08s/it]\u001b[A\n",
      "Finding best initial lr:   6%|▌         | 6/100 [00:06<01:44,  1.11s/it]\u001b[A\n",
      "Finding best initial lr:   7%|▋         | 7/100 [00:07<01:44,  1.12s/it]\u001b[A\n",
      "Finding best initial lr:   8%|▊         | 8/100 [00:08<01:44,  1.13s/it]\u001b[A\n",
      "Finding best initial lr:   9%|▉         | 9/100 [00:09<01:43,  1.14s/it]\u001b[A\n",
      "Finding best initial lr:  10%|█         | 10/100 [00:10<01:43,  1.15s/it]\u001b[A\n",
      "Finding best initial lr:  11%|█         | 11/100 [00:11<01:42,  1.16s/it]\u001b[A\n",
      "Finding best initial lr:  12%|█▏        | 12/100 [00:13<01:41,  1.16s/it]\u001b[A\n",
      "Finding best initial lr:  13%|█▎        | 13/100 [00:14<01:40,  1.16s/it]\u001b[A\n",
      "Finding best initial lr:  14%|█▍        | 14/100 [00:15<01:39,  1.16s/it]\u001b[A\n",
      "Finding best initial lr:  15%|█▌        | 15/100 [00:16<01:38,  1.16s/it]\u001b[A\n",
      "Finding best initial lr:  16%|█▌        | 16/100 [00:17<01:37,  1.16s/it]\u001b[A\n",
      "Finding best initial lr:  17%|█▋        | 17/100 [00:18<01:36,  1.16s/it]\u001b[A\n",
      "Finding best initial lr:  18%|█▊        | 18/100 [00:20<01:35,  1.16s/it]\u001b[A\n",
      "Finding best initial lr:  19%|█▉        | 19/100 [00:21<01:34,  1.16s/it]\u001b[A\n",
      "Finding best initial lr:  20%|██        | 20/100 [00:22<01:33,  1.17s/it]\u001b[A\n",
      "Finding best initial lr:  21%|██        | 21/100 [00:23<01:32,  1.17s/it]\u001b[A\n",
      "Finding best initial lr:  22%|██▏       | 22/100 [00:24<01:30,  1.16s/it]\u001b[A\n",
      "Finding best initial lr:  23%|██▎       | 23/100 [00:25<01:29,  1.16s/it]\u001b[A\n",
      "Finding best initial lr:  24%|██▍       | 24/100 [00:27<01:28,  1.16s/it]\u001b[A\n",
      "Finding best initial lr:  25%|██▌       | 25/100 [00:28<01:27,  1.16s/it]\u001b[A\n",
      "Finding best initial lr:  26%|██▌       | 26/100 [00:29<01:26,  1.16s/it]\u001b[A\n",
      "Finding best initial lr:  27%|██▋       | 27/100 [00:30<01:24,  1.16s/it]\u001b[A\n",
      "Finding best initial lr:  28%|██▊       | 28/100 [00:31<01:23,  1.16s/it]\u001b[A\n",
      "Finding best initial lr:  29%|██▉       | 29/100 [00:32<01:22,  1.17s/it]\u001b[A\n",
      "Finding best initial lr:  30%|███       | 30/100 [00:34<01:22,  1.17s/it]\u001b[A\n",
      "Finding best initial lr:  31%|███       | 31/100 [00:35<01:20,  1.17s/it]\u001b[A\n",
      "Finding best initial lr:  32%|███▏      | 32/100 [00:36<01:19,  1.17s/it]\u001b[A\n",
      "Finding best initial lr:  33%|███▎      | 33/100 [00:37<01:18,  1.17s/it]\u001b[A\n",
      "Finding best initial lr:  34%|███▍      | 34/100 [00:38<01:17,  1.17s/it]\u001b[A\n",
      "Finding best initial lr:  35%|███▌      | 35/100 [00:39<01:15,  1.16s/it]\u001b[A\n",
      "Finding best initial lr:  36%|███▌      | 36/100 [00:41<01:14,  1.17s/it]\u001b[A\n",
      "Finding best initial lr:  37%|███▋      | 37/100 [00:42<01:13,  1.17s/it]\u001b[A\n",
      "Finding best initial lr:  38%|███▊      | 38/100 [00:43<01:12,  1.17s/it]\u001b[A\n",
      "Finding best initial lr:  39%|███▉      | 39/100 [00:44<01:11,  1.17s/it]\u001b[A\n",
      "Finding best initial lr:  40%|████      | 40/100 [00:45<01:10,  1.18s/it]\u001b[A\n",
      "Finding best initial lr:  41%|████      | 41/100 [00:46<01:09,  1.17s/it]\u001b[A\n",
      "Finding best initial lr:  42%|████▏     | 42/100 [00:48<01:07,  1.17s/it]\u001b[A\n",
      "Finding best initial lr:  43%|████▎     | 43/100 [00:49<01:06,  1.17s/it]\u001b[A\n",
      "Finding best initial lr:  44%|████▍     | 44/100 [00:50<01:05,  1.17s/it]\u001b[A\n",
      "Finding best initial lr:  45%|████▌     | 45/100 [00:51<01:04,  1.17s/it]\u001b[A\n",
      "Finding best initial lr:  46%|████▌     | 46/100 [00:52<01:03,  1.17s/it]\u001b[A\n",
      "Finding best initial lr:  47%|████▋     | 47/100 [00:53<01:02,  1.17s/it]\u001b[A\n",
      "Finding best initial lr:  48%|████▊     | 48/100 [00:55<01:00,  1.17s/it]\u001b[A\n",
      "Finding best initial lr:  49%|████▉     | 49/100 [00:56<00:59,  1.17s/it]\u001b[A\n",
      "Finding best initial lr:  50%|█████     | 50/100 [00:57<00:58,  1.18s/it]\u001b[A\n",
      "Finding best initial lr:  51%|█████     | 51/100 [00:58<00:57,  1.17s/it]\u001b[A\n",
      "Finding best initial lr:  52%|█████▏    | 52/100 [00:59<00:56,  1.17s/it]\u001b[A\n",
      "Finding best initial lr:  53%|█████▎    | 53/100 [01:00<00:55,  1.17s/it]\u001b[A\n",
      "Finding best initial lr:  54%|█████▍    | 54/100 [01:02<00:53,  1.17s/it]\u001b[A\n",
      "Finding best initial lr:  55%|█████▌    | 55/100 [01:03<00:52,  1.17s/it]\u001b[A\n",
      "Finding best initial lr:  56%|█████▌    | 56/100 [01:04<00:51,  1.17s/it]\u001b[A\n",
      "Finding best initial lr:  57%|█████▋    | 57/100 [01:05<00:50,  1.17s/it]\u001b[A\n",
      "Finding best initial lr:  58%|█████▊    | 58/100 [01:06<00:49,  1.17s/it]\u001b[A\n",
      "Finding best initial lr:  59%|█████▉    | 59/100 [01:07<00:47,  1.17s/it]\u001b[A\n",
      "Finding best initial lr:  60%|██████    | 60/100 [01:09<00:46,  1.17s/it]\u001b[A\n",
      "Finding best initial lr:  61%|██████    | 61/100 [01:10<00:45,  1.17s/it]\u001b[A\n",
      "Finding best initial lr:  62%|██████▏   | 62/100 [01:11<00:44,  1.17s/it]\u001b[A\n",
      "Finding best initial lr:  63%|██████▎   | 63/100 [01:12<00:43,  1.17s/it]\u001b[A\n",
      "Finding best initial lr:  64%|██████▍   | 64/100 [01:13<00:41,  1.17s/it]\u001b[A\n",
      "Finding best initial lr:  65%|██████▌   | 65/100 [01:14<00:40,  1.17s/it]\u001b[A\n",
      "Finding best initial lr:  66%|██████▌   | 66/100 [01:16<00:39,  1.17s/it]\u001b[A\n",
      "Finding best initial lr:  67%|██████▋   | 67/100 [01:17<00:38,  1.17s/it]\u001b[A\n",
      "Finding best initial lr:  68%|██████▊   | 68/100 [01:18<00:37,  1.17s/it]\u001b[A\n",
      "Finding best initial lr:  69%|██████▉   | 69/100 [01:19<00:36,  1.17s/it]\u001b[A\n",
      "Finding best initial lr:  70%|███████   | 70/100 [01:20<00:35,  1.17s/it]\u001b[A\n",
      "Finding best initial lr:  71%|███████   | 71/100 [01:21<00:33,  1.17s/it]\u001b[A\n",
      "Finding best initial lr:  72%|███████▏  | 72/100 [01:23<00:32,  1.17s/it]\u001b[A\n",
      "Finding best initial lr:  73%|███████▎  | 73/100 [01:24<00:31,  1.17s/it]\u001b[A\n",
      "Finding best initial lr:  74%|███████▍  | 74/100 [01:25<00:30,  1.17s/it]\u001b[A\n",
      "Finding best initial lr:  75%|███████▌  | 75/100 [01:26<00:29,  1.17s/it]\u001b[A\n",
      "Finding best initial lr:  76%|███████▌  | 76/100 [01:27<00:27,  1.17s/it]\u001b[A\n",
      "Finding best initial lr:  77%|███████▋  | 77/100 [01:28<00:26,  1.17s/it]\u001b[A\n",
      "Finding best initial lr:  78%|███████▊  | 78/100 [01:30<00:25,  1.17s/it]\u001b[A\n",
      "Finding best initial lr:  79%|███████▉  | 79/100 [01:31<00:24,  1.17s/it]\u001b[A\n",
      "Finding best initial lr:  80%|████████  | 80/100 [01:32<00:23,  1.18s/it]\u001b[A\n",
      "Finding best initial lr:  81%|████████  | 81/100 [01:33<00:22,  1.18s/it]\u001b[A\n",
      "Finding best initial lr:  82%|████████▏ | 82/100 [01:34<00:21,  1.18s/it]\u001b[A\n",
      "Finding best initial lr:  83%|████████▎ | 83/100 [01:36<00:19,  1.17s/it]\u001b[A\n",
      "Finding best initial lr:  84%|████████▍ | 84/100 [01:37<00:18,  1.17s/it]\u001b[A\n",
      "Finding best initial lr:  85%|████████▌ | 85/100 [01:38<00:17,  1.18s/it]\u001b[A\n",
      "Finding best initial lr:  86%|████████▌ | 86/100 [01:39<00:16,  1.17s/it]\u001b[A\n",
      "Finding best initial lr:  87%|████████▋ | 87/100 [01:40<00:15,  1.17s/it]\u001b[A\n",
      "Finding best initial lr:  88%|████████▊ | 88/100 [01:41<00:14,  1.17s/it]\u001b[A\n",
      "Finding best initial lr:  89%|████████▉ | 89/100 [01:43<00:12,  1.17s/it]\u001b[A\n",
      "Finding best initial lr:  90%|█████████ | 90/100 [01:44<00:11,  1.18s/it]\u001b[A\n",
      "Finding best initial lr:  91%|█████████ | 91/100 [01:45<00:10,  1.18s/it]\u001b[A\n",
      "Finding best initial lr:  92%|█████████▏| 92/100 [01:46<00:09,  1.18s/it]\u001b[A\n",
      "Finding best initial lr:  93%|█████████▎| 93/100 [01:47<00:08,  1.18s/it]\u001b[A\n",
      "Finding best initial lr:  94%|█████████▍| 94/100 [01:48<00:07,  1.17s/it]\u001b[A\n",
      "Finding best initial lr:  95%|█████████▌| 95/100 [01:50<00:05,  1.17s/it]\u001b[A\n",
      "Finding best initial lr:  96%|█████████▌| 96/100 [01:51<00:04,  1.17s/it]\u001b[A\n",
      "Finding best initial lr:  97%|█████████▋| 97/100 [01:52<00:03,  1.17s/it]\u001b[A\n",
      "Finding best initial lr:  98%|█████████▊| 98/100 [01:53<00:02,  1.17s/it]\u001b[A\n",
      "Finding best initial lr:  99%|█████████▉| 99/100 [01:54<00:01,  1.17s/it]\u001b[A\n",
      "Finding best initial lr: 100%|██████████| 100/100 [01:56<00:00,  1.18s/it]\u001b[ARestored states from the checkpoint file at /opt/favordata/AI/Felix/kaggle-cassava/trained-models/tf_efficientnet_b4_ns_sgd_onecycle_smoothing=0.05_weighted_bitempered_t1=0.8_t2=1/lr_find_temp_model.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Learning rate set to 0.15848931924611143\n",
      "\n",
      "  | Name           | Type           | Params\n",
      "--------------------------------------------------\n",
      "0 | valid_accuracy | Accuracy       | 0     \n",
      "1 | test_accuracy  | Accuracy       | 0     \n",
      "2 | criterion      | BiTemperedLoss | 0     \n",
      "3 | model          | EfficientNet   | 17.6 M\n",
      "--------------------------------------------------\n",
      "17.4 M    Trainable params\n",
      "125 K     Non-trainable params\n",
      "17.6 M    Total params\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2:   3%|▎         | 33/967 [20:12<-1:08:27, -0.30it/s, loss=0.793, v_num=0, val_loss=nan, val_acc=0.852, train_loss=0.946]    "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Finding best initial lr: 100%|██████████| 100/100 [06:11<00:00,  3.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1:  88%|████████▊ | 848/967 [04:11<01:06,  1.78it/s, loss=0.434, v_num=0, val_loss=0.957, val_acc=0.258, train_loss=0.302]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1:  94%|█████████▍| 910/967 [04:29<00:30,  1.89it/s, loss=0.405, v_num=0, val_loss=0.957, val_acc=0.258, train_loss=0.219]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 1:  94%|█████████▍| 912/967 [04:31<00:29,  1.89it/s, loss=0.405, v_num=0, val_loss=0.957, val_acc=0.258, train_loss=0.219]\n",
      "Validating:   4%|▎         | 2/57 [00:02<00:57,  1.05s/it]\u001b[A\n",
      "Epoch 1:  95%|█████████▍| 914/967 [04:32<00:28,  1.89it/s, loss=0.405, v_num=0, val_loss=0.957, val_acc=0.258, train_loss=0.219]\n",
      "Validating:   7%|▋         | 4/57 [00:02<00:28,  1.88it/s]\u001b[A\n",
      "Epoch 1:  95%|█████████▍| 916/967 [04:33<00:26,  1.89it/s, loss=0.405, v_num=0, val_loss=0.957, val_acc=0.258, train_loss=0.219]\n",
      "Validating:  11%|█         | 6/57 [00:03<00:19,  2.55it/s]\u001b[A\n",
      "Epoch 1:  95%|█████████▍| 918/967 [04:33<00:25,  1.90it/s, loss=0.405, v_num=0, val_loss=0.957, val_acc=0.258, train_loss=0.219]\n",
      "Validating:  14%|█▍        | 8/57 [00:04<00:16,  3.00it/s]\u001b[A\n",
      "Epoch 1:  95%|█████████▌| 920/967 [04:34<00:24,  1.90it/s, loss=0.405, v_num=0, val_loss=0.957, val_acc=0.258, train_loss=0.219]\n",
      "Validating:  18%|█▊        | 10/57 [00:04<00:14,  3.29it/s]\u001b[A\n",
      "Epoch 1:  95%|█████████▌| 922/967 [04:34<00:23,  1.90it/s, loss=0.405, v_num=0, val_loss=0.957, val_acc=0.258, train_loss=0.219]\n",
      "Validating:  21%|██        | 12/57 [00:05<00:13,  3.39it/s]\u001b[A\n",
      "Epoch 1:  96%|█████████▌| 924/967 [04:35<00:22,  1.91it/s, loss=0.405, v_num=0, val_loss=0.957, val_acc=0.258, train_loss=0.219]\n",
      "Validating:  25%|██▍       | 14/57 [00:05<00:12,  3.44it/s]\u001b[A\n",
      "Epoch 1:  96%|█████████▌| 926/967 [04:35<00:21,  1.91it/s, loss=0.405, v_num=0, val_loss=0.957, val_acc=0.258, train_loss=0.219]\n",
      "Validating:  28%|██▊       | 16/57 [00:06<00:11,  3.49it/s]\u001b[A\n",
      "Epoch 1:  96%|█████████▌| 928/967 [04:36<00:20,  1.91it/s, loss=0.405, v_num=0, val_loss=0.957, val_acc=0.258, train_loss=0.219]\n",
      "Validating:  32%|███▏      | 18/57 [00:06<00:11,  3.54it/s]\u001b[A\n",
      "Epoch 1:  96%|█████████▌| 930/967 [04:37<00:19,  1.92it/s, loss=0.405, v_num=0, val_loss=0.957, val_acc=0.258, train_loss=0.219]\n",
      "Validating:  35%|███▌      | 20/57 [00:07<00:10,  3.57it/s]\u001b[A\n",
      "Epoch 1:  96%|█████████▋| 932/967 [04:37<00:18,  1.92it/s, loss=0.405, v_num=0, val_loss=0.957, val_acc=0.258, train_loss=0.219]\n",
      "Validating:  39%|███▊      | 22/57 [00:08<00:10,  3.27it/s]\u001b[A\n",
      "Epoch 1:  97%|█████████▋| 934/967 [04:38<00:17,  1.92it/s, loss=0.405, v_num=0, val_loss=0.957, val_acc=0.258, train_loss=0.219]\n",
      "Validating:  42%|████▏     | 24/57 [00:08<00:09,  3.38it/s]\u001b[A\n",
      "Epoch 1:  97%|█████████▋| 936/967 [04:38<00:16,  1.93it/s, loss=0.405, v_num=0, val_loss=0.957, val_acc=0.258, train_loss=0.219]\n",
      "Validating:  46%|████▌     | 26/57 [00:09<00:08,  3.50it/s]\u001b[A\n",
      "Epoch 1:  97%|█████████▋| 938/967 [04:39<00:15,  1.93it/s, loss=0.405, v_num=0, val_loss=0.957, val_acc=0.258, train_loss=0.219]\n",
      "Validating:  49%|████▉     | 28/57 [00:09<00:08,  3.56it/s]\u001b[A\n",
      "Epoch 1:  97%|█████████▋| 940/967 [04:39<00:13,  1.93it/s, loss=0.405, v_num=0, val_loss=0.957, val_acc=0.258, train_loss=0.219]\n",
      "Validating:  53%|█████▎    | 30/57 [00:10<00:07,  3.55it/s]\u001b[A\n",
      "Epoch 1:  97%|█████████▋| 942/967 [04:40<00:12,  1.94it/s, loss=0.405, v_num=0, val_loss=0.957, val_acc=0.258, train_loss=0.219]\n",
      "Validating:  56%|█████▌    | 32/57 [00:11<00:07,  3.37it/s]\u001b[A\n",
      "Epoch 1:  98%|█████████▊| 944/967 [04:41<00:11,  1.94it/s, loss=0.405, v_num=0, val_loss=0.957, val_acc=0.258, train_loss=0.219]\n",
      "Validating:  60%|█████▉    | 34/57 [00:11<00:06,  3.50it/s]\u001b[A\n",
      "Epoch 1:  98%|█████████▊| 946/967 [04:41<00:10,  1.94it/s, loss=0.405, v_num=0, val_loss=0.957, val_acc=0.258, train_loss=0.219]\n",
      "Validating:  63%|██████▎   | 36/57 [00:12<00:05,  3.54it/s]\u001b[A\n",
      "Epoch 1:  98%|█████████▊| 948/967 [04:42<00:09,  1.94it/s, loss=0.405, v_num=0, val_loss=0.957, val_acc=0.258, train_loss=0.219]\n",
      "Validating:  67%|██████▋   | 38/57 [00:12<00:05,  3.49it/s]\u001b[A\n",
      "Epoch 1:  98%|█████████▊| 950/967 [04:42<00:08,  1.95it/s, loss=0.405, v_num=0, val_loss=0.957, val_acc=0.258, train_loss=0.219]\n",
      "Validating:  70%|███████   | 40/57 [00:13<00:04,  3.48it/s]\u001b[A\n",
      "Epoch 1:  98%|█████████▊| 952/967 [04:43<00:07,  1.95it/s, loss=0.405, v_num=0, val_loss=0.957, val_acc=0.258, train_loss=0.219]\n",
      "Validating:  74%|███████▎  | 42/57 [00:13<00:04,  3.49it/s]\u001b[A\n",
      "Epoch 1:  99%|█████████▊| 954/967 [04:43<00:06,  1.95it/s, loss=0.405, v_num=0, val_loss=0.957, val_acc=0.258, train_loss=0.219]\n",
      "Validating:  77%|███████▋  | 44/57 [00:14<00:03,  3.54it/s]\u001b[A\n",
      "Epoch 1:  99%|█████████▉| 956/967 [04:44<00:05,  1.96it/s, loss=0.405, v_num=0, val_loss=0.957, val_acc=0.258, train_loss=0.219]\n",
      "Validating:  81%|████████  | 46/57 [00:14<00:03,  3.57it/s]\u001b[A\n",
      "Epoch 1:  99%|█████████▉| 958/967 [04:45<00:04,  1.96it/s, loss=0.405, v_num=0, val_loss=0.957, val_acc=0.258, train_loss=0.219]\n",
      "Validating:  84%|████████▍ | 48/57 [00:15<00:02,  3.57it/s]\u001b[A\n",
      "Epoch 1:  99%|█████████▉| 960/967 [04:45<00:03,  1.96it/s, loss=0.405, v_num=0, val_loss=0.957, val_acc=0.258, train_loss=0.219]\n",
      "Validating:  88%|████████▊ | 50/57 [00:16<00:01,  3.52it/s]\u001b[A\n",
      "Epoch 1:  99%|█████████▉| 962/967 [04:46<00:02,  1.97it/s, loss=0.405, v_num=0, val_loss=0.957, val_acc=0.258, train_loss=0.219]\n",
      "Validating:  91%|█████████ | 52/57 [00:16<00:01,  3.61it/s]\u001b[A\n",
      "Epoch 1: 100%|█████████▉| 964/967 [04:46<00:01,  1.97it/s, loss=0.405, v_num=0, val_loss=0.957, val_acc=0.258, train_loss=0.219]\n",
      "Validating:  95%|█████████▍| 54/57 [00:17<00:00,  3.65it/s]\u001b[A\n",
      "Epoch 1: 100%|█████████▉| 966/967 [04:47<00:00,  1.97it/s, loss=0.405, v_num=0, val_loss=0.957, val_acc=0.258, train_loss=0.219]\n",
      "Validating:  98%|█████████▊| 56/57 [00:17<00:00,  3.67it/s]\u001b[A\n",
      "Validating: 100%|██████████| 57/57 [00:17<00:00,  3.85it/s]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, global step 228: val_loss reached 0.26035 (best 0.26035), saving model to \"/opt/favordata/AI/Felix/kaggle-cassava/trained-models/tf_efficientnet_b4_ns_sgd_onecycle_smoothing=0.05_weighted_bitempered_t1=0.8_t2=1/tf_efficientnet_b4_ns_bitempered_smooth=0.05_val_loss=0.260_val_acc=0.851_fold0.ckpt\" as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 967/967 [04:48<00:00,  1.97it/s, loss=0.405, v_num=0, val_loss=0.26, val_acc=0.851, train_loss=0.486] \n",
      "Epoch 2:  94%|█████████▍| 910/967 [04:30<00:30,  1.89it/s, loss=0.337, v_num=0, val_loss=0.26, val_acc=0.851, train_loss=0.362]    \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 2:  94%|█████████▍| 912/967 [04:31<00:29,  1.89it/s, loss=0.337, v_num=0, val_loss=0.26, val_acc=0.851, train_loss=0.362]\n",
      "Validating:   4%|▎         | 2/57 [00:01<00:46,  1.17it/s]\u001b[A\n",
      "Epoch 2:  95%|█████████▍| 914/967 [04:32<00:28,  1.89it/s, loss=0.337, v_num=0, val_loss=0.26, val_acc=0.851, train_loss=0.362]\n",
      "Validating:   7%|▋         | 4/57 [00:02<00:24,  2.15it/s]\u001b[A\n",
      "Epoch 2:  95%|█████████▍| 916/967 [04:32<00:26,  1.89it/s, loss=0.337, v_num=0, val_loss=0.26, val_acc=0.851, train_loss=0.362]\n",
      "Validating:  11%|█         | 6/57 [00:03<00:19,  2.65it/s]\u001b[A\n",
      "Epoch 2:  95%|█████████▍| 918/967 [04:33<00:25,  1.90it/s, loss=0.337, v_num=0, val_loss=0.26, val_acc=0.851, train_loss=0.362]\n",
      "Validating:  14%|█▍        | 8/57 [00:03<00:15,  3.10it/s]\u001b[A\n",
      "Epoch 2:  95%|█████████▌| 920/967 [04:34<00:24,  1.90it/s, loss=0.337, v_num=0, val_loss=0.26, val_acc=0.851, train_loss=0.362]\n",
      "Validating:  18%|█▊        | 10/57 [00:04<00:14,  3.22it/s]\u001b[A\n",
      "Epoch 2:  95%|█████████▌| 922/967 [04:34<00:23,  1.90it/s, loss=0.337, v_num=0, val_loss=0.26, val_acc=0.851, train_loss=0.362]\n",
      "Validating:  21%|██        | 12/57 [00:04<00:13,  3.37it/s]\u001b[A\n",
      "Epoch 2:  96%|█████████▌| 924/967 [04:35<00:22,  1.91it/s, loss=0.337, v_num=0, val_loss=0.26, val_acc=0.851, train_loss=0.362]\n",
      "Validating:  25%|██▍       | 14/57 [00:05<00:13,  3.26it/s]\u001b[A\n",
      "Epoch 2:  96%|█████████▌| 926/967 [04:35<00:21,  1.91it/s, loss=0.337, v_num=0, val_loss=0.26, val_acc=0.851, train_loss=0.362]\n",
      "Validating:  28%|██▊       | 16/57 [00:06<00:12,  3.39it/s]\u001b[A\n",
      "Epoch 2:  96%|█████████▌| 928/967 [04:36<00:20,  1.91it/s, loss=0.337, v_num=0, val_loss=0.26, val_acc=0.851, train_loss=0.362]\n",
      "Validating:  32%|███▏      | 18/57 [00:06<00:11,  3.42it/s]\u001b[A\n",
      "Epoch 2:  96%|█████████▌| 930/967 [04:37<00:19,  1.92it/s, loss=0.337, v_num=0, val_loss=0.26, val_acc=0.851, train_loss=0.362]\n",
      "Validating:  35%|███▌      | 20/57 [00:07<00:10,  3.51it/s]\u001b[A\n",
      "Epoch 2:  96%|█████████▋| 932/967 [04:37<00:18,  1.92it/s, loss=0.337, v_num=0, val_loss=0.26, val_acc=0.851, train_loss=0.362]\n",
      "Validating:  39%|███▊      | 22/57 [00:07<00:09,  3.52it/s]\u001b[A\n",
      "Epoch 2:  97%|█████████▋| 934/967 [04:38<00:17,  1.92it/s, loss=0.337, v_num=0, val_loss=0.26, val_acc=0.851, train_loss=0.362]\n",
      "Validating:  42%|████▏     | 24/57 [00:08<00:09,  3.49it/s]\u001b[A\n",
      "Epoch 2:  97%|█████████▋| 936/967 [04:38<00:16,  1.93it/s, loss=0.337, v_num=0, val_loss=0.26, val_acc=0.851, train_loss=0.362]\n",
      "Validating:  46%|████▌     | 26/57 [00:08<00:08,  3.54it/s]\u001b[A\n",
      "Epoch 2:  97%|█████████▋| 938/967 [04:39<00:15,  1.93it/s, loss=0.337, v_num=0, val_loss=0.26, val_acc=0.851, train_loss=0.362]\n",
      "Validating:  49%|████▉     | 28/57 [00:09<00:08,  3.42it/s]\u001b[A\n",
      "Epoch 2:  97%|█████████▋| 940/967 [04:39<00:13,  1.93it/s, loss=0.337, v_num=0, val_loss=0.26, val_acc=0.851, train_loss=0.362]\n",
      "Validating:  53%|█████▎    | 30/57 [00:10<00:07,  3.49it/s]\u001b[A\n",
      "Epoch 2:  97%|█████████▋| 942/967 [04:40<00:12,  1.94it/s, loss=0.337, v_num=0, val_loss=0.26, val_acc=0.851, train_loss=0.362]\n",
      "Validating:  56%|█████▌    | 32/57 [00:10<00:07,  3.55it/s]\u001b[A\n",
      "Epoch 2:  98%|█████████▊| 944/967 [04:41<00:11,  1.94it/s, loss=0.337, v_num=0, val_loss=0.26, val_acc=0.851, train_loss=0.362]\n",
      "Validating:  60%|█████▉    | 34/57 [00:11<00:06,  3.57it/s]\u001b[A\n",
      "Epoch 2:  98%|█████████▊| 946/967 [04:41<00:10,  1.94it/s, loss=0.337, v_num=0, val_loss=0.26, val_acc=0.851, train_loss=0.362]\n",
      "Validating:  63%|██████▎   | 36/57 [00:11<00:05,  3.58it/s]\u001b[A\n",
      "Epoch 2:  98%|█████████▊| 948/967 [04:42<00:09,  1.95it/s, loss=0.337, v_num=0, val_loss=0.26, val_acc=0.851, train_loss=0.362]\n",
      "Validating:  67%|██████▋   | 38/57 [00:12<00:05,  3.59it/s]\u001b[A\n",
      "Epoch 2:  98%|█████████▊| 950/967 [04:42<00:08,  1.95it/s, loss=0.337, v_num=0, val_loss=0.26, val_acc=0.851, train_loss=0.362]\n",
      "Validating:  70%|███████   | 40/57 [00:12<00:04,  3.59it/s]\u001b[A\n",
      "Epoch 2:  98%|█████████▊| 952/967 [04:43<00:07,  1.95it/s, loss=0.337, v_num=0, val_loss=0.26, val_acc=0.851, train_loss=0.362]\n",
      "Validating:  74%|███████▎  | 42/57 [00:13<00:04,  3.57it/s]\u001b[A\n",
      "Epoch 2:  99%|█████████▊| 954/967 [04:43<00:06,  1.96it/s, loss=0.337, v_num=0, val_loss=0.26, val_acc=0.851, train_loss=0.362]\n",
      "Validating:  77%|███████▋  | 44/57 [00:13<00:03,  3.54it/s]\u001b[A\n",
      "Epoch 2:  99%|█████████▉| 956/967 [04:44<00:05,  1.96it/s, loss=0.337, v_num=0, val_loss=0.26, val_acc=0.851, train_loss=0.362]\n",
      "Validating:  81%|████████  | 46/57 [00:14<00:03,  3.56it/s]\u001b[A\n",
      "Epoch 2:  99%|█████████▉| 958/967 [04:44<00:04,  1.96it/s, loss=0.337, v_num=0, val_loss=0.26, val_acc=0.851, train_loss=0.362]\n",
      "Validating:  84%|████████▍ | 48/57 [00:15<00:02,  3.55it/s]\u001b[A\n",
      "Epoch 2:  99%|█████████▉| 960/967 [04:45<00:03,  1.96it/s, loss=0.337, v_num=0, val_loss=0.26, val_acc=0.851, train_loss=0.362]\n",
      "Validating:  88%|████████▊ | 50/57 [00:15<00:01,  3.55it/s]\u001b[A\n",
      "Epoch 2:  99%|█████████▉| 962/967 [04:46<00:02,  1.97it/s, loss=0.337, v_num=0, val_loss=0.26, val_acc=0.851, train_loss=0.362]\n",
      "Validating:  91%|█████████ | 52/57 [00:16<00:01,  3.62it/s]\u001b[A\n",
      "Epoch 2: 100%|█████████▉| 964/967 [04:46<00:01,  1.97it/s, loss=0.337, v_num=0, val_loss=0.26, val_acc=0.851, train_loss=0.362]\n",
      "Validating:  95%|█████████▍| 54/57 [00:16<00:00,  3.66it/s]\u001b[A\n",
      "Epoch 2: 100%|█████████▉| 966/967 [04:47<00:00,  1.97it/s, loss=0.337, v_num=0, val_loss=0.26, val_acc=0.851, train_loss=0.362]\n",
      "Validating:  98%|█████████▊| 56/57 [00:17<00:00,  3.68it/s]\u001b[A\n",
      "Validating: 100%|██████████| 57/57 [00:17<00:00,  3.86it/s]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2, global step 456: val_loss reached 0.22706 (best 0.22706), saving model to \"/opt/favordata/AI/Felix/kaggle-cassava/trained-models/tf_efficientnet_b4_ns_sgd_onecycle_smoothing=0.05_weighted_bitempered_t1=0.8_t2=1/tf_efficientnet_b4_ns_bitempered_smooth=0.05_val_loss=0.227_val_acc=0.872_fold0.ckpt\" as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 967/967 [04:48<00:00,  1.97it/s, loss=0.337, v_num=0, val_loss=0.227, val_acc=0.872, train_loss=0.379]\n",
      "Epoch 3:  94%|█████████▍| 910/967 [04:29<00:30,  1.89it/s, loss=0.296, v_num=0, val_loss=0.227, val_acc=0.872, train_loss=0.429]     \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 3:  94%|█████████▍| 912/967 [04:31<00:29,  1.89it/s, loss=0.296, v_num=0, val_loss=0.227, val_acc=0.872, train_loss=0.429]\n",
      "Validating:   4%|▎         | 2/57 [00:01<00:44,  1.25it/s]\u001b[A\n",
      "Epoch 3:  95%|█████████▍| 914/967 [04:31<00:27,  1.89it/s, loss=0.296, v_num=0, val_loss=0.227, val_acc=0.872, train_loss=0.429]\n",
      "Validating:   7%|▋         | 4/57 [00:02<00:23,  2.23it/s]\u001b[A\n",
      "Epoch 3:  95%|█████████▍| 916/967 [04:32<00:26,  1.90it/s, loss=0.296, v_num=0, val_loss=0.227, val_acc=0.872, train_loss=0.429]\n",
      "Validating:  11%|█         | 6/57 [00:02<00:18,  2.83it/s]\u001b[A\n",
      "Epoch 3:  95%|█████████▍| 918/967 [04:33<00:25,  1.90it/s, loss=0.296, v_num=0, val_loss=0.227, val_acc=0.872, train_loss=0.429]\n",
      "Validating:  14%|█▍        | 8/57 [00:03<00:15,  3.11it/s]\u001b[A\n",
      "Epoch 3:  95%|█████████▌| 920/967 [04:33<00:24,  1.90it/s, loss=0.296, v_num=0, val_loss=0.227, val_acc=0.872, train_loss=0.429]\n",
      "Validating:  18%|█▊        | 10/57 [00:04<00:14,  3.35it/s]\u001b[A\n",
      "Epoch 3:  95%|█████████▌| 922/967 [04:34<00:23,  1.91it/s, loss=0.296, v_num=0, val_loss=0.227, val_acc=0.872, train_loss=0.429]\n",
      "Validating:  21%|██        | 12/57 [00:04<00:13,  3.37it/s]\u001b[A\n",
      "Epoch 3:  96%|█████████▌| 924/967 [04:34<00:22,  1.91it/s, loss=0.296, v_num=0, val_loss=0.227, val_acc=0.872, train_loss=0.429]\n",
      "Validating:  25%|██▍       | 14/57 [00:05<00:12,  3.48it/s]\u001b[A\n",
      "Epoch 3:  96%|█████████▌| 926/967 [04:35<00:21,  1.91it/s, loss=0.296, v_num=0, val_loss=0.227, val_acc=0.872, train_loss=0.429]\n",
      "Validating:  28%|██▊       | 16/57 [00:05<00:12,  3.38it/s]\u001b[A\n",
      "Epoch 3:  96%|█████████▌| 928/967 [04:35<00:20,  1.92it/s, loss=0.296, v_num=0, val_loss=0.227, val_acc=0.872, train_loss=0.429]\n",
      "Validating:  32%|███▏      | 18/57 [00:06<00:11,  3.44it/s]\u001b[A\n",
      "Epoch 3:  96%|█████████▌| 930/967 [04:36<00:19,  1.92it/s, loss=0.296, v_num=0, val_loss=0.227, val_acc=0.872, train_loss=0.429]\n",
      "Validating:  35%|███▌      | 20/57 [00:07<00:10,  3.39it/s]\u001b[A\n",
      "Epoch 3:  96%|█████████▋| 932/967 [04:37<00:18,  1.92it/s, loss=0.296, v_num=0, val_loss=0.227, val_acc=0.872, train_loss=0.429]\n",
      "Validating:  39%|███▊      | 22/57 [00:07<00:10,  3.48it/s]\u001b[A\n",
      "Epoch 3:  97%|█████████▋| 934/967 [04:37<00:17,  1.93it/s, loss=0.296, v_num=0, val_loss=0.227, val_acc=0.872, train_loss=0.429]\n",
      "Validating:  42%|████▏     | 24/57 [00:08<00:09,  3.46it/s]\u001b[A\n",
      "Epoch 3:  97%|█████████▋| 936/967 [04:38<00:16,  1.93it/s, loss=0.296, v_num=0, val_loss=0.227, val_acc=0.872, train_loss=0.429]\n",
      "Validating:  46%|████▌     | 26/57 [00:08<00:08,  3.50it/s]\u001b[A\n",
      "Epoch 3:  97%|█████████▋| 938/967 [04:38<00:15,  1.93it/s, loss=0.296, v_num=0, val_loss=0.227, val_acc=0.872, train_loss=0.429]\n",
      "Validating:  49%|████▉     | 28/57 [00:09<00:08,  3.43it/s]\u001b[A\n",
      "Epoch 3:  97%|█████████▋| 940/967 [04:39<00:13,  1.94it/s, loss=0.296, v_num=0, val_loss=0.227, val_acc=0.872, train_loss=0.429]\n",
      "Validating:  53%|█████▎    | 30/57 [00:09<00:07,  3.49it/s]\u001b[A\n",
      "Epoch 3:  97%|█████████▋| 942/967 [04:39<00:12,  1.94it/s, loss=0.296, v_num=0, val_loss=0.227, val_acc=0.872, train_loss=0.429]\n",
      "Validating:  56%|█████▌    | 32/57 [00:10<00:07,  3.52it/s]\u001b[A\n",
      "Epoch 3:  98%|█████████▊| 944/967 [04:40<00:11,  1.94it/s, loss=0.296, v_num=0, val_loss=0.227, val_acc=0.872, train_loss=0.429]\n",
      "Validating:  60%|█████▉    | 34/57 [00:11<00:06,  3.52it/s]\u001b[A\n",
      "Epoch 3:  98%|█████████▊| 946/967 [04:41<00:10,  1.95it/s, loss=0.296, v_num=0, val_loss=0.227, val_acc=0.872, train_loss=0.429]\n",
      "Validating:  63%|██████▎   | 36/57 [00:11<00:05,  3.52it/s]\u001b[A\n",
      "Epoch 3:  98%|█████████▊| 948/967 [04:41<00:09,  1.95it/s, loss=0.296, v_num=0, val_loss=0.227, val_acc=0.872, train_loss=0.429]\n",
      "Validating:  67%|██████▋   | 38/57 [00:12<00:05,  3.45it/s]\u001b[A\n",
      "Epoch 3:  98%|█████████▊| 950/967 [04:42<00:08,  1.95it/s, loss=0.296, v_num=0, val_loss=0.227, val_acc=0.872, train_loss=0.429]\n",
      "Validating:  70%|███████   | 40/57 [00:12<00:04,  3.54it/s]\u001b[A\n",
      "Epoch 3:  98%|█████████▊| 952/967 [04:42<00:07,  1.96it/s, loss=0.296, v_num=0, val_loss=0.227, val_acc=0.872, train_loss=0.429]\n",
      "Validating:  74%|███████▎  | 42/57 [00:13<00:04,  3.45it/s]\u001b[A\n",
      "Epoch 3:  99%|█████████▊| 954/967 [04:43<00:06,  1.96it/s, loss=0.296, v_num=0, val_loss=0.227, val_acc=0.872, train_loss=0.429]\n",
      "Validating:  77%|███████▋  | 44/57 [00:13<00:03,  3.48it/s]\u001b[A\n",
      "Epoch 3:  99%|█████████▉| 956/967 [04:43<00:05,  1.96it/s, loss=0.296, v_num=0, val_loss=0.227, val_acc=0.872, train_loss=0.429]\n",
      "Validating:  81%|████████  | 46/57 [00:14<00:03,  3.54it/s]\u001b[A\n",
      "Epoch 3:  99%|█████████▉| 958/967 [04:44<00:04,  1.96it/s, loss=0.296, v_num=0, val_loss=0.227, val_acc=0.872, train_loss=0.429]\n",
      "Validating:  84%|████████▍ | 48/57 [00:15<00:02,  3.59it/s]\u001b[A\n",
      "Epoch 3:  99%|█████████▉| 960/967 [04:45<00:03,  1.97it/s, loss=0.296, v_num=0, val_loss=0.227, val_acc=0.872, train_loss=0.429]\n",
      "Validating:  88%|████████▊ | 50/57 [00:15<00:01,  3.58it/s]\u001b[A\n",
      "Epoch 3:  99%|█████████▉| 962/967 [04:45<00:02,  1.97it/s, loss=0.296, v_num=0, val_loss=0.227, val_acc=0.872, train_loss=0.429]\n",
      "Validating:  91%|█████████ | 52/57 [00:16<00:01,  3.63it/s]\u001b[A\n",
      "Epoch 3: 100%|█████████▉| 964/967 [04:46<00:01,  1.97it/s, loss=0.296, v_num=0, val_loss=0.227, val_acc=0.872, train_loss=0.429]\n",
      "Validating:  95%|█████████▍| 54/57 [00:16<00:00,  3.66it/s]\u001b[A\n",
      "Epoch 3: 100%|█████████▉| 966/967 [04:46<00:00,  1.98it/s, loss=0.296, v_num=0, val_loss=0.227, val_acc=0.872, train_loss=0.429]\n",
      "Validating:  98%|█████████▊| 56/57 [00:17<00:00,  3.68it/s]\u001b[A\n",
      "Validating: 100%|██████████| 57/57 [00:17<00:00,  3.86it/s]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3, global step 684: val_loss reached 0.21888 (best 0.21888), saving model to \"/opt/favordata/AI/Felix/kaggle-cassava/trained-models/tf_efficientnet_b4_ns_sgd_onecycle_smoothing=0.05_weighted_bitempered_t1=0.8_t2=1/tf_efficientnet_b4_ns_bitempered_smooth=0.05_val_loss=0.219_val_acc=0.875_fold0.ckpt\" as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 967/967 [04:47<00:00,  1.98it/s, loss=0.296, v_num=0, val_loss=0.219, val_acc=0.875, train_loss=0.193]\n",
      "Epoch 4:  94%|█████████▍| 910/967 [04:30<00:30,  1.89it/s, loss=0.31, v_num=0, val_loss=0.219, val_acc=0.875, train_loss=0.194]     \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 4:  94%|█████████▍| 912/967 [04:32<00:29,  1.89it/s, loss=0.31, v_num=0, val_loss=0.219, val_acc=0.875, train_loss=0.194]\n",
      "Validating:   4%|▎         | 2/57 [00:02<00:53,  1.04it/s]\u001b[A\n",
      "Epoch 4:  95%|█████████▍| 914/967 [04:32<00:28,  1.89it/s, loss=0.31, v_num=0, val_loss=0.219, val_acc=0.875, train_loss=0.194]\n",
      "Validating:   7%|▋         | 4/57 [00:02<00:27,  1.91it/s]\u001b[A\n",
      "Epoch 4:  95%|█████████▍| 916/967 [04:33<00:26,  1.89it/s, loss=0.31, v_num=0, val_loss=0.219, val_acc=0.875, train_loss=0.194]\n",
      "Validating:  11%|█         | 6/57 [00:03<00:19,  2.60it/s]\u001b[A\n",
      "Epoch 4:  95%|█████████▍| 918/967 [04:33<00:25,  1.90it/s, loss=0.31, v_num=0, val_loss=0.219, val_acc=0.875, train_loss=0.194]\n",
      "Validating:  14%|█▍        | 8/57 [00:03<00:16,  3.01it/s]\u001b[A\n",
      "Epoch 4:  95%|█████████▌| 920/967 [04:34<00:24,  1.90it/s, loss=0.31, v_num=0, val_loss=0.219, val_acc=0.875, train_loss=0.194]\n",
      "Validating:  18%|█▊        | 10/57 [00:04<00:14,  3.13it/s]\u001b[A\n",
      "Epoch 4:  95%|█████████▌| 922/967 [04:35<00:23,  1.90it/s, loss=0.31, v_num=0, val_loss=0.219, val_acc=0.875, train_loss=0.194]\n",
      "Validating:  21%|██        | 12/57 [00:05<00:13,  3.28it/s]\u001b[A\n",
      "Epoch 4:  96%|█████████▌| 924/967 [04:35<00:22,  1.90it/s, loss=0.31, v_num=0, val_loss=0.219, val_acc=0.875, train_loss=0.194]\n",
      "Validating:  25%|██▍       | 14/57 [00:05<00:13,  3.30it/s]\u001b[A\n",
      "Epoch 4:  96%|█████████▌| 926/967 [04:36<00:21,  1.91it/s, loss=0.31, v_num=0, val_loss=0.219, val_acc=0.875, train_loss=0.194]\n",
      "Validating:  28%|██▊       | 16/57 [00:06<00:12,  3.22it/s]\u001b[A\n",
      "Epoch 4:  96%|█████████▌| 928/967 [04:36<00:20,  1.91it/s, loss=0.31, v_num=0, val_loss=0.219, val_acc=0.875, train_loss=0.194]\n",
      "Validating:  32%|███▏      | 18/57 [00:06<00:11,  3.39it/s]\u001b[A\n",
      "Epoch 4:  96%|█████████▌| 930/967 [04:37<00:19,  1.91it/s, loss=0.31, v_num=0, val_loss=0.219, val_acc=0.875, train_loss=0.194]\n",
      "Validating:  35%|███▌      | 20/57 [00:07<00:10,  3.41it/s]\u001b[A\n",
      "Epoch 4:  96%|█████████▋| 932/967 [04:37<00:18,  1.92it/s, loss=0.31, v_num=0, val_loss=0.219, val_acc=0.875, train_loss=0.194]\n",
      "Validating:  39%|███▊      | 22/57 [00:08<00:10,  3.44it/s]\u001b[A\n",
      "Epoch 4:  97%|█████████▋| 934/967 [04:38<00:17,  1.92it/s, loss=0.31, v_num=0, val_loss=0.219, val_acc=0.875, train_loss=0.194]\n",
      "Validating:  42%|████▏     | 24/57 [00:08<00:09,  3.53it/s]\u001b[A\n",
      "Epoch 4:  97%|█████████▋| 936/967 [04:39<00:16,  1.92it/s, loss=0.31, v_num=0, val_loss=0.219, val_acc=0.875, train_loss=0.194]\n",
      "Validating:  46%|████▌     | 26/57 [00:09<00:08,  3.55it/s]\u001b[A\n",
      "Epoch 4:  97%|█████████▋| 938/967 [04:39<00:15,  1.93it/s, loss=0.31, v_num=0, val_loss=0.219, val_acc=0.875, train_loss=0.194]\n",
      "Validating:  49%|████▉     | 28/57 [00:09<00:08,  3.57it/s]\u001b[A\n",
      "Epoch 4:  97%|█████████▋| 940/967 [04:40<00:13,  1.93it/s, loss=0.31, v_num=0, val_loss=0.219, val_acc=0.875, train_loss=0.194]\n",
      "Validating:  53%|█████▎    | 30/57 [00:10<00:07,  3.59it/s]\u001b[A\n",
      "Epoch 4:  97%|█████████▋| 942/967 [04:40<00:12,  1.93it/s, loss=0.31, v_num=0, val_loss=0.219, val_acc=0.875, train_loss=0.194]\n",
      "Validating:  56%|█████▌    | 32/57 [00:10<00:07,  3.55it/s]\u001b[A\n",
      "Epoch 4:  98%|█████████▊| 944/967 [04:41<00:11,  1.94it/s, loss=0.31, v_num=0, val_loss=0.219, val_acc=0.875, train_loss=0.194]\n",
      "Validating:  60%|█████▉    | 34/57 [00:11<00:06,  3.56it/s]\u001b[A\n",
      "Epoch 4:  98%|█████████▊| 946/967 [04:41<00:10,  1.94it/s, loss=0.31, v_num=0, val_loss=0.219, val_acc=0.875, train_loss=0.194]\n",
      "Validating:  63%|██████▎   | 36/57 [00:12<00:05,  3.51it/s]\u001b[A\n",
      "Epoch 4:  98%|█████████▊| 948/967 [04:42<00:09,  1.94it/s, loss=0.31, v_num=0, val_loss=0.219, val_acc=0.875, train_loss=0.194]\n",
      "Validating:  67%|██████▋   | 38/57 [00:12<00:05,  3.46it/s]\u001b[A\n",
      "Epoch 4:  98%|█████████▊| 950/967 [04:43<00:08,  1.95it/s, loss=0.31, v_num=0, val_loss=0.219, val_acc=0.875, train_loss=0.194]\n",
      "Validating:  70%|███████   | 40/57 [00:13<00:04,  3.50it/s]\u001b[A\n",
      "Epoch 4:  98%|█████████▊| 952/967 [04:43<00:07,  1.95it/s, loss=0.31, v_num=0, val_loss=0.219, val_acc=0.875, train_loss=0.194]\n",
      "Validating:  74%|███████▎  | 42/57 [00:13<00:04,  3.50it/s]\u001b[A\n",
      "Epoch 4:  99%|█████████▊| 954/967 [04:44<00:06,  1.95it/s, loss=0.31, v_num=0, val_loss=0.219, val_acc=0.875, train_loss=0.194]\n",
      "Validating:  77%|███████▋  | 44/57 [00:14<00:03,  3.38it/s]\u001b[A\n",
      "Epoch 4:  99%|█████████▉| 956/967 [04:44<00:05,  1.96it/s, loss=0.31, v_num=0, val_loss=0.219, val_acc=0.875, train_loss=0.194]\n",
      "Validating:  81%|████████  | 46/57 [00:14<00:03,  3.50it/s]\u001b[A\n",
      "Epoch 4:  99%|█████████▉| 958/967 [04:45<00:04,  1.96it/s, loss=0.31, v_num=0, val_loss=0.219, val_acc=0.875, train_loss=0.194]\n",
      "Validating:  84%|████████▍ | 48/57 [00:15<00:02,  3.44it/s]\u001b[A\n",
      "Epoch 4:  99%|█████████▉| 960/967 [04:45<00:03,  1.96it/s, loss=0.31, v_num=0, val_loss=0.219, val_acc=0.875, train_loss=0.194]\n",
      "Validating:  88%|████████▊ | 50/57 [00:16<00:01,  3.56it/s]\u001b[A\n",
      "Epoch 4:  99%|█████████▉| 962/967 [04:46<00:02,  1.97it/s, loss=0.31, v_num=0, val_loss=0.219, val_acc=0.875, train_loss=0.194]\n",
      "Validating:  91%|█████████ | 52/57 [00:16<00:01,  3.62it/s]\u001b[A\n",
      "Epoch 4: 100%|█████████▉| 964/967 [04:47<00:01,  1.97it/s, loss=0.31, v_num=0, val_loss=0.219, val_acc=0.875, train_loss=0.194]\n",
      "Validating:  95%|█████████▍| 54/57 [00:17<00:00,  3.66it/s]\u001b[A\n",
      "Epoch 4: 100%|█████████▉| 966/967 [04:47<00:00,  1.97it/s, loss=0.31, v_num=0, val_loss=0.219, val_acc=0.875, train_loss=0.194]\n",
      "Validating:  98%|█████████▊| 56/57 [00:17<00:00,  3.67it/s]\u001b[A\n",
      "Validating: 100%|██████████| 57/57 [00:17<00:00,  3.85it/s]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4, global step 912: val_loss reached 0.21403 (best 0.21403), saving model to \"/opt/favordata/AI/Felix/kaggle-cassava/trained-models/tf_efficientnet_b4_ns_sgd_onecycle_smoothing=0.05_weighted_bitempered_t1=0.8_t2=1/tf_efficientnet_b4_ns_bitempered_smooth=0.05_val_loss=0.214_val_acc=0.882_fold0.ckpt\" as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 967/967 [04:48<00:00,  1.97it/s, loss=0.31, v_num=0, val_loss=0.214, val_acc=0.882, train_loss=0.154]\n",
      "Epoch 5:  94%|█████████▍| 910/967 [04:30<00:30,  1.89it/s, loss=0.285, v_num=0, val_loss=0.214, val_acc=0.882, train_loss=0.37]     \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 5:  94%|█████████▍| 912/967 [04:31<00:29,  1.89it/s, loss=0.285, v_num=0, val_loss=0.214, val_acc=0.882, train_loss=0.37]\n",
      "Validating:   4%|▎         | 2/57 [00:01<00:47,  1.15it/s]\u001b[A\n",
      "Epoch 5:  95%|█████████▍| 914/967 [04:32<00:28,  1.89it/s, loss=0.285, v_num=0, val_loss=0.214, val_acc=0.882, train_loss=0.37]\n",
      "Validating:   7%|▋         | 4/57 [00:02<00:25,  2.11it/s]\u001b[A\n",
      "Epoch 5:  95%|█████████▍| 916/967 [04:33<00:26,  1.89it/s, loss=0.285, v_num=0, val_loss=0.214, val_acc=0.882, train_loss=0.37]\n",
      "Validating:  11%|█         | 6/57 [00:03<00:19,  2.68it/s]\u001b[A\n",
      "Epoch 5:  95%|█████████▍| 918/967 [04:33<00:25,  1.90it/s, loss=0.285, v_num=0, val_loss=0.214, val_acc=0.882, train_loss=0.37]\n",
      "Validating:  14%|█▍        | 8/57 [00:03<00:15,  3.12it/s]\u001b[A\n",
      "Epoch 5:  95%|█████████▌| 920/967 [04:34<00:24,  1.90it/s, loss=0.285, v_num=0, val_loss=0.214, val_acc=0.882, train_loss=0.37]\n",
      "Validating:  18%|█▊        | 10/57 [00:04<00:15,  3.10it/s]\u001b[A\n",
      "Epoch 5:  95%|█████████▌| 922/967 [04:34<00:23,  1.90it/s, loss=0.285, v_num=0, val_loss=0.214, val_acc=0.882, train_loss=0.37]\n",
      "Validating:  21%|██        | 12/57 [00:04<00:13,  3.35it/s]\u001b[A\n",
      "Epoch 5:  96%|█████████▌| 924/967 [04:35<00:22,  1.91it/s, loss=0.285, v_num=0, val_loss=0.214, val_acc=0.882, train_loss=0.37]\n",
      "Validating:  25%|██▍       | 14/57 [00:05<00:13,  3.23it/s]\u001b[A\n",
      "Epoch 5:  96%|█████████▌| 926/967 [04:36<00:21,  1.91it/s, loss=0.285, v_num=0, val_loss=0.214, val_acc=0.882, train_loss=0.37]\n",
      "Validating:  28%|██▊       | 16/57 [00:06<00:12,  3.41it/s]\u001b[A\n",
      "Epoch 5:  96%|█████████▌| 928/967 [04:36<00:20,  1.91it/s, loss=0.285, v_num=0, val_loss=0.214, val_acc=0.882, train_loss=0.37]\n",
      "Validating:  32%|███▏      | 18/57 [00:06<00:11,  3.47it/s]\u001b[A\n",
      "Epoch 5:  96%|█████████▌| 930/967 [04:37<00:19,  1.92it/s, loss=0.285, v_num=0, val_loss=0.214, val_acc=0.882, train_loss=0.37]\n",
      "Validating:  35%|███▌      | 20/57 [00:07<00:10,  3.50it/s]\u001b[A\n",
      "Epoch 5:  96%|█████████▋| 932/967 [04:37<00:18,  1.92it/s, loss=0.285, v_num=0, val_loss=0.214, val_acc=0.882, train_loss=0.37]\n",
      "Validating:  39%|███▊      | 22/57 [00:07<00:10,  3.44it/s]\u001b[A\n",
      "Epoch 5:  97%|█████████▋| 934/967 [04:38<00:17,  1.92it/s, loss=0.285, v_num=0, val_loss=0.214, val_acc=0.882, train_loss=0.37]\n",
      "Validating:  42%|████▏     | 24/57 [00:08<00:09,  3.46it/s]\u001b[A\n",
      "Epoch 5:  97%|█████████▋| 936/967 [04:38<00:16,  1.93it/s, loss=0.285, v_num=0, val_loss=0.214, val_acc=0.882, train_loss=0.37]\n",
      "Validating:  46%|████▌     | 26/57 [00:08<00:08,  3.51it/s]\u001b[A\n",
      "Epoch 5:  97%|█████████▋| 938/967 [04:39<00:15,  1.93it/s, loss=0.285, v_num=0, val_loss=0.214, val_acc=0.882, train_loss=0.37]\n",
      "Validating:  49%|████▉     | 28/57 [00:09<00:08,  3.53it/s]\u001b[A\n",
      "Epoch 5:  97%|█████████▋| 940/967 [04:40<00:13,  1.93it/s, loss=0.285, v_num=0, val_loss=0.214, val_acc=0.882, train_loss=0.37]\n",
      "Validating:  53%|█████▎    | 30/57 [00:10<00:07,  3.56it/s]\u001b[A\n",
      "Epoch 5:  97%|█████████▋| 942/967 [04:40<00:12,  1.94it/s, loss=0.285, v_num=0, val_loss=0.214, val_acc=0.882, train_loss=0.37]\n",
      "Validating:  56%|█████▌    | 32/57 [00:10<00:06,  3.58it/s]\u001b[A\n",
      "Epoch 5:  98%|█████████▊| 944/967 [04:41<00:11,  1.94it/s, loss=0.285, v_num=0, val_loss=0.214, val_acc=0.882, train_loss=0.37]\n",
      "Validating:  60%|█████▉    | 34/57 [00:11<00:06,  3.59it/s]\u001b[A\n",
      "Epoch 5:  98%|█████████▊| 946/967 [04:41<00:10,  1.94it/s, loss=0.285, v_num=0, val_loss=0.214, val_acc=0.882, train_loss=0.37]\n",
      "Validating:  63%|██████▎   | 36/57 [00:11<00:05,  3.59it/s]\u001b[A\n",
      "Epoch 5:  98%|█████████▊| 948/967 [04:42<00:09,  1.94it/s, loss=0.285, v_num=0, val_loss=0.214, val_acc=0.882, train_loss=0.37]\n",
      "Validating:  67%|██████▋   | 38/57 [00:12<00:05,  3.51it/s]\u001b[A\n",
      "Epoch 5:  98%|█████████▊| 950/967 [04:42<00:08,  1.95it/s, loss=0.285, v_num=0, val_loss=0.214, val_acc=0.882, train_loss=0.37]\n",
      "Validating:  70%|███████   | 40/57 [00:12<00:04,  3.50it/s]\u001b[A\n",
      "Epoch 5:  98%|█████████▊| 952/967 [04:43<00:07,  1.95it/s, loss=0.285, v_num=0, val_loss=0.214, val_acc=0.882, train_loss=0.37]\n",
      "Validating:  74%|███████▎  | 42/57 [00:13<00:04,  3.51it/s]\u001b[A\n",
      "Epoch 5:  99%|█████████▊| 954/967 [04:44<00:06,  1.95it/s, loss=0.285, v_num=0, val_loss=0.214, val_acc=0.882, train_loss=0.37]\n",
      "Validating:  77%|███████▋  | 44/57 [00:14<00:03,  3.56it/s]\u001b[A\n",
      "Epoch 5:  99%|█████████▉| 956/967 [04:44<00:05,  1.96it/s, loss=0.285, v_num=0, val_loss=0.214, val_acc=0.882, train_loss=0.37]\n",
      "Validating:  81%|████████  | 46/57 [00:14<00:03,  3.36it/s]\u001b[A\n",
      "Epoch 5:  99%|█████████▉| 958/967 [04:45<00:04,  1.96it/s, loss=0.285, v_num=0, val_loss=0.214, val_acc=0.882, train_loss=0.37]\n",
      "Validating:  84%|████████▍ | 48/57 [00:15<00:02,  3.43it/s]\u001b[A\n",
      "Epoch 5:  99%|█████████▉| 960/967 [04:45<00:03,  1.96it/s, loss=0.285, v_num=0, val_loss=0.214, val_acc=0.882, train_loss=0.37]\n",
      "Validating:  88%|████████▊ | 50/57 [00:15<00:01,  3.51it/s]\u001b[A\n",
      "Epoch 5:  99%|█████████▉| 962/967 [04:46<00:02,  1.97it/s, loss=0.285, v_num=0, val_loss=0.214, val_acc=0.882, train_loss=0.37]\n",
      "Validating:  91%|█████████ | 52/57 [00:16<00:01,  3.60it/s]\u001b[A\n",
      "Epoch 5: 100%|█████████▉| 964/967 [04:46<00:01,  1.97it/s, loss=0.285, v_num=0, val_loss=0.214, val_acc=0.882, train_loss=0.37]\n",
      "Validating:  95%|█████████▍| 54/57 [00:16<00:00,  3.65it/s]\u001b[A\n",
      "Epoch 5: 100%|█████████▉| 966/967 [04:47<00:00,  1.97it/s, loss=0.285, v_num=0, val_loss=0.214, val_acc=0.882, train_loss=0.37]\n",
      "Validating:  98%|█████████▊| 56/57 [00:17<00:00,  3.67it/s]\u001b[A\n",
      "Validating: 100%|██████████| 57/57 [00:17<00:00,  3.85it/s]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5, global step 1140: val_loss reached 0.20602 (best 0.20602), saving model to \"/opt/favordata/AI/Felix/kaggle-cassava/trained-models/tf_efficientnet_b4_ns_sgd_onecycle_smoothing=0.05_weighted_bitempered_t1=0.8_t2=1/tf_efficientnet_b4_ns_bitempered_smooth=0.05_val_loss=0.206_val_acc=0.889_fold0.ckpt\" as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|██████████| 967/967 [04:48<00:00,  1.97it/s, loss=0.285, v_num=0, val_loss=0.206, val_acc=0.889, train_loss=0.245]\n",
      "Epoch 6:  94%|█████████▍| 910/967 [04:29<00:30,  1.89it/s, loss=0.279, v_num=0, val_loss=0.206, val_acc=0.889, train_loss=0.216]    \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 6:  94%|█████████▍| 912/967 [04:32<00:29,  1.89it/s, loss=0.279, v_num=0, val_loss=0.206, val_acc=0.889, train_loss=0.216]\n",
      "Validating:   4%|▎         | 2/57 [00:02<00:56,  1.03s/it]\u001b[A\n",
      "Epoch 6:  95%|█████████▍| 914/967 [04:32<00:28,  1.89it/s, loss=0.279, v_num=0, val_loss=0.206, val_acc=0.889, train_loss=0.216]\n",
      "Validating:   7%|▋         | 4/57 [00:02<00:28,  1.87it/s]\u001b[A\n",
      "Epoch 6:  95%|█████████▍| 916/967 [04:33<00:26,  1.89it/s, loss=0.279, v_num=0, val_loss=0.206, val_acc=0.889, train_loss=0.216]\n",
      "Validating:  11%|█         | 6/57 [00:03<00:19,  2.60it/s]\u001b[A\n",
      "Epoch 6:  95%|█████████▍| 918/967 [04:33<00:25,  1.90it/s, loss=0.279, v_num=0, val_loss=0.206, val_acc=0.889, train_loss=0.216]\n",
      "Validating:  14%|█▍        | 8/57 [00:04<00:17,  2.86it/s]\u001b[A\n",
      "Epoch 6:  95%|█████████▌| 920/967 [04:34<00:24,  1.90it/s, loss=0.279, v_num=0, val_loss=0.206, val_acc=0.889, train_loss=0.216]\n",
      "Validating:  18%|█▊        | 10/57 [00:04<00:14,  3.21it/s]\u001b[A\n",
      "Epoch 6:  95%|█████████▌| 922/967 [04:34<00:23,  1.90it/s, loss=0.279, v_num=0, val_loss=0.206, val_acc=0.889, train_loss=0.216]\n",
      "Validating:  21%|██        | 12/57 [00:05<00:13,  3.36it/s]\u001b[A\n",
      "Epoch 6:  96%|█████████▌| 924/967 [04:35<00:22,  1.91it/s, loss=0.279, v_num=0, val_loss=0.206, val_acc=0.889, train_loss=0.216]\n",
      "Validating:  25%|██▍       | 14/57 [00:05<00:12,  3.44it/s]\u001b[A\n",
      "Epoch 6:  96%|█████████▌| 926/967 [04:36<00:21,  1.91it/s, loss=0.279, v_num=0, val_loss=0.206, val_acc=0.889, train_loss=0.216]\n",
      "Validating:  28%|██▊       | 16/57 [00:06<00:11,  3.52it/s]\u001b[A\n",
      "Epoch 6:  96%|█████████▌| 928/967 [04:36<00:20,  1.91it/s, loss=0.279, v_num=0, val_loss=0.206, val_acc=0.889, train_loss=0.216]\n",
      "Validating:  32%|███▏      | 18/57 [00:06<00:11,  3.51it/s]\u001b[A\n",
      "Epoch 6:  96%|█████████▌| 930/967 [04:37<00:19,  1.92it/s, loss=0.279, v_num=0, val_loss=0.206, val_acc=0.889, train_loss=0.216]\n",
      "Validating:  35%|███▌      | 20/57 [00:07<00:10,  3.54it/s]\u001b[A\n",
      "Epoch 6:  96%|█████████▋| 932/967 [04:37<00:18,  1.92it/s, loss=0.279, v_num=0, val_loss=0.206, val_acc=0.889, train_loss=0.216]\n",
      "Validating:  39%|███▊      | 22/57 [00:08<00:09,  3.53it/s]\u001b[A\n",
      "Epoch 6:  97%|█████████▋| 934/967 [04:38<00:17,  1.92it/s, loss=0.279, v_num=0, val_loss=0.206, val_acc=0.889, train_loss=0.216]\n",
      "Validating:  42%|████▏     | 24/57 [00:08<00:09,  3.55it/s]\u001b[A\n",
      "Epoch 6:  97%|█████████▋| 936/967 [04:38<00:16,  1.93it/s, loss=0.279, v_num=0, val_loss=0.206, val_acc=0.889, train_loss=0.216]\n",
      "Validating:  46%|████▌     | 26/57 [00:09<00:09,  3.36it/s]\u001b[A\n",
      "Epoch 6:  97%|█████████▋| 938/967 [04:39<00:15,  1.93it/s, loss=0.279, v_num=0, val_loss=0.206, val_acc=0.889, train_loss=0.216]\n",
      "Validating:  49%|████▉     | 28/57 [00:09<00:08,  3.48it/s]\u001b[A\n",
      "Epoch 6:  97%|█████████▋| 940/967 [04:40<00:13,  1.93it/s, loss=0.279, v_num=0, val_loss=0.206, val_acc=0.889, train_loss=0.216]\n",
      "Validating:  53%|█████▎    | 30/57 [00:10<00:07,  3.56it/s]\u001b[A\n",
      "Epoch 6:  97%|█████████▋| 942/967 [04:40<00:12,  1.94it/s, loss=0.279, v_num=0, val_loss=0.206, val_acc=0.889, train_loss=0.216]\n",
      "Validating:  56%|█████▌    | 32/57 [00:10<00:07,  3.54it/s]\u001b[A\n",
      "Epoch 6:  98%|█████████▊| 944/967 [04:41<00:11,  1.94it/s, loss=0.279, v_num=0, val_loss=0.206, val_acc=0.889, train_loss=0.216]\n",
      "Validating:  60%|█████▉    | 34/57 [00:11<00:06,  3.53it/s]\u001b[A\n",
      "Epoch 6:  98%|█████████▊| 946/967 [04:41<00:10,  1.94it/s, loss=0.279, v_num=0, val_loss=0.206, val_acc=0.889, train_loss=0.216]\n",
      "Validating:  63%|██████▎   | 36/57 [00:12<00:05,  3.58it/s]\u001b[A\n",
      "Epoch 6:  98%|█████████▊| 948/967 [04:42<00:09,  1.94it/s, loss=0.279, v_num=0, val_loss=0.206, val_acc=0.889, train_loss=0.216]\n",
      "Validating:  67%|██████▋   | 38/57 [00:12<00:05,  3.59it/s]\u001b[A\n",
      "Epoch 6:  98%|█████████▊| 950/967 [04:42<00:08,  1.95it/s, loss=0.279, v_num=0, val_loss=0.206, val_acc=0.889, train_loss=0.216]\n",
      "Validating:  70%|███████   | 40/57 [00:13<00:04,  3.61it/s]\u001b[A\n",
      "Epoch 6:  98%|█████████▊| 952/967 [04:43<00:07,  1.95it/s, loss=0.279, v_num=0, val_loss=0.206, val_acc=0.889, train_loss=0.216]\n",
      "Validating:  74%|███████▎  | 42/57 [00:13<00:04,  3.57it/s]\u001b[A\n",
      "Epoch 6:  99%|█████████▊| 954/967 [04:43<00:06,  1.95it/s, loss=0.279, v_num=0, val_loss=0.206, val_acc=0.889, train_loss=0.216]\n",
      "Validating:  77%|███████▋  | 44/57 [00:14<00:03,  3.47it/s]\u001b[A\n",
      "Epoch 6:  99%|█████████▉| 956/967 [04:44<00:05,  1.96it/s, loss=0.279, v_num=0, val_loss=0.206, val_acc=0.889, train_loss=0.216]\n",
      "Validating:  81%|████████  | 46/57 [00:14<00:03,  3.49it/s]\u001b[A\n",
      "Epoch 6:  99%|█████████▉| 958/967 [04:45<00:04,  1.96it/s, loss=0.279, v_num=0, val_loss=0.206, val_acc=0.889, train_loss=0.216]\n",
      "Validating:  84%|████████▍ | 48/57 [00:15<00:02,  3.46it/s]\u001b[A\n",
      "Epoch 6:  99%|█████████▉| 960/967 [04:45<00:03,  1.96it/s, loss=0.279, v_num=0, val_loss=0.206, val_acc=0.889, train_loss=0.216]\n",
      "Validating:  88%|████████▊ | 50/57 [00:16<00:01,  3.55it/s]\u001b[A\n",
      "Epoch 6:  99%|█████████▉| 962/967 [04:46<00:02,  1.97it/s, loss=0.279, v_num=0, val_loss=0.206, val_acc=0.889, train_loss=0.216]\n",
      "Validating:  91%|█████████ | 52/57 [00:16<00:01,  3.62it/s]\u001b[A\n",
      "Epoch 6: 100%|█████████▉| 964/967 [04:46<00:01,  1.97it/s, loss=0.279, v_num=0, val_loss=0.206, val_acc=0.889, train_loss=0.216]\n",
      "Validating:  95%|█████████▍| 54/57 [00:17<00:00,  3.66it/s]\u001b[A\n",
      "Epoch 6: 100%|█████████▉| 966/967 [04:47<00:00,  1.97it/s, loss=0.279, v_num=0, val_loss=0.206, val_acc=0.889, train_loss=0.216]\n",
      "Validating:  98%|█████████▊| 56/57 [00:17<00:00,  3.67it/s]\u001b[A\n",
      "Validating: 100%|██████████| 57/57 [00:17<00:00,  3.85it/s]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6, step 1368: val_loss was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: 100%|██████████| 967/967 [04:47<00:00,  1.97it/s, loss=0.279, v_num=0, val_loss=0.213, val_acc=0.876, train_loss=0.202]\n",
      "Epoch 7:  94%|█████████▍| 910/967 [04:30<00:30,  1.89it/s, loss=0.278, v_num=0, val_loss=0.213, val_acc=0.876, train_loss=0.13]     \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 7:  94%|█████████▍| 912/967 [04:31<00:29,  1.89it/s, loss=0.278, v_num=0, val_loss=0.213, val_acc=0.876, train_loss=0.13]\n",
      "Validating:   4%|▎         | 2/57 [00:02<00:49,  1.11it/s]\u001b[A\n",
      "Epoch 7:  95%|█████████▍| 914/967 [04:32<00:28,  1.89it/s, loss=0.278, v_num=0, val_loss=0.213, val_acc=0.876, train_loss=0.13]\n",
      "Validating:   7%|▋         | 4/57 [00:02<00:25,  2.06it/s]\u001b[A\n",
      "Epoch 7:  95%|█████████▍| 916/967 [04:32<00:26,  1.89it/s, loss=0.278, v_num=0, val_loss=0.213, val_acc=0.876, train_loss=0.13]\n",
      "Validating:  11%|█         | 6/57 [00:03<00:19,  2.66it/s]\u001b[A\n",
      "Epoch 7:  95%|█████████▍| 918/967 [04:33<00:25,  1.90it/s, loss=0.278, v_num=0, val_loss=0.213, val_acc=0.876, train_loss=0.13]\n",
      "Validating:  14%|█▍        | 8/57 [00:03<00:15,  3.12it/s]\u001b[A\n",
      "Epoch 7:  95%|█████████▌| 920/967 [04:34<00:24,  1.90it/s, loss=0.278, v_num=0, val_loss=0.213, val_acc=0.876, train_loss=0.13]\n",
      "Validating:  18%|█▊        | 10/57 [00:04<00:14,  3.15it/s]\u001b[A\n",
      "Epoch 7:  95%|█████████▌| 922/967 [04:34<00:23,  1.90it/s, loss=0.278, v_num=0, val_loss=0.213, val_acc=0.876, train_loss=0.13]\n",
      "Validating:  21%|██        | 12/57 [00:04<00:13,  3.39it/s]\u001b[A\n",
      "Epoch 7:  96%|█████████▌| 924/967 [04:35<00:22,  1.91it/s, loss=0.278, v_num=0, val_loss=0.213, val_acc=0.876, train_loss=0.13]\n",
      "Validating:  25%|██▍       | 14/57 [00:05<00:13,  3.30it/s]\u001b[A\n",
      "Epoch 7:  96%|█████████▌| 926/967 [04:35<00:21,  1.91it/s, loss=0.278, v_num=0, val_loss=0.213, val_acc=0.876, train_loss=0.13]\n",
      "Validating:  28%|██▊       | 16/57 [00:06<00:11,  3.43it/s]\u001b[A\n",
      "Epoch 7:  96%|█████████▌| 928/967 [04:36<00:20,  1.91it/s, loss=0.278, v_num=0, val_loss=0.213, val_acc=0.876, train_loss=0.13]\n",
      "Validating:  32%|███▏      | 18/57 [00:06<00:11,  3.49it/s]\u001b[A\n",
      "Epoch 7:  96%|█████████▌| 930/967 [04:36<00:19,  1.92it/s, loss=0.278, v_num=0, val_loss=0.213, val_acc=0.876, train_loss=0.13]\n",
      "Validating:  35%|███▌      | 20/57 [00:07<00:10,  3.48it/s]\u001b[A\n",
      "Epoch 7:  96%|█████████▋| 932/967 [04:37<00:18,  1.92it/s, loss=0.278, v_num=0, val_loss=0.213, val_acc=0.876, train_loss=0.13]\n",
      "Validating:  39%|███▊      | 22/57 [00:07<00:09,  3.57it/s]\u001b[A\n",
      "Epoch 7:  97%|█████████▋| 934/967 [04:38<00:17,  1.92it/s, loss=0.278, v_num=0, val_loss=0.213, val_acc=0.876, train_loss=0.13]\n",
      "Validating:  42%|████▏     | 24/57 [00:08<00:09,  3.52it/s]\u001b[A\n",
      "Epoch 7:  97%|█████████▋| 936/967 [04:38<00:16,  1.93it/s, loss=0.278, v_num=0, val_loss=0.213, val_acc=0.876, train_loss=0.13]\n",
      "Validating:  46%|████▌     | 26/57 [00:08<00:08,  3.59it/s]\u001b[A\n",
      "Epoch 7:  97%|█████████▋| 938/967 [04:39<00:15,  1.93it/s, loss=0.278, v_num=0, val_loss=0.213, val_acc=0.876, train_loss=0.13]\n",
      "Validating:  49%|████▉     | 28/57 [00:09<00:08,  3.59it/s]\u001b[A\n",
      "Epoch 7:  97%|█████████▋| 940/967 [04:39<00:13,  1.93it/s, loss=0.278, v_num=0, val_loss=0.213, val_acc=0.876, train_loss=0.13]\n",
      "Validating:  53%|█████▎    | 30/57 [00:09<00:07,  3.61it/s]\u001b[A\n",
      "Epoch 7:  97%|█████████▋| 942/967 [04:40<00:12,  1.94it/s, loss=0.278, v_num=0, val_loss=0.213, val_acc=0.876, train_loss=0.13]\n",
      "Validating:  56%|█████▌    | 32/57 [00:10<00:06,  3.64it/s]\u001b[A\n",
      "Epoch 7:  98%|█████████▊| 944/967 [04:40<00:11,  1.94it/s, loss=0.278, v_num=0, val_loss=0.213, val_acc=0.876, train_loss=0.13]\n",
      "Validating:  60%|█████▉    | 34/57 [00:11<00:06,  3.52it/s]\u001b[A\n",
      "Epoch 7:  98%|█████████▊| 946/967 [04:41<00:10,  1.94it/s, loss=0.278, v_num=0, val_loss=0.213, val_acc=0.876, train_loss=0.13]\n",
      "Validating:  63%|██████▎   | 36/57 [00:11<00:06,  3.49it/s]\u001b[A\n",
      "Epoch 7:  98%|█████████▊| 948/967 [04:42<00:09,  1.95it/s, loss=0.278, v_num=0, val_loss=0.213, val_acc=0.876, train_loss=0.13]\n",
      "Validating:  67%|██████▋   | 38/57 [00:12<00:05,  3.57it/s]\u001b[A\n",
      "Epoch 7:  98%|█████████▊| 950/967 [04:42<00:08,  1.95it/s, loss=0.278, v_num=0, val_loss=0.213, val_acc=0.876, train_loss=0.13]\n",
      "Validating:  70%|███████   | 40/57 [00:12<00:04,  3.57it/s]\u001b[A\n",
      "Epoch 7:  98%|█████████▊| 952/967 [04:43<00:07,  1.95it/s, loss=0.278, v_num=0, val_loss=0.213, val_acc=0.876, train_loss=0.13]\n",
      "Validating:  74%|███████▎  | 42/57 [00:13<00:04,  3.59it/s]\u001b[A\n",
      "Epoch 7:  99%|█████████▊| 954/967 [04:43<00:06,  1.96it/s, loss=0.278, v_num=0, val_loss=0.213, val_acc=0.876, train_loss=0.13]\n",
      "Validating:  77%|███████▋  | 44/57 [00:13<00:03,  3.61it/s]\u001b[A\n",
      "Epoch 7:  99%|█████████▉| 956/967 [04:44<00:05,  1.96it/s, loss=0.278, v_num=0, val_loss=0.213, val_acc=0.876, train_loss=0.13]\n",
      "Validating:  81%|████████  | 46/57 [00:14<00:03,  3.45it/s]\u001b[A\n",
      "Epoch 7:  99%|█████████▉| 958/967 [04:44<00:04,  1.96it/s, loss=0.278, v_num=0, val_loss=0.213, val_acc=0.876, train_loss=0.13]\n",
      "Validating:  84%|████████▍ | 48/57 [00:15<00:02,  3.50it/s]\u001b[A\n",
      "Epoch 7:  99%|█████████▉| 960/967 [04:45<00:03,  1.97it/s, loss=0.278, v_num=0, val_loss=0.213, val_acc=0.876, train_loss=0.13]\n",
      "Validating:  88%|████████▊ | 50/57 [00:15<00:01,  3.60it/s]\u001b[A\n",
      "Epoch 7:  99%|█████████▉| 962/967 [04:45<00:02,  1.97it/s, loss=0.278, v_num=0, val_loss=0.213, val_acc=0.876, train_loss=0.13]\n",
      "Validating:  91%|█████████ | 52/57 [00:16<00:01,  3.66it/s]\u001b[A\n",
      "Epoch 7: 100%|█████████▉| 964/967 [04:46<00:01,  1.97it/s, loss=0.278, v_num=0, val_loss=0.213, val_acc=0.876, train_loss=0.13]\n",
      "Validating:  95%|█████████▍| 54/57 [00:16<00:00,  3.70it/s]\u001b[A\n",
      "Epoch 7: 100%|█████████▉| 966/967 [04:47<00:00,  1.98it/s, loss=0.278, v_num=0, val_loss=0.213, val_acc=0.876, train_loss=0.13]\n",
      "Validating:  98%|█████████▊| 56/57 [00:17<00:00,  3.72it/s]\u001b[A\n",
      "Validating: 100%|██████████| 57/57 [00:17<00:00,  3.90it/s]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7, step 1596: val_loss was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7: 100%|██████████| 967/967 [04:47<00:00,  1.97it/s, loss=0.278, v_num=0, val_loss=nan, val_acc=0.0522, train_loss=0.209]\n",
      "Epoch 8:  94%|█████████▍| 910/967 [04:29<00:30,  1.89it/s, loss=0.271, v_num=0, val_loss=nan, val_acc=0.0522, train_loss=0.266]    \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 8:  94%|█████████▍| 912/967 [04:31<00:29,  1.89it/s, loss=0.271, v_num=0, val_loss=nan, val_acc=0.0522, train_loss=0.266]\n",
      "Validating:   4%|▎         | 2/57 [00:02<00:53,  1.03it/s]\u001b[A\n",
      "Epoch 8:  95%|█████████▍| 914/967 [04:32<00:28,  1.89it/s, loss=0.271, v_num=0, val_loss=nan, val_acc=0.0522, train_loss=0.266]\n",
      "Validating:   7%|▋         | 4/57 [00:02<00:26,  1.99it/s]\u001b[A\n",
      "Epoch 8:  95%|█████████▍| 916/967 [04:33<00:26,  1.89it/s, loss=0.271, v_num=0, val_loss=nan, val_acc=0.0522, train_loss=0.266]\n",
      "Validating:  11%|█         | 6/57 [00:03<00:19,  2.68it/s]\u001b[A\n",
      "Epoch 8:  95%|█████████▍| 918/967 [04:33<00:25,  1.90it/s, loss=0.271, v_num=0, val_loss=nan, val_acc=0.0522, train_loss=0.266]\n",
      "Validating:  14%|█▍        | 8/57 [00:03<00:16,  2.96it/s]\u001b[A\n",
      "Epoch 8:  95%|█████████▌| 920/967 [04:34<00:24,  1.90it/s, loss=0.271, v_num=0, val_loss=nan, val_acc=0.0522, train_loss=0.266]\n",
      "Validating:  18%|█▊        | 10/57 [00:04<00:14,  3.23it/s]\u001b[A\n",
      "Epoch 8:  95%|█████████▌| 922/967 [04:34<00:23,  1.90it/s, loss=0.271, v_num=0, val_loss=nan, val_acc=0.0522, train_loss=0.266]\n",
      "Validating:  21%|██        | 12/57 [00:05<00:13,  3.43it/s]\u001b[A\n",
      "Epoch 8:  96%|█████████▌| 924/967 [04:35<00:22,  1.91it/s, loss=0.271, v_num=0, val_loss=nan, val_acc=0.0522, train_loss=0.266]\n",
      "Validating:  25%|██▍       | 14/57 [00:05<00:12,  3.45it/s]\u001b[A\n",
      "Epoch 8:  96%|█████████▌| 926/967 [04:35<00:21,  1.91it/s, loss=0.271, v_num=0, val_loss=nan, val_acc=0.0522, train_loss=0.266]\n",
      "Validating:  28%|██▊       | 16/57 [00:06<00:11,  3.55it/s]\u001b[A\n",
      "Epoch 8:  96%|█████████▌| 928/967 [04:36<00:20,  1.91it/s, loss=0.271, v_num=0, val_loss=nan, val_acc=0.0522, train_loss=0.266]\n",
      "Validating:  32%|███▏      | 18/57 [00:06<00:11,  3.50it/s]\u001b[A\n",
      "Epoch 8:  96%|█████████▌| 930/967 [04:36<00:19,  1.92it/s, loss=0.271, v_num=0, val_loss=nan, val_acc=0.0522, train_loss=0.266]\n",
      "Validating:  35%|███▌      | 20/57 [00:07<00:10,  3.57it/s]\u001b[A\n",
      "Epoch 8:  96%|█████████▋| 932/967 [04:37<00:18,  1.92it/s, loss=0.271, v_num=0, val_loss=nan, val_acc=0.0522, train_loss=0.266]\n",
      "Validating:  39%|███▊      | 22/57 [00:07<00:09,  3.54it/s]\u001b[A\n",
      "Epoch 8:  97%|█████████▋| 934/967 [04:38<00:17,  1.92it/s, loss=0.271, v_num=0, val_loss=nan, val_acc=0.0522, train_loss=0.266]\n",
      "Validating:  42%|████▏     | 24/57 [00:08<00:09,  3.56it/s]\u001b[A\n",
      "Epoch 8:  97%|█████████▋| 936/967 [04:38<00:16,  1.93it/s, loss=0.271, v_num=0, val_loss=nan, val_acc=0.0522, train_loss=0.266]\n",
      "Validating:  46%|████▌     | 26/57 [00:09<00:08,  3.54it/s]\u001b[A\n",
      "Epoch 8:  97%|█████████▋| 938/967 [04:39<00:15,  1.93it/s, loss=0.271, v_num=0, val_loss=nan, val_acc=0.0522, train_loss=0.266]\n",
      "Validating:  49%|████▉     | 28/57 [00:09<00:08,  3.57it/s]\u001b[A\n",
      "Epoch 8:  97%|█████████▋| 940/967 [04:39<00:13,  1.93it/s, loss=0.271, v_num=0, val_loss=nan, val_acc=0.0522, train_loss=0.266]\n",
      "Validating:  53%|█████▎    | 30/57 [00:10<00:07,  3.60it/s]\u001b[A\n",
      "Epoch 8:  97%|█████████▋| 942/967 [04:40<00:12,  1.94it/s, loss=0.271, v_num=0, val_loss=nan, val_acc=0.0522, train_loss=0.266]\n",
      "Validating:  56%|█████▌    | 32/57 [00:10<00:07,  3.44it/s]\u001b[A\n",
      "Epoch 8:  98%|█████████▊| 944/967 [04:40<00:11,  1.94it/s, loss=0.271, v_num=0, val_loss=nan, val_acc=0.0522, train_loss=0.266]\n",
      "Validating:  60%|█████▉    | 34/57 [00:11<00:06,  3.55it/s]\u001b[A\n",
      "Epoch 8:  98%|█████████▊| 946/967 [04:41<00:10,  1.94it/s, loss=0.271, v_num=0, val_loss=nan, val_acc=0.0522, train_loss=0.266]\n",
      "Validating:  63%|██████▎   | 36/57 [00:11<00:05,  3.55it/s]\u001b[A\n",
      "Epoch 8:  98%|█████████▊| 948/967 [04:42<00:09,  1.95it/s, loss=0.271, v_num=0, val_loss=nan, val_acc=0.0522, train_loss=0.266]\n",
      "Validating:  67%|██████▋   | 38/57 [00:12<00:05,  3.62it/s]\u001b[A\n",
      "Epoch 8:  98%|█████████▊| 950/967 [04:42<00:08,  1.95it/s, loss=0.271, v_num=0, val_loss=nan, val_acc=0.0522, train_loss=0.266]\n",
      "Validating:  70%|███████   | 40/57 [00:12<00:04,  3.63it/s]\u001b[A\n",
      "Epoch 8:  98%|█████████▊| 952/967 [04:43<00:07,  1.95it/s, loss=0.271, v_num=0, val_loss=nan, val_acc=0.0522, train_loss=0.266]\n",
      "Validating:  74%|███████▎  | 42/57 [00:13<00:04,  3.59it/s]\u001b[A\n",
      "Epoch 8:  99%|█████████▊| 954/967 [04:43<00:06,  1.96it/s, loss=0.271, v_num=0, val_loss=nan, val_acc=0.0522, train_loss=0.266]\n",
      "Validating:  77%|███████▋  | 44/57 [00:14<00:03,  3.36it/s]\u001b[A\n",
      "Epoch 8:  99%|█████████▉| 956/967 [04:44<00:05,  1.96it/s, loss=0.271, v_num=0, val_loss=nan, val_acc=0.0522, train_loss=0.266]\n",
      "Validating:  81%|████████  | 46/57 [00:14<00:03,  3.50it/s]\u001b[A\n",
      "Epoch 8:  99%|█████████▉| 958/967 [04:44<00:04,  1.96it/s, loss=0.271, v_num=0, val_loss=nan, val_acc=0.0522, train_loss=0.266]\n",
      "Validating:  84%|████████▍ | 48/57 [00:15<00:02,  3.54it/s]\u001b[A\n",
      "Epoch 8:  99%|█████████▉| 960/967 [04:45<00:03,  1.97it/s, loss=0.271, v_num=0, val_loss=nan, val_acc=0.0522, train_loss=0.266]\n",
      "Validating:  88%|████████▊ | 50/57 [00:15<00:01,  3.59it/s]\u001b[A\n",
      "Epoch 8:  99%|█████████▉| 962/967 [04:45<00:02,  1.97it/s, loss=0.271, v_num=0, val_loss=nan, val_acc=0.0522, train_loss=0.266]\n",
      "Validating:  91%|█████████ | 52/57 [00:16<00:01,  3.66it/s]\u001b[A\n",
      "Epoch 8: 100%|█████████▉| 964/967 [04:46<00:01,  1.97it/s, loss=0.271, v_num=0, val_loss=nan, val_acc=0.0522, train_loss=0.266]\n",
      "Validating:  95%|█████████▍| 54/57 [00:16<00:00,  3.70it/s]\u001b[A\n",
      "Epoch 8: 100%|█████████▉| 966/967 [04:47<00:00,  1.98it/s, loss=0.271, v_num=0, val_loss=nan, val_acc=0.0522, train_loss=0.266]\n",
      "Validating:  98%|█████████▊| 56/57 [00:17<00:00,  3.72it/s]\u001b[A\n",
      "Validating: 100%|██████████| 57/57 [00:17<00:00,  3.90it/s]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8, step 1824: val_loss was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8: 100%|██████████| 967/967 [04:47<00:00,  1.97it/s, loss=0.271, v_num=0, val_loss=nan, val_acc=0.0522, train_loss=0.174]\n",
      "Epoch 9:   7%|▋         | 68/967 [00:20<-1:59:04, -15.87it/s, loss=0.26, v_num=0, val_loss=nan, val_acc=0.0522, train_loss=0.162]  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: None, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Using native 16bit precision.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training fold 1\n",
      "Class sample counts [ 758 1471 1622 8933 1765]\n",
      "After class sample counts [2274 2942 3730 8933 4765]\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    try:\n",
    "        debug = False\n",
    "        print('Running in debug mode:', debug)\n",
    "        main(experiment_name='tf_efficientnet_b4_ns_sgd_onecycle_smoothing=0.05_weighted_bitempered_t1=0.8_t2=1', debug=debug,\n",
    "             resume=False, finetune=False, freeze_bn=True, freeze_feature_extractor=False)\n",
    "    except KeyboardInterrupt:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
