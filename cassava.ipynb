{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cassava Leaf Disease Classification\n",
    "\n",
    "This notebook builds and trains a model for cassava leaf disease classification for the [Kaggle competition](https://www.kaggle.com/c/cassava-leaf-disease-classification/overview)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ideas\n",
    "\n",
    "1. Cross entropy loss, stratified CV, no fmix, cutmix, mixup, w gradient scaling & accumulation [done]\n",
    "2. add hyperparam tuning with raytune\n",
    "2. Add smoothed cross entropy loss\n",
    "3. Add *mixes\n",
    "4. external data\n",
    "5. emsemble of models - train a model for each fold and then average their predictions during inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "package_paths = [\n",
    "    # this is a project by Ross Wightman (https://github.com/rwightman/pytorch-image-models)\n",
    "    '../pytorch-image-models'\n",
    "]\n",
    "import sys; \n",
    "\n",
    "for pth in package_paths:\n",
    "    sys.path.append(pth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from datetime import datetime\n",
    "import time\n",
    "import random\n",
    "import warnings\n",
    "import joblib\n",
    "import warnings\n",
    "\n",
    "# My modules\n",
    "from config import Config\n",
    "from logger import init_logger\n",
    "from train_loop_functions import train_epoch, valid_epoch, inference\n",
    "from common_utils import set_seeds, read_csvs, get_image, stratify_split, get_train_transforms, get_valid_transforms, setup\n",
    "from modes import Model\n",
    "\n",
    "from sklearn.metric import accuracy_score\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.optim import Adam\n",
    "from torch.optim.lr_scheduler import CosineAnnealingWarmRestarts, CosineAnnealingLR, ReduceLROnPlateau\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.cuda.amp import autocast, GradScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preliminary data loading and setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = read_csvs(Config.data_dir, Config.debug)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_map = pd.read_json(Config.data_dir + '/label_num_to_disease_map.json', orient='index')\n",
    "label_map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the distribution of classes is uneven, we could do stratified k-fold cross validation to make each fold's train and validation distributions representative of the original distributions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_seeds(Config.seed)\n",
    "LOGGER = init_logger() # uses Python's logging framework\n",
    "\n",
    "sample_img = get_image(Config.train_img_dir + '/1000015157.jpg')\n",
    "plt.imshow(sample_img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test it out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cassava_dataset = CassavaDataset(train, Config.train_img_dir, output_label=True)\n",
    "fig = plt.figure()\n",
    "for i in range(2):\n",
    "    img, target = cassava_dataset[i]\n",
    "    print(i, img.shape, target)\n",
    "    \n",
    "    ax = plt.subplot(1, 2, i + 1)\n",
    "    plt.tight_layout()\n",
    "    ax.set_title('Class: {}'.format(target))\n",
    "    ax.axis('off')\n",
    "    plt.imshow(img)\n",
    "    if i == 3:\n",
    "        plt.show()\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stratified Cross Validation Folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_folds = stratifySplit(train, Config.fold_num, Config.seed, Config.target_col)\n",
    "train_folds.groupby(['fold', 'label']).count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and Validation Functions\n",
    "\n",
    "gradient scaling https://pytorch.org/docs/stable/notes/amp_examples.html\n",
    "\n",
    "gradient accumulation https://towardsdatascience.com/what-is-gradient-accumulation-in-deep-learning-ec034122cfa\n",
    "\n",
    "https://towardsdatascience.com/deep-learning-model-training-loop-e41055a24b73"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    Trains the model over epochs for a given fold\n",
    "    \n",
    "    train_folds_df: the dataset with a column for fold number\n",
    "    fold: an integer representing the fold used for validation\n",
    "    \n",
    "    Returns a DataFrame consisting of only the the rows used for validation along with the model's predictions\n",
    "''' \n",
    "def train_fold(train_folds_df, fold, model, optimizer, scheduler, criterion, resultsStore):\n",
    "    # -------- DATASETS AND LOADERS --------\n",
    "    train_dataloader, valid_dataloader = get_loaders(train_folds_df, fold, Config.train_bs)\n",
    "    \n",
    "    accuracy, best_accuracy = 0., 0.\n",
    "    for e in range(Config.epochs):\n",
    "        epoch_start_time = time.time()\n",
    "        LOGGER.info(f'Training epoch {e+1}/{Config.epochs}')\n",
    "        \n",
    "        # -------- TRAIN --------\n",
    "        training_losses = train_epoch(train_dataloader, model, criterion, optimizer, scheduler, GradScaler())\n",
    "        avg_training_loss = sum(training_losses) / len(train_dataloader)\n",
    "        \n",
    "        # -------- VALIDATE --------\n",
    "        validation_losses, preds = valid_epoch(valid_dataloader, model, criterion)\n",
    "        avg_validation_loss = sum(validation_losses) / len(valid_dataloader)\n",
    "        \n",
    "        epoch_elapsed_time = time.time() - epoch_start_time\n",
    "\n",
    "        # -------- SCORE METRICS & LOGGING FOR THIS EPOCH --------\n",
    "        validation_labels = valid_df[Config.target_col].values\n",
    "        accuracy = accuracy_score(y_true=validation_labels, y_pred=preds)\n",
    "        \n",
    "        LOGGER.info(f'\\nEpoch training summary:\\n Fold {fold}/{Config.fold_num} | ' + \\\n",
    "                    f'Epoch: {e+1}/{Config.epochs} | ' + \\\n",
    "                    f'Epoch time: {epoch_elapsed_time} sec | ' + \\\n",
    "                    f'Training loss: {avg_training_loss} | ' + \\\n",
    "                    f'Validation loss: {avg_validation_loss} | ' + \\\n",
    "                    f'Accuracy: {accuracy}\\n')\n",
    "        \n",
    "        # SAVE MODEL (keeps only the best model for this fold)\n",
    "        if accuracy > best_accuracy: \n",
    "            best_accuracy = accuracy\n",
    "            torch.save({'model': model.state_dict(), 'preds': preds, 'accuracy': best_accuracy, 'fold': fold},\n",
    "                      Config.save_dir + f'/{Config.model_arch}_fold{fold}.pth')\n",
    "            LOGGER.info(f'Saved model on epoch {e+1}, fold {fold}, and accuracy score {accuracy:.3f}')\n",
    "        \n",
    "        # -------- UPDATE LR (POTENTIALLY) --------\n",
    "        if scheduler:\n",
    "            if Config.scheduler == 'ReduceLROnPlateau':\n",
    "                scheduler.step(avg_validation_loss)\n",
    "            elif Config.scheduler == 'CosineAnnealingLR' or Config.scheduler == 'CosineAnnealingWarmRestarts':\n",
    "                scheduler.step()\n",
    "\n",
    "    checkpoint = torch.load(Config.save_dir + f'/{Config.model_arch}_fold{fold}.pth')\n",
    "    valid_df['prediction'] = checkpoint['preds']\n",
    "    return valid_df, best_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "\n",
    "class Results:\n",
    "    def __init__(self):\n",
    "        self.fold_to_predictions = {}\n",
    "        self.fold_to_accuracy = {}\n",
    "        \n",
    "def main():    \n",
    "    try:\n",
    "        resultsStore = Results()\n",
    "        model, optimizer, scheduler, criterion = setup()\n",
    "            \n",
    "        if Config.train:\n",
    "            LOGGER.info('\\n========== Running training ==========\\n')\n",
    "            \n",
    "            aggregated_output_df = pd.DataFrame()\n",
    "            \n",
    "            for fold in range(Config.fold_num):\n",
    "                # _df is the validation prediction output\n",
    "                # _df.columns: ['image_id', 'label', 'fold', 'prediction']\n",
    "                _df, best_fold_accuracy = train_fold(train_folds, fold, model, optimizer, scheduler, criterion, resultsStore)\n",
    "                \n",
    "                if aggregated_output_df.empty:\n",
    "                    aggregated_output_df[['image_id', 'label']] = _df[['image_id', 'label']]\n",
    "                aggregated_output_df[['prediction_fold'+str(fold)]] = _df['prediction']\n",
    "                \n",
    "                resultsStore.fold_to_predictions[fold] = _df[['image_id', 'label', 'prediction']]\n",
    "                resultsStore.fold_to_accuracy[fold] = best_fold_accuracy\n",
    "                \n",
    "                LOGGER.info(f'========== fold: {fold} result ==========')\n",
    "                LOGGER.info(f'Accuracy: {best_fold_accuracy}')\n",
    "                \n",
    "            # Cross validation\n",
    "            LOGGER.info(f\"========== CV ==========\") # best results across all folds\n",
    "            LOGGER.info(f\"{resultsStore.fold_to_accuracy}\")\n",
    "            \n",
    "            # Save result\n",
    "            aggregated_output_df.to_csv(Config.save_dir + '/aggregated_output_df.csv', index=False)\n",
    "            \n",
    "        if Config.inference: \n",
    "            LOGGER.info('\\n========== Running inference ==========\\n')\n",
    "            test_dataset = CassavaDataset(test, Config.test_img_dir, output_label=True, \n",
    "                                          transform=get_valid_transforms())\n",
    "            \n",
    "            test_dataloader = DataLoader(test_dataset, batch_size=Config.valid_bs, \n",
    "                                  pin_memory=True, shuffle=False, \n",
    "                                  num_workers=Config.num_workers)\n",
    "\n",
    "            predictions = inference(model, test_dataloader)\n",
    "            targets = test.label.values\n",
    "            \n",
    "            # submission\n",
    "            submission = pd.DataFrame()\n",
    "            submission['image_id'] = test['image_id']\n",
    "            submission['label'] = predictions\n",
    "            submission.to_csv(Config.save_dir + '/submission.csv', index=False)\n",
    "    finally: \n",
    "        del model\n",
    "        torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each fold, run tune? Each fold gets num_samples trials."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    try:\n",
    "        print('Training in debug mode: ', Config.debug)\n",
    "        main()\n",
    "    except KeyboardInterrupt:\n",
    "        pass"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
