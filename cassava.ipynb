{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cassava Leaf Disease Classification\n",
    "\n",
    "This notebook builds and trains a model for cassava leaf disease classification for the [Kaggle competition](https://www.kaggle.com/c/cassava-leaf-disease-classification/overview)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ideas\n",
    "\n",
    "1. Cross entropy loss, stratified CV, no fmix, cutmix, mixup, w gradient scaling & accumulation [done]\n",
    "2. add hyperparam tuning with raytune [done]\n",
    "2. Add smoothed cross entropy loss\n",
    "3. Add *mixes\n",
    "4. external data\n",
    "5. emsemble of models - train a model for each fold and then average their predictions during inference [done]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from datetime import datetime\n",
    "import time\n",
    "import random\n",
    "import warnings\n",
    "import joblib\n",
    "import warnings\n",
    "import gc\n",
    "\n",
    "# My modules\n",
    "from config import Config\n",
    "from logger import init_logger\n",
    "from common_utils import (set_seeds, read_csvs, stratify_split, setup_model_optimizer, \n",
    "                          get_data_dfs, get_loaders, create_holdout_loader, get_schd_crit)\n",
    "from model import Model\n",
    "from train_loop_functions import train_epoch, valid_epoch, ensemble_inference\n",
    "from cassava_dataset import CassavaDataset\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.cuda.amp import GradScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preliminaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_map = pd.read_json(Config.data_dir + '/label_num_to_disease_map.json', orient='index')\n",
    "label_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_seeds(Config.seed)\n",
    "LOGGER = init_logger() # uses Python's logging framework"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and Validation Functions\n",
    "\n",
    "gradient scaling https://pytorch.org/docs/stable/notes/amp_examples.html\n",
    "\n",
    "gradient accumulation https://towardsdatascience.com/what-is-gradient-accumulation-in-deep-learning-ec034122cfa\n",
    "\n",
    "https://towardsdatascience.com/deep-learning-model-training-loop-e41055a24b73"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    Trains the model over N epochs for a given fold\n",
    "    \n",
    "    train_folds_df: the dataset with a column for fold number\n",
    "    fold: an integer representing the fold used for validation\n",
    "    \n",
    "    Returns a DataFrame consisting of only the the rows used for validation along with the model's predictions\n",
    "''' \n",
    "def train_valid_test(train_folds_df, fold, resultsStore, device, \n",
    "                     experiment_name_dir, holdout_dataloader, holdout_targets):\n",
    "    \n",
    "    # -------- DATASETS AND LOADERS --------\n",
    "    # select one of the folds, create train & validation set loaders\n",
    "    train_df, valid_df = get_data_dfs(train_folds_df, fold)\n",
    "    train_dataloader, valid_dataloader = get_loaders(train_df, valid_df,\n",
    "                                                     Config.train_bs, \n",
    "                                                     Config.data_dir+'/train_images')\n",
    "    \n",
    "    \n",
    "    # make model and optimizer\n",
    "    model, optimizer = setup_model_optimizer(Config.model_arch, \n",
    "                                           Config.lr, \n",
    "                                           Config.is_amsgrad, \n",
    "                                           num_labels=train_folds_df.label.nunique(), \n",
    "                                           weight_decay=Config.weight_decay,\n",
    "                                           fc_layer={\"middle_fc\": False, \"middle_fc_size\": 0},\n",
    "                                           device=device,\n",
    "                                           checkpoint=None)\n",
    "\n",
    "    scheduler, criterion = get_schd_crit(optimizer)\n",
    "    \n",
    "    accuracy = 0.\n",
    "    best_val_loss = float('inf')\n",
    "    train_losses, val_losses = [], []\n",
    "    \n",
    "    for e in range(Config.epochs):\n",
    "        epoch_start_time = time.time()\n",
    "        LOGGER.info(f'Training epoch {e+1}/{Config.epochs}')\n",
    "        \n",
    "        # -------- TRAIN --------\n",
    "        avg_training_loss = train_epoch(train_dataloader, model, \n",
    "                                      criterion, optimizer, \n",
    "                                      scheduler, GradScaler(), \n",
    "                                      Config.accum_iter, LOGGER,\n",
    "                                      device)\n",
    "\n",
    "        # -------- VALIDATE --------\n",
    "        avg_validation_loss, preds = valid_epoch(valid_dataloader, model, \n",
    "                                                 criterion, LOGGER, device)\n",
    "        \n",
    "        train_losses.append(avg_training_loss)\n",
    "        val_losses.append(avg_validation_loss)\n",
    "\n",
    "        # -------- SCORE METRICS & LOGGING FOR THIS EPOCH --------\n",
    "        validation_labels = valid_df[Config.target_col].values\n",
    "        accuracy = accuracy_score(y_true=validation_labels, y_pred=preds)\n",
    "       \n",
    "        epoch_elapsed_time = time.time() - epoch_start_time\n",
    "        \n",
    "        LOGGER.info(f'\\nEpoch training summary:\\n Fold {fold+1}/{Config.fold_num} | ' + \\\n",
    "                    f'Epoch: {e+1}/{Config.epochs} | ' + \\\n",
    "                    f'Epoch time: {epoch_elapsed_time} sec\\n' + \\\n",
    "                    f'Training loss: {avg_training_loss} | ' + \\\n",
    "                    f'Validation loss: {avg_validation_loss} | ' + \\\n",
    "                    f'Accuracy: {accuracy}\\n')\n",
    "        \n",
    "        # --------SAVE MODEL --------\n",
    "        if avg_validation_loss < best_val_loss: \n",
    "            best_val_loss = avg_validation_loss\n",
    "            torch.save({'model': model.state_dict(), \n",
    "                        'accuracy': accuracy, \n",
    "                        'preds': preds,\n",
    "                        'val_loss': best_val_loss,\n",
    "                        'fold': fold\n",
    "                       },\n",
    "                      Config.save_dir + f'/{experiment_name_dir}/{Config.model_arch}_fold{fold}.pth')\n",
    "            LOGGER.info(f'Saved model!')\n",
    "        \n",
    "        # -------- UPDATE LR --------\n",
    "        if scheduler and e > 2:\n",
    "            if Config.scheduler == 'ReduceLROnPlateau':\n",
    "                scheduler.step(avg_validation_loss)\n",
    "            elif Config.scheduler == 'CosineAnnealingLR' or Config.scheduler == 'CosineAnnealingWarmRestarts':\n",
    "                scheduler.step()\n",
    "        gc.collect()\n",
    "\n",
    "    # -------- TEST ON HOLDOUT SET --------\n",
    "    # load best model\n",
    "    checkpoint = torch.load(Config.save_dir + f'/{experiment_name_dir}/{Config.model_arch}_fold{fold}.pth')\n",
    "    model.load_state_dict(checkpoint['model']) \n",
    "    # test\n",
    "    _, holdout_preds = valid_epoch(holdout_dataloader, model, criterion, LOGGER, device)\n",
    "    holdout_accuracy = accuracy_score(y_true=holdout_targets, y_pred=holdout_preds)\n",
    "    \n",
    "    valid_df['prediction'] = checkpoint['preds']\n",
    "    del model\n",
    "    del optimizer\n",
    "    del train_dataloader\n",
    "\n",
    "    del valid_dataloader\n",
    "    return valid_df, checkpoint['accuracy'], holdout_accuracy, train_losses, val_losses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Results:\n",
    "    def __init__(self):\n",
    "        self.fold_to_predictions = {}\n",
    "        self.fold_to_accuracy = {}\n",
    "\n",
    "\"\"\"\n",
    "Entry point to training and inference. \n",
    "experiment_name_dir (required): a name for a directory in ./trained-models \n",
    "\"\"\"\n",
    "def main(experiment_name_dir, kaggle):\n",
    "    base_experiment_filename = Config.save_dir + f'/{experiment_name_dir}/{Config.model_arch}_fold'\n",
    "    \n",
    "    try:\n",
    "        # -------- SETUP --------\n",
    "        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        resultsStore = Results()\n",
    "        \n",
    "\n",
    "        # -------- LOAD DATA FROM FILE --------\n",
    "        data_df, sample_df, holdout_df = read_csvs(Config.data_dir, Config.debug, test_proportion=0.15)\n",
    "        folds = stratify_split(data_df, Config.fold_num, Config.seed, Config.target_col)\n",
    "        test_df, test_loader = None, None\n",
    "        \n",
    "        # create holdout dataloader to test on totally unseen data\n",
    "        holdout_dataloader, holdout_targets = create_holdout_loader(holdout_df, Config.data_dir + '/train_images')   \n",
    "\n",
    "        experiment_list = os.listdir(Config.save_dir)\n",
    "        if experiment_name_dir in experiment_list: # resume training from the last fold's checkpoint\n",
    "            last_fold = len(os.listdir(Config.save_dir + f'/{experiment_name_dir}')) - 1\n",
    "            if last_fold >= 0: \n",
    "                print(f'Experiment exists. Resuming training from latest fold ({last_fold}).')\n",
    "\n",
    "                checkpoint = torch.load(base_experiment_filename + f'{last_fold}.pth')\n",
    "\n",
    "                #resume(checkpoint, fold, model, optimizer)\n",
    "        else: # -------- START TRAINING --------\n",
    "            # make directory for experiment\n",
    "            try:\n",
    "                os.makedirs(Config.save_dir + f'/{experiment_name_dir}')\n",
    "            except OSError as e:\n",
    "                if e.errno != errno.EEXIST:\n",
    "                    raise\n",
    "            \n",
    "            \n",
    "            if Config.train:\n",
    "                LOGGER.info('\\n========== Running training ==========\\n')\n",
    "\n",
    "                aggregated_output_df = pd.DataFrame()\n",
    "\n",
    "                for fold in range(Config.fold_num):    \n",
    "                    # _df is the validation prediction output\n",
    "                    # _df.columns: ['image_id', 'label', 'fold', 'prediction']\n",
    "                    _df, val_accuracy, holdout_accuracy, train_losses, val_losses = train_valid_test(\n",
    "                                                                        folds, fold, \n",
    "                                                                        resultsStore, device,\n",
    "                                                                        experiment_name_dir,\n",
    "                                                                        holdout_dataloader, \n",
    "                                                                        holdout_targets)\n",
    "                    \n",
    "                    if aggregated_output_df.empty:\n",
    "                        aggregated_output_df[['image_id', 'label']] = _df[['image_id', 'label']]\n",
    "                    aggregated_output_df[['prediction_fold'+str(fold)]] = _df['prediction']\n",
    "\n",
    "                    resultsStore.fold_to_predictions[fold] = _df[['image_id', 'label', 'prediction']]\n",
    "                    resultsStore.fold_to_accuracy[fold] = (val_accuracy, holdout_accuracy)\n",
    "\n",
    "                    LOGGER.info(f'========== fold: {fold} result ==========')\n",
    "                    LOGGER.info(f'Validation Accuracy: {val_accuracy}')\n",
    "                    LOGGER.info(f'Holdout Accuracy: {holdout_accuracy}')\n",
    "\n",
    "                # Cross validation\n",
    "                LOGGER.info(f\"========== CV ==========\") # best results across all folds\n",
    "                LOGGER.info(f\"{resultsStore.fold_to_accuracy}\")\n",
    "\n",
    "                # Save result\n",
    "                aggregated_output_df.to_csv(Config.save_dir + '/aggregated_output_df.csv', index=False)\n",
    "\n",
    "        if Config.inference: # runs inference on all trained models, averages result\n",
    "            LOGGER.info('\\n========== Running inference ==========\\n')\n",
    "            \n",
    "            model_states = [torch.load(base_experiment_filename + f'{fold}.pth')['model']\n",
    "                            for fold in range(Config.fold_num)]\n",
    "            assert len(model_states) == Config.fold_num\n",
    "            \n",
    "            \n",
    "            if not kaggle: \n",
    "                loader = holdout_dataloader\n",
    "                num_samples = len(holdout_df)\n",
    "            else: \n",
    "                loader = test_dataloader \n",
    "                num_samples = len(test_df)\n",
    "                \n",
    "            predictions = ensemble_inference(states, Config.model_arch, \n",
    "                                    data_df.label.nunique(), loader, num_samples, device)\n",
    "            \n",
    "            if not kaggle:\n",
    "                holdout_accuracy = accuracy_score(y_true=holdout_targets, y_pred=predictions)\n",
    "                LOGGER.info(f\"Ensemble model holdout accuracy: {holdout_accuracy}\")\n",
    "            \n",
    "                \n",
    "            \n",
    "            # submission\n",
    "            submission = pd.DataFrame()\n",
    "            submission['image_id'] = test['image_id']\n",
    "            submission['label'] = predictions\n",
    "            submission.to_csv(Config.save_dir + '/submission.csv', index=False)\n",
    "    finally: \n",
    "        torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    try:\n",
    "        print('Training in debug mode: ', Config.debug)\n",
    "        main(experiment_name_dir='exp0', kaggle=False)\n",
    "        \n",
    "    except KeyboardInterrupt:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
