{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import argparse\n",
    "import errno\n",
    "import glob\n",
    "import json\n",
    "import os\n",
    "import re\n",
    "import shutil\n",
    "from types import SimpleNamespace\n",
    "import cv2\n",
    "import torch\n",
    "import warnings\n",
    "from lightning_objects import LightningModel\n",
    "warnings.filterwarnings('ignore')\n",
    "from config import Configuration\n",
    "import pandas as pd\n",
    "from utils import stratify_split, make_holdout_df, set_seeds\n",
    "from train_manager import TrainManager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def main(experiment_name: str, debug, resume=False,\n",
    "         finetune=False, freeze_bn=True, freeze_feature_extractor=False,\n",
    "         data_csv='/train.csv'):\n",
    "\n",
    "    experiment_dir = os.path.abspath(f'trained-models/{experiment_name}')\n",
    "    print('Experiment directory', experiment_dir)\n",
    "\n",
    "    try:\n",
    "        # -------- SETUP --------\n",
    "        checkpoint_params = None\n",
    "        finetune_model_fnames = None\n",
    "        folds_df, holdout_df = None, None\n",
    "\n",
    "        if not resume and not finetune: # totally new experiment\n",
    "            make_experiment_directory(experiment_dir)\n",
    "            config = Configuration()\n",
    "            config.debug = debug\n",
    "            set_seeds(config.seed)\n",
    "\n",
    "            # -------- LOAD DATA FROM TRAIN FILE --------\n",
    "            data_df = pd.read_csv(config.data_dir + data_csv, engine='python')\n",
    "            data_df, holdout_df = make_holdout_df(data_df, seed=config.seed)\n",
    "            folds_df = stratify_split(data_df, config.fold_num, config.seed, config.target_col)\n",
    "\n",
    "            # -------- SAVE FILES (experiment state: things like resuming, fine tuning, and inference on holdout) --------\n",
    "            folds_df.to_csv(experiment_dir + '/folds.csv', index=False)\n",
    "            holdout_df.to_csv(experiment_dir + '/holdout.csv', index=False)\n",
    "            with open(experiment_dir + '/experiment_config.json', 'w') as f:\n",
    "                json.dump(config.__dict__, f)\n",
    "        elif resume or finetune:\n",
    "            # LOAD DATA FROM SAVED FILES\n",
    "            with open(experiment_dir + '/experiment_config.json', 'r') as f:\n",
    "                config = json.load(f, object_hook=lambda d: SimpleNamespace(**d))\n",
    "                set_seeds(config.seed)\n",
    "                config.debug = debug\n",
    "            \n",
    "            holdout_df = pd.read_csv(experiment_dir + '/holdout.csv', engine='python')\n",
    "            if data_csv != '/train.csv': # create new folds from new data file\n",
    "                data_df = pd.read_csv(config.data_dir + data_csv, engine='python') \n",
    "                data_df, _ = make_holdout_df(data_df, seed=config.seed) # use same previous holdout with noise\n",
    "                folds_df = stratify_split(data_df, config.fold_num, config.seed, config.target_col)\n",
    "            else: # use existing folds\n",
    "                folds_df = pd.read_csv(experiment_dir + '/folds.csv', engine='python')\n",
    "\n",
    "            if finetune and not resume:\n",
    "                print('finetuning...')\n",
    "                # verify there are checkpoints to fine tune\n",
    "                finetune_model_fnames = glob.glob(experiment_dir + '/*fold*.ckpt')\n",
    "                assert len(finetune_model_fnames) > 0\n",
    "                finetune_model_fnames.sort()\n",
    "\n",
    "                # make new directory for tuning experiment with files from training run 1\n",
    "                make_experiment_directory(experiment_dir + '_tune')\n",
    "                for f in os.listdir(experiment_dir):\n",
    "                    print(f\"copying {f} to {experiment_dir + '_tune'}\")\n",
    "                    shutil.copy2(experiment_dir + '/' + f, experiment_dir + '_tune')\n",
    "                experiment_dir += '_tune'\n",
    "                experiment_name += '_tune'\n",
    "    \n",
    "                # overwrite folds from old experiment\n",
    "                folds_df.to_csv(experiment_dir + '/folds.csv', index=False) \n",
    "                \n",
    "            else:\n",
    "                print('resuming from last checkpoint...')\n",
    "                checkpoint_params = get_checkpoint_params(experiment_dir, resume)\n",
    "\n",
    "        assert holdout_df is not None, 'holdout_df is None'\n",
    "        assert folds_df is not None, 'folds_df is None'\n",
    "\n",
    "        # cv2 multithreading seems to go into deadlock with PyTorch data loaders\n",
    "        if config.num_workers > 0:\n",
    "            cv2.setNumThreads(0)\n",
    "\n",
    "        config.lr = 0.00003\n",
    "        config.lr_test = True\n",
    "        config.train_bs = 8\n",
    "\n",
    "        trainer = TrainManager(experiment_name=experiment_name, experiment_dir=experiment_dir,\n",
    "                               folds_df=folds_df, holdout_df=holdout_df,\n",
    "                               checkpoint_params=checkpoint_params, config=config,\n",
    "                               finetune=finetune, freeze_bn=freeze_bn,\n",
    "                               freeze_feature_extractor=freeze_feature_extractor,\n",
    "                               finetune_model_fnames=finetune_model_fnames)\n",
    "        trainer.run()\n",
    "    finally:\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "def make_experiment_directory(name):\n",
    "    try:\n",
    "        os.makedirs(name)\n",
    "    except FileExistsError as e:\n",
    "        print('Experiment already exists. Be sure to resume training appropriately or start a new experiment.')\n",
    "        if e.errno == errno.EEXIST: raise\n",
    "\n",
    "\n",
    "def get_checkpoint_params(basename, resume):\n",
    "    checkpoint_params = None\n",
    "    if resume:\n",
    "        checkpoint_params = {}\n",
    "        model_filenames = glob.glob(basename + '/*fold*.ckpt')\n",
    "        model_filenames.sort()\n",
    "        trained_folds = [re.findall(r'fold\\d+', f)[0][len('fold'):] for f in model_filenames]\n",
    "        most_recent_fold = int(max(trained_folds)) if len(trained_folds) > 0 else 0\n",
    "\n",
    "        checkpoint_params['restart_from'] = most_recent_fold\n",
    "        checkpoint_params['checkpoint_file_path'] = model_filenames[-1]\n",
    "\n",
    "    return checkpoint_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running in debug mode: False\n",
      "Experiment directory /opt/favordata/AI/Felix/kaggle-cassava/trained-models/sgd_coswarm_bnf_bitemp_smooth_weighted_t1=0.3_t2=1.0_89-53\n",
      "finetuning...\n",
      "copying tf_efficientnet_b4_ns_bitempered_smooth=0.05_val_loss=0.103_val_acc=0.889_fold1.ckpt to /opt/favordata/AI/Felix/kaggle-cassava/trained-models/sgd_coswarm_bnf_bitemp_smooth_weighted_t1=0.3_t2=1.0_89-53_tune\n",
      "copying tf_efficientnet_b4_ns_bitempered_smooth=0.05_val_loss=0.109_val_acc=0.878_fold2.ckpt to /opt/favordata/AI/Felix/kaggle-cassava/trained-models/sgd_coswarm_bnf_bitemp_smooth_weighted_t1=0.3_t2=1.0_89-53_tune\n",
      "copying experiment_config.json to /opt/favordata/AI/Felix/kaggle-cassava/trained-models/sgd_coswarm_bnf_bitemp_smooth_weighted_t1=0.3_t2=1.0_89-53_tune\n",
      "copying tf_efficientnet_b4_ns_bitempered_smooth=0.05_val_loss=0.104_val_acc=0.887_fold3.ckpt to /opt/favordata/AI/Felix/kaggle-cassava/trained-models/sgd_coswarm_bnf_bitemp_smooth_weighted_t1=0.3_t2=1.0_89-53_tune\n",
      "copying folds.csv to /opt/favordata/AI/Felix/kaggle-cassava/trained-models/sgd_coswarm_bnf_bitemp_smooth_weighted_t1=0.3_t2=1.0_89-53_tune\n",
      "copying tf_efficientnet_b4_ns_bitempered_smooth=0.05_val_loss=0.101_val_acc=0.892_fold0.ckpt to /opt/favordata/AI/Felix/kaggle-cassava/trained-models/sgd_coswarm_bnf_bitemp_smooth_weighted_t1=0.3_t2=1.0_89-53_tune\n",
      "copying holdout.csv to /opt/favordata/AI/Felix/kaggle-cassava/trained-models/sgd_coswarm_bnf_bitemp_smooth_weighted_t1=0.3_t2=1.0_89-53_tune\n",
      "copying tf_efficientnet_b4_ns_bitempered_smooth=0.05_val_loss=0.108_val_acc=0.883_fold4.ckpt to /opt/favordata/AI/Felix/kaggle-cassava/trained-models/sgd_coswarm_bnf_bitemp_smooth_weighted_t1=0.3_t2=1.0_89-53_tune\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: None, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models to fine tune\n",
      " ['/opt/favordata/AI/Felix/kaggle-cassava/trained-models/sgd_coswarm_bnf_bitemp_smooth_weighted_t1=0.3_t2=1.0_89-53/tf_efficientnet_b4_ns_bitempered_smooth=0.05_val_loss=0.101_val_acc=0.892_fold0.ckpt', '/opt/favordata/AI/Felix/kaggle-cassava/trained-models/sgd_coswarm_bnf_bitemp_smooth_weighted_t1=0.3_t2=1.0_89-53/tf_efficientnet_b4_ns_bitempered_smooth=0.05_val_loss=0.103_val_acc=0.889_fold1.ckpt', '/opt/favordata/AI/Felix/kaggle-cassava/trained-models/sgd_coswarm_bnf_bitemp_smooth_weighted_t1=0.3_t2=1.0_89-53/tf_efficientnet_b4_ns_bitempered_smooth=0.05_val_loss=0.104_val_acc=0.887_fold3.ckpt', '/opt/favordata/AI/Felix/kaggle-cassava/trained-models/sgd_coswarm_bnf_bitemp_smooth_weighted_t1=0.3_t2=1.0_89-53/tf_efficientnet_b4_ns_bitempered_smooth=0.05_val_loss=0.108_val_acc=0.883_fold4.ckpt', '/opt/favordata/AI/Felix/kaggle-cassava/trained-models/sgd_coswarm_bnf_bitemp_smooth_weighted_t1=0.3_t2=1.0_89-53/tf_efficientnet_b4_ns_bitempered_smooth=0.05_val_loss=0.109_val_acc=0.878_fold2.ckpt']\n",
      "folds_df len 17157, holdout_df len 3210\n",
      "Training fold 0\n",
      "Class sample counts [ 675 1382 1482 8724 1462]\n",
      "After class sample counts [2025 2764 3408 8724 3947]\n",
      "conv_stem.weight True\n",
      "bn1.weight False\n",
      "bn1.bias False\n",
      "blocks.0.0.conv_dw.weight True\n",
      "blocks.0.0.bn1.weight False\n",
      "blocks.0.0.bn1.bias False\n",
      "blocks.0.0.se.conv_reduce.weight True\n",
      "blocks.0.0.se.conv_reduce.bias True\n",
      "blocks.0.0.se.conv_expand.weight True\n",
      "blocks.0.0.se.conv_expand.bias True\n",
      "blocks.0.0.conv_pw.weight True\n",
      "blocks.0.0.bn2.weight False\n",
      "blocks.0.0.bn2.bias False\n",
      "blocks.0.1.conv_dw.weight True\n",
      "blocks.0.1.bn1.weight False\n",
      "blocks.0.1.bn1.bias False\n",
      "blocks.0.1.se.conv_reduce.weight True\n",
      "blocks.0.1.se.conv_reduce.bias True\n",
      "blocks.0.1.se.conv_expand.weight True\n",
      "blocks.0.1.se.conv_expand.bias True\n",
      "blocks.0.1.conv_pw.weight True\n",
      "blocks.0.1.bn2.weight False\n",
      "blocks.0.1.bn2.bias False\n",
      "blocks.1.0.conv_pw.weight True\n",
      "blocks.1.0.bn1.weight False\n",
      "blocks.1.0.bn1.bias False\n",
      "blocks.1.0.conv_dw.weight True\n",
      "blocks.1.0.bn2.weight False\n",
      "blocks.1.0.bn2.bias False\n",
      "blocks.1.0.se.conv_reduce.weight True\n",
      "blocks.1.0.se.conv_reduce.bias True\n",
      "blocks.1.0.se.conv_expand.weight True\n",
      "blocks.1.0.se.conv_expand.bias True\n",
      "blocks.1.0.conv_pwl.weight True\n",
      "blocks.1.0.bn3.weight False\n",
      "blocks.1.0.bn3.bias False\n",
      "blocks.1.1.conv_pw.weight True\n",
      "blocks.1.1.bn1.weight False\n",
      "blocks.1.1.bn1.bias False\n",
      "blocks.1.1.conv_dw.weight True\n",
      "blocks.1.1.bn2.weight False\n",
      "blocks.1.1.bn2.bias False\n",
      "blocks.1.1.se.conv_reduce.weight True\n",
      "blocks.1.1.se.conv_reduce.bias True\n",
      "blocks.1.1.se.conv_expand.weight True\n",
      "blocks.1.1.se.conv_expand.bias True\n",
      "blocks.1.1.conv_pwl.weight True\n",
      "blocks.1.1.bn3.weight False\n",
      "blocks.1.1.bn3.bias False\n",
      "blocks.1.2.conv_pw.weight True\n",
      "blocks.1.2.bn1.weight False\n",
      "blocks.1.2.bn1.bias False\n",
      "blocks.1.2.conv_dw.weight True\n",
      "blocks.1.2.bn2.weight False\n",
      "blocks.1.2.bn2.bias False\n",
      "blocks.1.2.se.conv_reduce.weight True\n",
      "blocks.1.2.se.conv_reduce.bias True\n",
      "blocks.1.2.se.conv_expand.weight True\n",
      "blocks.1.2.se.conv_expand.bias True\n",
      "blocks.1.2.conv_pwl.weight True\n",
      "blocks.1.2.bn3.weight False\n",
      "blocks.1.2.bn3.bias False\n",
      "blocks.1.3.conv_pw.weight True\n",
      "blocks.1.3.bn1.weight False\n",
      "blocks.1.3.bn1.bias False\n",
      "blocks.1.3.conv_dw.weight True\n",
      "blocks.1.3.bn2.weight False\n",
      "blocks.1.3.bn2.bias False\n",
      "blocks.1.3.se.conv_reduce.weight True\n",
      "blocks.1.3.se.conv_reduce.bias True\n",
      "blocks.1.3.se.conv_expand.weight True\n",
      "blocks.1.3.se.conv_expand.bias True\n",
      "blocks.1.3.conv_pwl.weight True\n",
      "blocks.1.3.bn3.weight False\n",
      "blocks.1.3.bn3.bias False\n",
      "blocks.2.0.conv_pw.weight True\n",
      "blocks.2.0.bn1.weight False\n",
      "blocks.2.0.bn1.bias False\n",
      "blocks.2.0.conv_dw.weight True\n",
      "blocks.2.0.bn2.weight False\n",
      "blocks.2.0.bn2.bias False\n",
      "blocks.2.0.se.conv_reduce.weight True\n",
      "blocks.2.0.se.conv_reduce.bias True\n",
      "blocks.2.0.se.conv_expand.weight True\n",
      "blocks.2.0.se.conv_expand.bias True\n",
      "blocks.2.0.conv_pwl.weight True\n",
      "blocks.2.0.bn3.weight False\n",
      "blocks.2.0.bn3.bias False\n",
      "blocks.2.1.conv_pw.weight True\n",
      "blocks.2.1.bn1.weight False\n",
      "blocks.2.1.bn1.bias False\n",
      "blocks.2.1.conv_dw.weight True\n",
      "blocks.2.1.bn2.weight False\n",
      "blocks.2.1.bn2.bias False\n",
      "blocks.2.1.se.conv_reduce.weight True\n",
      "blocks.2.1.se.conv_reduce.bias True\n",
      "blocks.2.1.se.conv_expand.weight True\n",
      "blocks.2.1.se.conv_expand.bias True\n",
      "blocks.2.1.conv_pwl.weight True\n",
      "blocks.2.1.bn3.weight False\n",
      "blocks.2.1.bn3.bias False\n",
      "blocks.2.2.conv_pw.weight True\n",
      "blocks.2.2.bn1.weight False\n",
      "blocks.2.2.bn1.bias False\n",
      "blocks.2.2.conv_dw.weight True\n",
      "blocks.2.2.bn2.weight False\n",
      "blocks.2.2.bn2.bias False\n",
      "blocks.2.2.se.conv_reduce.weight True\n",
      "blocks.2.2.se.conv_reduce.bias True\n",
      "blocks.2.2.se.conv_expand.weight True\n",
      "blocks.2.2.se.conv_expand.bias True\n",
      "blocks.2.2.conv_pwl.weight True\n",
      "blocks.2.2.bn3.weight False\n",
      "blocks.2.2.bn3.bias False\n",
      "blocks.2.3.conv_pw.weight True\n",
      "blocks.2.3.bn1.weight False\n",
      "blocks.2.3.bn1.bias False\n",
      "blocks.2.3.conv_dw.weight True\n",
      "blocks.2.3.bn2.weight False\n",
      "blocks.2.3.bn2.bias False\n",
      "blocks.2.3.se.conv_reduce.weight True\n",
      "blocks.2.3.se.conv_reduce.bias True\n",
      "blocks.2.3.se.conv_expand.weight True\n",
      "blocks.2.3.se.conv_expand.bias True\n",
      "blocks.2.3.conv_pwl.weight True\n",
      "blocks.2.3.bn3.weight False\n",
      "blocks.2.3.bn3.bias False\n",
      "blocks.3.0.conv_pw.weight True\n",
      "blocks.3.0.bn1.weight False\n",
      "blocks.3.0.bn1.bias False\n",
      "blocks.3.0.conv_dw.weight True\n",
      "blocks.3.0.bn2.weight False\n",
      "blocks.3.0.bn2.bias False\n",
      "blocks.3.0.se.conv_reduce.weight True\n",
      "blocks.3.0.se.conv_reduce.bias True\n",
      "blocks.3.0.se.conv_expand.weight True\n",
      "blocks.3.0.se.conv_expand.bias True\n",
      "blocks.3.0.conv_pwl.weight True\n",
      "blocks.3.0.bn3.weight False\n",
      "blocks.3.0.bn3.bias False\n",
      "blocks.3.1.conv_pw.weight True\n",
      "blocks.3.1.bn1.weight False\n",
      "blocks.3.1.bn1.bias False\n",
      "blocks.3.1.conv_dw.weight True\n",
      "blocks.3.1.bn2.weight False\n",
      "blocks.3.1.bn2.bias False\n",
      "blocks.3.1.se.conv_reduce.weight True\n",
      "blocks.3.1.se.conv_reduce.bias True\n",
      "blocks.3.1.se.conv_expand.weight True\n",
      "blocks.3.1.se.conv_expand.bias True\n",
      "blocks.3.1.conv_pwl.weight True\n",
      "blocks.3.1.bn3.weight False\n",
      "blocks.3.1.bn3.bias False\n",
      "blocks.3.2.conv_pw.weight True\n",
      "blocks.3.2.bn1.weight False\n",
      "blocks.3.2.bn1.bias False\n",
      "blocks.3.2.conv_dw.weight True\n",
      "blocks.3.2.bn2.weight False\n",
      "blocks.3.2.bn2.bias False\n",
      "blocks.3.2.se.conv_reduce.weight True\n",
      "blocks.3.2.se.conv_reduce.bias True\n",
      "blocks.3.2.se.conv_expand.weight True\n",
      "blocks.3.2.se.conv_expand.bias True\n",
      "blocks.3.2.conv_pwl.weight True\n",
      "blocks.3.2.bn3.weight False\n",
      "blocks.3.2.bn3.bias False\n",
      "blocks.3.3.conv_pw.weight True\n",
      "blocks.3.3.bn1.weight False\n",
      "blocks.3.3.bn1.bias False\n",
      "blocks.3.3.conv_dw.weight True\n",
      "blocks.3.3.bn2.weight False\n",
      "blocks.3.3.bn2.bias False\n",
      "blocks.3.3.se.conv_reduce.weight True\n",
      "blocks.3.3.se.conv_reduce.bias True\n",
      "blocks.3.3.se.conv_expand.weight True\n",
      "blocks.3.3.se.conv_expand.bias True\n",
      "blocks.3.3.conv_pwl.weight True\n",
      "blocks.3.3.bn3.weight False\n",
      "blocks.3.3.bn3.bias False\n",
      "blocks.3.4.conv_pw.weight True\n",
      "blocks.3.4.bn1.weight False\n",
      "blocks.3.4.bn1.bias False\n",
      "blocks.3.4.conv_dw.weight True\n",
      "blocks.3.4.bn2.weight False\n",
      "blocks.3.4.bn2.bias False\n",
      "blocks.3.4.se.conv_reduce.weight True\n",
      "blocks.3.4.se.conv_reduce.bias True\n",
      "blocks.3.4.se.conv_expand.weight True\n",
      "blocks.3.4.se.conv_expand.bias True\n",
      "blocks.3.4.conv_pwl.weight True\n",
      "blocks.3.4.bn3.weight False\n",
      "blocks.3.4.bn3.bias False\n",
      "blocks.3.5.conv_pw.weight True\n",
      "blocks.3.5.bn1.weight False\n",
      "blocks.3.5.bn1.bias False\n",
      "blocks.3.5.conv_dw.weight True\n",
      "blocks.3.5.bn2.weight False\n",
      "blocks.3.5.bn2.bias False\n",
      "blocks.3.5.se.conv_reduce.weight True\n",
      "blocks.3.5.se.conv_reduce.bias True\n",
      "blocks.3.5.se.conv_expand.weight True\n",
      "blocks.3.5.se.conv_expand.bias True\n",
      "blocks.3.5.conv_pwl.weight True\n",
      "blocks.3.5.bn3.weight False\n",
      "blocks.3.5.bn3.bias False\n",
      "blocks.4.0.conv_pw.weight True\n",
      "blocks.4.0.bn1.weight False\n",
      "blocks.4.0.bn1.bias False\n",
      "blocks.4.0.conv_dw.weight True\n",
      "blocks.4.0.bn2.weight False\n",
      "blocks.4.0.bn2.bias False\n",
      "blocks.4.0.se.conv_reduce.weight True\n",
      "blocks.4.0.se.conv_reduce.bias True\n",
      "blocks.4.0.se.conv_expand.weight True\n",
      "blocks.4.0.se.conv_expand.bias True\n",
      "blocks.4.0.conv_pwl.weight True\n",
      "blocks.4.0.bn3.weight False\n",
      "blocks.4.0.bn3.bias False\n",
      "blocks.4.1.conv_pw.weight True\n",
      "blocks.4.1.bn1.weight False\n",
      "blocks.4.1.bn1.bias False\n",
      "blocks.4.1.conv_dw.weight True\n",
      "blocks.4.1.bn2.weight False\n",
      "blocks.4.1.bn2.bias False\n",
      "blocks.4.1.se.conv_reduce.weight True\n",
      "blocks.4.1.se.conv_reduce.bias True\n",
      "blocks.4.1.se.conv_expand.weight True\n",
      "blocks.4.1.se.conv_expand.bias True\n",
      "blocks.4.1.conv_pwl.weight True\n",
      "blocks.4.1.bn3.weight False\n",
      "blocks.4.1.bn3.bias False\n",
      "blocks.4.2.conv_pw.weight True\n",
      "blocks.4.2.bn1.weight False\n",
      "blocks.4.2.bn1.bias False\n",
      "blocks.4.2.conv_dw.weight True\n",
      "blocks.4.2.bn2.weight False\n",
      "blocks.4.2.bn2.bias False\n",
      "blocks.4.2.se.conv_reduce.weight True\n",
      "blocks.4.2.se.conv_reduce.bias True\n",
      "blocks.4.2.se.conv_expand.weight True\n",
      "blocks.4.2.se.conv_expand.bias True\n",
      "blocks.4.2.conv_pwl.weight True\n",
      "blocks.4.2.bn3.weight False\n",
      "blocks.4.2.bn3.bias False\n",
      "blocks.4.3.conv_pw.weight True\n",
      "blocks.4.3.bn1.weight False\n",
      "blocks.4.3.bn1.bias False\n",
      "blocks.4.3.conv_dw.weight True\n",
      "blocks.4.3.bn2.weight False\n",
      "blocks.4.3.bn2.bias False\n",
      "blocks.4.3.se.conv_reduce.weight True\n",
      "blocks.4.3.se.conv_reduce.bias True\n",
      "blocks.4.3.se.conv_expand.weight True\n",
      "blocks.4.3.se.conv_expand.bias True\n",
      "blocks.4.3.conv_pwl.weight True\n",
      "blocks.4.3.bn3.weight False\n",
      "blocks.4.3.bn3.bias False\n",
      "blocks.4.4.conv_pw.weight True\n",
      "blocks.4.4.bn1.weight False\n",
      "blocks.4.4.bn1.bias False\n",
      "blocks.4.4.conv_dw.weight True\n",
      "blocks.4.4.bn2.weight False\n",
      "blocks.4.4.bn2.bias False\n",
      "blocks.4.4.se.conv_reduce.weight True\n",
      "blocks.4.4.se.conv_reduce.bias True\n",
      "blocks.4.4.se.conv_expand.weight True\n",
      "blocks.4.4.se.conv_expand.bias True\n",
      "blocks.4.4.conv_pwl.weight True\n",
      "blocks.4.4.bn3.weight False\n",
      "blocks.4.4.bn3.bias False\n",
      "blocks.4.5.conv_pw.weight True\n",
      "blocks.4.5.bn1.weight False\n",
      "blocks.4.5.bn1.bias False\n",
      "blocks.4.5.conv_dw.weight True\n",
      "blocks.4.5.bn2.weight False\n",
      "blocks.4.5.bn2.bias False\n",
      "blocks.4.5.se.conv_reduce.weight True\n",
      "blocks.4.5.se.conv_reduce.bias True\n",
      "blocks.4.5.se.conv_expand.weight True\n",
      "blocks.4.5.se.conv_expand.bias True\n",
      "blocks.4.5.conv_pwl.weight True\n",
      "blocks.4.5.bn3.weight False\n",
      "blocks.4.5.bn3.bias False\n",
      "blocks.5.0.conv_pw.weight True\n",
      "blocks.5.0.bn1.weight False\n",
      "blocks.5.0.bn1.bias False\n",
      "blocks.5.0.conv_dw.weight True\n",
      "blocks.5.0.bn2.weight False\n",
      "blocks.5.0.bn2.bias False\n",
      "blocks.5.0.se.conv_reduce.weight True\n",
      "blocks.5.0.se.conv_reduce.bias True\n",
      "blocks.5.0.se.conv_expand.weight True\n",
      "blocks.5.0.se.conv_expand.bias True\n",
      "blocks.5.0.conv_pwl.weight True\n",
      "blocks.5.0.bn3.weight False\n",
      "blocks.5.0.bn3.bias False\n",
      "blocks.5.1.conv_pw.weight True\n",
      "blocks.5.1.bn1.weight False\n",
      "blocks.5.1.bn1.bias False\n",
      "blocks.5.1.conv_dw.weight True\n",
      "blocks.5.1.bn2.weight False\n",
      "blocks.5.1.bn2.bias False\n",
      "blocks.5.1.se.conv_reduce.weight True\n",
      "blocks.5.1.se.conv_reduce.bias True\n",
      "blocks.5.1.se.conv_expand.weight True\n",
      "blocks.5.1.se.conv_expand.bias True\n",
      "blocks.5.1.conv_pwl.weight True\n",
      "blocks.5.1.bn3.weight False\n",
      "blocks.5.1.bn3.bias False\n",
      "blocks.5.2.conv_pw.weight True\n",
      "blocks.5.2.bn1.weight False\n",
      "blocks.5.2.bn1.bias False\n",
      "blocks.5.2.conv_dw.weight True\n",
      "blocks.5.2.bn2.weight False\n",
      "blocks.5.2.bn2.bias False\n",
      "blocks.5.2.se.conv_reduce.weight True\n",
      "blocks.5.2.se.conv_reduce.bias True\n",
      "blocks.5.2.se.conv_expand.weight True\n",
      "blocks.5.2.se.conv_expand.bias True\n",
      "blocks.5.2.conv_pwl.weight True\n",
      "blocks.5.2.bn3.weight False\n",
      "blocks.5.2.bn3.bias False\n",
      "blocks.5.3.conv_pw.weight True\n",
      "blocks.5.3.bn1.weight False\n",
      "blocks.5.3.bn1.bias False\n",
      "blocks.5.3.conv_dw.weight True\n",
      "blocks.5.3.bn2.weight False\n",
      "blocks.5.3.bn2.bias False\n",
      "blocks.5.3.se.conv_reduce.weight True\n",
      "blocks.5.3.se.conv_reduce.bias True\n",
      "blocks.5.3.se.conv_expand.weight True\n",
      "blocks.5.3.se.conv_expand.bias True\n",
      "blocks.5.3.conv_pwl.weight True\n",
      "blocks.5.3.bn3.weight False\n",
      "blocks.5.3.bn3.bias False\n",
      "blocks.5.4.conv_pw.weight True\n",
      "blocks.5.4.bn1.weight False\n",
      "blocks.5.4.bn1.bias False\n",
      "blocks.5.4.conv_dw.weight True\n",
      "blocks.5.4.bn2.weight False\n",
      "blocks.5.4.bn2.bias False\n",
      "blocks.5.4.se.conv_reduce.weight True\n",
      "blocks.5.4.se.conv_reduce.bias True\n",
      "blocks.5.4.se.conv_expand.weight True\n",
      "blocks.5.4.se.conv_expand.bias True\n",
      "blocks.5.4.conv_pwl.weight True\n",
      "blocks.5.4.bn3.weight False\n",
      "blocks.5.4.bn3.bias False\n",
      "blocks.5.5.conv_pw.weight True\n",
      "blocks.5.5.bn1.weight False\n",
      "blocks.5.5.bn1.bias False\n",
      "blocks.5.5.conv_dw.weight True\n",
      "blocks.5.5.bn2.weight False\n",
      "blocks.5.5.bn2.bias False\n",
      "blocks.5.5.se.conv_reduce.weight True\n",
      "blocks.5.5.se.conv_reduce.bias True\n",
      "blocks.5.5.se.conv_expand.weight True\n",
      "blocks.5.5.se.conv_expand.bias True\n",
      "blocks.5.5.conv_pwl.weight True\n",
      "blocks.5.5.bn3.weight False\n",
      "blocks.5.5.bn3.bias False\n",
      "blocks.5.6.conv_pw.weight True\n",
      "blocks.5.6.bn1.weight False\n",
      "blocks.5.6.bn1.bias False\n",
      "blocks.5.6.conv_dw.weight True\n",
      "blocks.5.6.bn2.weight False\n",
      "blocks.5.6.bn2.bias False\n",
      "blocks.5.6.se.conv_reduce.weight True\n",
      "blocks.5.6.se.conv_reduce.bias True\n",
      "blocks.5.6.se.conv_expand.weight True\n",
      "blocks.5.6.se.conv_expand.bias True\n",
      "blocks.5.6.conv_pwl.weight True\n",
      "blocks.5.6.bn3.weight False\n",
      "blocks.5.6.bn3.bias False\n",
      "blocks.5.7.conv_pw.weight True\n",
      "blocks.5.7.bn1.weight False\n",
      "blocks.5.7.bn1.bias False\n",
      "blocks.5.7.conv_dw.weight True\n",
      "blocks.5.7.bn2.weight False\n",
      "blocks.5.7.bn2.bias False\n",
      "blocks.5.7.se.conv_reduce.weight True\n",
      "blocks.5.7.se.conv_reduce.bias True\n",
      "blocks.5.7.se.conv_expand.weight True\n",
      "blocks.5.7.se.conv_expand.bias True\n",
      "blocks.5.7.conv_pwl.weight True\n",
      "blocks.5.7.bn3.weight False\n",
      "blocks.5.7.bn3.bias False\n",
      "blocks.6.0.conv_pw.weight True\n",
      "blocks.6.0.bn1.weight False\n",
      "blocks.6.0.bn1.bias False\n",
      "blocks.6.0.conv_dw.weight True\n",
      "blocks.6.0.bn2.weight False\n",
      "blocks.6.0.bn2.bias False\n",
      "blocks.6.0.se.conv_reduce.weight True\n",
      "blocks.6.0.se.conv_reduce.bias True\n",
      "blocks.6.0.se.conv_expand.weight True\n",
      "blocks.6.0.se.conv_expand.bias True\n",
      "blocks.6.0.conv_pwl.weight True\n",
      "blocks.6.0.bn3.weight False\n",
      "blocks.6.0.bn3.bias False\n",
      "blocks.6.1.conv_pw.weight True\n",
      "blocks.6.1.bn1.weight False\n",
      "blocks.6.1.bn1.bias False\n",
      "blocks.6.1.conv_dw.weight True\n",
      "blocks.6.1.bn2.weight False\n",
      "blocks.6.1.bn2.bias False\n",
      "blocks.6.1.se.conv_reduce.weight True\n",
      "blocks.6.1.se.conv_reduce.bias True\n",
      "blocks.6.1.se.conv_expand.weight True\n",
      "blocks.6.1.se.conv_expand.bias True\n",
      "blocks.6.1.conv_pwl.weight True\n",
      "blocks.6.1.bn3.weight False\n",
      "blocks.6.1.bn3.bias False\n",
      "conv_head.weight True\n",
      "bn2.weight False\n",
      "bn2.bias False\n",
      "classifier.weight True\n",
      "classifier.bias True\n",
      "EfficientNet(\n",
      "  (conv_stem): Conv2dSame(3, 48, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
      "  (bn1): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (act1): SiLU(inplace=True)\n",
      "  (blocks): Sequential(\n",
      "    (0): Sequential(\n",
      "      (0): DepthwiseSeparableConv(\n",
      "        (conv_dw): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=48, bias=False)\n",
      "        (bn1): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act1): SiLU(inplace=True)\n",
      "        (se): SqueezeExcite(\n",
      "          (conv_reduce): Conv2d(48, 12, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (act1): SiLU(inplace=True)\n",
      "          (conv_expand): Conv2d(12, 48, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "        (conv_pw): Conv2d(48, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(24, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act2): Identity()\n",
      "      )\n",
      "      (1): DepthwiseSeparableConv(\n",
      "        (conv_dw): Conv2d(24, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=24, bias=False)\n",
      "        (bn1): BatchNorm2d(24, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act1): SiLU(inplace=True)\n",
      "        (se): SqueezeExcite(\n",
      "          (conv_reduce): Conv2d(24, 6, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (act1): SiLU(inplace=True)\n",
      "          (conv_expand): Conv2d(6, 24, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "        (conv_pw): Conv2d(24, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(24, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act2): Identity()\n",
      "      )\n",
      "    )\n",
      "    (1): Sequential(\n",
      "      (0): InvertedResidual(\n",
      "        (conv_pw): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(144, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act1): SiLU(inplace=True)\n",
      "        (conv_dw): Conv2dSame(144, 144, kernel_size=(3, 3), stride=(2, 2), groups=144, bias=False)\n",
      "        (bn2): BatchNorm2d(144, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act2): SiLU(inplace=True)\n",
      "        (se): SqueezeExcite(\n",
      "          (conv_reduce): Conv2d(144, 6, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (act1): SiLU(inplace=True)\n",
      "          (conv_expand): Conv2d(6, 144, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "        (conv_pwl): Conv2d(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (1): InvertedResidual(\n",
      "        (conv_pw): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act1): SiLU(inplace=True)\n",
      "        (conv_dw): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
      "        (bn2): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act2): SiLU(inplace=True)\n",
      "        (se): SqueezeExcite(\n",
      "          (conv_reduce): Conv2d(192, 8, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (act1): SiLU(inplace=True)\n",
      "          (conv_expand): Conv2d(8, 192, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "        (conv_pwl): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (2): InvertedResidual(\n",
      "        (conv_pw): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act1): SiLU(inplace=True)\n",
      "        (conv_dw): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
      "        (bn2): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act2): SiLU(inplace=True)\n",
      "        (se): SqueezeExcite(\n",
      "          (conv_reduce): Conv2d(192, 8, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (act1): SiLU(inplace=True)\n",
      "          (conv_expand): Conv2d(8, 192, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "        (conv_pwl): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (3): InvertedResidual(\n",
      "        (conv_pw): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act1): SiLU(inplace=True)\n",
      "        (conv_dw): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
      "        (bn2): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act2): SiLU(inplace=True)\n",
      "        (se): SqueezeExcite(\n",
      "          (conv_reduce): Conv2d(192, 8, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (act1): SiLU(inplace=True)\n",
      "          (conv_expand): Conv2d(8, 192, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "        (conv_pwl): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (2): Sequential(\n",
      "      (0): InvertedResidual(\n",
      "        (conv_pw): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act1): SiLU(inplace=True)\n",
      "        (conv_dw): Conv2dSame(192, 192, kernel_size=(5, 5), stride=(2, 2), groups=192, bias=False)\n",
      "        (bn2): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act2): SiLU(inplace=True)\n",
      "        (se): SqueezeExcite(\n",
      "          (conv_reduce): Conv2d(192, 8, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (act1): SiLU(inplace=True)\n",
      "          (conv_expand): Conv2d(8, 192, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "        (conv_pwl): Conv2d(192, 56, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(56, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (1): InvertedResidual(\n",
      "        (conv_pw): Conv2d(56, 336, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(336, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act1): SiLU(inplace=True)\n",
      "        (conv_dw): Conv2d(336, 336, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=336, bias=False)\n",
      "        (bn2): BatchNorm2d(336, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act2): SiLU(inplace=True)\n",
      "        (se): SqueezeExcite(\n",
      "          (conv_reduce): Conv2d(336, 14, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (act1): SiLU(inplace=True)\n",
      "          (conv_expand): Conv2d(14, 336, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "        (conv_pwl): Conv2d(336, 56, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(56, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (2): InvertedResidual(\n",
      "        (conv_pw): Conv2d(56, 336, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(336, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act1): SiLU(inplace=True)\n",
      "        (conv_dw): Conv2d(336, 336, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=336, bias=False)\n",
      "        (bn2): BatchNorm2d(336, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act2): SiLU(inplace=True)\n",
      "        (se): SqueezeExcite(\n",
      "          (conv_reduce): Conv2d(336, 14, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (act1): SiLU(inplace=True)\n",
      "          (conv_expand): Conv2d(14, 336, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "        (conv_pwl): Conv2d(336, 56, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(56, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (3): InvertedResidual(\n",
      "        (conv_pw): Conv2d(56, 336, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(336, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act1): SiLU(inplace=True)\n",
      "        (conv_dw): Conv2d(336, 336, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=336, bias=False)\n",
      "        (bn2): BatchNorm2d(336, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act2): SiLU(inplace=True)\n",
      "        (se): SqueezeExcite(\n",
      "          (conv_reduce): Conv2d(336, 14, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (act1): SiLU(inplace=True)\n",
      "          (conv_expand): Conv2d(14, 336, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "        (conv_pwl): Conv2d(336, 56, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(56, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (3): Sequential(\n",
      "      (0): InvertedResidual(\n",
      "        (conv_pw): Conv2d(56, 336, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(336, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act1): SiLU(inplace=True)\n",
      "        (conv_dw): Conv2dSame(336, 336, kernel_size=(3, 3), stride=(2, 2), groups=336, bias=False)\n",
      "        (bn2): BatchNorm2d(336, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act2): SiLU(inplace=True)\n",
      "        (se): SqueezeExcite(\n",
      "          (conv_reduce): Conv2d(336, 14, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (act1): SiLU(inplace=True)\n",
      "          (conv_expand): Conv2d(14, 336, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "        (conv_pwl): Conv2d(336, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(112, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (1): InvertedResidual(\n",
      "        (conv_pw): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act1): SiLU(inplace=True)\n",
      "        (conv_dw): Conv2d(672, 672, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=672, bias=False)\n",
      "        (bn2): BatchNorm2d(672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act2): SiLU(inplace=True)\n",
      "        (se): SqueezeExcite(\n",
      "          (conv_reduce): Conv2d(672, 28, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (act1): SiLU(inplace=True)\n",
      "          (conv_expand): Conv2d(28, 672, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "        (conv_pwl): Conv2d(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(112, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (2): InvertedResidual(\n",
      "        (conv_pw): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act1): SiLU(inplace=True)\n",
      "        (conv_dw): Conv2d(672, 672, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=672, bias=False)\n",
      "        (bn2): BatchNorm2d(672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act2): SiLU(inplace=True)\n",
      "        (se): SqueezeExcite(\n",
      "          (conv_reduce): Conv2d(672, 28, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (act1): SiLU(inplace=True)\n",
      "          (conv_expand): Conv2d(28, 672, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "        (conv_pwl): Conv2d(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(112, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (3): InvertedResidual(\n",
      "        (conv_pw): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act1): SiLU(inplace=True)\n",
      "        (conv_dw): Conv2d(672, 672, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=672, bias=False)\n",
      "        (bn2): BatchNorm2d(672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act2): SiLU(inplace=True)\n",
      "        (se): SqueezeExcite(\n",
      "          (conv_reduce): Conv2d(672, 28, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (act1): SiLU(inplace=True)\n",
      "          (conv_expand): Conv2d(28, 672, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "        (conv_pwl): Conv2d(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(112, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (4): InvertedResidual(\n",
      "        (conv_pw): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act1): SiLU(inplace=True)\n",
      "        (conv_dw): Conv2d(672, 672, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=672, bias=False)\n",
      "        (bn2): BatchNorm2d(672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act2): SiLU(inplace=True)\n",
      "        (se): SqueezeExcite(\n",
      "          (conv_reduce): Conv2d(672, 28, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (act1): SiLU(inplace=True)\n",
      "          (conv_expand): Conv2d(28, 672, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "        (conv_pwl): Conv2d(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(112, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (5): InvertedResidual(\n",
      "        (conv_pw): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act1): SiLU(inplace=True)\n",
      "        (conv_dw): Conv2d(672, 672, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=672, bias=False)\n",
      "        (bn2): BatchNorm2d(672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act2): SiLU(inplace=True)\n",
      "        (se): SqueezeExcite(\n",
      "          (conv_reduce): Conv2d(672, 28, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (act1): SiLU(inplace=True)\n",
      "          (conv_expand): Conv2d(28, 672, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "        (conv_pwl): Conv2d(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(112, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (4): Sequential(\n",
      "      (0): InvertedResidual(\n",
      "        (conv_pw): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act1): SiLU(inplace=True)\n",
      "        (conv_dw): Conv2d(672, 672, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=672, bias=False)\n",
      "        (bn2): BatchNorm2d(672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act2): SiLU(inplace=True)\n",
      "        (se): SqueezeExcite(\n",
      "          (conv_reduce): Conv2d(672, 28, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (act1): SiLU(inplace=True)\n",
      "          (conv_expand): Conv2d(28, 672, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "        (conv_pwl): Conv2d(672, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (1): InvertedResidual(\n",
      "        (conv_pw): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(960, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act1): SiLU(inplace=True)\n",
      "        (conv_dw): Conv2d(960, 960, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=960, bias=False)\n",
      "        (bn2): BatchNorm2d(960, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act2): SiLU(inplace=True)\n",
      "        (se): SqueezeExcite(\n",
      "          (conv_reduce): Conv2d(960, 40, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (act1): SiLU(inplace=True)\n",
      "          (conv_expand): Conv2d(40, 960, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "        (conv_pwl): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (2): InvertedResidual(\n",
      "        (conv_pw): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(960, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act1): SiLU(inplace=True)\n",
      "        (conv_dw): Conv2d(960, 960, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=960, bias=False)\n",
      "        (bn2): BatchNorm2d(960, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act2): SiLU(inplace=True)\n",
      "        (se): SqueezeExcite(\n",
      "          (conv_reduce): Conv2d(960, 40, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (act1): SiLU(inplace=True)\n",
      "          (conv_expand): Conv2d(40, 960, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "        (conv_pwl): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (3): InvertedResidual(\n",
      "        (conv_pw): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(960, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act1): SiLU(inplace=True)\n",
      "        (conv_dw): Conv2d(960, 960, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=960, bias=False)\n",
      "        (bn2): BatchNorm2d(960, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act2): SiLU(inplace=True)\n",
      "        (se): SqueezeExcite(\n",
      "          (conv_reduce): Conv2d(960, 40, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (act1): SiLU(inplace=True)\n",
      "          (conv_expand): Conv2d(40, 960, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "        (conv_pwl): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (4): InvertedResidual(\n",
      "        (conv_pw): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(960, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act1): SiLU(inplace=True)\n",
      "        (conv_dw): Conv2d(960, 960, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=960, bias=False)\n",
      "        (bn2): BatchNorm2d(960, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act2): SiLU(inplace=True)\n",
      "        (se): SqueezeExcite(\n",
      "          (conv_reduce): Conv2d(960, 40, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (act1): SiLU(inplace=True)\n",
      "          (conv_expand): Conv2d(40, 960, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "        (conv_pwl): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (5): InvertedResidual(\n",
      "        (conv_pw): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(960, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act1): SiLU(inplace=True)\n",
      "        (conv_dw): Conv2d(960, 960, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=960, bias=False)\n",
      "        (bn2): BatchNorm2d(960, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act2): SiLU(inplace=True)\n",
      "        (se): SqueezeExcite(\n",
      "          (conv_reduce): Conv2d(960, 40, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (act1): SiLU(inplace=True)\n",
      "          (conv_expand): Conv2d(40, 960, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "        (conv_pwl): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (5): Sequential(\n",
      "      (0): InvertedResidual(\n",
      "        (conv_pw): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(960, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act1): SiLU(inplace=True)\n",
      "        (conv_dw): Conv2dSame(960, 960, kernel_size=(5, 5), stride=(2, 2), groups=960, bias=False)\n",
      "        (bn2): BatchNorm2d(960, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act2): SiLU(inplace=True)\n",
      "        (se): SqueezeExcite(\n",
      "          (conv_reduce): Conv2d(960, 40, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (act1): SiLU(inplace=True)\n",
      "          (conv_expand): Conv2d(40, 960, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "        (conv_pwl): Conv2d(960, 272, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(272, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (1): InvertedResidual(\n",
      "        (conv_pw): Conv2d(272, 1632, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(1632, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act1): SiLU(inplace=True)\n",
      "        (conv_dw): Conv2d(1632, 1632, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1632, bias=False)\n",
      "        (bn2): BatchNorm2d(1632, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act2): SiLU(inplace=True)\n",
      "        (se): SqueezeExcite(\n",
      "          (conv_reduce): Conv2d(1632, 68, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (act1): SiLU(inplace=True)\n",
      "          (conv_expand): Conv2d(68, 1632, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "        (conv_pwl): Conv2d(1632, 272, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(272, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (2): InvertedResidual(\n",
      "        (conv_pw): Conv2d(272, 1632, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(1632, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act1): SiLU(inplace=True)\n",
      "        (conv_dw): Conv2d(1632, 1632, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1632, bias=False)\n",
      "        (bn2): BatchNorm2d(1632, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act2): SiLU(inplace=True)\n",
      "        (se): SqueezeExcite(\n",
      "          (conv_reduce): Conv2d(1632, 68, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (act1): SiLU(inplace=True)\n",
      "          (conv_expand): Conv2d(68, 1632, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "        (conv_pwl): Conv2d(1632, 272, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(272, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (3): InvertedResidual(\n",
      "        (conv_pw): Conv2d(272, 1632, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(1632, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act1): SiLU(inplace=True)\n",
      "        (conv_dw): Conv2d(1632, 1632, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1632, bias=False)\n",
      "        (bn2): BatchNorm2d(1632, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act2): SiLU(inplace=True)\n",
      "        (se): SqueezeExcite(\n",
      "          (conv_reduce): Conv2d(1632, 68, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (act1): SiLU(inplace=True)\n",
      "          (conv_expand): Conv2d(68, 1632, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "        (conv_pwl): Conv2d(1632, 272, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(272, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (4): InvertedResidual(\n",
      "        (conv_pw): Conv2d(272, 1632, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(1632, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act1): SiLU(inplace=True)\n",
      "        (conv_dw): Conv2d(1632, 1632, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1632, bias=False)\n",
      "        (bn2): BatchNorm2d(1632, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act2): SiLU(inplace=True)\n",
      "        (se): SqueezeExcite(\n",
      "          (conv_reduce): Conv2d(1632, 68, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (act1): SiLU(inplace=True)\n",
      "          (conv_expand): Conv2d(68, 1632, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "        (conv_pwl): Conv2d(1632, 272, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(272, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (5): InvertedResidual(\n",
      "        (conv_pw): Conv2d(272, 1632, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(1632, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act1): SiLU(inplace=True)\n",
      "        (conv_dw): Conv2d(1632, 1632, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1632, bias=False)\n",
      "        (bn2): BatchNorm2d(1632, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act2): SiLU(inplace=True)\n",
      "        (se): SqueezeExcite(\n",
      "          (conv_reduce): Conv2d(1632, 68, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (act1): SiLU(inplace=True)\n",
      "          (conv_expand): Conv2d(68, 1632, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "        (conv_pwl): Conv2d(1632, 272, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(272, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (6): InvertedResidual(\n",
      "        (conv_pw): Conv2d(272, 1632, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(1632, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act1): SiLU(inplace=True)\n",
      "        (conv_dw): Conv2d(1632, 1632, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1632, bias=False)\n",
      "        (bn2): BatchNorm2d(1632, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act2): SiLU(inplace=True)\n",
      "        (se): SqueezeExcite(\n",
      "          (conv_reduce): Conv2d(1632, 68, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (act1): SiLU(inplace=True)\n",
      "          (conv_expand): Conv2d(68, 1632, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "        (conv_pwl): Conv2d(1632, 272, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(272, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (7): InvertedResidual(\n",
      "        (conv_pw): Conv2d(272, 1632, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(1632, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act1): SiLU(inplace=True)\n",
      "        (conv_dw): Conv2d(1632, 1632, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1632, bias=False)\n",
      "        (bn2): BatchNorm2d(1632, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act2): SiLU(inplace=True)\n",
      "        (se): SqueezeExcite(\n",
      "          (conv_reduce): Conv2d(1632, 68, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (act1): SiLU(inplace=True)\n",
      "          (conv_expand): Conv2d(68, 1632, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "        (conv_pwl): Conv2d(1632, 272, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(272, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (6): Sequential(\n",
      "      (0): InvertedResidual(\n",
      "        (conv_pw): Conv2d(272, 1632, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(1632, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act1): SiLU(inplace=True)\n",
      "        (conv_dw): Conv2d(1632, 1632, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1632, bias=False)\n",
      "        (bn2): BatchNorm2d(1632, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act2): SiLU(inplace=True)\n",
      "        (se): SqueezeExcite(\n",
      "          (conv_reduce): Conv2d(1632, 68, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (act1): SiLU(inplace=True)\n",
      "          (conv_expand): Conv2d(68, 1632, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "        (conv_pwl): Conv2d(1632, 448, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(448, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (1): InvertedResidual(\n",
      "        (conv_pw): Conv2d(448, 2688, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(2688, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act1): SiLU(inplace=True)\n",
      "        (conv_dw): Conv2d(2688, 2688, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2688, bias=False)\n",
      "        (bn2): BatchNorm2d(2688, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act2): SiLU(inplace=True)\n",
      "        (se): SqueezeExcite(\n",
      "          (conv_reduce): Conv2d(2688, 112, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (act1): SiLU(inplace=True)\n",
      "          (conv_expand): Conv2d(112, 2688, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "        (conv_pwl): Conv2d(2688, 448, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(448, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (conv_head): Conv2d(448, 1792, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (bn2): BatchNorm2d(1792, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (act2): SiLU(inplace=True)\n",
      "  (global_pool): SelectAdaptivePool2d (pool_type=avg, flatten=True)\n",
      "  (classifier): Linear(in_features=1792, out_features=5, bias=True)\n",
      ")\n",
      "Tuning /opt/favordata/AI/Felix/kaggle-cassava/trained-models/sgd_coswarm_bnf_bitemp_smooth_weighted_t1=0.3_t2=1.0_89-53/tf_efficientnet_b4_ns_bitempered_smooth=0.05_val_loss=0.101_val_acc=0.892_fold0.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name           | Type           | Params\n",
      "--------------------------------------------------\n",
      "0 | valid_accuracy | Accuracy       | 0     \n",
      "1 | test_accuracy  | Accuracy       | 0     \n",
      "2 | criterion      | BiTemperedLoss | 0     \n",
      "3 | model          | EfficientNet   | 17.6 M\n",
      "--------------------------------------------------\n",
      "17.4 M    Trainable params\n",
      "125 K     Non-trainable params\n",
      "17.6 M    Total params\n",
      "Finding best initial lr: 100%|██████████| 100/100 [01:37<00:00,  1.01it/s]Restored states from the checkpoint file at /opt/favordata/AI/Felix/kaggle-cassava/trained-models/sgd_coswarm_bnf_bitemp_smooth_weighted_t1=0.3_t2=1.0_89-53_tune/lr_find_temp_model.ckpt\n",
      "Learning rate set to 1e-06\n",
      "\n",
      "  | Name           | Type           | Params\n",
      "--------------------------------------------------\n",
      "0 | valid_accuracy | Accuracy       | 0     \n",
      "1 | test_accuracy  | Accuracy       | 0     \n",
      "2 | criterion      | BiTemperedLoss | 0     \n",
      "3 | model          | EfficientNet   | 17.6 M\n",
      "--------------------------------------------------\n",
      "17.4 M    Trainable params\n",
      "125 K     Non-trainable params\n",
      "17.6 M    Total params\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1:   9%|▉         | 167/1770 [00:42<-1:55:08, -5.48it/s, loss=0.168, v_num=7, val_loss=0.0557, val_acc=0.961, train_loss=0.0484] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Finding best initial lr: 100%|██████████| 100/100 [02:24<00:00,  1.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1:   9%|▉         | 168/1770 [00:42<-1:55:05, -5.42it/s, loss=0.166, v_num=7, val_loss=0.0557, val_acc=0.961, train_loss=0.464] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1:  97%|█████████▋| 1716/1770 [07:12<00:17,  3.04it/s, loss=0.194, v_num=7, val_loss=0.0557, val_acc=0.961, train_loss=0.433]    \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 1:  97%|█████████▋| 1718/1770 [07:14<00:17,  3.03it/s, loss=0.194, v_num=7, val_loss=0.0557, val_acc=0.961, train_loss=0.433]\n",
      "Validating:   4%|▎         | 2/54 [00:02<01:09,  1.34s/it]\u001b[A\n",
      "Epoch 1:  97%|█████████▋| 1720/1770 [07:16<00:16,  3.03it/s, loss=0.194, v_num=7, val_loss=0.0557, val_acc=0.961, train_loss=0.433]\n",
      "Validating:   7%|▋         | 4/54 [00:04<00:43,  1.15it/s]\u001b[A\n",
      "Epoch 1:  97%|█████████▋| 1722/1770 [07:17<00:15,  3.02it/s, loss=0.194, v_num=7, val_loss=0.0557, val_acc=0.961, train_loss=0.433]\n",
      "Validating:  11%|█         | 6/54 [00:05<00:33,  1.43it/s]\u001b[A\n",
      "Epoch 1:  97%|█████████▋| 1724/1770 [07:18<00:15,  3.02it/s, loss=0.194, v_num=7, val_loss=0.0557, val_acc=0.961, train_loss=0.433]\n",
      "Validating:  15%|█▍        | 8/54 [00:06<00:29,  1.58it/s]\u001b[A\n",
      "Epoch 1:  98%|█████████▊| 1726/1770 [07:19<00:14,  3.02it/s, loss=0.194, v_num=7, val_loss=0.0557, val_acc=0.961, train_loss=0.433]\n",
      "Validating:  19%|█▊        | 10/54 [00:07<00:26,  1.65it/s]\u001b[A\n",
      "Epoch 1:  98%|█████████▊| 1728/1770 [07:20<00:13,  3.01it/s, loss=0.194, v_num=7, val_loss=0.0557, val_acc=0.961, train_loss=0.433]\n",
      "Validating:  22%|██▏       | 12/54 [00:08<00:24,  1.70it/s]\u001b[A\n",
      "Epoch 1:  98%|█████████▊| 1730/1770 [07:22<00:13,  3.01it/s, loss=0.194, v_num=7, val_loss=0.0557, val_acc=0.961, train_loss=0.433]\n",
      "Validating:  26%|██▌       | 14/54 [00:10<00:23,  1.72it/s]\u001b[A\n",
      "Epoch 1:  98%|█████████▊| 1732/1770 [07:23<00:12,  3.01it/s, loss=0.194, v_num=7, val_loss=0.0557, val_acc=0.961, train_loss=0.433]\n",
      "Validating:  30%|██▉       | 16/54 [00:11<00:21,  1.73it/s]\u001b[A\n",
      "Epoch 1:  98%|█████████▊| 1734/1770 [07:24<00:11,  3.00it/s, loss=0.194, v_num=7, val_loss=0.0557, val_acc=0.961, train_loss=0.433]\n",
      "Validating:  33%|███▎      | 18/54 [00:12<00:20,  1.73it/s]\u001b[A\n",
      "Epoch 1:  98%|█████████▊| 1736/1770 [07:25<00:11,  3.00it/s, loss=0.194, v_num=7, val_loss=0.0557, val_acc=0.961, train_loss=0.433]\n",
      "Validating:  37%|███▋      | 20/54 [00:13<00:19,  1.74it/s]\u001b[A\n",
      "Epoch 1:  98%|█████████▊| 1738/1770 [07:26<00:10,  3.00it/s, loss=0.194, v_num=7, val_loss=0.0557, val_acc=0.961, train_loss=0.433]\n",
      "Validating:  41%|████      | 22/54 [00:14<00:18,  1.74it/s]\u001b[A\n",
      "Epoch 1:  98%|█████████▊| 1740/1770 [07:27<00:10,  2.99it/s, loss=0.194, v_num=7, val_loss=0.0557, val_acc=0.961, train_loss=0.433]\n",
      "Validating:  44%|████▍     | 24/54 [00:15<00:17,  1.74it/s]\u001b[A\n",
      "Epoch 1:  98%|█████████▊| 1742/1770 [07:28<00:09,  2.99it/s, loss=0.194, v_num=7, val_loss=0.0557, val_acc=0.961, train_loss=0.433]\n",
      "Validating:  48%|████▊     | 26/54 [00:16<00:16,  1.74it/s]\u001b[A\n",
      "Epoch 1:  99%|█████████▊| 1744/1770 [07:30<00:08,  2.99it/s, loss=0.194, v_num=7, val_loss=0.0557, val_acc=0.961, train_loss=0.433]\n",
      "Validating:  52%|█████▏    | 28/54 [00:18<00:14,  1.74it/s]\u001b[A\n",
      "Epoch 1:  99%|█████████▊| 1746/1770 [07:31<00:08,  2.98it/s, loss=0.194, v_num=7, val_loss=0.0557, val_acc=0.961, train_loss=0.433]\n",
      "Validating:  56%|█████▌    | 30/54 [00:19<00:13,  1.74it/s]\u001b[A\n",
      "Epoch 1:  99%|█████████▉| 1748/1770 [07:32<00:07,  2.98it/s, loss=0.194, v_num=7, val_loss=0.0557, val_acc=0.961, train_loss=0.433]\n",
      "Validating:  59%|█████▉    | 32/54 [00:20<00:12,  1.74it/s]\u001b[A\n",
      "Epoch 1:  99%|█████████▉| 1750/1770 [07:33<00:06,  2.98it/s, loss=0.194, v_num=7, val_loss=0.0557, val_acc=0.961, train_loss=0.433]\n",
      "Validating:  63%|██████▎   | 34/54 [00:21<00:11,  1.74it/s]\u001b[A\n",
      "Epoch 1:  99%|█████████▉| 1752/1770 [07:34<00:06,  2.98it/s, loss=0.194, v_num=7, val_loss=0.0557, val_acc=0.961, train_loss=0.433]\n",
      "Validating:  67%|██████▋   | 36/54 [00:22<00:10,  1.74it/s]\u001b[A\n",
      "Epoch 1:  99%|█████████▉| 1754/1770 [07:35<00:05,  2.97it/s, loss=0.194, v_num=7, val_loss=0.0557, val_acc=0.961, train_loss=0.433]\n",
      "Validating:  70%|███████   | 38/54 [00:23<00:09,  1.73it/s]\u001b[A\n",
      "Epoch 1:  99%|█████████▉| 1756/1770 [07:37<00:04,  2.97it/s, loss=0.194, v_num=7, val_loss=0.0557, val_acc=0.961, train_loss=0.433]\n",
      "Validating:  74%|███████▍  | 40/54 [00:24<00:08,  1.74it/s]\u001b[A\n",
      "Epoch 1:  99%|█████████▉| 1758/1770 [07:38<00:04,  2.97it/s, loss=0.194, v_num=7, val_loss=0.0557, val_acc=0.961, train_loss=0.433]\n",
      "Validating:  78%|███████▊  | 42/54 [00:26<00:06,  1.72it/s]\u001b[A\n",
      "Epoch 1:  99%|█████████▉| 1760/1770 [07:39<00:03,  2.96it/s, loss=0.194, v_num=7, val_loss=0.0557, val_acc=0.961, train_loss=0.433]\n",
      "Validating:  81%|████████▏ | 44/54 [00:27<00:05,  1.74it/s]\u001b[A\n",
      "Epoch 1: 100%|█████████▉| 1762/1770 [07:40<00:02,  2.96it/s, loss=0.194, v_num=7, val_loss=0.0557, val_acc=0.961, train_loss=0.433]\n",
      "Validating:  85%|████████▌ | 46/54 [00:28<00:04,  1.76it/s]\u001b[A\n",
      "Epoch 1: 100%|█████████▉| 1764/1770 [07:41<00:02,  2.96it/s, loss=0.194, v_num=7, val_loss=0.0557, val_acc=0.961, train_loss=0.433]\n",
      "Validating:  89%|████████▉ | 48/54 [00:29<00:03,  1.78it/s]\u001b[A\n",
      "Epoch 1: 100%|█████████▉| 1766/1770 [07:42<00:01,  2.95it/s, loss=0.194, v_num=7, val_loss=0.0557, val_acc=0.961, train_loss=0.433]\n",
      "Validating:  93%|█████████▎| 50/54 [00:30<00:02,  1.79it/s]\u001b[A\n",
      "Epoch 1: 100%|█████████▉| 1768/1770 [07:43<00:00,  2.95it/s, loss=0.194, v_num=7, val_loss=0.0557, val_acc=0.961, train_loss=0.433]\n",
      "Validating:  96%|█████████▋| 52/54 [00:31<00:01,  1.79it/s]\u001b[A\n",
      "Epoch 1: 100%|██████████| 1770/1770 [07:44<00:00,  2.95it/s, loss=0.194, v_num=7, val_loss=0.0557, val_acc=0.961, train_loss=0.433]\n",
      "Validating: 100%|██████████| 54/54 [00:33<00:00,  1.33it/s]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, global step 429: val_loss reached 0.05619 (best 0.05619), saving model to \"/opt/favordata/AI/Felix/kaggle-cassava/trained-models/sgd_coswarm_bnf_bitemp_smooth_weighted_t1=0.3_t2=1.0_89-53_tune/tf_efficientnet_b4_ns_bitempered_smooth=0.05_val_loss=0.056_val_acc=0.958_fold0.ckpt\" as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 1770/1770 [07:46<00:00,  2.94it/s, loss=0.194, v_num=7, val_loss=0.0562, val_acc=0.958, train_loss=0.0171]\n",
      "Epoch 2:  97%|█████████▋| 1716/1770 [07:11<00:17,  3.05it/s, loss=0.196, v_num=7, val_loss=0.0562, val_acc=0.958, train_loss=0.273]    \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 2:  97%|█████████▋| 1718/1770 [07:13<00:17,  3.04it/s, loss=0.196, v_num=7, val_loss=0.0562, val_acc=0.958, train_loss=0.273]\n",
      "Validating:   4%|▎         | 2/54 [00:03<01:12,  1.39s/it]\u001b[A\n",
      "Epoch 2:  97%|█████████▋| 1720/1770 [07:14<00:16,  3.04it/s, loss=0.196, v_num=7, val_loss=0.0562, val_acc=0.958, train_loss=0.273]\n",
      "Validating:   7%|▋         | 4/54 [00:04<00:42,  1.19it/s]\u001b[A\n",
      "Epoch 2:  97%|█████████▋| 1722/1770 [07:15<00:15,  3.03it/s, loss=0.196, v_num=7, val_loss=0.0562, val_acc=0.958, train_loss=0.273]\n",
      "Validating:  11%|█         | 6/54 [00:05<00:32,  1.46it/s]\u001b[A\n",
      "Epoch 2:  97%|█████████▋| 1724/1770 [07:17<00:15,  3.03it/s, loss=0.196, v_num=7, val_loss=0.0562, val_acc=0.958, train_loss=0.273]\n",
      "Validating:  15%|█▍        | 8/54 [00:06<00:29,  1.59it/s]\u001b[A\n",
      "Epoch 2:  98%|█████████▊| 1726/1770 [07:18<00:14,  3.03it/s, loss=0.196, v_num=7, val_loss=0.0562, val_acc=0.958, train_loss=0.273]\n",
      "Validating:  19%|█▊        | 10/54 [00:07<00:26,  1.66it/s]\u001b[A\n",
      "Epoch 2:  98%|█████████▊| 1728/1770 [07:19<00:13,  3.02it/s, loss=0.196, v_num=7, val_loss=0.0562, val_acc=0.958, train_loss=0.273]\n",
      "Validating:  22%|██▏       | 12/54 [00:08<00:24,  1.70it/s]\u001b[A\n",
      "Epoch 2:  98%|█████████▊| 1730/1770 [07:20<00:13,  3.02it/s, loss=0.196, v_num=7, val_loss=0.0562, val_acc=0.958, train_loss=0.273]\n",
      "Validating:  26%|██▌       | 14/54 [00:09<00:23,  1.71it/s]\u001b[A\n",
      "Epoch 2:  98%|█████████▊| 1732/1770 [07:21<00:12,  3.02it/s, loss=0.196, v_num=7, val_loss=0.0562, val_acc=0.958, train_loss=0.273]\n",
      "Validating:  30%|██▉       | 16/54 [00:11<00:22,  1.73it/s]\u001b[A\n",
      "Epoch 2:  98%|█████████▊| 1734/1770 [07:22<00:11,  3.01it/s, loss=0.196, v_num=7, val_loss=0.0562, val_acc=0.958, train_loss=0.273]\n",
      "Validating:  33%|███▎      | 18/54 [00:12<00:20,  1.74it/s]\u001b[A\n",
      "Epoch 2:  98%|█████████▊| 1736/1770 [07:24<00:11,  3.01it/s, loss=0.196, v_num=7, val_loss=0.0562, val_acc=0.958, train_loss=0.273]\n",
      "Validating:  37%|███▋      | 20/54 [00:13<00:19,  1.73it/s]\u001b[A\n",
      "Epoch 2:  98%|█████████▊| 1738/1770 [07:25<00:10,  3.01it/s, loss=0.196, v_num=7, val_loss=0.0562, val_acc=0.958, train_loss=0.273]\n",
      "Validating:  41%|████      | 22/54 [00:14<00:18,  1.74it/s]\u001b[A\n",
      "Epoch 2:  98%|█████████▊| 1740/1770 [07:26<00:09,  3.00it/s, loss=0.196, v_num=7, val_loss=0.0562, val_acc=0.958, train_loss=0.273]\n",
      "Validating:  44%|████▍     | 24/54 [00:15<00:17,  1.74it/s]\u001b[A\n",
      "Epoch 2:  98%|█████████▊| 1742/1770 [07:27<00:09,  3.00it/s, loss=0.196, v_num=7, val_loss=0.0562, val_acc=0.958, train_loss=0.273]\n",
      "Validating:  48%|████▊     | 26/54 [00:16<00:16,  1.74it/s]\u001b[A\n",
      "Epoch 2:  99%|█████████▊| 1744/1770 [07:28<00:08,  3.00it/s, loss=0.196, v_num=7, val_loss=0.0562, val_acc=0.958, train_loss=0.273]\n",
      "Validating:  52%|█████▏    | 28/54 [00:18<00:14,  1.74it/s]\u001b[A\n",
      "Epoch 2:  99%|█████████▊| 1746/1770 [07:29<00:08,  2.99it/s, loss=0.196, v_num=7, val_loss=0.0562, val_acc=0.958, train_loss=0.273]\n",
      "Validating:  56%|█████▌    | 30/54 [00:19<00:13,  1.74it/s]\u001b[A\n",
      "Epoch 2:  99%|█████████▉| 1748/1770 [07:30<00:07,  2.99it/s, loss=0.196, v_num=7, val_loss=0.0562, val_acc=0.958, train_loss=0.273]\n",
      "Validating:  59%|█████▉    | 32/54 [00:20<00:12,  1.74it/s]\u001b[A\n",
      "Epoch 2:  99%|█████████▉| 1750/1770 [07:32<00:06,  2.99it/s, loss=0.196, v_num=7, val_loss=0.0562, val_acc=0.958, train_loss=0.273]\n",
      "Validating:  63%|██████▎   | 34/54 [00:21<00:11,  1.74it/s]\u001b[A\n",
      "Epoch 2:  99%|█████████▉| 1752/1770 [07:33<00:06,  2.99it/s, loss=0.196, v_num=7, val_loss=0.0562, val_acc=0.958, train_loss=0.273]\n",
      "Validating:  67%|██████▋   | 36/54 [00:22<00:10,  1.74it/s]\u001b[A\n",
      "Epoch 2:  99%|█████████▉| 1754/1770 [07:34<00:05,  2.98it/s, loss=0.196, v_num=7, val_loss=0.0562, val_acc=0.958, train_loss=0.273]\n",
      "Validating:  70%|███████   | 38/54 [00:23<00:09,  1.74it/s]\u001b[A\n",
      "Epoch 2:  99%|█████████▉| 1756/1770 [07:35<00:04,  2.98it/s, loss=0.196, v_num=7, val_loss=0.0562, val_acc=0.958, train_loss=0.273]\n",
      "Validating:  74%|███████▍  | 40/54 [00:24<00:08,  1.75it/s]\u001b[A\n",
      "Epoch 2:  99%|█████████▉| 1758/1770 [07:36<00:04,  2.98it/s, loss=0.196, v_num=7, val_loss=0.0562, val_acc=0.958, train_loss=0.273]\n",
      "Validating:  78%|███████▊  | 42/54 [00:26<00:06,  1.74it/s]\u001b[A\n",
      "Epoch 2:  99%|█████████▉| 1760/1770 [07:37<00:03,  2.97it/s, loss=0.196, v_num=7, val_loss=0.0562, val_acc=0.958, train_loss=0.273]\n",
      "Validating:  81%|████████▏ | 44/54 [00:27<00:05,  1.74it/s]\u001b[A\n",
      "Epoch 2: 100%|█████████▉| 1762/1770 [07:38<00:02,  2.97it/s, loss=0.196, v_num=7, val_loss=0.0562, val_acc=0.958, train_loss=0.273]\n",
      "Validating:  85%|████████▌ | 46/54 [00:28<00:04,  1.77it/s]\u001b[A\n",
      "Epoch 2: 100%|█████████▉| 1764/1770 [07:40<00:02,  2.97it/s, loss=0.196, v_num=7, val_loss=0.0562, val_acc=0.958, train_loss=0.273]\n",
      "Validating:  89%|████████▉ | 48/54 [00:29<00:03,  1.78it/s]\u001b[A\n",
      "Epoch 2: 100%|█████████▉| 1766/1770 [07:41<00:01,  2.96it/s, loss=0.196, v_num=7, val_loss=0.0562, val_acc=0.958, train_loss=0.273]\n",
      "Validating:  93%|█████████▎| 50/54 [00:30<00:02,  1.79it/s]\u001b[A\n",
      "Epoch 2: 100%|█████████▉| 1768/1770 [07:42<00:00,  2.96it/s, loss=0.196, v_num=7, val_loss=0.0562, val_acc=0.958, train_loss=0.273]\n",
      "Validating:  96%|█████████▋| 52/54 [00:31<00:01,  1.79it/s]\u001b[A\n",
      "Epoch 2: 100%|██████████| 1770/1770 [07:43<00:00,  2.96it/s, loss=0.196, v_num=7, val_loss=0.0562, val_acc=0.958, train_loss=0.273]\n",
      "Validating: 100%|██████████| 54/54 [00:32<00:00,  2.02it/s]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2, step 858: val_loss was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 1770/1770 [07:43<00:00,  2.96it/s, loss=0.196, v_num=7, val_loss=0.0629, val_acc=0.948, train_loss=0.399]\n",
      "Epoch 3:  97%|█████████▋| 1716/1770 [07:11<00:17,  3.05it/s, loss=0.15, v_num=7, val_loss=0.0629, val_acc=0.948, train_loss=0.113]     \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 3:  97%|█████████▋| 1718/1770 [07:13<00:17,  3.04it/s, loss=0.15, v_num=7, val_loss=0.0629, val_acc=0.948, train_loss=0.113]\n",
      "Validating:   4%|▎         | 2/54 [00:02<01:07,  1.29s/it]\u001b[A\n",
      "Epoch 3:  97%|█████████▋| 1720/1770 [07:14<00:16,  3.04it/s, loss=0.15, v_num=7, val_loss=0.0629, val_acc=0.948, train_loss=0.113]\n",
      "Validating:   7%|▋         | 4/54 [00:04<00:43,  1.14it/s]\u001b[A\n",
      "Epoch 3:  97%|█████████▋| 1722/1770 [07:15<00:15,  3.03it/s, loss=0.15, v_num=7, val_loss=0.0629, val_acc=0.948, train_loss=0.113]\n",
      "Validating:  11%|█         | 6/54 [00:05<00:33,  1.42it/s]\u001b[A\n",
      "Epoch 3:  97%|█████████▋| 1724/1770 [07:17<00:15,  3.03it/s, loss=0.15, v_num=7, val_loss=0.0629, val_acc=0.948, train_loss=0.113]\n",
      "Validating:  15%|█▍        | 8/54 [00:06<00:29,  1.58it/s]\u001b[A\n",
      "Epoch 3:  98%|█████████▊| 1726/1770 [07:18<00:14,  3.03it/s, loss=0.15, v_num=7, val_loss=0.0629, val_acc=0.948, train_loss=0.113]\n",
      "Validating:  19%|█▊        | 10/54 [00:07<00:26,  1.66it/s]\u001b[A\n",
      "Epoch 3:  98%|█████████▊| 1728/1770 [07:19<00:13,  3.02it/s, loss=0.15, v_num=7, val_loss=0.0629, val_acc=0.948, train_loss=0.113]\n",
      "Validating:  22%|██▏       | 12/54 [00:08<00:24,  1.70it/s]\u001b[A\n",
      "Epoch 3:  98%|█████████▊| 1730/1770 [07:20<00:13,  3.02it/s, loss=0.15, v_num=7, val_loss=0.0629, val_acc=0.948, train_loss=0.113]\n",
      "Validating:  26%|██▌       | 14/54 [00:09<00:23,  1.72it/s]\u001b[A\n",
      "Epoch 3:  98%|█████████▊| 1732/1770 [07:21<00:12,  3.02it/s, loss=0.15, v_num=7, val_loss=0.0629, val_acc=0.948, train_loss=0.113]\n",
      "Validating:  30%|██▉       | 16/54 [00:11<00:21,  1.73it/s]\u001b[A\n",
      "Epoch 3:  98%|█████████▊| 1734/1770 [07:22<00:11,  3.01it/s, loss=0.15, v_num=7, val_loss=0.0629, val_acc=0.948, train_loss=0.113]\n",
      "Validating:  33%|███▎      | 18/54 [00:12<00:20,  1.74it/s]\u001b[A\n",
      "Epoch 3:  98%|█████████▊| 1736/1770 [07:24<00:11,  3.01it/s, loss=0.15, v_num=7, val_loss=0.0629, val_acc=0.948, train_loss=0.113]\n",
      "Validating:  37%|███▋      | 20/54 [00:13<00:19,  1.74it/s]\u001b[A\n",
      "Epoch 3:  98%|█████████▊| 1738/1770 [07:25<00:10,  3.01it/s, loss=0.15, v_num=7, val_loss=0.0629, val_acc=0.948, train_loss=0.113]\n",
      "Validating:  41%|████      | 22/54 [00:14<00:18,  1.74it/s]\u001b[A\n",
      "Epoch 3:  98%|█████████▊| 1740/1770 [07:26<00:09,  3.00it/s, loss=0.15, v_num=7, val_loss=0.0629, val_acc=0.948, train_loss=0.113]\n",
      "Validating:  44%|████▍     | 24/54 [00:15<00:17,  1.75it/s]\u001b[A\n",
      "Epoch 3:  98%|█████████▊| 1742/1770 [07:27<00:09,  3.00it/s, loss=0.15, v_num=7, val_loss=0.0629, val_acc=0.948, train_loss=0.113]\n",
      "Validating:  48%|████▊     | 26/54 [00:16<00:16,  1.75it/s]\u001b[A\n",
      "Epoch 3:  99%|█████████▊| 1744/1770 [07:28<00:08,  3.00it/s, loss=0.15, v_num=7, val_loss=0.0629, val_acc=0.948, train_loss=0.113]\n",
      "Validating:  52%|█████▏    | 28/54 [00:17<00:14,  1.74it/s]\u001b[A\n",
      "Epoch 3:  99%|█████████▊| 1746/1770 [07:29<00:08,  2.99it/s, loss=0.15, v_num=7, val_loss=0.0629, val_acc=0.948, train_loss=0.113]\n",
      "Validating:  56%|█████▌    | 30/54 [00:19<00:13,  1.74it/s]\u001b[A\n",
      "Epoch 3:  99%|█████████▉| 1748/1770 [07:30<00:07,  2.99it/s, loss=0.15, v_num=7, val_loss=0.0629, val_acc=0.948, train_loss=0.113]\n",
      "Validating:  59%|█████▉    | 32/54 [00:20<00:12,  1.74it/s]\u001b[A\n",
      "Epoch 3:  99%|█████████▉| 1750/1770 [07:32<00:06,  2.99it/s, loss=0.15, v_num=7, val_loss=0.0629, val_acc=0.948, train_loss=0.113]\n",
      "Validating:  63%|██████▎   | 34/54 [00:21<00:11,  1.74it/s]\u001b[A\n",
      "Epoch 3:  99%|█████████▉| 1752/1770 [07:33<00:06,  2.99it/s, loss=0.15, v_num=7, val_loss=0.0629, val_acc=0.948, train_loss=0.113]\n",
      "Validating:  67%|██████▋   | 36/54 [00:22<00:10,  1.74it/s]\u001b[A\n",
      "Epoch 3:  99%|█████████▉| 1754/1770 [07:34<00:05,  2.98it/s, loss=0.15, v_num=7, val_loss=0.0629, val_acc=0.948, train_loss=0.113]\n",
      "Validating:  70%|███████   | 38/54 [00:23<00:09,  1.75it/s]\u001b[A\n",
      "Epoch 3:  99%|█████████▉| 1756/1770 [07:35<00:04,  2.98it/s, loss=0.15, v_num=7, val_loss=0.0629, val_acc=0.948, train_loss=0.113]\n",
      "Validating:  74%|███████▍  | 40/54 [00:24<00:08,  1.74it/s]\u001b[A\n",
      "Epoch 3:  99%|█████████▉| 1758/1770 [07:36<00:04,  2.98it/s, loss=0.15, v_num=7, val_loss=0.0629, val_acc=0.948, train_loss=0.113]\n",
      "Validating:  78%|███████▊  | 42/54 [00:26<00:06,  1.73it/s]\u001b[A\n",
      "Epoch 3:  99%|█████████▉| 1760/1770 [07:37<00:03,  2.97it/s, loss=0.15, v_num=7, val_loss=0.0629, val_acc=0.948, train_loss=0.113]\n",
      "Validating:  81%|████████▏ | 44/54 [00:27<00:05,  1.74it/s]\u001b[A\n",
      "Epoch 3: 100%|█████████▉| 1762/1770 [07:38<00:02,  2.97it/s, loss=0.15, v_num=7, val_loss=0.0629, val_acc=0.948, train_loss=0.113]\n",
      "Validating:  85%|████████▌ | 46/54 [00:28<00:04,  1.76it/s]\u001b[A\n",
      "Epoch 3: 100%|█████████▉| 1764/1770 [07:40<00:02,  2.97it/s, loss=0.15, v_num=7, val_loss=0.0629, val_acc=0.948, train_loss=0.113]\n",
      "Validating:  89%|████████▉ | 48/54 [00:29<00:03,  1.78it/s]\u001b[A\n",
      "Epoch 3: 100%|█████████▉| 1766/1770 [07:41<00:01,  2.96it/s, loss=0.15, v_num=7, val_loss=0.0629, val_acc=0.948, train_loss=0.113]\n",
      "Validating:  93%|█████████▎| 50/54 [00:30<00:02,  1.78it/s]\u001b[A\n",
      "Epoch 3: 100%|█████████▉| 1768/1770 [07:42<00:00,  2.96it/s, loss=0.15, v_num=7, val_loss=0.0629, val_acc=0.948, train_loss=0.113]\n",
      "Validating:  96%|█████████▋| 52/54 [00:31<00:01,  1.79it/s]\u001b[A\n",
      "Epoch 3: 100%|██████████| 1770/1770 [07:43<00:00,  2.96it/s, loss=0.15, v_num=7, val_loss=0.0629, val_acc=0.948, train_loss=0.113]\n",
      "Validating: 100%|██████████| 54/54 [00:32<00:00,  2.01it/s]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3, step 1287: val_loss was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 1770/1770 [07:43<00:00,  2.96it/s, loss=0.15, v_num=7, val_loss=0.0574, val_acc=0.956, train_loss=0.315]\n",
      "Epoch 4:  97%|█████████▋| 1716/1770 [07:10<00:17,  3.06it/s, loss=0.172, v_num=7, val_loss=0.0574, val_acc=0.956, train_loss=0.026]    \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 4:  97%|█████████▋| 1718/1770 [07:12<00:17,  3.05it/s, loss=0.172, v_num=7, val_loss=0.0574, val_acc=0.956, train_loss=0.026]\n",
      "Validating:   4%|▎         | 2/54 [00:02<01:05,  1.27s/it]\u001b[A\n",
      "Epoch 4:  97%|█████████▋| 1720/1770 [07:14<00:16,  3.04it/s, loss=0.172, v_num=7, val_loss=0.0574, val_acc=0.956, train_loss=0.026]\n",
      "Validating:   7%|▋         | 4/54 [00:04<00:42,  1.18it/s]\u001b[A\n",
      "Epoch 4:  97%|█████████▋| 1722/1770 [07:15<00:15,  3.04it/s, loss=0.172, v_num=7, val_loss=0.0574, val_acc=0.956, train_loss=0.026]\n",
      "Validating:  11%|█         | 6/54 [00:05<00:33,  1.45it/s]\u001b[A\n",
      "Epoch 4:  97%|█████████▋| 1724/1770 [07:16<00:15,  3.04it/s, loss=0.172, v_num=7, val_loss=0.0574, val_acc=0.956, train_loss=0.026]\n",
      "Validating:  15%|█▍        | 8/54 [00:06<00:28,  1.59it/s]\u001b[A\n",
      "Epoch 4:  98%|█████████▊| 1726/1770 [07:17<00:14,  3.03it/s, loss=0.172, v_num=7, val_loss=0.0574, val_acc=0.956, train_loss=0.026]\n",
      "Validating:  19%|█▊        | 10/54 [00:07<00:26,  1.66it/s]\u001b[A\n",
      "Epoch 4:  98%|█████████▊| 1728/1770 [07:18<00:13,  3.03it/s, loss=0.172, v_num=7, val_loss=0.0574, val_acc=0.956, train_loss=0.026]\n",
      "Validating:  22%|██▏       | 12/54 [00:08<00:24,  1.70it/s]\u001b[A\n",
      "Epoch 4:  98%|█████████▊| 1730/1770 [07:19<00:13,  3.03it/s, loss=0.172, v_num=7, val_loss=0.0574, val_acc=0.956, train_loss=0.026]\n",
      "Validating:  26%|██▌       | 14/54 [00:09<00:23,  1.72it/s]\u001b[A\n",
      "Epoch 4:  98%|█████████▊| 1732/1770 [07:20<00:12,  3.02it/s, loss=0.172, v_num=7, val_loss=0.0574, val_acc=0.956, train_loss=0.026]\n",
      "Validating:  30%|██▉       | 16/54 [00:11<00:22,  1.73it/s]\u001b[A\n",
      "Epoch 4:  98%|█████████▊| 1734/1770 [07:22<00:11,  3.02it/s, loss=0.172, v_num=7, val_loss=0.0574, val_acc=0.956, train_loss=0.026]\n",
      "Validating:  33%|███▎      | 18/54 [00:12<00:20,  1.73it/s]\u001b[A\n",
      "Epoch 4:  98%|█████████▊| 1736/1770 [07:23<00:11,  3.02it/s, loss=0.172, v_num=7, val_loss=0.0574, val_acc=0.956, train_loss=0.026]\n",
      "Validating:  37%|███▋      | 20/54 [00:13<00:19,  1.74it/s]\u001b[A\n",
      "Epoch 4:  98%|█████████▊| 1738/1770 [07:24<00:10,  3.01it/s, loss=0.172, v_num=7, val_loss=0.0574, val_acc=0.956, train_loss=0.026]\n",
      "Validating:  41%|████      | 22/54 [00:14<00:18,  1.74it/s]\u001b[A\n",
      "Epoch 4:  98%|█████████▊| 1740/1770 [07:25<00:09,  3.01it/s, loss=0.172, v_num=7, val_loss=0.0574, val_acc=0.956, train_loss=0.026]\n",
      "Validating:  44%|████▍     | 24/54 [00:15<00:17,  1.74it/s]\u001b[A\n",
      "Epoch 4:  98%|█████████▊| 1742/1770 [07:26<00:09,  3.01it/s, loss=0.172, v_num=7, val_loss=0.0574, val_acc=0.956, train_loss=0.026]\n",
      "Validating:  48%|████▊     | 26/54 [00:16<00:16,  1.74it/s]\u001b[A\n",
      "Epoch 4:  99%|█████████▊| 1744/1770 [07:27<00:08,  3.00it/s, loss=0.172, v_num=7, val_loss=0.0574, val_acc=0.956, train_loss=0.026]\n",
      "Validating:  52%|█████▏    | 28/54 [00:17<00:14,  1.74it/s]\u001b[A\n",
      "Epoch 4:  99%|█████████▊| 1746/1770 [07:29<00:08,  3.00it/s, loss=0.172, v_num=7, val_loss=0.0574, val_acc=0.956, train_loss=0.026]\n",
      "Validating:  56%|█████▌    | 30/54 [00:19<00:13,  1.74it/s]\u001b[A\n",
      "Epoch 4:  99%|█████████▉| 1748/1770 [07:30<00:07,  3.00it/s, loss=0.172, v_num=7, val_loss=0.0574, val_acc=0.956, train_loss=0.026]\n",
      "Validating:  59%|█████▉    | 32/54 [00:20<00:12,  1.74it/s]\u001b[A\n",
      "Epoch 4:  99%|█████████▉| 1750/1770 [07:31<00:06,  2.99it/s, loss=0.172, v_num=7, val_loss=0.0574, val_acc=0.956, train_loss=0.026]\n",
      "Validating:  63%|██████▎   | 34/54 [00:21<00:11,  1.74it/s]\u001b[A\n",
      "Epoch 4:  99%|█████████▉| 1752/1770 [07:32<00:06,  2.99it/s, loss=0.172, v_num=7, val_loss=0.0574, val_acc=0.956, train_loss=0.026]\n",
      "Validating:  67%|██████▋   | 36/54 [00:22<00:10,  1.74it/s]\u001b[A\n",
      "Epoch 4:  99%|█████████▉| 1754/1770 [07:33<00:05,  2.99it/s, loss=0.172, v_num=7, val_loss=0.0574, val_acc=0.956, train_loss=0.026]\n",
      "Validating:  70%|███████   | 38/54 [00:23<00:09,  1.74it/s]\u001b[A\n",
      "Epoch 4:  99%|█████████▉| 1756/1770 [07:34<00:04,  2.98it/s, loss=0.172, v_num=7, val_loss=0.0574, val_acc=0.956, train_loss=0.026]\n",
      "Validating:  74%|███████▍  | 40/54 [00:24<00:08,  1.74it/s]\u001b[A\n",
      "Epoch 4:  99%|█████████▉| 1758/1770 [07:35<00:04,  2.98it/s, loss=0.172, v_num=7, val_loss=0.0574, val_acc=0.956, train_loss=0.026]\n",
      "Validating:  78%|███████▊  | 42/54 [00:25<00:06,  1.74it/s]\u001b[A\n",
      "Epoch 4:  99%|█████████▉| 1760/1770 [07:37<00:03,  2.98it/s, loss=0.172, v_num=7, val_loss=0.0574, val_acc=0.956, train_loss=0.026]\n",
      "Validating:  81%|████████▏ | 44/54 [00:27<00:05,  1.74it/s]\u001b[A\n",
      "Epoch 4: 100%|█████████▉| 1762/1770 [07:38<00:02,  2.97it/s, loss=0.172, v_num=7, val_loss=0.0574, val_acc=0.956, train_loss=0.026]\n",
      "Validating:  85%|████████▌ | 46/54 [00:28<00:04,  1.77it/s]\u001b[A\n",
      "Epoch 4: 100%|█████████▉| 1764/1770 [07:39<00:02,  2.97it/s, loss=0.172, v_num=7, val_loss=0.0574, val_acc=0.956, train_loss=0.026]\n",
      "Validating:  89%|████████▉ | 48/54 [00:29<00:03,  1.78it/s]\u001b[A\n",
      "Epoch 4: 100%|█████████▉| 1766/1770 [07:40<00:01,  2.97it/s, loss=0.172, v_num=7, val_loss=0.0574, val_acc=0.956, train_loss=0.026]\n",
      "Validating:  93%|█████████▎| 50/54 [00:30<00:02,  1.79it/s]\u001b[A\n",
      "Epoch 4: 100%|█████████▉| 1768/1770 [07:41<00:00,  2.97it/s, loss=0.172, v_num=7, val_loss=0.0574, val_acc=0.956, train_loss=0.026]\n",
      "Validating:  96%|█████████▋| 52/54 [00:31<00:01,  1.79it/s]\u001b[A\n",
      "Epoch 4: 100%|██████████| 1770/1770 [07:42<00:00,  2.96it/s, loss=0.172, v_num=7, val_loss=0.0574, val_acc=0.956, train_loss=0.026]\n",
      "Validating: 100%|██████████| 54/54 [00:32<00:00,  2.02it/s]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4, global step 1716: val_loss reached 0.05545 (best 0.05545), saving model to \"/opt/favordata/AI/Felix/kaggle-cassava/trained-models/sgd_coswarm_bnf_bitemp_smooth_weighted_t1=0.3_t2=1.0_89-53_tune/tf_efficientnet_b4_ns_bitempered_smooth=0.05_val_loss=0.055_val_acc=0.956_fold0.ckpt\" as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 1770/1770 [07:43<00:00,  2.96it/s, loss=0.172, v_num=7, val_loss=0.0554, val_acc=0.956, train_loss=0.161]\n",
      "Epoch 5:  97%|█████████▋| 1716/1770 [07:11<00:17,  3.06it/s, loss=0.186, v_num=7, val_loss=0.0554, val_acc=0.956, train_loss=0.0379]   \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 5:  97%|█████████▋| 1718/1770 [07:13<00:17,  3.04it/s, loss=0.186, v_num=7, val_loss=0.0554, val_acc=0.956, train_loss=0.0379]\n",
      "Validating:   4%|▎         | 2/54 [00:02<01:06,  1.28s/it]\u001b[A\n",
      "Epoch 5:  97%|█████████▋| 1720/1770 [07:14<00:16,  3.04it/s, loss=0.186, v_num=7, val_loss=0.0554, val_acc=0.956, train_loss=0.0379]\n",
      "Validating:   7%|▋         | 4/54 [00:04<00:41,  1.21it/s]\u001b[A\n",
      "Epoch 5:  97%|█████████▋| 1722/1770 [07:15<00:15,  3.04it/s, loss=0.186, v_num=7, val_loss=0.0554, val_acc=0.956, train_loss=0.0379]\n",
      "Validating:  11%|█         | 6/54 [00:05<00:32,  1.47it/s]\u001b[A\n",
      "Epoch 5:  97%|█████████▋| 1724/1770 [07:16<00:15,  3.03it/s, loss=0.186, v_num=7, val_loss=0.0554, val_acc=0.956, train_loss=0.0379]\n",
      "Validating:  15%|█▍        | 8/54 [00:06<00:28,  1.61it/s]\u001b[A\n",
      "Epoch 5:  98%|█████████▊| 1726/1770 [07:17<00:14,  3.03it/s, loss=0.186, v_num=7, val_loss=0.0554, val_acc=0.956, train_loss=0.0379]\n",
      "Validating:  19%|█▊        | 10/54 [00:07<00:26,  1.68it/s]\u001b[A\n",
      "Epoch 5:  98%|█████████▊| 1728/1770 [07:19<00:13,  3.03it/s, loss=0.186, v_num=7, val_loss=0.0554, val_acc=0.956, train_loss=0.0379]\n",
      "Validating:  22%|██▏       | 12/54 [00:08<00:24,  1.71it/s]\u001b[A\n",
      "Epoch 5:  98%|█████████▊| 1730/1770 [07:20<00:13,  3.02it/s, loss=0.186, v_num=7, val_loss=0.0554, val_acc=0.956, train_loss=0.0379]\n",
      "Validating:  26%|██▌       | 14/54 [00:09<00:23,  1.73it/s]\u001b[A\n",
      "Epoch 5:  98%|█████████▊| 1732/1770 [07:21<00:12,  3.02it/s, loss=0.186, v_num=7, val_loss=0.0554, val_acc=0.956, train_loss=0.0379]\n",
      "Validating:  30%|██▉       | 16/54 [00:10<00:21,  1.73it/s]\u001b[A\n",
      "Epoch 5:  98%|█████████▊| 1734/1770 [07:22<00:11,  3.02it/s, loss=0.186, v_num=7, val_loss=0.0554, val_acc=0.956, train_loss=0.0379]\n",
      "Validating:  33%|███▎      | 18/54 [00:12<00:20,  1.74it/s]\u001b[A\n",
      "Epoch 5:  98%|█████████▊| 1736/1770 [07:23<00:11,  3.01it/s, loss=0.186, v_num=7, val_loss=0.0554, val_acc=0.956, train_loss=0.0379]\n",
      "Validating:  37%|███▋      | 20/54 [00:13<00:19,  1.74it/s]\u001b[A\n",
      "Epoch 5:  98%|█████████▊| 1738/1770 [07:24<00:10,  3.01it/s, loss=0.186, v_num=7, val_loss=0.0554, val_acc=0.956, train_loss=0.0379]\n",
      "Validating:  41%|████      | 22/54 [00:14<00:18,  1.74it/s]\u001b[A\n",
      "Epoch 5:  98%|█████████▊| 1740/1770 [07:26<00:09,  3.01it/s, loss=0.186, v_num=7, val_loss=0.0554, val_acc=0.956, train_loss=0.0379]\n",
      "Validating:  44%|████▍     | 24/54 [00:15<00:17,  1.74it/s]\u001b[A\n",
      "Epoch 5:  98%|█████████▊| 1742/1770 [07:27<00:09,  3.00it/s, loss=0.186, v_num=7, val_loss=0.0554, val_acc=0.956, train_loss=0.0379]\n",
      "Validating:  48%|████▊     | 26/54 [00:16<00:16,  1.74it/s]\u001b[A\n",
      "Epoch 5:  99%|█████████▊| 1744/1770 [07:28<00:08,  3.00it/s, loss=0.186, v_num=7, val_loss=0.0554, val_acc=0.956, train_loss=0.0379]\n",
      "Validating:  52%|█████▏    | 28/54 [00:17<00:14,  1.74it/s]\u001b[A\n",
      "Epoch 5:  99%|█████████▊| 1746/1770 [07:29<00:08,  3.00it/s, loss=0.186, v_num=7, val_loss=0.0554, val_acc=0.956, train_loss=0.0379]\n",
      "Validating:  56%|█████▌    | 30/54 [00:18<00:13,  1.73it/s]\u001b[A\n",
      "Epoch 5:  99%|█████████▉| 1748/1770 [07:30<00:07,  2.99it/s, loss=0.186, v_num=7, val_loss=0.0554, val_acc=0.956, train_loss=0.0379]\n",
      "Validating:  59%|█████▉    | 32/54 [00:20<00:12,  1.74it/s]\u001b[A\n",
      "Epoch 5:  99%|█████████▉| 1750/1770 [07:31<00:06,  2.99it/s, loss=0.186, v_num=7, val_loss=0.0554, val_acc=0.956, train_loss=0.0379]\n",
      "Validating:  63%|██████▎   | 34/54 [00:21<00:11,  1.74it/s]\u001b[A\n",
      "Epoch 5:  99%|█████████▉| 1752/1770 [07:32<00:06,  2.99it/s, loss=0.186, v_num=7, val_loss=0.0554, val_acc=0.956, train_loss=0.0379]\n",
      "Validating:  67%|██████▋   | 36/54 [00:22<00:10,  1.74it/s]\u001b[A\n",
      "Epoch 5:  99%|█████████▉| 1754/1770 [07:34<00:05,  2.98it/s, loss=0.186, v_num=7, val_loss=0.0554, val_acc=0.956, train_loss=0.0379]\n",
      "Validating:  70%|███████   | 38/54 [00:23<00:09,  1.74it/s]\u001b[A\n",
      "Epoch 5:  99%|█████████▉| 1756/1770 [07:35<00:04,  2.98it/s, loss=0.186, v_num=7, val_loss=0.0554, val_acc=0.956, train_loss=0.0379]\n",
      "Validating:  74%|███████▍  | 40/54 [00:24<00:08,  1.74it/s]\u001b[A\n",
      "Epoch 5:  99%|█████████▉| 1758/1770 [07:36<00:04,  2.98it/s, loss=0.186, v_num=7, val_loss=0.0554, val_acc=0.956, train_loss=0.0379]\n",
      "Validating:  78%|███████▊  | 42/54 [00:25<00:06,  1.74it/s]\u001b[A\n",
      "Epoch 5:  99%|█████████▉| 1760/1770 [07:37<00:03,  2.97it/s, loss=0.186, v_num=7, val_loss=0.0554, val_acc=0.956, train_loss=0.0379]\n",
      "Validating:  81%|████████▏ | 44/54 [00:27<00:05,  1.74it/s]\u001b[A\n",
      "Epoch 5: 100%|█████████▉| 1762/1770 [07:38<00:02,  2.97it/s, loss=0.186, v_num=7, val_loss=0.0554, val_acc=0.956, train_loss=0.0379]\n",
      "Validating:  85%|████████▌ | 46/54 [00:28<00:04,  1.77it/s]\u001b[A\n",
      "Epoch 5: 100%|█████████▉| 1764/1770 [07:39<00:02,  2.97it/s, loss=0.186, v_num=7, val_loss=0.0554, val_acc=0.956, train_loss=0.0379]\n",
      "Validating:  89%|████████▉ | 48/54 [00:29<00:03,  1.78it/s]\u001b[A\n",
      "Epoch 5: 100%|█████████▉| 1766/1770 [07:40<00:01,  2.97it/s, loss=0.186, v_num=7, val_loss=0.0554, val_acc=0.956, train_loss=0.0379]\n",
      "Validating:  93%|█████████▎| 50/54 [00:30<00:02,  1.79it/s]\u001b[A\n",
      "Epoch 5: 100%|█████████▉| 1768/1770 [07:41<00:00,  2.96it/s, loss=0.186, v_num=7, val_loss=0.0554, val_acc=0.956, train_loss=0.0379]\n",
      "Validating:  96%|█████████▋| 52/54 [00:31<00:01,  1.79it/s]\u001b[A\n",
      "Epoch 5: 100%|██████████| 1770/1770 [07:43<00:00,  2.96it/s, loss=0.186, v_num=7, val_loss=0.0554, val_acc=0.956, train_loss=0.0379]\n",
      "Validating: 100%|██████████| 54/54 [00:32<00:00,  2.02it/s]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5, step 2145: val_loss was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|██████████| 1770/1770 [07:43<00:00,  2.96it/s, loss=0.186, v_num=7, val_loss=0.058, val_acc=0.955, train_loss=0.361]  \n",
      "Epoch 6:  97%|█████████▋| 1716/1770 [07:10<00:17,  3.06it/s, loss=0.194, v_num=7, val_loss=0.058, val_acc=0.955, train_loss=0.738]    \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 6:  97%|█████████▋| 1718/1770 [07:13<00:17,  3.05it/s, loss=0.194, v_num=7, val_loss=0.058, val_acc=0.955, train_loss=0.738]\n",
      "Validating:   4%|▎         | 2/54 [00:02<01:05,  1.26s/it]\u001b[A\n",
      "Epoch 6:  97%|█████████▋| 1720/1770 [07:14<00:16,  3.04it/s, loss=0.194, v_num=7, val_loss=0.058, val_acc=0.955, train_loss=0.738]\n",
      "Validating:   7%|▋         | 4/54 [00:04<00:42,  1.19it/s]\u001b[A\n",
      "Epoch 6:  97%|█████████▋| 1722/1770 [07:15<00:15,  3.04it/s, loss=0.194, v_num=7, val_loss=0.058, val_acc=0.955, train_loss=0.738]\n",
      "Validating:  11%|█         | 6/54 [00:05<00:32,  1.46it/s]\u001b[A\n",
      "Epoch 6:  97%|█████████▋| 1724/1770 [07:16<00:15,  3.03it/s, loss=0.194, v_num=7, val_loss=0.058, val_acc=0.955, train_loss=0.738]\n",
      "Validating:  15%|█▍        | 8/54 [00:06<00:28,  1.60it/s]\u001b[A\n",
      "Epoch 6:  98%|█████████▊| 1726/1770 [07:17<00:14,  3.03it/s, loss=0.194, v_num=7, val_loss=0.058, val_acc=0.955, train_loss=0.738]\n",
      "Validating:  19%|█▊        | 10/54 [00:07<00:26,  1.67it/s]\u001b[A\n",
      "Epoch 6:  98%|█████████▊| 1728/1770 [07:18<00:13,  3.03it/s, loss=0.194, v_num=7, val_loss=0.058, val_acc=0.955, train_loss=0.738]\n",
      "Validating:  22%|██▏       | 12/54 [00:08<00:24,  1.71it/s]\u001b[A\n",
      "Epoch 6:  98%|█████████▊| 1730/1770 [07:20<00:13,  3.02it/s, loss=0.194, v_num=7, val_loss=0.058, val_acc=0.955, train_loss=0.738]\n",
      "Validating:  26%|██▌       | 14/54 [00:09<00:23,  1.72it/s]\u001b[A\n",
      "Epoch 6:  98%|█████████▊| 1732/1770 [07:21<00:12,  3.02it/s, loss=0.194, v_num=7, val_loss=0.058, val_acc=0.955, train_loss=0.738]\n",
      "Validating:  30%|██▉       | 16/54 [00:10<00:21,  1.73it/s]\u001b[A\n",
      "Epoch 6:  98%|█████████▊| 1734/1770 [07:22<00:11,  3.02it/s, loss=0.194, v_num=7, val_loss=0.058, val_acc=0.955, train_loss=0.738]\n",
      "Validating:  33%|███▎      | 18/54 [00:12<00:20,  1.74it/s]\u001b[A\n",
      "Epoch 6:  98%|█████████▊| 1736/1770 [07:23<00:11,  3.01it/s, loss=0.194, v_num=7, val_loss=0.058, val_acc=0.955, train_loss=0.738]\n",
      "Validating:  37%|███▋      | 20/54 [00:13<00:19,  1.74it/s]\u001b[A\n",
      "Epoch 6:  98%|█████████▊| 1738/1770 [07:24<00:10,  3.01it/s, loss=0.194, v_num=7, val_loss=0.058, val_acc=0.955, train_loss=0.738]\n",
      "Validating:  41%|████      | 22/54 [00:14<00:18,  1.74it/s]\u001b[A\n",
      "Epoch 6:  98%|█████████▊| 1740/1770 [07:25<00:09,  3.01it/s, loss=0.194, v_num=7, val_loss=0.058, val_acc=0.955, train_loss=0.738]\n",
      "Validating:  44%|████▍     | 24/54 [00:15<00:17,  1.74it/s]\u001b[A\n",
      "Epoch 6:  98%|█████████▊| 1742/1770 [07:27<00:09,  3.00it/s, loss=0.194, v_num=7, val_loss=0.058, val_acc=0.955, train_loss=0.738]\n",
      "Validating:  48%|████▊     | 26/54 [00:16<00:16,  1.73it/s]\u001b[A\n",
      "Epoch 6:  99%|█████████▊| 1744/1770 [07:28<00:08,  3.00it/s, loss=0.194, v_num=7, val_loss=0.058, val_acc=0.955, train_loss=0.738]\n",
      "Validating:  52%|█████▏    | 28/54 [00:17<00:14,  1.74it/s]\u001b[A\n",
      "Epoch 6:  99%|█████████▊| 1746/1770 [07:29<00:08,  3.00it/s, loss=0.194, v_num=7, val_loss=0.058, val_acc=0.955, train_loss=0.738]\n",
      "Validating:  56%|█████▌    | 30/54 [00:19<00:13,  1.74it/s]\u001b[A\n",
      "Epoch 6:  99%|█████████▉| 1748/1770 [07:30<00:07,  2.99it/s, loss=0.194, v_num=7, val_loss=0.058, val_acc=0.955, train_loss=0.738]\n",
      "Validating:  59%|█████▉    | 32/54 [00:20<00:12,  1.72it/s]\u001b[A\n",
      "Epoch 6:  99%|█████████▉| 1750/1770 [07:31<00:06,  2.99it/s, loss=0.194, v_num=7, val_loss=0.058, val_acc=0.955, train_loss=0.738]\n",
      "Validating:  63%|██████▎   | 34/54 [00:21<00:11,  1.73it/s]\u001b[A\n",
      "Epoch 6:  99%|█████████▉| 1752/1770 [07:32<00:06,  2.99it/s, loss=0.194, v_num=7, val_loss=0.058, val_acc=0.955, train_loss=0.738]\n",
      "Validating:  67%|██████▋   | 36/54 [00:22<00:10,  1.73it/s]\u001b[A\n",
      "Epoch 6:  99%|█████████▉| 1754/1770 [07:33<00:05,  2.98it/s, loss=0.194, v_num=7, val_loss=0.058, val_acc=0.955, train_loss=0.738]\n",
      "Validating:  70%|███████   | 38/54 [00:23<00:09,  1.74it/s]\u001b[A\n",
      "Epoch 6:  99%|█████████▉| 1756/1770 [07:35<00:04,  2.98it/s, loss=0.194, v_num=7, val_loss=0.058, val_acc=0.955, train_loss=0.738]\n",
      "Validating:  74%|███████▍  | 40/54 [00:24<00:08,  1.74it/s]\u001b[A\n",
      "Epoch 6:  99%|█████████▉| 1758/1770 [07:36<00:04,  2.98it/s, loss=0.194, v_num=7, val_loss=0.058, val_acc=0.955, train_loss=0.738]\n",
      "Validating:  78%|███████▊  | 42/54 [00:25<00:06,  1.73it/s]\u001b[A\n",
      "Epoch 6:  99%|█████████▉| 1760/1770 [07:37<00:03,  2.98it/s, loss=0.194, v_num=7, val_loss=0.058, val_acc=0.955, train_loss=0.738]\n",
      "Validating:  81%|████████▏ | 44/54 [00:27<00:05,  1.73it/s]\u001b[A\n",
      "Epoch 6: 100%|█████████▉| 1762/1770 [07:38<00:02,  2.97it/s, loss=0.194, v_num=7, val_loss=0.058, val_acc=0.955, train_loss=0.738]\n",
      "Validating:  85%|████████▌ | 46/54 [00:28<00:04,  1.76it/s]\u001b[A\n",
      "Epoch 6: 100%|█████████▉| 1764/1770 [07:39<00:02,  2.97it/s, loss=0.194, v_num=7, val_loss=0.058, val_acc=0.955, train_loss=0.738]\n",
      "Validating:  89%|████████▉ | 48/54 [00:29<00:03,  1.78it/s]\u001b[A\n",
      "Epoch 6: 100%|█████████▉| 1766/1770 [07:40<00:01,  2.97it/s, loss=0.194, v_num=7, val_loss=0.058, val_acc=0.955, train_loss=0.738]\n",
      "Validating:  93%|█████████▎| 50/54 [00:30<00:02,  1.78it/s]\u001b[A\n",
      "Epoch 6: 100%|█████████▉| 1768/1770 [07:41<00:00,  2.96it/s, loss=0.194, v_num=7, val_loss=0.058, val_acc=0.955, train_loss=0.738]\n",
      "Validating:  96%|█████████▋| 52/54 [00:31<00:01,  1.79it/s]\u001b[A\n",
      "Epoch 6: 100%|██████████| 1770/1770 [07:43<00:00,  2.96it/s, loss=0.194, v_num=7, val_loss=0.058, val_acc=0.955, train_loss=0.738]\n",
      "Validating: 100%|██████████| 54/54 [00:32<00:00,  2.02it/s]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6, step 2574: val_loss was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: 100%|██████████| 1770/1770 [07:43<00:00,  2.96it/s, loss=0.194, v_num=7, val_loss=0.0558, val_acc=0.957, train_loss=0.257]\n",
      "Epoch 8:  97%|█████████▋| 1716/1770 [07:10<00:17,  3.06it/s, loss=0.188, v_num=7, val_loss=0.0577, val_acc=0.955, train_loss=0.0578]   \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 8:  97%|█████████▋| 1718/1770 [07:13<00:17,  3.04it/s, loss=0.188, v_num=7, val_loss=0.0577, val_acc=0.955, train_loss=0.0578]\n",
      "Validating:   4%|▎         | 2/54 [00:02<01:10,  1.35s/it]\u001b[A\n",
      "Epoch 8:  97%|█████████▋| 1720/1770 [07:14<00:16,  3.04it/s, loss=0.188, v_num=7, val_loss=0.0577, val_acc=0.955, train_loss=0.0578]\n",
      "Validating:   7%|▋         | 4/54 [00:04<00:42,  1.17it/s]\u001b[A\n",
      "Epoch 8:  97%|█████████▋| 1722/1770 [07:15<00:15,  3.04it/s, loss=0.188, v_num=7, val_loss=0.0577, val_acc=0.955, train_loss=0.0578]\n",
      "Validating:  11%|█         | 6/54 [00:05<00:33,  1.44it/s]\u001b[A\n",
      "Epoch 8:  97%|█████████▋| 1724/1770 [07:16<00:15,  3.03it/s, loss=0.188, v_num=7, val_loss=0.0577, val_acc=0.955, train_loss=0.0578]\n",
      "Validating:  15%|█▍        | 8/54 [00:06<00:28,  1.59it/s]\u001b[A\n",
      "Epoch 8:  98%|█████████▊| 1726/1770 [07:17<00:14,  3.03it/s, loss=0.188, v_num=7, val_loss=0.0577, val_acc=0.955, train_loss=0.0578]\n",
      "Validating:  19%|█▊        | 10/54 [00:07<00:26,  1.66it/s]\u001b[A\n",
      "Epoch 8:  98%|█████████▊| 1728/1770 [07:19<00:13,  3.03it/s, loss=0.188, v_num=7, val_loss=0.0577, val_acc=0.955, train_loss=0.0578]\n",
      "Validating:  22%|██▏       | 12/54 [00:08<00:24,  1.70it/s]\u001b[A\n",
      "Epoch 8:  98%|█████████▊| 1730/1770 [07:20<00:13,  3.02it/s, loss=0.188, v_num=7, val_loss=0.0577, val_acc=0.955, train_loss=0.0578]\n",
      "Validating:  26%|██▌       | 14/54 [00:09<00:23,  1.72it/s]\u001b[A\n",
      "Epoch 8:  98%|█████████▊| 1732/1770 [07:21<00:12,  3.02it/s, loss=0.188, v_num=7, val_loss=0.0577, val_acc=0.955, train_loss=0.0578]\n",
      "Validating:  30%|██▉       | 16/54 [00:11<00:21,  1.73it/s]\u001b[A\n",
      "Epoch 8:  98%|█████████▊| 1734/1770 [07:22<00:11,  3.02it/s, loss=0.188, v_num=7, val_loss=0.0577, val_acc=0.955, train_loss=0.0578]\n",
      "Validating:  33%|███▎      | 18/54 [00:12<00:20,  1.74it/s]\u001b[A\n",
      "Epoch 8:  98%|█████████▊| 1736/1770 [07:23<00:11,  3.01it/s, loss=0.188, v_num=7, val_loss=0.0577, val_acc=0.955, train_loss=0.0578]\n",
      "Validating:  37%|███▋      | 20/54 [00:13<00:19,  1.74it/s]\u001b[A\n",
      "Epoch 8:  98%|█████████▊| 1738/1770 [07:24<00:10,  3.01it/s, loss=0.188, v_num=7, val_loss=0.0577, val_acc=0.955, train_loss=0.0578]\n",
      "Validating:  41%|████      | 22/54 [00:14<00:18,  1.74it/s]\u001b[A\n",
      "Epoch 8:  98%|█████████▊| 1740/1770 [07:25<00:09,  3.01it/s, loss=0.188, v_num=7, val_loss=0.0577, val_acc=0.955, train_loss=0.0578]\n",
      "Validating:  44%|████▍     | 24/54 [00:15<00:17,  1.74it/s]\u001b[A\n",
      "Epoch 8:  98%|█████████▊| 1742/1770 [07:27<00:09,  3.00it/s, loss=0.188, v_num=7, val_loss=0.0577, val_acc=0.955, train_loss=0.0578]\n",
      "Validating:  48%|████▊     | 26/54 [00:16<00:16,  1.74it/s]\u001b[A\n",
      "Epoch 8:  99%|█████████▊| 1744/1770 [07:28<00:08,  3.00it/s, loss=0.188, v_num=7, val_loss=0.0577, val_acc=0.955, train_loss=0.0578]\n",
      "Validating:  52%|█████▏    | 28/54 [00:17<00:14,  1.74it/s]\u001b[A\n",
      "Epoch 8:  99%|█████████▊| 1746/1770 [07:29<00:08,  3.00it/s, loss=0.188, v_num=7, val_loss=0.0577, val_acc=0.955, train_loss=0.0578]\n",
      "Validating:  56%|█████▌    | 30/54 [00:19<00:13,  1.74it/s]\u001b[A\n",
      "Epoch 8:  99%|█████████▉| 1748/1770 [07:30<00:07,  2.99it/s, loss=0.188, v_num=7, val_loss=0.0577, val_acc=0.955, train_loss=0.0578]\n",
      "Validating:  59%|█████▉    | 32/54 [00:20<00:12,  1.74it/s]\u001b[A\n",
      "Epoch 8:  99%|█████████▉| 1750/1770 [07:31<00:06,  2.99it/s, loss=0.188, v_num=7, val_loss=0.0577, val_acc=0.955, train_loss=0.0578]\n",
      "Validating:  63%|██████▎   | 34/54 [00:21<00:11,  1.74it/s]\u001b[A\n",
      "Epoch 8:  99%|█████████▉| 1752/1770 [07:32<00:06,  2.99it/s, loss=0.188, v_num=7, val_loss=0.0577, val_acc=0.955, train_loss=0.0578]\n",
      "Validating:  67%|██████▋   | 36/54 [00:22<00:10,  1.74it/s]\u001b[A\n",
      "Epoch 8:  99%|█████████▉| 1754/1770 [07:34<00:05,  2.98it/s, loss=0.188, v_num=7, val_loss=0.0577, val_acc=0.955, train_loss=0.0578]\n",
      "Validating:  70%|███████   | 38/54 [00:23<00:09,  1.74it/s]\u001b[A\n",
      "Epoch 8:  99%|█████████▉| 1756/1770 [07:35<00:04,  2.98it/s, loss=0.188, v_num=7, val_loss=0.0577, val_acc=0.955, train_loss=0.0578]\n",
      "Validating:  74%|███████▍  | 40/54 [00:24<00:08,  1.73it/s]\u001b[A\n",
      "Epoch 8:  99%|█████████▉| 1758/1770 [07:36<00:04,  2.98it/s, loss=0.188, v_num=7, val_loss=0.0577, val_acc=0.955, train_loss=0.0578]\n",
      "Validating:  78%|███████▊  | 42/54 [00:26<00:06,  1.73it/s]\u001b[A\n",
      "Epoch 8:  99%|█████████▉| 1760/1770 [07:37<00:03,  2.98it/s, loss=0.188, v_num=7, val_loss=0.0577, val_acc=0.955, train_loss=0.0578]\n",
      "Validating:  81%|████████▏ | 44/54 [00:27<00:05,  1.73it/s]\u001b[A\n",
      "Epoch 8: 100%|█████████▉| 1762/1770 [07:38<00:02,  2.97it/s, loss=0.188, v_num=7, val_loss=0.0577, val_acc=0.955, train_loss=0.0578]\n",
      "Validating:  85%|████████▌ | 46/54 [00:28<00:04,  1.76it/s]\u001b[A\n",
      "Epoch 8: 100%|█████████▉| 1764/1770 [07:39<00:02,  2.97it/s, loss=0.188, v_num=7, val_loss=0.0577, val_acc=0.955, train_loss=0.0578]\n",
      "Validating:  89%|████████▉ | 48/54 [00:29<00:03,  1.78it/s]\u001b[A\n",
      "Epoch 8: 100%|█████████▉| 1766/1770 [07:40<00:01,  2.97it/s, loss=0.188, v_num=7, val_loss=0.0577, val_acc=0.955, train_loss=0.0578]\n",
      "Validating:  93%|█████████▎| 50/54 [00:30<00:02,  1.78it/s]\u001b[A\n",
      "Epoch 8: 100%|█████████▉| 1768/1770 [07:41<00:00,  2.96it/s, loss=0.188, v_num=7, val_loss=0.0577, val_acc=0.955, train_loss=0.0578]\n",
      "Validating:  96%|█████████▋| 52/54 [00:31<00:01,  1.79it/s]\u001b[A\n",
      "Epoch 8: 100%|██████████| 1770/1770 [07:43<00:00,  2.96it/s, loss=0.188, v_num=7, val_loss=0.0577, val_acc=0.955, train_loss=0.0578]\n",
      "Validating: 100%|██████████| 54/54 [00:32<00:00,  2.02it/s]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8, step 3432: val_loss was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8: 100%|██████████| 1770/1770 [07:43<00:00,  2.96it/s, loss=0.188, v_num=7, val_loss=0.0583, val_acc=0.955, train_loss=0.241] \n",
      "Epoch 9:  97%|█████████▋| 1716/1770 [07:11<00:17,  3.06it/s, loss=0.193, v_num=7, val_loss=0.0583, val_acc=0.955, train_loss=0.145]    \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 9:  97%|█████████▋| 1718/1770 [07:13<00:17,  3.04it/s, loss=0.193, v_num=7, val_loss=0.0583, val_acc=0.955, train_loss=0.145]\n",
      "Validating:   4%|▎         | 2/54 [00:03<01:11,  1.38s/it]\u001b[A\n",
      "Epoch 9:  97%|█████████▋| 1720/1770 [07:14<00:16,  3.04it/s, loss=0.193, v_num=7, val_loss=0.0583, val_acc=0.955, train_loss=0.145]\n",
      "Validating:   7%|▋         | 4/54 [00:04<00:43,  1.14it/s]\u001b[A\n",
      "Epoch 9:  97%|█████████▋| 1722/1770 [07:15<00:15,  3.03it/s, loss=0.193, v_num=7, val_loss=0.0583, val_acc=0.955, train_loss=0.145]\n",
      "Validating:  11%|█         | 6/54 [00:05<00:33,  1.42it/s]\u001b[A\n",
      "Epoch 9:  97%|█████████▋| 1724/1770 [07:17<00:15,  3.03it/s, loss=0.193, v_num=7, val_loss=0.0583, val_acc=0.955, train_loss=0.145]\n",
      "Validating:  15%|█▍        | 8/54 [00:06<00:29,  1.57it/s]\u001b[A\n",
      "Epoch 9:  98%|█████████▊| 1726/1770 [07:18<00:14,  3.03it/s, loss=0.193, v_num=7, val_loss=0.0583, val_acc=0.955, train_loss=0.145]\n",
      "Validating:  19%|█▊        | 10/54 [00:07<00:26,  1.65it/s]\u001b[A\n",
      "Epoch 9:  98%|█████████▊| 1728/1770 [07:19<00:13,  3.02it/s, loss=0.193, v_num=7, val_loss=0.0583, val_acc=0.955, train_loss=0.145]\n",
      "Validating:  22%|██▏       | 12/54 [00:08<00:24,  1.70it/s]\u001b[A\n",
      "Epoch 9:  98%|█████████▊| 1730/1770 [07:20<00:13,  3.02it/s, loss=0.193, v_num=7, val_loss=0.0583, val_acc=0.955, train_loss=0.145]\n",
      "Validating:  26%|██▌       | 14/54 [00:10<00:23,  1.72it/s]\u001b[A\n",
      "Epoch 9:  98%|█████████▊| 1732/1770 [07:21<00:12,  3.02it/s, loss=0.193, v_num=7, val_loss=0.0583, val_acc=0.955, train_loss=0.145]\n",
      "Validating:  30%|██▉       | 16/54 [00:11<00:21,  1.73it/s]\u001b[A\n",
      "Epoch 9:  98%|█████████▊| 1734/1770 [07:22<00:11,  3.01it/s, loss=0.193, v_num=7, val_loss=0.0583, val_acc=0.955, train_loss=0.145]\n",
      "Validating:  33%|███▎      | 18/54 [00:12<00:20,  1.74it/s]\u001b[A\n",
      "Epoch 9:  98%|█████████▊| 1736/1770 [07:23<00:11,  3.01it/s, loss=0.193, v_num=7, val_loss=0.0583, val_acc=0.955, train_loss=0.145]\n",
      "Validating:  37%|███▋      | 20/54 [00:13<00:19,  1.74it/s]\u001b[A\n",
      "Epoch 9:  98%|█████████▊| 1738/1770 [07:25<00:10,  3.01it/s, loss=0.193, v_num=7, val_loss=0.0583, val_acc=0.955, train_loss=0.145]\n",
      "Validating:  41%|████      | 22/54 [00:14<00:18,  1.74it/s]\u001b[A\n",
      "Epoch 9:  98%|█████████▊| 1740/1770 [07:26<00:09,  3.00it/s, loss=0.193, v_num=7, val_loss=0.0583, val_acc=0.955, train_loss=0.145]\n",
      "Validating:  44%|████▍     | 24/54 [00:15<00:17,  1.74it/s]\u001b[A\n",
      "Epoch 9:  98%|█████████▊| 1742/1770 [07:27<00:09,  3.00it/s, loss=0.193, v_num=7, val_loss=0.0583, val_acc=0.955, train_loss=0.145]\n",
      "Validating:  48%|████▊     | 26/54 [00:16<00:16,  1.74it/s]\u001b[A\n",
      "Epoch 9:  99%|█████████▊| 1744/1770 [07:28<00:08,  3.00it/s, loss=0.193, v_num=7, val_loss=0.0583, val_acc=0.955, train_loss=0.145]\n",
      "Validating:  52%|█████▏    | 28/54 [00:18<00:14,  1.74it/s]\u001b[A\n",
      "Epoch 9:  99%|█████████▊| 1746/1770 [07:29<00:08,  3.00it/s, loss=0.193, v_num=7, val_loss=0.0583, val_acc=0.955, train_loss=0.145]\n",
      "Validating:  56%|█████▌    | 30/54 [00:19<00:13,  1.74it/s]\u001b[A\n",
      "Epoch 9:  99%|█████████▉| 1748/1770 [07:30<00:07,  2.99it/s, loss=0.193, v_num=7, val_loss=0.0583, val_acc=0.955, train_loss=0.145]\n",
      "Validating:  59%|█████▉    | 32/54 [00:20<00:12,  1.74it/s]\u001b[A\n",
      "Epoch 9:  99%|█████████▉| 1750/1770 [07:32<00:06,  2.99it/s, loss=0.193, v_num=7, val_loss=0.0583, val_acc=0.955, train_loss=0.145]\n",
      "Validating:  63%|██████▎   | 34/54 [00:21<00:11,  1.74it/s]\u001b[A\n",
      "Epoch 9:  99%|█████████▉| 1752/1770 [07:33<00:06,  2.99it/s, loss=0.193, v_num=7, val_loss=0.0583, val_acc=0.955, train_loss=0.145]\n",
      "Validating:  67%|██████▋   | 36/54 [00:22<00:10,  1.74it/s]\u001b[A\n",
      "Epoch 9:  99%|█████████▉| 1754/1770 [07:34<00:05,  2.98it/s, loss=0.193, v_num=7, val_loss=0.0583, val_acc=0.955, train_loss=0.145]\n",
      "Validating:  70%|███████   | 38/54 [00:23<00:09,  1.74it/s]\u001b[A\n",
      "Epoch 9:  99%|█████████▉| 1756/1770 [07:35<00:04,  2.98it/s, loss=0.193, v_num=7, val_loss=0.0583, val_acc=0.955, train_loss=0.145]\n",
      "Validating:  74%|███████▍  | 40/54 [00:24<00:08,  1.74it/s]\u001b[A\n",
      "Epoch 9:  99%|█████████▉| 1758/1770 [07:36<00:04,  2.98it/s, loss=0.193, v_num=7, val_loss=0.0583, val_acc=0.955, train_loss=0.145]\n",
      "Validating:  78%|███████▊  | 42/54 [00:26<00:06,  1.74it/s]\u001b[A\n",
      "Epoch 9:  99%|█████████▉| 1760/1770 [07:37<00:03,  2.97it/s, loss=0.193, v_num=7, val_loss=0.0583, val_acc=0.955, train_loss=0.145]\n",
      "Validating:  81%|████████▏ | 44/54 [00:27<00:05,  1.74it/s]\u001b[A\n",
      "Epoch 9: 100%|█████████▉| 1762/1770 [07:38<00:02,  2.97it/s, loss=0.193, v_num=7, val_loss=0.0583, val_acc=0.955, train_loss=0.145]\n",
      "Validating:  85%|████████▌ | 46/54 [00:28<00:04,  1.77it/s]\u001b[A\n",
      "Epoch 9: 100%|█████████▉| 1764/1770 [07:40<00:02,  2.97it/s, loss=0.193, v_num=7, val_loss=0.0583, val_acc=0.955, train_loss=0.145]\n",
      "Validating:  89%|████████▉ | 48/54 [00:29<00:03,  1.78it/s]\u001b[A\n",
      "Epoch 9: 100%|█████████▉| 1766/1770 [07:41<00:01,  2.96it/s, loss=0.193, v_num=7, val_loss=0.0583, val_acc=0.955, train_loss=0.145]\n",
      "Validating:  93%|█████████▎| 50/54 [00:30<00:02,  1.79it/s]\u001b[A\n",
      "Epoch 9: 100%|█████████▉| 1768/1770 [07:42<00:00,  2.96it/s, loss=0.193, v_num=7, val_loss=0.0583, val_acc=0.955, train_loss=0.145]\n",
      "Validating:  96%|█████████▋| 52/54 [00:31<00:01,  1.79it/s]\u001b[A\n",
      "Epoch 9: 100%|██████████| 1770/1770 [07:43<00:00,  2.96it/s, loss=0.193, v_num=7, val_loss=0.0583, val_acc=0.955, train_loss=0.145]\n",
      "Validating: 100%|██████████| 54/54 [00:32<00:00,  2.02it/s]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9, step 3861: val_loss was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 1770/1770 [07:43<00:00,  2.96it/s, loss=0.193, v_num=7, val_loss=0.0559, val_acc=0.956, train_loss=0.0343]\n",
      "Epoch 10:  97%|█████████▋| 1716/1770 [07:10<00:17,  3.06it/s, loss=0.167, v_num=7, val_loss=0.0559, val_acc=0.956, train_loss=0.0849]   \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 10:  97%|█████████▋| 1718/1770 [07:13<00:17,  3.04it/s, loss=0.167, v_num=7, val_loss=0.0559, val_acc=0.956, train_loss=0.0849]\n",
      "Validating:   4%|▎         | 2/54 [00:03<01:12,  1.38s/it]\u001b[A\n",
      "Epoch 10:  97%|█████████▋| 1720/1770 [07:14<00:16,  3.04it/s, loss=0.167, v_num=7, val_loss=0.0559, val_acc=0.956, train_loss=0.0849]\n",
      "Validating:   7%|▋         | 4/54 [00:04<00:43,  1.16it/s]\u001b[A\n",
      "Epoch 10:  97%|█████████▋| 1722/1770 [07:15<00:15,  3.04it/s, loss=0.167, v_num=7, val_loss=0.0559, val_acc=0.956, train_loss=0.0849]\n",
      "Validating:  11%|█         | 6/54 [00:05<00:33,  1.43it/s]\u001b[A\n",
      "Epoch 10:  97%|█████████▋| 1724/1770 [07:16<00:15,  3.03it/s, loss=0.167, v_num=7, val_loss=0.0559, val_acc=0.956, train_loss=0.0849]\n",
      "Validating:  15%|█▍        | 8/54 [00:06<00:29,  1.58it/s]\u001b[A\n",
      "Epoch 10:  98%|█████████▊| 1726/1770 [07:17<00:14,  3.03it/s, loss=0.167, v_num=7, val_loss=0.0559, val_acc=0.956, train_loss=0.0849]\n",
      "Validating:  19%|█▊        | 10/54 [00:07<00:26,  1.66it/s]\u001b[A\n",
      "Epoch 10:  98%|█████████▊| 1728/1770 [07:19<00:13,  3.03it/s, loss=0.167, v_num=7, val_loss=0.0559, val_acc=0.956, train_loss=0.0849]\n",
      "Validating:  22%|██▏       | 12/54 [00:08<00:24,  1.70it/s]\u001b[A\n",
      "Epoch 10:  98%|█████████▊| 1730/1770 [07:20<00:13,  3.02it/s, loss=0.167, v_num=7, val_loss=0.0559, val_acc=0.956, train_loss=0.0849]\n",
      "Validating:  26%|██▌       | 14/54 [00:10<00:23,  1.72it/s]\u001b[A\n",
      "Epoch 10:  98%|█████████▊| 1732/1770 [07:21<00:12,  3.02it/s, loss=0.167, v_num=7, val_loss=0.0559, val_acc=0.956, train_loss=0.0849]\n",
      "Validating:  30%|██▉       | 16/54 [00:11<00:21,  1.73it/s]\u001b[A\n",
      "Epoch 10:  98%|█████████▊| 1734/1770 [07:22<00:11,  3.02it/s, loss=0.167, v_num=7, val_loss=0.0559, val_acc=0.956, train_loss=0.0849]\n",
      "Validating:  33%|███▎      | 18/54 [00:12<00:20,  1.73it/s]\u001b[A\n",
      "Epoch 10:  98%|█████████▊| 1736/1770 [07:23<00:11,  3.01it/s, loss=0.167, v_num=7, val_loss=0.0559, val_acc=0.956, train_loss=0.0849]\n",
      "Validating:  37%|███▋      | 20/54 [00:13<00:19,  1.73it/s]\u001b[A\n",
      "Epoch 10:  98%|█████████▊| 1738/1770 [07:24<00:10,  3.01it/s, loss=0.167, v_num=7, val_loss=0.0559, val_acc=0.956, train_loss=0.0849]\n",
      "Validating:  41%|████      | 22/54 [00:14<00:18,  1.74it/s]\u001b[A\n",
      "Epoch 10:  98%|█████████▊| 1740/1770 [07:26<00:09,  3.01it/s, loss=0.167, v_num=7, val_loss=0.0559, val_acc=0.956, train_loss=0.0849]\n",
      "Validating:  44%|████▍     | 24/54 [00:15<00:17,  1.74it/s]\u001b[A\n",
      "Epoch 10:  98%|█████████▊| 1742/1770 [07:27<00:09,  3.00it/s, loss=0.167, v_num=7, val_loss=0.0559, val_acc=0.956, train_loss=0.0849]\n",
      "Validating:  48%|████▊     | 26/54 [00:16<00:16,  1.74it/s]\u001b[A\n",
      "Epoch 10:  99%|█████████▊| 1744/1770 [07:28<00:08,  3.00it/s, loss=0.167, v_num=7, val_loss=0.0559, val_acc=0.956, train_loss=0.0849]\n",
      "Validating:  52%|█████▏    | 28/54 [00:18<00:15,  1.73it/s]\u001b[A\n",
      "Epoch 10:  99%|█████████▊| 1746/1770 [07:29<00:08,  3.00it/s, loss=0.167, v_num=7, val_loss=0.0559, val_acc=0.956, train_loss=0.0849]\n",
      "Validating:  56%|█████▌    | 30/54 [00:19<00:13,  1.74it/s]\u001b[A\n",
      "Epoch 10:  99%|█████████▉| 1748/1770 [07:30<00:07,  2.99it/s, loss=0.167, v_num=7, val_loss=0.0559, val_acc=0.956, train_loss=0.0849]\n",
      "Validating:  59%|█████▉    | 32/54 [00:20<00:12,  1.74it/s]\u001b[A\n",
      "Epoch 10:  99%|█████████▉| 1750/1770 [07:31<00:06,  2.99it/s, loss=0.167, v_num=7, val_loss=0.0559, val_acc=0.956, train_loss=0.0849]\n",
      "Validating:  63%|██████▎   | 34/54 [00:21<00:11,  1.74it/s]\u001b[A\n",
      "Epoch 10:  99%|█████████▉| 1752/1770 [07:32<00:06,  2.99it/s, loss=0.167, v_num=7, val_loss=0.0559, val_acc=0.956, train_loss=0.0849]\n",
      "Validating:  67%|██████▋   | 36/54 [00:22<00:10,  1.74it/s]\u001b[A\n",
      "Epoch 10:  99%|█████████▉| 1754/1770 [07:34<00:05,  2.98it/s, loss=0.167, v_num=7, val_loss=0.0559, val_acc=0.956, train_loss=0.0849]\n",
      "Validating:  70%|███████   | 38/54 [00:23<00:09,  1.74it/s]\u001b[A\n",
      "Epoch 10:  99%|█████████▉| 1756/1770 [07:35<00:04,  2.98it/s, loss=0.167, v_num=7, val_loss=0.0559, val_acc=0.956, train_loss=0.0849]\n",
      "Validating:  74%|███████▍  | 40/54 [00:25<00:08,  1.73it/s]\u001b[A\n",
      "Epoch 10:  99%|█████████▉| 1758/1770 [07:36<00:04,  2.98it/s, loss=0.167, v_num=7, val_loss=0.0559, val_acc=0.956, train_loss=0.0849]\n",
      "Validating:  78%|███████▊  | 42/54 [00:26<00:06,  1.73it/s]\u001b[A\n",
      "Epoch 10:  99%|█████████▉| 1760/1770 [07:37<00:03,  2.97it/s, loss=0.167, v_num=7, val_loss=0.0559, val_acc=0.956, train_loss=0.0849]\n",
      "Validating:  81%|████████▏ | 44/54 [00:27<00:05,  1.73it/s]\u001b[A\n",
      "Epoch 10: 100%|█████████▉| 1762/1770 [07:38<00:02,  2.97it/s, loss=0.167, v_num=7, val_loss=0.0559, val_acc=0.956, train_loss=0.0849]\n",
      "Validating:  85%|████████▌ | 46/54 [00:28<00:04,  1.76it/s]\u001b[A\n",
      "Epoch 10: 100%|█████████▉| 1764/1770 [07:39<00:02,  2.97it/s, loss=0.167, v_num=7, val_loss=0.0559, val_acc=0.956, train_loss=0.0849]\n",
      "Validating:  89%|████████▉ | 48/54 [00:29<00:03,  1.78it/s]\u001b[A\n",
      "Epoch 10: 100%|█████████▉| 1766/1770 [07:40<00:01,  2.97it/s, loss=0.167, v_num=7, val_loss=0.0559, val_acc=0.956, train_loss=0.0849]\n",
      "Validating:  93%|█████████▎| 50/54 [00:30<00:02,  1.79it/s]\u001b[A\n",
      "Epoch 10: 100%|█████████▉| 1768/1770 [07:42<00:00,  2.96it/s, loss=0.167, v_num=7, val_loss=0.0559, val_acc=0.956, train_loss=0.0849]\n",
      "Validating:  96%|█████████▋| 52/54 [00:31<00:01,  1.79it/s]\u001b[A\n",
      "Epoch 10: 100%|██████████| 1770/1770 [07:43<00:00,  2.96it/s, loss=0.167, v_num=7, val_loss=0.0559, val_acc=0.956, train_loss=0.0849]\n",
      "Validating: 100%|██████████| 54/54 [00:32<00:00,  2.02it/s]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10, step 4290: val_loss was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10: 100%|██████████| 1770/1770 [07:43<00:00,  2.96it/s, loss=0.167, v_num=7, val_loss=0.0566, val_acc=0.958, train_loss=0.291] \n",
      "                                                           \u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer was signaled to stop but required minimum epochs (15) or minimum steps (None) has not been met. Training will continue...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11:   0%|          | 2/1770 [00:00<-1:59:57, -583.91it/s, loss=0.167, v_num=7, val_loss=0.0566, val_acc=0.958, train_loss=0.291]  \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   2%|▏         | 1/54 [00:02<01:50,  2.09s/it]\u001b[A\n",
      "Epoch 11:   0%|          | 4/1770 [00:03<-1:59:45, -115.53it/s, loss=0.167, v_num=7, val_loss=0.0566, val_acc=0.958, train_loss=0.291]\n",
      "Validating:   6%|▌         | 3/54 [00:03<00:50,  1.01it/s]\u001b[A\n",
      "Epoch 11:   0%|          | 6/1770 [00:04<-1:59:39, -82.32it/s, loss=0.167, v_num=7, val_loss=0.0566, val_acc=0.958, train_loss=0.291] \n",
      "Validating:   9%|▉         | 5/54 [00:04<00:37,  1.32it/s]\u001b[A\n",
      "Epoch 11:   0%|          | 8/1770 [00:05<-1:59:34, -65.99it/s, loss=0.167, v_num=7, val_loss=0.0566, val_acc=0.958, train_loss=0.291]\n",
      "Validating:  13%|█▎        | 7/54 [00:05<00:30,  1.52it/s]\u001b[A\n",
      "Epoch 11:   1%|          | 10/1770 [00:07<-1:59:28, -54.91it/s, loss=0.167, v_num=7, val_loss=0.0566, val_acc=0.958, train_loss=0.291]\n",
      "Validating:  17%|█▋        | 9/54 [00:06<00:27,  1.63it/s]\u001b[A\n",
      "Epoch 11:   1%|          | 12/1770 [00:08<-1:59:23, -47.00it/s, loss=0.167, v_num=7, val_loss=0.0566, val_acc=0.958, train_loss=0.291]\n",
      "Validating:  20%|██        | 11/54 [00:08<00:25,  1.68it/s]\u001b[A\n",
      "Epoch 11:   1%|          | 14/1770 [00:09<-1:59:18, -41.00it/s, loss=0.167, v_num=7, val_loss=0.0566, val_acc=0.958, train_loss=0.291]\n",
      "Validating:  24%|██▍       | 13/54 [00:09<00:24,  1.71it/s]\u001b[A\n",
      "Epoch 11:   1%|          | 16/1770 [00:10<-1:59:12, -36.34it/s, loss=0.167, v_num=7, val_loss=0.0566, val_acc=0.958, train_loss=0.291]\n",
      "Validating:  28%|██▊       | 15/54 [00:10<00:22,  1.72it/s]\u001b[A\n",
      "Epoch 11:   1%|          | 18/1770 [00:11<-1:59:07, -32.58it/s, loss=0.167, v_num=7, val_loss=0.0566, val_acc=0.958, train_loss=0.291]\n",
      "Validating:  31%|███▏      | 17/54 [00:11<00:21,  1.73it/s]\u001b[A\n",
      "Epoch 11:   1%|          | 20/1770 [00:12<-1:59:01, -29.51it/s, loss=0.167, v_num=7, val_loss=0.0566, val_acc=0.958, train_loss=0.291]\n",
      "Validating:  35%|███▌      | 19/54 [00:12<00:20,  1.74it/s]\u001b[A\n",
      "Epoch 11:   1%|          | 22/1770 [00:13<-1:58:56, -26.95it/s, loss=0.167, v_num=7, val_loss=0.0566, val_acc=0.958, train_loss=0.291]\n",
      "Validating:  39%|███▉      | 21/54 [00:13<00:18,  1.74it/s]\u001b[A\n",
      "Epoch 11:   1%|▏         | 24/1770 [00:15<-1:58:50, -24.78it/s, loss=0.167, v_num=7, val_loss=0.0566, val_acc=0.958, train_loss=0.291]\n",
      "Validating:  43%|████▎     | 23/54 [00:15<00:17,  1.74it/s]\u001b[A\n",
      "Epoch 11:   1%|▏         | 26/1770 [00:16<-1:58:44, -22.89it/s, loss=0.167, v_num=7, val_loss=0.0566, val_acc=0.958, train_loss=0.291]\n",
      "Validating:  46%|████▋     | 25/54 [00:16<00:16,  1.74it/s]\u001b[A\n",
      "Epoch 11:   2%|▏         | 28/1770 [00:17<-1:58:39, -21.27it/s, loss=0.167, v_num=7, val_loss=0.0566, val_acc=0.958, train_loss=0.291]\n",
      "Validating:  50%|█████     | 27/54 [00:17<00:15,  1.74it/s]\u001b[A\n",
      "Epoch 11:   2%|▏         | 30/1770 [00:18<-1:58:33, -19.85it/s, loss=0.167, v_num=7, val_loss=0.0566, val_acc=0.958, train_loss=0.291]\n",
      "Validating:  54%|█████▎    | 29/54 [00:18<00:14,  1.74it/s]\u001b[A\n",
      "Epoch 11:   2%|▏         | 32/1770 [00:19<-1:58:27, -18.59it/s, loss=0.167, v_num=7, val_loss=0.0566, val_acc=0.958, train_loss=0.291]\n",
      "Validating:  57%|█████▋    | 31/54 [00:19<00:13,  1.73it/s]\u001b[A\n",
      "Epoch 11:   2%|▏         | 34/1770 [00:20<-1:58:21, -17.46it/s, loss=0.167, v_num=7, val_loss=0.0566, val_acc=0.958, train_loss=0.291]\n",
      "Validating:  61%|██████    | 33/54 [00:20<00:12,  1.73it/s]\u001b[A\n",
      "Epoch 11:   2%|▏         | 36/1770 [00:22<-1:58:15, -16.46it/s, loss=0.167, v_num=7, val_loss=0.0566, val_acc=0.958, train_loss=0.291]\n",
      "Validating:  65%|██████▍   | 35/54 [00:21<00:10,  1.74it/s]\u001b[A\n",
      "Epoch 11:   2%|▏         | 38/1770 [00:23<-1:58:09, -15.56it/s, loss=0.167, v_num=7, val_loss=0.0566, val_acc=0.958, train_loss=0.291]\n",
      "Validating:  69%|██████▊   | 37/54 [00:23<00:09,  1.74it/s]\u001b[A\n",
      "Epoch 11:   2%|▏         | 40/1770 [00:24<-1:58:03, -14.74it/s, loss=0.167, v_num=7, val_loss=0.0566, val_acc=0.958, train_loss=0.291]\n",
      "Validating:  72%|███████▏  | 39/54 [00:24<00:08,  1.74it/s]\u001b[A\n",
      "Epoch 11:   2%|▏         | 42/1770 [00:25<-1:57:57, -14.00it/s, loss=0.167, v_num=7, val_loss=0.0566, val_acc=0.958, train_loss=0.291]\n",
      "Validating:  76%|███████▌  | 41/54 [00:25<00:07,  1.74it/s]\u001b[A\n",
      "Epoch 11:   2%|▏         | 44/1770 [00:26<-1:57:51, -13.32it/s, loss=0.167, v_num=7, val_loss=0.0566, val_acc=0.958, train_loss=0.291]\n",
      "Validating:  80%|███████▉  | 43/54 [00:26<00:06,  1.74it/s]\u001b[A\n",
      "Epoch 11:   3%|▎         | 46/1770 [00:27<-1:57:45, -12.70it/s, loss=0.167, v_num=7, val_loss=0.0566, val_acc=0.958, train_loss=0.291]\n",
      "Validating:  83%|████████▎ | 45/54 [00:27<00:05,  1.75it/s]\u001b[A\n",
      "Epoch 11:   3%|▎         | 48/1770 [00:28<-1:57:39, -12.14it/s, loss=0.167, v_num=7, val_loss=0.0566, val_acc=0.958, train_loss=0.291]\n",
      "Validating:  87%|████████▋ | 47/54 [00:28<00:03,  1.77it/s]\u001b[A\n",
      "Epoch 11:   3%|▎         | 50/1770 [00:30<-1:57:33, -11.62it/s, loss=0.167, v_num=7, val_loss=0.0566, val_acc=0.958, train_loss=0.291]\n",
      "Validating:  91%|█████████ | 49/54 [00:29<00:02,  1.78it/s]\u001b[A\n",
      "Epoch 11:   3%|▎         | 52/1770 [00:31<-1:57:26, -11.14it/s, loss=0.167, v_num=7, val_loss=0.0566, val_acc=0.958, train_loss=0.291]\n",
      "Validating:  94%|█████████▍| 51/54 [00:31<00:01,  1.79it/s]\u001b[A\n",
      "Epoch 11:   3%|▎         | 54/1770 [00:32<-1:57:20, -10.70it/s, loss=0.167, v_num=7, val_loss=0.0566, val_acc=0.958, train_loss=0.291]\n",
      "Validating:  98%|█████████▊| 53/54 [00:32<00:00,  1.79it/s]\u001b[A\n",
      "Epoch 11:   3%|▎         | 56/1770 [00:33<-1:57:15, -10.34it/s, loss=0.167, v_num=7, val_loss=0.0566, val_acc=0.958, train_loss=0.291]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11, step 4291: val_loss was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11:   3%|▎         | 56/1770 [00:33<-1:57:14, -10.31it/s, loss=0.167, v_num=7, val_loss=0.0567, val_acc=0.957, train_loss=0.0768]\n",
      "                                                           \u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer was signaled to stop but required minimum epochs (15) or minimum steps (None) has not been met. Training will continue...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12:   0%|          | 2/1770 [00:00<-1:59:57, -558.05it/s, loss=0.167, v_num=7, val_loss=0.0567, val_acc=0.957, train_loss=0.0768] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   2%|▏         | 1/54 [00:01<01:40,  1.90s/it]\u001b[A\n",
      "Epoch 12:   0%|          | 4/1770 [00:03<-1:59:46, -122.66it/s, loss=0.167, v_num=7, val_loss=0.0567, val_acc=0.957, train_loss=0.0768]\n",
      "Validating:   6%|▌         | 3/54 [00:03<00:46,  1.09it/s]\u001b[A\n",
      "Epoch 12:   0%|          | 6/1770 [00:04<-1:59:40, -87.31it/s, loss=0.167, v_num=7, val_loss=0.0567, val_acc=0.957, train_loss=0.0768] \n",
      "Validating:   9%|▉         | 5/54 [00:04<00:36,  1.34it/s]\u001b[A\n",
      "Epoch 12:   0%|          | 8/1770 [00:05<-1:59:35, -68.31it/s, loss=0.167, v_num=7, val_loss=0.0567, val_acc=0.957, train_loss=0.0768]\n",
      "Validating:  13%|█▎        | 7/54 [00:05<00:30,  1.53it/s]\u001b[A\n",
      "Epoch 12:   1%|          | 10/1770 [00:06<-1:59:29, -56.52it/s, loss=0.167, v_num=7, val_loss=0.0567, val_acc=0.957, train_loss=0.0768]\n",
      "Validating:  17%|█▋        | 9/54 [00:06<00:27,  1.63it/s]\u001b[A\n",
      "Epoch 12:   1%|          | 12/1770 [00:08<-1:59:24, -48.17it/s, loss=0.167, v_num=7, val_loss=0.0567, val_acc=0.957, train_loss=0.0768]\n",
      "Validating:  20%|██        | 11/54 [00:07<00:25,  1.68it/s]\u001b[A\n",
      "Epoch 12:   1%|          | 14/1770 [00:09<-1:59:19, -41.89it/s, loss=0.167, v_num=7, val_loss=0.0567, val_acc=0.957, train_loss=0.0768]\n",
      "Validating:  24%|██▍       | 13/54 [00:09<00:23,  1.71it/s]\u001b[A\n",
      "Epoch 12:   1%|          | 16/1770 [00:10<-1:59:13, -37.03it/s, loss=0.167, v_num=7, val_loss=0.0567, val_acc=0.957, train_loss=0.0768]\n",
      "Validating:  28%|██▊       | 15/54 [00:10<00:22,  1.72it/s]\u001b[A\n",
      "Epoch 12:   1%|          | 18/1770 [00:11<-1:59:08, -33.15it/s, loss=0.167, v_num=7, val_loss=0.0567, val_acc=0.957, train_loss=0.0768]\n",
      "Validating:  31%|███▏      | 17/54 [00:11<00:21,  1.73it/s]\u001b[A\n",
      "Epoch 12:   1%|          | 20/1770 [00:12<-1:59:02, -29.99it/s, loss=0.167, v_num=7, val_loss=0.0567, val_acc=0.957, train_loss=0.0768]\n",
      "Validating:  35%|███▌      | 19/54 [00:12<00:20,  1.74it/s]\u001b[A\n",
      "Epoch 12:   1%|          | 22/1770 [00:13<-1:58:57, -27.33it/s, loss=0.167, v_num=7, val_loss=0.0567, val_acc=0.957, train_loss=0.0768]\n",
      "Validating:  39%|███▉      | 21/54 [00:13<00:19,  1.73it/s]\u001b[A\n",
      "Epoch 12:   1%|▏         | 24/1770 [00:14<-1:58:51, -25.08it/s, loss=0.167, v_num=7, val_loss=0.0567, val_acc=0.957, train_loss=0.0768]\n",
      "Validating:  43%|████▎     | 23/54 [00:14<00:17,  1.73it/s]\u001b[A\n",
      "Epoch 12:   1%|▏         | 26/1770 [00:16<-1:58:45, -23.16it/s, loss=0.167, v_num=7, val_loss=0.0567, val_acc=0.957, train_loss=0.0768]\n",
      "Validating:  46%|████▋     | 25/54 [00:15<00:16,  1.73it/s]\u001b[A\n",
      "Epoch 12:   2%|▏         | 28/1770 [00:17<-1:58:39, -21.49it/s, loss=0.167, v_num=7, val_loss=0.0567, val_acc=0.957, train_loss=0.0768]\n",
      "Validating:  50%|█████     | 27/54 [00:17<00:15,  1.73it/s]\u001b[A\n",
      "Epoch 12:   2%|▏         | 30/1770 [00:18<-1:58:34, -20.04it/s, loss=0.167, v_num=7, val_loss=0.0567, val_acc=0.957, train_loss=0.0768]\n",
      "Validating:  54%|█████▎    | 29/54 [00:18<00:14,  1.73it/s]\u001b[A\n",
      "Epoch 12:   2%|▏         | 32/1770 [00:19<-1:58:28, -18.75it/s, loss=0.167, v_num=7, val_loss=0.0567, val_acc=0.957, train_loss=0.0768]\n",
      "Validating:  57%|█████▋    | 31/54 [00:19<00:13,  1.73it/s]\u001b[A\n",
      "Epoch 12:   2%|▏         | 34/1770 [00:20<-1:58:22, -17.61it/s, loss=0.167, v_num=7, val_loss=0.0567, val_acc=0.957, train_loss=0.0768]\n",
      "Validating:  61%|██████    | 33/54 [00:20<00:12,  1.73it/s]\u001b[A\n",
      "Epoch 12:   2%|▏         | 36/1770 [00:21<-1:58:16, -16.59it/s, loss=0.167, v_num=7, val_loss=0.0567, val_acc=0.957, train_loss=0.0768]\n",
      "Validating:  65%|██████▍   | 35/54 [00:21<00:10,  1.73it/s]\u001b[A\n",
      "Epoch 12:   2%|▏         | 38/1770 [00:23<-1:58:10, -15.67it/s, loss=0.167, v_num=7, val_loss=0.0567, val_acc=0.957, train_loss=0.0768]\n",
      "Validating:  69%|██████▊   | 37/54 [00:22<00:09,  1.73it/s]\u001b[A\n",
      "Epoch 12:   2%|▏         | 40/1770 [00:24<-1:58:04, -14.84it/s, loss=0.167, v_num=7, val_loss=0.0567, val_acc=0.957, train_loss=0.0768]\n",
      "Validating:  72%|███████▏  | 39/54 [00:24<00:08,  1.74it/s]\u001b[A\n",
      "Epoch 12:   2%|▏         | 42/1770 [00:25<-1:57:58, -14.09it/s, loss=0.167, v_num=7, val_loss=0.0567, val_acc=0.957, train_loss=0.0768]\n",
      "Validating:  76%|███████▌  | 41/54 [00:25<00:07,  1.74it/s]\u001b[A\n",
      "Epoch 12:   2%|▏         | 44/1770 [00:26<-1:57:52, -13.40it/s, loss=0.167, v_num=7, val_loss=0.0567, val_acc=0.957, train_loss=0.0768]\n",
      "Validating:  80%|███████▉  | 43/54 [00:26<00:06,  1.74it/s]\u001b[A\n",
      "Epoch 12:   3%|▎         | 46/1770 [00:27<-1:57:46, -12.77it/s, loss=0.167, v_num=7, val_loss=0.0567, val_acc=0.957, train_loss=0.0768]\n",
      "Validating:  83%|████████▎ | 45/54 [00:27<00:05,  1.75it/s]\u001b[A\n",
      "Epoch 12:   3%|▎         | 48/1770 [00:28<-1:57:39, -12.21it/s, loss=0.167, v_num=7, val_loss=0.0567, val_acc=0.957, train_loss=0.0768]\n",
      "Validating:  87%|████████▋ | 47/54 [00:28<00:03,  1.77it/s]\u001b[A\n",
      "Epoch 12:   3%|▎         | 50/1770 [00:29<-1:57:33, -11.68it/s, loss=0.167, v_num=7, val_loss=0.0567, val_acc=0.957, train_loss=0.0768]\n",
      "Validating:  91%|█████████ | 49/54 [00:29<00:02,  1.78it/s]\u001b[A\n",
      "Epoch 12:   3%|▎         | 52/1770 [00:30<-1:57:27, -11.20it/s, loss=0.167, v_num=7, val_loss=0.0567, val_acc=0.957, train_loss=0.0768]\n",
      "Validating:  94%|█████████▍| 51/54 [00:30<00:01,  1.79it/s]\u001b[A\n",
      "Epoch 12:   3%|▎         | 54/1770 [00:32<-1:57:21, -10.75it/s, loss=0.167, v_num=7, val_loss=0.0567, val_acc=0.957, train_loss=0.0768]\n",
      "Validating:  98%|█████████▊| 53/54 [00:31<00:00,  1.79it/s]\u001b[A\n",
      "Epoch 12:   3%|▎         | 56/1770 [00:33<-1:57:15, -10.36it/s, loss=0.167, v_num=7, val_loss=0.0571, val_acc=0.956, train_loss=0.189] \n",
      "                                                           \u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer was signaled to stop but required minimum epochs (15) or minimum steps (None) has not been met. Training will continue...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13:   0%|          | 2/1770 [00:00<-1:59:57, -560.59it/s, loss=0.167, v_num=7, val_loss=0.0571, val_acc=0.956, train_loss=0.189] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   2%|▏         | 1/54 [00:02<02:07,  2.41s/it]\u001b[A\n",
      "Epoch 13:   0%|          | 4/1770 [00:03<-1:59:44, -106.35it/s, loss=0.167, v_num=7, val_loss=0.0571, val_acc=0.956, train_loss=0.189]\n",
      "Validating:   6%|▌         | 3/54 [00:03<00:50,  1.00it/s]\u001b[A\n",
      "Epoch 13:   0%|          | 6/1770 [00:04<-1:59:38, -79.69it/s, loss=0.167, v_num=7, val_loss=0.0571, val_acc=0.956, train_loss=0.189] \n",
      "Validating:   9%|▉         | 5/54 [00:04<00:36,  1.33it/s]\u001b[A\n",
      "Epoch 13:   0%|          | 8/1770 [00:06<-1:59:33, -64.19it/s, loss=0.167, v_num=7, val_loss=0.0571, val_acc=0.956, train_loss=0.189]\n",
      "Validating:  13%|█▎        | 7/54 [00:05<00:30,  1.52it/s]\u001b[A\n",
      "Epoch 13:   1%|          | 10/1770 [00:07<-1:59:28, -53.67it/s, loss=0.167, v_num=7, val_loss=0.0571, val_acc=0.956, train_loss=0.189]\n",
      "Validating:  17%|█▋        | 9/54 [00:07<00:27,  1.63it/s]\u001b[A\n",
      "Epoch 13:   1%|          | 12/1770 [00:08<-1:59:22, -46.08it/s, loss=0.167, v_num=7, val_loss=0.0571, val_acc=0.956, train_loss=0.189]\n",
      "Validating:  20%|██        | 11/54 [00:08<00:25,  1.68it/s]\u001b[A\n",
      "Epoch 13:   1%|          | 14/1770 [00:09<-1:59:17, -40.31it/s, loss=0.167, v_num=7, val_loss=0.0571, val_acc=0.956, train_loss=0.189]\n",
      "Validating:  24%|██▍       | 13/54 [00:09<00:24,  1.71it/s]\u001b[A\n",
      "Epoch 13:   1%|          | 16/1770 [00:10<-1:59:11, -35.78it/s, loss=0.167, v_num=7, val_loss=0.0571, val_acc=0.956, train_loss=0.189]\n",
      "Validating:  28%|██▊       | 15/54 [00:10<00:22,  1.72it/s]\u001b[A\n",
      "Epoch 13:   1%|          | 18/1770 [00:11<-1:59:06, -32.15it/s, loss=0.167, v_num=7, val_loss=0.0571, val_acc=0.956, train_loss=0.189]\n",
      "Validating:  31%|███▏      | 17/54 [00:11<00:21,  1.73it/s]\u001b[A\n",
      "Epoch 13:   1%|          | 20/1770 [00:13<-1:59:00, -29.15it/s, loss=0.167, v_num=7, val_loss=0.0571, val_acc=0.956, train_loss=0.189]\n",
      "Validating:  35%|███▌      | 19/54 [00:12<00:20,  1.74it/s]\u001b[A\n",
      "Epoch 13:   1%|          | 22/1770 [00:14<-1:58:55, -26.64it/s, loss=0.167, v_num=7, val_loss=0.0571, val_acc=0.956, train_loss=0.189]\n",
      "Validating:  39%|███▉      | 21/54 [00:14<00:18,  1.74it/s]\u001b[A\n",
      "Epoch 13:   1%|▏         | 24/1770 [00:15<-1:58:49, -24.51it/s, loss=0.167, v_num=7, val_loss=0.0571, val_acc=0.956, train_loss=0.189]\n",
      "Validating:  43%|████▎     | 23/54 [00:15<00:17,  1.73it/s]\u001b[A\n",
      "Epoch 13:   1%|▏         | 26/1770 [00:16<-1:58:44, -22.66it/s, loss=0.167, v_num=7, val_loss=0.0571, val_acc=0.956, train_loss=0.189]\n",
      "Validating:  46%|████▋     | 25/54 [00:16<00:16,  1.73it/s]\u001b[A\n",
      "Epoch 13:   2%|▏         | 28/1770 [00:17<-1:58:38, -21.06it/s, loss=0.167, v_num=7, val_loss=0.0571, val_acc=0.956, train_loss=0.189]\n",
      "Validating:  50%|█████     | 27/54 [00:17<00:15,  1.74it/s]\u001b[A\n",
      "Epoch 13:   2%|▏         | 30/1770 [00:18<-1:58:32, -19.67it/s, loss=0.167, v_num=7, val_loss=0.0571, val_acc=0.956, train_loss=0.189]\n",
      "Validating:  54%|█████▎    | 29/54 [00:18<00:14,  1.73it/s]\u001b[A\n",
      "Epoch 13:   2%|▏         | 32/1770 [00:19<-1:58:26, -18.43it/s, loss=0.167, v_num=7, val_loss=0.0571, val_acc=0.956, train_loss=0.189]\n",
      "Validating:  57%|█████▋    | 31/54 [00:19<00:13,  1.73it/s]\u001b[A\n",
      "Epoch 13:   2%|▏         | 34/1770 [00:21<-1:58:20, -17.32it/s, loss=0.167, v_num=7, val_loss=0.0571, val_acc=0.956, train_loss=0.189]\n",
      "Validating:  61%|██████    | 33/54 [00:20<00:12,  1.73it/s]\u001b[A\n",
      "Epoch 13:   2%|▏         | 36/1770 [00:22<-1:58:14, -16.33it/s, loss=0.167, v_num=7, val_loss=0.0571, val_acc=0.956, train_loss=0.189]\n",
      "Validating:  65%|██████▍   | 35/54 [00:22<00:10,  1.73it/s]\u001b[A\n",
      "Epoch 13:   2%|▏         | 38/1770 [00:23<-1:58:08, -15.44it/s, loss=0.167, v_num=7, val_loss=0.0571, val_acc=0.956, train_loss=0.189]\n",
      "Validating:  69%|██████▊   | 37/54 [00:23<00:09,  1.73it/s]\u001b[A\n",
      "Epoch 13:   2%|▏         | 40/1770 [00:24<-1:58:02, -14.63it/s, loss=0.167, v_num=7, val_loss=0.0571, val_acc=0.956, train_loss=0.189]\n",
      "Validating:  72%|███████▏  | 39/54 [00:24<00:08,  1.73it/s]\u001b[A\n",
      "Epoch 13:   2%|▏         | 42/1770 [00:25<-1:57:56, -13.89it/s, loss=0.167, v_num=7, val_loss=0.0571, val_acc=0.956, train_loss=0.189]\n",
      "Validating:  76%|███████▌  | 41/54 [00:25<00:07,  1.73it/s]\u001b[A\n",
      "Epoch 13:   2%|▏         | 44/1770 [00:26<-1:57:50, -13.22it/s, loss=0.167, v_num=7, val_loss=0.0571, val_acc=0.956, train_loss=0.189]\n",
      "Validating:  80%|███████▉  | 43/54 [00:26<00:06,  1.73it/s]\u001b[A\n",
      "Epoch 13:   3%|▎         | 46/1770 [00:28<-1:57:44, -12.60it/s, loss=0.167, v_num=7, val_loss=0.0571, val_acc=0.956, train_loss=0.189]\n",
      "Validating:  83%|████████▎ | 45/54 [00:27<00:05,  1.75it/s]\u001b[A\n",
      "Epoch 13:   3%|▎         | 48/1770 [00:29<-1:57:38, -12.05it/s, loss=0.167, v_num=7, val_loss=0.0571, val_acc=0.956, train_loss=0.189]\n",
      "Validating:  87%|████████▋ | 47/54 [00:28<00:03,  1.77it/s]\u001b[A\n",
      "Epoch 13:   3%|▎         | 50/1770 [00:30<-1:57:31, -11.54it/s, loss=0.167, v_num=7, val_loss=0.0571, val_acc=0.956, train_loss=0.189]\n",
      "Validating:  91%|█████████ | 49/54 [00:30<00:02,  1.78it/s]\u001b[A\n",
      "Epoch 13:   3%|▎         | 52/1770 [00:31<-1:57:25, -11.07it/s, loss=0.167, v_num=7, val_loss=0.0571, val_acc=0.956, train_loss=0.189]\n",
      "Validating:  94%|█████████▍| 51/54 [00:31<00:01,  1.79it/s]\u001b[A\n",
      "Epoch 13:   3%|▎         | 54/1770 [00:32<-1:57:19, -10.63it/s, loss=0.167, v_num=7, val_loss=0.0571, val_acc=0.956, train_loss=0.189]\n",
      "Validating:  98%|█████████▊| 53/54 [00:32<00:00,  1.79it/s]\u001b[A\n",
      "Epoch 13:   3%|▎         | 56/1770 [00:33<-1:57:13, -10.25it/s, loss=0.167, v_num=7, val_loss=0.0576, val_acc=0.957, train_loss=0.136]\n",
      "                                                           \u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer was signaled to stop but required minimum epochs (15) or minimum steps (None) has not been met. Training will continue...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14:   0%|          | 2/1770 [00:00<-1:59:57, -565.83it/s, loss=0.167, v_num=7, val_loss=0.0576, val_acc=0.957, train_loss=0.136] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   2%|▏         | 1/54 [00:01<01:42,  1.93s/it]\u001b[A\n",
      "Epoch 14:   0%|          | 4/1770 [00:03<-1:59:46, -120.26it/s, loss=0.167, v_num=7, val_loss=0.0576, val_acc=0.957, train_loss=0.136]\n",
      "Validating:   6%|▌         | 3/54 [00:03<00:47,  1.07it/s]\u001b[A\n",
      "Epoch 14:   0%|          | 6/1770 [00:04<-1:59:40, -86.21it/s, loss=0.167, v_num=7, val_loss=0.0576, val_acc=0.957, train_loss=0.136] \n",
      "Validating:   9%|▉         | 5/54 [00:04<00:35,  1.38it/s]\u001b[A\n",
      "Epoch 14:   0%|          | 8/1770 [00:05<-1:59:35, -68.43it/s, loss=0.167, v_num=7, val_loss=0.0576, val_acc=0.957, train_loss=0.136]\n",
      "Validating:  13%|█▎        | 7/54 [00:05<00:30,  1.55it/s]\u001b[A\n",
      "Epoch 14:   1%|          | 10/1770 [00:06<-1:59:29, -56.61it/s, loss=0.167, v_num=7, val_loss=0.0576, val_acc=0.957, train_loss=0.136]\n",
      "Validating:  17%|█▋        | 9/54 [00:06<00:27,  1.64it/s]\u001b[A\n",
      "Epoch 14:   1%|          | 12/1770 [00:08<-1:59:24, -48.19it/s, loss=0.167, v_num=7, val_loss=0.0576, val_acc=0.957, train_loss=0.136]\n",
      "Validating:  20%|██        | 11/54 [00:07<00:25,  1.68it/s]\u001b[A\n",
      "Epoch 14:   1%|          | 14/1770 [00:09<-1:59:19, -41.91it/s, loss=0.167, v_num=7, val_loss=0.0576, val_acc=0.957, train_loss=0.136]\n",
      "Validating:  24%|██▍       | 13/54 [00:09<00:23,  1.71it/s]\u001b[A\n",
      "Epoch 14:   1%|          | 16/1770 [00:10<-1:59:13, -37.05it/s, loss=0.167, v_num=7, val_loss=0.0576, val_acc=0.957, train_loss=0.136]\n",
      "Validating:  28%|██▊       | 15/54 [00:10<00:22,  1.72it/s]\u001b[A\n",
      "Epoch 14:   1%|          | 18/1770 [00:11<-1:59:08, -33.15it/s, loss=0.167, v_num=7, val_loss=0.0576, val_acc=0.957, train_loss=0.136]\n",
      "Validating:  31%|███▏      | 17/54 [00:11<00:21,  1.72it/s]\u001b[A\n",
      "Epoch 14:   1%|          | 20/1770 [00:12<-1:59:02, -29.96it/s, loss=0.167, v_num=7, val_loss=0.0576, val_acc=0.957, train_loss=0.136]\n",
      "Validating:  35%|███▌      | 19/54 [00:12<00:20,  1.73it/s]\u001b[A\n",
      "Epoch 14:   1%|          | 22/1770 [00:13<-1:58:56, -27.30it/s, loss=0.167, v_num=7, val_loss=0.0576, val_acc=0.957, train_loss=0.136]\n",
      "Validating:  39%|███▉      | 21/54 [00:13<00:19,  1.73it/s]\u001b[A\n",
      "Epoch 14:   1%|▏         | 24/1770 [00:14<-1:58:51, -25.08it/s, loss=0.167, v_num=7, val_loss=0.0576, val_acc=0.957, train_loss=0.136]\n",
      "Validating:  43%|████▎     | 23/54 [00:14<00:17,  1.73it/s]\u001b[A\n",
      "Epoch 14:   1%|▏         | 26/1770 [00:16<-1:58:45, -23.17it/s, loss=0.167, v_num=7, val_loss=0.0576, val_acc=0.957, train_loss=0.136]\n",
      "Validating:  46%|████▋     | 25/54 [00:15<00:16,  1.74it/s]\u001b[A\n",
      "Epoch 14:   2%|▏         | 28/1770 [00:17<-1:58:40, -21.51it/s, loss=0.167, v_num=7, val_loss=0.0576, val_acc=0.957, train_loss=0.136]\n",
      "Validating:  50%|█████     | 27/54 [00:17<00:15,  1.74it/s]\u001b[A\n",
      "Epoch 14:   2%|▏         | 30/1770 [00:18<-1:58:34, -20.06it/s, loss=0.167, v_num=7, val_loss=0.0576, val_acc=0.957, train_loss=0.136]\n",
      "Validating:  54%|█████▎    | 29/54 [00:18<00:14,  1.74it/s]\u001b[A\n",
      "Epoch 14:   2%|▏         | 32/1770 [00:19<-1:58:28, -18.78it/s, loss=0.167, v_num=7, val_loss=0.0576, val_acc=0.957, train_loss=0.136]\n",
      "Validating:  57%|█████▋    | 31/54 [00:19<00:13,  1.74it/s]\u001b[A\n",
      "Epoch 14:   2%|▏         | 34/1770 [00:20<-1:58:22, -17.64it/s, loss=0.167, v_num=7, val_loss=0.0576, val_acc=0.957, train_loss=0.136]\n",
      "Validating:  61%|██████    | 33/54 [00:20<00:12,  1.74it/s]\u001b[A\n",
      "Epoch 14:   2%|▏         | 36/1770 [00:21<-1:58:16, -16.62it/s, loss=0.167, v_num=7, val_loss=0.0576, val_acc=0.957, train_loss=0.136]\n",
      "Validating:  65%|██████▍   | 35/54 [00:21<00:10,  1.74it/s]\u001b[A\n",
      "Epoch 14:   2%|▏         | 38/1770 [00:22<-1:58:10, -15.70it/s, loss=0.167, v_num=7, val_loss=0.0576, val_acc=0.957, train_loss=0.136]\n",
      "Validating:  69%|██████▊   | 37/54 [00:22<00:09,  1.74it/s]\u001b[A\n",
      "Epoch 14:   2%|▏         | 40/1770 [00:24<-1:58:04, -14.87it/s, loss=0.167, v_num=7, val_loss=0.0576, val_acc=0.957, train_loss=0.136]\n",
      "Validating:  72%|███████▏  | 39/54 [00:24<00:08,  1.74it/s]\u001b[A\n",
      "Epoch 14:   2%|▏         | 42/1770 [00:25<-1:57:58, -14.11it/s, loss=0.167, v_num=7, val_loss=0.0576, val_acc=0.957, train_loss=0.136]\n",
      "Validating:  76%|███████▌  | 41/54 [00:25<00:07,  1.74it/s]\u001b[A\n",
      "Epoch 14:   2%|▏         | 44/1770 [00:26<-1:57:52, -13.42it/s, loss=0.167, v_num=7, val_loss=0.0576, val_acc=0.957, train_loss=0.136]\n",
      "Validating:  80%|███████▉  | 43/54 [00:26<00:06,  1.74it/s]\u001b[A\n",
      "Epoch 14:   3%|▎         | 46/1770 [00:27<-1:57:46, -12.80it/s, loss=0.167, v_num=7, val_loss=0.0576, val_acc=0.957, train_loss=0.136]\n",
      "Validating:  83%|████████▎ | 45/54 [00:27<00:05,  1.76it/s]\u001b[A\n",
      "Epoch 14:   3%|▎         | 48/1770 [00:28<-1:57:40, -12.23it/s, loss=0.167, v_num=7, val_loss=0.0576, val_acc=0.957, train_loss=0.136]\n",
      "Validating:  87%|████████▋ | 47/54 [00:28<00:03,  1.78it/s]\u001b[A\n",
      "Epoch 14:   3%|▎         | 50/1770 [00:29<-1:57:34, -11.70it/s, loss=0.167, v_num=7, val_loss=0.0576, val_acc=0.957, train_loss=0.136]\n",
      "Validating:  91%|█████████ | 49/54 [00:29<00:02,  1.79it/s]\u001b[A\n",
      "Epoch 14:   3%|▎         | 52/1770 [00:30<-1:57:27, -11.22it/s, loss=0.167, v_num=7, val_loss=0.0576, val_acc=0.957, train_loss=0.136]\n",
      "Validating:  94%|█████████▍| 51/54 [00:30<00:01,  1.79it/s]\u001b[A\n",
      "Epoch 14:   3%|▎         | 54/1770 [00:32<-1:57:21, -10.77it/s, loss=0.167, v_num=7, val_loss=0.0576, val_acc=0.957, train_loss=0.136]\n",
      "Validating:  98%|█████████▊| 53/54 [00:31<00:00,  1.79it/s]\u001b[A\n",
      "Epoch 14:   3%|▎         | 56/1770 [00:33<-1:57:15, -10.38it/s, loss=0.167, v_num=7, val_loss=0.0577, val_acc=0.957, train_loss=0.226]\n",
      "                                                           \u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: None, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training fold 1\n",
      "Class sample counts [ 675 1381 1481 8725 1463]\n",
      "After class sample counts [2025 2762 3406 8725 3950]\n",
      "conv_stem.weight True\n",
      "bn1.weight False\n",
      "bn1.bias False\n",
      "blocks.0.0.conv_dw.weight True\n",
      "blocks.0.0.bn1.weight False\n",
      "blocks.0.0.bn1.bias False\n",
      "blocks.0.0.se.conv_reduce.weight True\n",
      "blocks.0.0.se.conv_reduce.bias True\n",
      "blocks.0.0.se.conv_expand.weight True\n",
      "blocks.0.0.se.conv_expand.bias True\n",
      "blocks.0.0.conv_pw.weight True\n",
      "blocks.0.0.bn2.weight False\n",
      "blocks.0.0.bn2.bias False\n",
      "blocks.0.1.conv_dw.weight True\n",
      "blocks.0.1.bn1.weight False\n",
      "blocks.0.1.bn1.bias False\n",
      "blocks.0.1.se.conv_reduce.weight True\n",
      "blocks.0.1.se.conv_reduce.bias True\n",
      "blocks.0.1.se.conv_expand.weight True\n",
      "blocks.0.1.se.conv_expand.bias True\n",
      "blocks.0.1.conv_pw.weight True\n",
      "blocks.0.1.bn2.weight False\n",
      "blocks.0.1.bn2.bias False\n",
      "blocks.1.0.conv_pw.weight True\n",
      "blocks.1.0.bn1.weight False\n",
      "blocks.1.0.bn1.bias False\n",
      "blocks.1.0.conv_dw.weight True\n",
      "blocks.1.0.bn2.weight False\n",
      "blocks.1.0.bn2.bias False\n",
      "blocks.1.0.se.conv_reduce.weight True\n",
      "blocks.1.0.se.conv_reduce.bias True\n",
      "blocks.1.0.se.conv_expand.weight True\n",
      "blocks.1.0.se.conv_expand.bias True\n",
      "blocks.1.0.conv_pwl.weight True\n",
      "blocks.1.0.bn3.weight False\n",
      "blocks.1.0.bn3.bias False\n",
      "blocks.1.1.conv_pw.weight True\n",
      "blocks.1.1.bn1.weight False\n",
      "blocks.1.1.bn1.bias False\n",
      "blocks.1.1.conv_dw.weight True\n",
      "blocks.1.1.bn2.weight False\n",
      "blocks.1.1.bn2.bias False\n",
      "blocks.1.1.se.conv_reduce.weight True\n",
      "blocks.1.1.se.conv_reduce.bias True\n",
      "blocks.1.1.se.conv_expand.weight True\n",
      "blocks.1.1.se.conv_expand.bias True\n",
      "blocks.1.1.conv_pwl.weight True\n",
      "blocks.1.1.bn3.weight False\n",
      "blocks.1.1.bn3.bias False\n",
      "blocks.1.2.conv_pw.weight True\n",
      "blocks.1.2.bn1.weight False\n",
      "blocks.1.2.bn1.bias False\n",
      "blocks.1.2.conv_dw.weight True\n",
      "blocks.1.2.bn2.weight False\n",
      "blocks.1.2.bn2.bias False\n",
      "blocks.1.2.se.conv_reduce.weight True\n",
      "blocks.1.2.se.conv_reduce.bias True\n",
      "blocks.1.2.se.conv_expand.weight True\n",
      "blocks.1.2.se.conv_expand.bias True\n",
      "blocks.1.2.conv_pwl.weight True\n",
      "blocks.1.2.bn3.weight False\n",
      "blocks.1.2.bn3.bias False\n",
      "blocks.1.3.conv_pw.weight True\n",
      "blocks.1.3.bn1.weight False\n",
      "blocks.1.3.bn1.bias False\n",
      "blocks.1.3.conv_dw.weight True\n",
      "blocks.1.3.bn2.weight False\n",
      "blocks.1.3.bn2.bias False\n",
      "blocks.1.3.se.conv_reduce.weight True\n",
      "blocks.1.3.se.conv_reduce.bias True\n",
      "blocks.1.3.se.conv_expand.weight True\n",
      "blocks.1.3.se.conv_expand.bias True\n",
      "blocks.1.3.conv_pwl.weight True\n",
      "blocks.1.3.bn3.weight False\n",
      "blocks.1.3.bn3.bias False\n",
      "blocks.2.0.conv_pw.weight True\n",
      "blocks.2.0.bn1.weight False\n",
      "blocks.2.0.bn1.bias False\n",
      "blocks.2.0.conv_dw.weight True\n",
      "blocks.2.0.bn2.weight False\n",
      "blocks.2.0.bn2.bias False\n",
      "blocks.2.0.se.conv_reduce.weight True\n",
      "blocks.2.0.se.conv_reduce.bias True\n",
      "blocks.2.0.se.conv_expand.weight True\n",
      "blocks.2.0.se.conv_expand.bias True\n",
      "blocks.2.0.conv_pwl.weight True\n",
      "blocks.2.0.bn3.weight False\n",
      "blocks.2.0.bn3.bias False\n",
      "blocks.2.1.conv_pw.weight True\n",
      "blocks.2.1.bn1.weight False\n",
      "blocks.2.1.bn1.bias False\n",
      "blocks.2.1.conv_dw.weight True\n",
      "blocks.2.1.bn2.weight False\n",
      "blocks.2.1.bn2.bias False\n",
      "blocks.2.1.se.conv_reduce.weight True\n",
      "blocks.2.1.se.conv_reduce.bias True\n",
      "blocks.2.1.se.conv_expand.weight True\n",
      "blocks.2.1.se.conv_expand.bias True\n",
      "blocks.2.1.conv_pwl.weight True\n",
      "blocks.2.1.bn3.weight False\n",
      "blocks.2.1.bn3.bias False\n",
      "blocks.2.2.conv_pw.weight True\n",
      "blocks.2.2.bn1.weight False\n",
      "blocks.2.2.bn1.bias False\n",
      "blocks.2.2.conv_dw.weight True\n",
      "blocks.2.2.bn2.weight False\n",
      "blocks.2.2.bn2.bias False\n",
      "blocks.2.2.se.conv_reduce.weight True\n",
      "blocks.2.2.se.conv_reduce.bias True\n",
      "blocks.2.2.se.conv_expand.weight True\n",
      "blocks.2.2.se.conv_expand.bias True\n",
      "blocks.2.2.conv_pwl.weight True\n",
      "blocks.2.2.bn3.weight False\n",
      "blocks.2.2.bn3.bias False\n",
      "blocks.2.3.conv_pw.weight True\n",
      "blocks.2.3.bn1.weight False\n",
      "blocks.2.3.bn1.bias False\n",
      "blocks.2.3.conv_dw.weight True\n",
      "blocks.2.3.bn2.weight False\n",
      "blocks.2.3.bn2.bias False\n",
      "blocks.2.3.se.conv_reduce.weight True\n",
      "blocks.2.3.se.conv_reduce.bias True\n",
      "blocks.2.3.se.conv_expand.weight True\n",
      "blocks.2.3.se.conv_expand.bias True\n",
      "blocks.2.3.conv_pwl.weight True\n",
      "blocks.2.3.bn3.weight False\n",
      "blocks.2.3.bn3.bias False\n",
      "blocks.3.0.conv_pw.weight True\n",
      "blocks.3.0.bn1.weight False\n",
      "blocks.3.0.bn1.bias False\n",
      "blocks.3.0.conv_dw.weight True\n",
      "blocks.3.0.bn2.weight False\n",
      "blocks.3.0.bn2.bias False\n",
      "blocks.3.0.se.conv_reduce.weight True\n",
      "blocks.3.0.se.conv_reduce.bias True\n",
      "blocks.3.0.se.conv_expand.weight True\n",
      "blocks.3.0.se.conv_expand.bias True\n",
      "blocks.3.0.conv_pwl.weight True\n",
      "blocks.3.0.bn3.weight False\n",
      "blocks.3.0.bn3.bias False\n",
      "blocks.3.1.conv_pw.weight True\n",
      "blocks.3.1.bn1.weight False\n",
      "blocks.3.1.bn1.bias False\n",
      "blocks.3.1.conv_dw.weight True\n",
      "blocks.3.1.bn2.weight False\n",
      "blocks.3.1.bn2.bias False\n",
      "blocks.3.1.se.conv_reduce.weight True\n",
      "blocks.3.1.se.conv_reduce.bias True\n",
      "blocks.3.1.se.conv_expand.weight True\n",
      "blocks.3.1.se.conv_expand.bias True\n",
      "blocks.3.1.conv_pwl.weight True\n",
      "blocks.3.1.bn3.weight False\n",
      "blocks.3.1.bn3.bias False\n",
      "blocks.3.2.conv_pw.weight True\n",
      "blocks.3.2.bn1.weight False\n",
      "blocks.3.2.bn1.bias False\n",
      "blocks.3.2.conv_dw.weight True\n",
      "blocks.3.2.bn2.weight False\n",
      "blocks.3.2.bn2.bias False\n",
      "blocks.3.2.se.conv_reduce.weight True\n",
      "blocks.3.2.se.conv_reduce.bias True\n",
      "blocks.3.2.se.conv_expand.weight True\n",
      "blocks.3.2.se.conv_expand.bias True\n",
      "blocks.3.2.conv_pwl.weight True\n",
      "blocks.3.2.bn3.weight False\n",
      "blocks.3.2.bn3.bias False\n",
      "blocks.3.3.conv_pw.weight True\n",
      "blocks.3.3.bn1.weight False\n",
      "blocks.3.3.bn1.bias False\n",
      "blocks.3.3.conv_dw.weight True\n",
      "blocks.3.3.bn2.weight False\n",
      "blocks.3.3.bn2.bias False\n",
      "blocks.3.3.se.conv_reduce.weight True\n",
      "blocks.3.3.se.conv_reduce.bias True\n",
      "blocks.3.3.se.conv_expand.weight True\n",
      "blocks.3.3.se.conv_expand.bias True\n",
      "blocks.3.3.conv_pwl.weight True\n",
      "blocks.3.3.bn3.weight False\n",
      "blocks.3.3.bn3.bias False\n",
      "blocks.3.4.conv_pw.weight True\n",
      "blocks.3.4.bn1.weight False\n",
      "blocks.3.4.bn1.bias False\n",
      "blocks.3.4.conv_dw.weight True\n",
      "blocks.3.4.bn2.weight False\n",
      "blocks.3.4.bn2.bias False\n",
      "blocks.3.4.se.conv_reduce.weight True\n",
      "blocks.3.4.se.conv_reduce.bias True\n",
      "blocks.3.4.se.conv_expand.weight True\n",
      "blocks.3.4.se.conv_expand.bias True\n",
      "blocks.3.4.conv_pwl.weight True\n",
      "blocks.3.4.bn3.weight False\n",
      "blocks.3.4.bn3.bias False\n",
      "blocks.3.5.conv_pw.weight True\n",
      "blocks.3.5.bn1.weight False\n",
      "blocks.3.5.bn1.bias False\n",
      "blocks.3.5.conv_dw.weight True\n",
      "blocks.3.5.bn2.weight False\n",
      "blocks.3.5.bn2.bias False\n",
      "blocks.3.5.se.conv_reduce.weight True\n",
      "blocks.3.5.se.conv_reduce.bias True\n",
      "blocks.3.5.se.conv_expand.weight True\n",
      "blocks.3.5.se.conv_expand.bias True\n",
      "blocks.3.5.conv_pwl.weight True\n",
      "blocks.3.5.bn3.weight False\n",
      "blocks.3.5.bn3.bias False\n",
      "blocks.4.0.conv_pw.weight True\n",
      "blocks.4.0.bn1.weight False\n",
      "blocks.4.0.bn1.bias False\n",
      "blocks.4.0.conv_dw.weight True\n",
      "blocks.4.0.bn2.weight False\n",
      "blocks.4.0.bn2.bias False\n",
      "blocks.4.0.se.conv_reduce.weight True\n",
      "blocks.4.0.se.conv_reduce.bias True\n",
      "blocks.4.0.se.conv_expand.weight True\n",
      "blocks.4.0.se.conv_expand.bias True\n",
      "blocks.4.0.conv_pwl.weight True\n",
      "blocks.4.0.bn3.weight False\n",
      "blocks.4.0.bn3.bias False\n",
      "blocks.4.1.conv_pw.weight True\n",
      "blocks.4.1.bn1.weight False\n",
      "blocks.4.1.bn1.bias False\n",
      "blocks.4.1.conv_dw.weight True\n",
      "blocks.4.1.bn2.weight False\n",
      "blocks.4.1.bn2.bias False\n",
      "blocks.4.1.se.conv_reduce.weight True\n",
      "blocks.4.1.se.conv_reduce.bias True\n",
      "blocks.4.1.se.conv_expand.weight True\n",
      "blocks.4.1.se.conv_expand.bias True\n",
      "blocks.4.1.conv_pwl.weight True\n",
      "blocks.4.1.bn3.weight False\n",
      "blocks.4.1.bn3.bias False\n",
      "blocks.4.2.conv_pw.weight True\n",
      "blocks.4.2.bn1.weight False\n",
      "blocks.4.2.bn1.bias False\n",
      "blocks.4.2.conv_dw.weight True\n",
      "blocks.4.2.bn2.weight False\n",
      "blocks.4.2.bn2.bias False\n",
      "blocks.4.2.se.conv_reduce.weight True\n",
      "blocks.4.2.se.conv_reduce.bias True\n",
      "blocks.4.2.se.conv_expand.weight True\n",
      "blocks.4.2.se.conv_expand.bias True\n",
      "blocks.4.2.conv_pwl.weight True\n",
      "blocks.4.2.bn3.weight False\n",
      "blocks.4.2.bn3.bias False\n",
      "blocks.4.3.conv_pw.weight True\n",
      "blocks.4.3.bn1.weight False\n",
      "blocks.4.3.bn1.bias False\n",
      "blocks.4.3.conv_dw.weight True\n",
      "blocks.4.3.bn2.weight False\n",
      "blocks.4.3.bn2.bias False\n",
      "blocks.4.3.se.conv_reduce.weight True\n",
      "blocks.4.3.se.conv_reduce.bias True\n",
      "blocks.4.3.se.conv_expand.weight True\n",
      "blocks.4.3.se.conv_expand.bias True\n",
      "blocks.4.3.conv_pwl.weight True\n",
      "blocks.4.3.bn3.weight False\n",
      "blocks.4.3.bn3.bias False\n",
      "blocks.4.4.conv_pw.weight True\n",
      "blocks.4.4.bn1.weight False\n",
      "blocks.4.4.bn1.bias False\n",
      "blocks.4.4.conv_dw.weight True\n",
      "blocks.4.4.bn2.weight False\n",
      "blocks.4.4.bn2.bias False\n",
      "blocks.4.4.se.conv_reduce.weight True\n",
      "blocks.4.4.se.conv_reduce.bias True\n",
      "blocks.4.4.se.conv_expand.weight True\n",
      "blocks.4.4.se.conv_expand.bias True\n",
      "blocks.4.4.conv_pwl.weight True\n",
      "blocks.4.4.bn3.weight False\n",
      "blocks.4.4.bn3.bias False\n",
      "blocks.4.5.conv_pw.weight True\n",
      "blocks.4.5.bn1.weight False\n",
      "blocks.4.5.bn1.bias False\n",
      "blocks.4.5.conv_dw.weight True\n",
      "blocks.4.5.bn2.weight False\n",
      "blocks.4.5.bn2.bias False\n",
      "blocks.4.5.se.conv_reduce.weight True\n",
      "blocks.4.5.se.conv_reduce.bias True\n",
      "blocks.4.5.se.conv_expand.weight True\n",
      "blocks.4.5.se.conv_expand.bias True\n",
      "blocks.4.5.conv_pwl.weight True\n",
      "blocks.4.5.bn3.weight False\n",
      "blocks.4.5.bn3.bias False\n",
      "blocks.5.0.conv_pw.weight True\n",
      "blocks.5.0.bn1.weight False\n",
      "blocks.5.0.bn1.bias False\n",
      "blocks.5.0.conv_dw.weight True\n",
      "blocks.5.0.bn2.weight False\n",
      "blocks.5.0.bn2.bias False\n",
      "blocks.5.0.se.conv_reduce.weight True\n",
      "blocks.5.0.se.conv_reduce.bias True\n",
      "blocks.5.0.se.conv_expand.weight True\n",
      "blocks.5.0.se.conv_expand.bias True\n",
      "blocks.5.0.conv_pwl.weight True\n",
      "blocks.5.0.bn3.weight False\n",
      "blocks.5.0.bn3.bias False\n",
      "blocks.5.1.conv_pw.weight True\n",
      "blocks.5.1.bn1.weight False\n",
      "blocks.5.1.bn1.bias False\n",
      "blocks.5.1.conv_dw.weight True\n",
      "blocks.5.1.bn2.weight False\n",
      "blocks.5.1.bn2.bias False\n",
      "blocks.5.1.se.conv_reduce.weight True\n",
      "blocks.5.1.se.conv_reduce.bias True\n",
      "blocks.5.1.se.conv_expand.weight True\n",
      "blocks.5.1.se.conv_expand.bias True\n",
      "blocks.5.1.conv_pwl.weight True\n",
      "blocks.5.1.bn3.weight False\n",
      "blocks.5.1.bn3.bias False\n",
      "blocks.5.2.conv_pw.weight True\n",
      "blocks.5.2.bn1.weight False\n",
      "blocks.5.2.bn1.bias False\n",
      "blocks.5.2.conv_dw.weight True\n",
      "blocks.5.2.bn2.weight False\n",
      "blocks.5.2.bn2.bias False\n",
      "blocks.5.2.se.conv_reduce.weight True\n",
      "blocks.5.2.se.conv_reduce.bias True\n",
      "blocks.5.2.se.conv_expand.weight True\n",
      "blocks.5.2.se.conv_expand.bias True\n",
      "blocks.5.2.conv_pwl.weight True\n",
      "blocks.5.2.bn3.weight False\n",
      "blocks.5.2.bn3.bias False\n",
      "blocks.5.3.conv_pw.weight True\n",
      "blocks.5.3.bn1.weight False\n",
      "blocks.5.3.bn1.bias False\n",
      "blocks.5.3.conv_dw.weight True\n",
      "blocks.5.3.bn2.weight False\n",
      "blocks.5.3.bn2.bias False\n",
      "blocks.5.3.se.conv_reduce.weight True\n",
      "blocks.5.3.se.conv_reduce.bias True\n",
      "blocks.5.3.se.conv_expand.weight True\n",
      "blocks.5.3.se.conv_expand.bias True\n",
      "blocks.5.3.conv_pwl.weight True\n",
      "blocks.5.3.bn3.weight False\n",
      "blocks.5.3.bn3.bias False\n",
      "blocks.5.4.conv_pw.weight True\n",
      "blocks.5.4.bn1.weight False\n",
      "blocks.5.4.bn1.bias False\n",
      "blocks.5.4.conv_dw.weight True\n",
      "blocks.5.4.bn2.weight False\n",
      "blocks.5.4.bn2.bias False\n",
      "blocks.5.4.se.conv_reduce.weight True\n",
      "blocks.5.4.se.conv_reduce.bias True\n",
      "blocks.5.4.se.conv_expand.weight True\n",
      "blocks.5.4.se.conv_expand.bias True\n",
      "blocks.5.4.conv_pwl.weight True\n",
      "blocks.5.4.bn3.weight False\n",
      "blocks.5.4.bn3.bias False\n",
      "blocks.5.5.conv_pw.weight True\n",
      "blocks.5.5.bn1.weight False\n",
      "blocks.5.5.bn1.bias False\n",
      "blocks.5.5.conv_dw.weight True\n",
      "blocks.5.5.bn2.weight False\n",
      "blocks.5.5.bn2.bias False\n",
      "blocks.5.5.se.conv_reduce.weight True\n",
      "blocks.5.5.se.conv_reduce.bias True\n",
      "blocks.5.5.se.conv_expand.weight True\n",
      "blocks.5.5.se.conv_expand.bias True\n",
      "blocks.5.5.conv_pwl.weight True\n",
      "blocks.5.5.bn3.weight False\n",
      "blocks.5.5.bn3.bias False\n",
      "blocks.5.6.conv_pw.weight True\n",
      "blocks.5.6.bn1.weight False\n",
      "blocks.5.6.bn1.bias False\n",
      "blocks.5.6.conv_dw.weight True\n",
      "blocks.5.6.bn2.weight False\n",
      "blocks.5.6.bn2.bias False\n",
      "blocks.5.6.se.conv_reduce.weight True\n",
      "blocks.5.6.se.conv_reduce.bias True\n",
      "blocks.5.6.se.conv_expand.weight True\n",
      "blocks.5.6.se.conv_expand.bias True\n",
      "blocks.5.6.conv_pwl.weight True\n",
      "blocks.5.6.bn3.weight False\n",
      "blocks.5.6.bn3.bias False\n",
      "blocks.5.7.conv_pw.weight True\n",
      "blocks.5.7.bn1.weight False\n",
      "blocks.5.7.bn1.bias False\n",
      "blocks.5.7.conv_dw.weight True\n",
      "blocks.5.7.bn2.weight False\n",
      "blocks.5.7.bn2.bias False\n",
      "blocks.5.7.se.conv_reduce.weight True\n",
      "blocks.5.7.se.conv_reduce.bias True\n",
      "blocks.5.7.se.conv_expand.weight True\n",
      "blocks.5.7.se.conv_expand.bias True\n",
      "blocks.5.7.conv_pwl.weight True\n",
      "blocks.5.7.bn3.weight False\n",
      "blocks.5.7.bn3.bias False\n",
      "blocks.6.0.conv_pw.weight True\n",
      "blocks.6.0.bn1.weight False\n",
      "blocks.6.0.bn1.bias False\n",
      "blocks.6.0.conv_dw.weight True\n",
      "blocks.6.0.bn2.weight False\n",
      "blocks.6.0.bn2.bias False\n",
      "blocks.6.0.se.conv_reduce.weight True\n",
      "blocks.6.0.se.conv_reduce.bias True\n",
      "blocks.6.0.se.conv_expand.weight True\n",
      "blocks.6.0.se.conv_expand.bias True\n",
      "blocks.6.0.conv_pwl.weight True\n",
      "blocks.6.0.bn3.weight False\n",
      "blocks.6.0.bn3.bias False\n",
      "blocks.6.1.conv_pw.weight True\n",
      "blocks.6.1.bn1.weight False\n",
      "blocks.6.1.bn1.bias False\n",
      "blocks.6.1.conv_dw.weight True\n",
      "blocks.6.1.bn2.weight False\n",
      "blocks.6.1.bn2.bias False\n",
      "blocks.6.1.se.conv_reduce.weight True\n",
      "blocks.6.1.se.conv_reduce.bias True\n",
      "blocks.6.1.se.conv_expand.weight True\n",
      "blocks.6.1.se.conv_expand.bias True\n",
      "blocks.6.1.conv_pwl.weight True\n",
      "blocks.6.1.bn3.weight False\n",
      "blocks.6.1.bn3.bias False\n",
      "conv_head.weight True\n",
      "bn2.weight False\n",
      "bn2.bias False\n",
      "classifier.weight True\n",
      "classifier.bias True\n",
      "EfficientNet(\n",
      "  (conv_stem): Conv2dSame(3, 48, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
      "  (bn1): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (act1): SiLU(inplace=True)\n",
      "  (blocks): Sequential(\n",
      "    (0): Sequential(\n",
      "      (0): DepthwiseSeparableConv(\n",
      "        (conv_dw): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=48, bias=False)\n",
      "        (bn1): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act1): SiLU(inplace=True)\n",
      "        (se): SqueezeExcite(\n",
      "          (conv_reduce): Conv2d(48, 12, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (act1): SiLU(inplace=True)\n",
      "          (conv_expand): Conv2d(12, 48, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "        (conv_pw): Conv2d(48, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(24, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act2): Identity()\n",
      "      )\n",
      "      (1): DepthwiseSeparableConv(\n",
      "        (conv_dw): Conv2d(24, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=24, bias=False)\n",
      "        (bn1): BatchNorm2d(24, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act1): SiLU(inplace=True)\n",
      "        (se): SqueezeExcite(\n",
      "          (conv_reduce): Conv2d(24, 6, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (act1): SiLU(inplace=True)\n",
      "          (conv_expand): Conv2d(6, 24, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "        (conv_pw): Conv2d(24, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(24, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act2): Identity()\n",
      "      )\n",
      "    )\n",
      "    (1): Sequential(\n",
      "      (0): InvertedResidual(\n",
      "        (conv_pw): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(144, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act1): SiLU(inplace=True)\n",
      "        (conv_dw): Conv2dSame(144, 144, kernel_size=(3, 3), stride=(2, 2), groups=144, bias=False)\n",
      "        (bn2): BatchNorm2d(144, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act2): SiLU(inplace=True)\n",
      "        (se): SqueezeExcite(\n",
      "          (conv_reduce): Conv2d(144, 6, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (act1): SiLU(inplace=True)\n",
      "          (conv_expand): Conv2d(6, 144, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "        (conv_pwl): Conv2d(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (1): InvertedResidual(\n",
      "        (conv_pw): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act1): SiLU(inplace=True)\n",
      "        (conv_dw): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
      "        (bn2): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act2): SiLU(inplace=True)\n",
      "        (se): SqueezeExcite(\n",
      "          (conv_reduce): Conv2d(192, 8, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (act1): SiLU(inplace=True)\n",
      "          (conv_expand): Conv2d(8, 192, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "        (conv_pwl): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (2): InvertedResidual(\n",
      "        (conv_pw): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act1): SiLU(inplace=True)\n",
      "        (conv_dw): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
      "        (bn2): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act2): SiLU(inplace=True)\n",
      "        (se): SqueezeExcite(\n",
      "          (conv_reduce): Conv2d(192, 8, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (act1): SiLU(inplace=True)\n",
      "          (conv_expand): Conv2d(8, 192, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "        (conv_pwl): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (3): InvertedResidual(\n",
      "        (conv_pw): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act1): SiLU(inplace=True)\n",
      "        (conv_dw): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
      "        (bn2): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act2): SiLU(inplace=True)\n",
      "        (se): SqueezeExcite(\n",
      "          (conv_reduce): Conv2d(192, 8, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (act1): SiLU(inplace=True)\n",
      "          (conv_expand): Conv2d(8, 192, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "        (conv_pwl): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (2): Sequential(\n",
      "      (0): InvertedResidual(\n",
      "        (conv_pw): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act1): SiLU(inplace=True)\n",
      "        (conv_dw): Conv2dSame(192, 192, kernel_size=(5, 5), stride=(2, 2), groups=192, bias=False)\n",
      "        (bn2): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act2): SiLU(inplace=True)\n",
      "        (se): SqueezeExcite(\n",
      "          (conv_reduce): Conv2d(192, 8, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (act1): SiLU(inplace=True)\n",
      "          (conv_expand): Conv2d(8, 192, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "        (conv_pwl): Conv2d(192, 56, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(56, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (1): InvertedResidual(\n",
      "        (conv_pw): Conv2d(56, 336, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(336, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act1): SiLU(inplace=True)\n",
      "        (conv_dw): Conv2d(336, 336, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=336, bias=False)\n",
      "        (bn2): BatchNorm2d(336, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act2): SiLU(inplace=True)\n",
      "        (se): SqueezeExcite(\n",
      "          (conv_reduce): Conv2d(336, 14, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (act1): SiLU(inplace=True)\n",
      "          (conv_expand): Conv2d(14, 336, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "        (conv_pwl): Conv2d(336, 56, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(56, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (2): InvertedResidual(\n",
      "        (conv_pw): Conv2d(56, 336, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(336, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act1): SiLU(inplace=True)\n",
      "        (conv_dw): Conv2d(336, 336, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=336, bias=False)\n",
      "        (bn2): BatchNorm2d(336, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act2): SiLU(inplace=True)\n",
      "        (se): SqueezeExcite(\n",
      "          (conv_reduce): Conv2d(336, 14, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (act1): SiLU(inplace=True)\n",
      "          (conv_expand): Conv2d(14, 336, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "        (conv_pwl): Conv2d(336, 56, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(56, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (3): InvertedResidual(\n",
      "        (conv_pw): Conv2d(56, 336, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(336, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act1): SiLU(inplace=True)\n",
      "        (conv_dw): Conv2d(336, 336, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=336, bias=False)\n",
      "        (bn2): BatchNorm2d(336, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act2): SiLU(inplace=True)\n",
      "        (se): SqueezeExcite(\n",
      "          (conv_reduce): Conv2d(336, 14, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (act1): SiLU(inplace=True)\n",
      "          (conv_expand): Conv2d(14, 336, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "        (conv_pwl): Conv2d(336, 56, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(56, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (3): Sequential(\n",
      "      (0): InvertedResidual(\n",
      "        (conv_pw): Conv2d(56, 336, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(336, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act1): SiLU(inplace=True)\n",
      "        (conv_dw): Conv2dSame(336, 336, kernel_size=(3, 3), stride=(2, 2), groups=336, bias=False)\n",
      "        (bn2): BatchNorm2d(336, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act2): SiLU(inplace=True)\n",
      "        (se): SqueezeExcite(\n",
      "          (conv_reduce): Conv2d(336, 14, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (act1): SiLU(inplace=True)\n",
      "          (conv_expand): Conv2d(14, 336, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "        (conv_pwl): Conv2d(336, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(112, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (1): InvertedResidual(\n",
      "        (conv_pw): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act1): SiLU(inplace=True)\n",
      "        (conv_dw): Conv2d(672, 672, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=672, bias=False)\n",
      "        (bn2): BatchNorm2d(672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act2): SiLU(inplace=True)\n",
      "        (se): SqueezeExcite(\n",
      "          (conv_reduce): Conv2d(672, 28, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (act1): SiLU(inplace=True)\n",
      "          (conv_expand): Conv2d(28, 672, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "        (conv_pwl): Conv2d(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(112, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (2): InvertedResidual(\n",
      "        (conv_pw): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act1): SiLU(inplace=True)\n",
      "        (conv_dw): Conv2d(672, 672, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=672, bias=False)\n",
      "        (bn2): BatchNorm2d(672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act2): SiLU(inplace=True)\n",
      "        (se): SqueezeExcite(\n",
      "          (conv_reduce): Conv2d(672, 28, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (act1): SiLU(inplace=True)\n",
      "          (conv_expand): Conv2d(28, 672, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "        (conv_pwl): Conv2d(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(112, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (3): InvertedResidual(\n",
      "        (conv_pw): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act1): SiLU(inplace=True)\n",
      "        (conv_dw): Conv2d(672, 672, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=672, bias=False)\n",
      "        (bn2): BatchNorm2d(672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act2): SiLU(inplace=True)\n",
      "        (se): SqueezeExcite(\n",
      "          (conv_reduce): Conv2d(672, 28, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (act1): SiLU(inplace=True)\n",
      "          (conv_expand): Conv2d(28, 672, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "        (conv_pwl): Conv2d(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(112, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (4): InvertedResidual(\n",
      "        (conv_pw): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act1): SiLU(inplace=True)\n",
      "        (conv_dw): Conv2d(672, 672, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=672, bias=False)\n",
      "        (bn2): BatchNorm2d(672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act2): SiLU(inplace=True)\n",
      "        (se): SqueezeExcite(\n",
      "          (conv_reduce): Conv2d(672, 28, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (act1): SiLU(inplace=True)\n",
      "          (conv_expand): Conv2d(28, 672, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "        (conv_pwl): Conv2d(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(112, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (5): InvertedResidual(\n",
      "        (conv_pw): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act1): SiLU(inplace=True)\n",
      "        (conv_dw): Conv2d(672, 672, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=672, bias=False)\n",
      "        (bn2): BatchNorm2d(672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act2): SiLU(inplace=True)\n",
      "        (se): SqueezeExcite(\n",
      "          (conv_reduce): Conv2d(672, 28, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (act1): SiLU(inplace=True)\n",
      "          (conv_expand): Conv2d(28, 672, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "        (conv_pwl): Conv2d(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(112, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (4): Sequential(\n",
      "      (0): InvertedResidual(\n",
      "        (conv_pw): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act1): SiLU(inplace=True)\n",
      "        (conv_dw): Conv2d(672, 672, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=672, bias=False)\n",
      "        (bn2): BatchNorm2d(672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act2): SiLU(inplace=True)\n",
      "        (se): SqueezeExcite(\n",
      "          (conv_reduce): Conv2d(672, 28, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (act1): SiLU(inplace=True)\n",
      "          (conv_expand): Conv2d(28, 672, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "        (conv_pwl): Conv2d(672, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (1): InvertedResidual(\n",
      "        (conv_pw): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(960, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act1): SiLU(inplace=True)\n",
      "        (conv_dw): Conv2d(960, 960, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=960, bias=False)\n",
      "        (bn2): BatchNorm2d(960, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act2): SiLU(inplace=True)\n",
      "        (se): SqueezeExcite(\n",
      "          (conv_reduce): Conv2d(960, 40, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (act1): SiLU(inplace=True)\n",
      "          (conv_expand): Conv2d(40, 960, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "        (conv_pwl): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (2): InvertedResidual(\n",
      "        (conv_pw): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(960, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act1): SiLU(inplace=True)\n",
      "        (conv_dw): Conv2d(960, 960, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=960, bias=False)\n",
      "        (bn2): BatchNorm2d(960, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act2): SiLU(inplace=True)\n",
      "        (se): SqueezeExcite(\n",
      "          (conv_reduce): Conv2d(960, 40, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (act1): SiLU(inplace=True)\n",
      "          (conv_expand): Conv2d(40, 960, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "        (conv_pwl): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (3): InvertedResidual(\n",
      "        (conv_pw): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(960, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act1): SiLU(inplace=True)\n",
      "        (conv_dw): Conv2d(960, 960, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=960, bias=False)\n",
      "        (bn2): BatchNorm2d(960, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act2): SiLU(inplace=True)\n",
      "        (se): SqueezeExcite(\n",
      "          (conv_reduce): Conv2d(960, 40, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (act1): SiLU(inplace=True)\n",
      "          (conv_expand): Conv2d(40, 960, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "        (conv_pwl): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (4): InvertedResidual(\n",
      "        (conv_pw): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(960, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act1): SiLU(inplace=True)\n",
      "        (conv_dw): Conv2d(960, 960, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=960, bias=False)\n",
      "        (bn2): BatchNorm2d(960, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act2): SiLU(inplace=True)\n",
      "        (se): SqueezeExcite(\n",
      "          (conv_reduce): Conv2d(960, 40, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (act1): SiLU(inplace=True)\n",
      "          (conv_expand): Conv2d(40, 960, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "        (conv_pwl): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (5): InvertedResidual(\n",
      "        (conv_pw): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(960, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act1): SiLU(inplace=True)\n",
      "        (conv_dw): Conv2d(960, 960, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=960, bias=False)\n",
      "        (bn2): BatchNorm2d(960, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act2): SiLU(inplace=True)\n",
      "        (se): SqueezeExcite(\n",
      "          (conv_reduce): Conv2d(960, 40, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (act1): SiLU(inplace=True)\n",
      "          (conv_expand): Conv2d(40, 960, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "        (conv_pwl): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (5): Sequential(\n",
      "      (0): InvertedResidual(\n",
      "        (conv_pw): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(960, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act1): SiLU(inplace=True)\n",
      "        (conv_dw): Conv2dSame(960, 960, kernel_size=(5, 5), stride=(2, 2), groups=960, bias=False)\n",
      "        (bn2): BatchNorm2d(960, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act2): SiLU(inplace=True)\n",
      "        (se): SqueezeExcite(\n",
      "          (conv_reduce): Conv2d(960, 40, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (act1): SiLU(inplace=True)\n",
      "          (conv_expand): Conv2d(40, 960, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "        (conv_pwl): Conv2d(960, 272, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(272, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (1): InvertedResidual(\n",
      "        (conv_pw): Conv2d(272, 1632, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(1632, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act1): SiLU(inplace=True)\n",
      "        (conv_dw): Conv2d(1632, 1632, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1632, bias=False)\n",
      "        (bn2): BatchNorm2d(1632, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act2): SiLU(inplace=True)\n",
      "        (se): SqueezeExcite(\n",
      "          (conv_reduce): Conv2d(1632, 68, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (act1): SiLU(inplace=True)\n",
      "          (conv_expand): Conv2d(68, 1632, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "        (conv_pwl): Conv2d(1632, 272, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(272, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (2): InvertedResidual(\n",
      "        (conv_pw): Conv2d(272, 1632, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(1632, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act1): SiLU(inplace=True)\n",
      "        (conv_dw): Conv2d(1632, 1632, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1632, bias=False)\n",
      "        (bn2): BatchNorm2d(1632, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act2): SiLU(inplace=True)\n",
      "        (se): SqueezeExcite(\n",
      "          (conv_reduce): Conv2d(1632, 68, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (act1): SiLU(inplace=True)\n",
      "          (conv_expand): Conv2d(68, 1632, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "        (conv_pwl): Conv2d(1632, 272, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(272, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (3): InvertedResidual(\n",
      "        (conv_pw): Conv2d(272, 1632, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(1632, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act1): SiLU(inplace=True)\n",
      "        (conv_dw): Conv2d(1632, 1632, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1632, bias=False)\n",
      "        (bn2): BatchNorm2d(1632, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act2): SiLU(inplace=True)\n",
      "        (se): SqueezeExcite(\n",
      "          (conv_reduce): Conv2d(1632, 68, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (act1): SiLU(inplace=True)\n",
      "          (conv_expand): Conv2d(68, 1632, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "        (conv_pwl): Conv2d(1632, 272, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(272, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (4): InvertedResidual(\n",
      "        (conv_pw): Conv2d(272, 1632, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(1632, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act1): SiLU(inplace=True)\n",
      "        (conv_dw): Conv2d(1632, 1632, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1632, bias=False)\n",
      "        (bn2): BatchNorm2d(1632, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act2): SiLU(inplace=True)\n",
      "        (se): SqueezeExcite(\n",
      "          (conv_reduce): Conv2d(1632, 68, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (act1): SiLU(inplace=True)\n",
      "          (conv_expand): Conv2d(68, 1632, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "        (conv_pwl): Conv2d(1632, 272, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(272, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (5): InvertedResidual(\n",
      "        (conv_pw): Conv2d(272, 1632, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(1632, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act1): SiLU(inplace=True)\n",
      "        (conv_dw): Conv2d(1632, 1632, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1632, bias=False)\n",
      "        (bn2): BatchNorm2d(1632, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act2): SiLU(inplace=True)\n",
      "        (se): SqueezeExcite(\n",
      "          (conv_reduce): Conv2d(1632, 68, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (act1): SiLU(inplace=True)\n",
      "          (conv_expand): Conv2d(68, 1632, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "        (conv_pwl): Conv2d(1632, 272, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(272, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (6): InvertedResidual(\n",
      "        (conv_pw): Conv2d(272, 1632, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(1632, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act1): SiLU(inplace=True)\n",
      "        (conv_dw): Conv2d(1632, 1632, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1632, bias=False)\n",
      "        (bn2): BatchNorm2d(1632, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act2): SiLU(inplace=True)\n",
      "        (se): SqueezeExcite(\n",
      "          (conv_reduce): Conv2d(1632, 68, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (act1): SiLU(inplace=True)\n",
      "          (conv_expand): Conv2d(68, 1632, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "        (conv_pwl): Conv2d(1632, 272, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(272, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (7): InvertedResidual(\n",
      "        (conv_pw): Conv2d(272, 1632, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(1632, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act1): SiLU(inplace=True)\n",
      "        (conv_dw): Conv2d(1632, 1632, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1632, bias=False)\n",
      "        (bn2): BatchNorm2d(1632, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act2): SiLU(inplace=True)\n",
      "        (se): SqueezeExcite(\n",
      "          (conv_reduce): Conv2d(1632, 68, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (act1): SiLU(inplace=True)\n",
      "          (conv_expand): Conv2d(68, 1632, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "        (conv_pwl): Conv2d(1632, 272, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(272, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (6): Sequential(\n",
      "      (0): InvertedResidual(\n",
      "        (conv_pw): Conv2d(272, 1632, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(1632, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act1): SiLU(inplace=True)\n",
      "        (conv_dw): Conv2d(1632, 1632, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1632, bias=False)\n",
      "        (bn2): BatchNorm2d(1632, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act2): SiLU(inplace=True)\n",
      "        (se): SqueezeExcite(\n",
      "          (conv_reduce): Conv2d(1632, 68, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (act1): SiLU(inplace=True)\n",
      "          (conv_expand): Conv2d(68, 1632, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "        (conv_pwl): Conv2d(1632, 448, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(448, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (1): InvertedResidual(\n",
      "        (conv_pw): Conv2d(448, 2688, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(2688, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act1): SiLU(inplace=True)\n",
      "        (conv_dw): Conv2d(2688, 2688, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2688, bias=False)\n",
      "        (bn2): BatchNorm2d(2688, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act2): SiLU(inplace=True)\n",
      "        (se): SqueezeExcite(\n",
      "          (conv_reduce): Conv2d(2688, 112, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (act1): SiLU(inplace=True)\n",
      "          (conv_expand): Conv2d(112, 2688, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "        (conv_pwl): Conv2d(2688, 448, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(448, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (conv_head): Conv2d(448, 1792, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (bn2): BatchNorm2d(1792, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (act2): SiLU(inplace=True)\n",
      "  (global_pool): SelectAdaptivePool2d (pool_type=avg, flatten=True)\n",
      "  (classifier): Linear(in_features=1792, out_features=5, bias=True)\n",
      ")\n",
      "Tuning /opt/favordata/AI/Felix/kaggle-cassava/trained-models/sgd_coswarm_bnf_bitemp_smooth_weighted_t1=0.3_t2=1.0_89-53/tf_efficientnet_b4_ns_bitempered_smooth=0.05_val_loss=0.103_val_acc=0.889_fold1.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name           | Type           | Params\n",
      "--------------------------------------------------\n",
      "0 | valid_accuracy | Accuracy       | 0     \n",
      "1 | test_accuracy  | Accuracy       | 0     \n",
      "2 | criterion      | BiTemperedLoss | 0     \n",
      "3 | model          | EfficientNet   | 17.6 M\n",
      "--------------------------------------------------\n",
      "17.4 M    Trainable params\n",
      "125 K     Non-trainable params\n",
      "17.6 M    Total params\n",
      "\n",
      "Finding best initial lr:   0%|          | 0/100 [00:00<?, ?it/s]\u001b[A\n",
      "Finding best initial lr:   1%|          | 1/100 [00:00<00:26,  3.79it/s]\u001b[A\n",
      "Finding best initial lr:   2%|▏         | 2/100 [00:01<01:07,  1.45it/s]\u001b[A\n",
      "Finding best initial lr:   3%|▎         | 3/100 [00:02<01:20,  1.21it/s]\u001b[A\n",
      "Finding best initial lr:   4%|▍         | 4/100 [00:03<01:25,  1.12it/s]\u001b[A\n",
      "Finding best initial lr:   5%|▌         | 5/100 [00:04<01:27,  1.08it/s]\u001b[A\n",
      "Finding best initial lr:   6%|▌         | 6/100 [00:05<01:28,  1.06it/s]\u001b[A\n",
      "Finding best initial lr:   7%|▋         | 7/100 [00:06<01:29,  1.04it/s]\u001b[A\n",
      "Finding best initial lr:   8%|▊         | 8/100 [00:07<01:29,  1.03it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 14:   3%|▎         | 56/1770 [00:47<-1:56:04, -7.23it/s, loss=0.167, v_num=7, val_loss=0.0577, val_acc=0.957, train_loss=0.226] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Finding best initial lr:   9%|▉         | 9/100 [00:08<01:28,  1.03it/s]\u001b[A\n",
      "Finding best initial lr:  10%|█         | 10/100 [00:09<01:28,  1.01it/s]\u001b[A\n",
      "Finding best initial lr:  11%|█         | 11/100 [00:10<01:27,  1.01it/s]\u001b[A\n",
      "Finding best initial lr:  12%|█▏        | 12/100 [00:11<01:27,  1.01it/s]\u001b[A\n",
      "Finding best initial lr:  13%|█▎        | 13/100 [00:12<01:26,  1.01it/s]\u001b[A\n",
      "Finding best initial lr:  14%|█▍        | 14/100 [00:13<01:25,  1.01it/s]\u001b[A\n",
      "Finding best initial lr:  15%|█▌        | 15/100 [00:14<01:24,  1.01it/s]\u001b[A\n",
      "Finding best initial lr:  16%|█▌        | 16/100 [00:15<01:23,  1.01it/s]\u001b[A\n",
      "Finding best initial lr:  17%|█▋        | 17/100 [00:16<01:22,  1.01it/s]\u001b[A\n",
      "Finding best initial lr:  18%|█▊        | 18/100 [00:17<01:21,  1.01it/s]\u001b[A\n",
      "Finding best initial lr:  19%|█▉        | 19/100 [00:18<01:20,  1.01it/s]\u001b[A\n",
      "Finding best initial lr:  20%|██        | 20/100 [00:19<01:19,  1.00it/s]\u001b[A\n",
      "Finding best initial lr:  21%|██        | 21/100 [00:20<01:18,  1.00it/s]\u001b[A\n",
      "Finding best initial lr:  22%|██▏       | 22/100 [00:21<01:17,  1.01it/s]\u001b[A\n",
      "Finding best initial lr:  23%|██▎       | 23/100 [00:22<01:16,  1.01it/s]\u001b[A\n",
      "Finding best initial lr:  24%|██▍       | 24/100 [00:23<01:15,  1.01it/s]\u001b[A\n",
      "Finding best initial lr:  25%|██▌       | 25/100 [00:24<01:14,  1.01it/s]\u001b[A\n",
      "Finding best initial lr:  26%|██▌       | 26/100 [00:25<01:13,  1.01it/s]\u001b[A\n",
      "Finding best initial lr:  27%|██▋       | 27/100 [00:26<01:12,  1.01it/s]\u001b[A\n",
      "Finding best initial lr:  28%|██▊       | 28/100 [00:27<01:11,  1.01it/s]\u001b[A\n",
      "Finding best initial lr:  29%|██▉       | 29/100 [00:28<01:10,  1.01it/s]\u001b[A\n",
      "Finding best initial lr:  30%|███       | 30/100 [00:29<01:09,  1.00it/s]\u001b[A\n",
      "Finding best initial lr:  31%|███       | 31/100 [00:30<01:08,  1.00it/s]\u001b[A\n",
      "Finding best initial lr:  32%|███▏      | 32/100 [00:31<01:07,  1.01it/s]\u001b[A\n",
      "Finding best initial lr:  33%|███▎      | 33/100 [00:32<01:06,  1.01it/s]\u001b[A\n",
      "Finding best initial lr:  34%|███▍      | 34/100 [00:32<01:05,  1.01it/s]\u001b[A\n",
      "Finding best initial lr:  35%|███▌      | 35/100 [00:33<01:04,  1.01it/s]\u001b[A\n",
      "Finding best initial lr:  36%|███▌      | 36/100 [00:34<01:03,  1.01it/s]\u001b[A\n",
      "Finding best initial lr:  37%|███▋      | 37/100 [00:35<01:02,  1.01it/s]\u001b[A\n",
      "Finding best initial lr:  38%|███▊      | 38/100 [00:36<01:01,  1.01it/s]\u001b[A\n",
      "Finding best initial lr:  39%|███▉      | 39/100 [00:37<01:00,  1.01it/s]\u001b[A\n",
      "Finding best initial lr:  40%|████      | 40/100 [00:38<00:59,  1.00it/s]\u001b[A\n",
      "Finding best initial lr:  41%|████      | 41/100 [00:39<00:58,  1.00it/s]\u001b[A\n",
      "Finding best initial lr:  42%|████▏     | 42/100 [00:40<00:57,  1.01it/s]\u001b[A\n",
      "Finding best initial lr:  43%|████▎     | 43/100 [00:41<00:56,  1.01it/s]\u001b[A\n",
      "Finding best initial lr:  44%|████▍     | 44/100 [00:42<00:55,  1.01it/s]\u001b[A\n",
      "Finding best initial lr:  45%|████▌     | 45/100 [00:43<00:54,  1.01it/s]\u001b[A\n",
      "Finding best initial lr:  46%|████▌     | 46/100 [00:44<00:53,  1.01it/s]\u001b[A\n",
      "Finding best initial lr:  47%|████▋     | 47/100 [00:45<00:52,  1.01it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1:  97%|█████████▋| 1716/1770 [07:11<00:17,  3.05it/s, loss=0.155, v_num=7, val_loss=0.0714, val_acc=0.938, train_loss=0.274]  \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 1:  97%|█████████▋| 1718/1770 [07:14<00:17,  3.04it/s, loss=0.155, v_num=7, val_loss=0.0714, val_acc=0.938, train_loss=0.274]\n",
      "Validating:   4%|▎         | 2/54 [00:03<01:16,  1.47s/it]\u001b[A\n",
      "Epoch 1:  97%|█████████▋| 1720/1770 [07:15<00:16,  3.03it/s, loss=0.155, v_num=7, val_loss=0.0714, val_acc=0.938, train_loss=0.274]\n",
      "Validating:   7%|▋         | 4/54 [00:04<00:43,  1.15it/s]\u001b[A\n",
      "Epoch 1:  97%|█████████▋| 1722/1770 [07:16<00:15,  3.03it/s, loss=0.155, v_num=7, val_loss=0.0714, val_acc=0.938, train_loss=0.274]\n",
      "Validating:  11%|█         | 6/54 [00:05<00:33,  1.42it/s]\u001b[A\n",
      "Epoch 1:  97%|█████████▋| 1724/1770 [07:17<00:15,  3.03it/s, loss=0.155, v_num=7, val_loss=0.0714, val_acc=0.938, train_loss=0.274]\n",
      "Validating:  15%|█▍        | 8/54 [00:06<00:29,  1.58it/s]\u001b[A\n",
      "Epoch 1:  98%|█████████▊| 1726/1770 [07:18<00:14,  3.02it/s, loss=0.155, v_num=7, val_loss=0.0714, val_acc=0.938, train_loss=0.274]\n",
      "Validating:  19%|█▊        | 10/54 [00:07<00:26,  1.66it/s]\u001b[A\n",
      "Epoch 1:  98%|█████████▊| 1728/1770 [07:20<00:13,  3.02it/s, loss=0.155, v_num=7, val_loss=0.0714, val_acc=0.938, train_loss=0.274]\n",
      "Validating:  22%|██▏       | 12/54 [00:08<00:24,  1.70it/s]\u001b[A\n",
      "Epoch 1:  98%|█████████▊| 1730/1770 [07:21<00:13,  3.02it/s, loss=0.155, v_num=7, val_loss=0.0714, val_acc=0.938, train_loss=0.274]\n",
      "Validating:  26%|██▌       | 14/54 [00:10<00:23,  1.72it/s]\u001b[A\n",
      "Epoch 1:  98%|█████████▊| 1732/1770 [07:22<00:12,  3.01it/s, loss=0.155, v_num=7, val_loss=0.0714, val_acc=0.938, train_loss=0.274]\n",
      "Validating:  30%|██▉       | 16/54 [00:11<00:21,  1.73it/s]\u001b[A\n",
      "Epoch 1:  98%|█████████▊| 1734/1770 [07:23<00:11,  3.01it/s, loss=0.155, v_num=7, val_loss=0.0714, val_acc=0.938, train_loss=0.274]\n",
      "Validating:  33%|███▎      | 18/54 [00:12<00:20,  1.74it/s]\u001b[A\n",
      "Epoch 1:  98%|█████████▊| 1736/1770 [07:24<00:11,  3.01it/s, loss=0.155, v_num=7, val_loss=0.0714, val_acc=0.938, train_loss=0.274]\n",
      "Validating:  37%|███▋      | 20/54 [00:13<00:19,  1.74it/s]\u001b[A\n",
      "Epoch 1:  98%|█████████▊| 1738/1770 [07:25<00:10,  3.00it/s, loss=0.155, v_num=7, val_loss=0.0714, val_acc=0.938, train_loss=0.274]\n",
      "Validating:  41%|████      | 22/54 [00:14<00:18,  1.74it/s]\u001b[A\n",
      "Epoch 1:  98%|█████████▊| 1740/1770 [07:26<00:09,  3.00it/s, loss=0.155, v_num=7, val_loss=0.0714, val_acc=0.938, train_loss=0.274]\n",
      "Validating:  44%|████▍     | 24/54 [00:15<00:17,  1.74it/s]\u001b[A\n",
      "Epoch 1:  98%|█████████▊| 1742/1770 [07:28<00:09,  3.00it/s, loss=0.155, v_num=7, val_loss=0.0714, val_acc=0.938, train_loss=0.274]\n",
      "Validating:  48%|████▊     | 26/54 [00:17<00:16,  1.74it/s]\u001b[A\n",
      "Epoch 1:  99%|█████████▊| 1744/1770 [07:29<00:08,  2.99it/s, loss=0.155, v_num=7, val_loss=0.0714, val_acc=0.938, train_loss=0.274]\n",
      "Validating:  52%|█████▏    | 28/54 [00:18<00:14,  1.74it/s]\u001b[A\n",
      "Epoch 1:  99%|█████████▊| 1746/1770 [07:30<00:08,  2.99it/s, loss=0.155, v_num=7, val_loss=0.0714, val_acc=0.938, train_loss=0.274]\n",
      "Validating:  56%|█████▌    | 30/54 [00:19<00:13,  1.74it/s]\u001b[A\n",
      "Epoch 1:  99%|█████████▉| 1748/1770 [07:31<00:07,  2.99it/s, loss=0.155, v_num=7, val_loss=0.0714, val_acc=0.938, train_loss=0.274]\n",
      "Validating:  59%|█████▉    | 32/54 [00:20<00:12,  1.74it/s]\u001b[A\n",
      "Epoch 1:  99%|█████████▉| 1750/1770 [07:32<00:06,  2.98it/s, loss=0.155, v_num=7, val_loss=0.0714, val_acc=0.938, train_loss=0.274]\n",
      "Validating:  63%|██████▎   | 34/54 [00:21<00:11,  1.74it/s]\u001b[A\n",
      "Epoch 1:  99%|█████████▉| 1752/1770 [07:33<00:06,  2.98it/s, loss=0.155, v_num=7, val_loss=0.0714, val_acc=0.938, train_loss=0.274]\n",
      "Validating:  67%|██████▋   | 36/54 [00:22<00:10,  1.74it/s]\u001b[A\n",
      "Epoch 1:  99%|█████████▉| 1754/1770 [07:35<00:05,  2.98it/s, loss=0.155, v_num=7, val_loss=0.0714, val_acc=0.938, train_loss=0.274]\n",
      "Validating:  70%|███████   | 38/54 [00:23<00:09,  1.74it/s]\u001b[A\n",
      "Epoch 1:  99%|█████████▉| 1756/1770 [07:36<00:04,  2.97it/s, loss=0.155, v_num=7, val_loss=0.0714, val_acc=0.938, train_loss=0.274]\n",
      "Validating:  74%|███████▍  | 40/54 [00:25<00:08,  1.75it/s]\u001b[A\n",
      "Epoch 1:  99%|█████████▉| 1758/1770 [07:37<00:04,  2.97it/s, loss=0.155, v_num=7, val_loss=0.0714, val_acc=0.938, train_loss=0.274]\n",
      "Validating:  78%|███████▊  | 42/54 [00:26<00:06,  1.74it/s]\u001b[A\n",
      "Epoch 1:  99%|█████████▉| 1760/1770 [07:38<00:03,  2.97it/s, loss=0.155, v_num=7, val_loss=0.0714, val_acc=0.938, train_loss=0.274]\n",
      "Validating:  81%|████████▏ | 44/54 [00:27<00:05,  1.74it/s]\u001b[A\n",
      "Epoch 1: 100%|█████████▉| 1762/1770 [07:39<00:02,  2.97it/s, loss=0.155, v_num=7, val_loss=0.0714, val_acc=0.938, train_loss=0.274]\n",
      "Validating:  85%|████████▌ | 46/54 [00:28<00:04,  1.77it/s]\u001b[A\n",
      "Epoch 1: 100%|█████████▉| 1764/1770 [07:40<00:02,  2.96it/s, loss=0.155, v_num=7, val_loss=0.0714, val_acc=0.938, train_loss=0.274]\n",
      "Validating:  89%|████████▉ | 48/54 [00:29<00:03,  1.78it/s]\u001b[A\n",
      "Epoch 1: 100%|█████████▉| 1766/1770 [07:41<00:01,  2.96it/s, loss=0.155, v_num=7, val_loss=0.0714, val_acc=0.938, train_loss=0.274]\n",
      "Validating:  93%|█████████▎| 50/54 [00:30<00:02,  1.79it/s]\u001b[A\n",
      "Epoch 1: 100%|█████████▉| 1768/1770 [07:42<00:00,  2.96it/s, loss=0.155, v_num=7, val_loss=0.0714, val_acc=0.938, train_loss=0.274]\n",
      "Validating:  96%|█████████▋| 52/54 [00:31<00:01,  1.79it/s]\u001b[A\n",
      "Epoch 1: 100%|██████████| 1770/1770 [07:44<00:00,  2.95it/s, loss=0.155, v_num=7, val_loss=0.0714, val_acc=0.938, train_loss=0.274]\n",
      "Validating: 100%|██████████| 54/54 [00:32<00:00,  2.02it/s]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, global step 429: val_loss reached 0.05885 (best 0.05885), saving model to \"/opt/favordata/AI/Felix/kaggle-cassava/trained-models/sgd_coswarm_bnf_bitemp_smooth_weighted_t1=0.3_t2=1.0_89-53_tune/tf_efficientnet_b4_ns_bitempered_smooth=0.05_val_loss=0.059_val_acc=0.953_fold1.ckpt\" as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 1770/1770 [07:44<00:00,  2.95it/s, loss=0.155, v_num=7, val_loss=0.0588, val_acc=0.953, train_loss=0.327]\n",
      "Epoch 2:  97%|█████████▋| 1716/1770 [07:10<00:17,  3.06it/s, loss=0.169, v_num=7, val_loss=0.0588, val_acc=0.953, train_loss=0.261]    \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 2:  97%|█████████▋| 1718/1770 [07:12<00:17,  3.05it/s, loss=0.169, v_num=7, val_loss=0.0588, val_acc=0.953, train_loss=0.261]\n",
      "Validating:   4%|▎         | 2/54 [00:02<01:02,  1.21s/it]\u001b[A\n",
      "Epoch 2:  97%|█████████▋| 1720/1770 [07:13<00:16,  3.04it/s, loss=0.169, v_num=7, val_loss=0.0588, val_acc=0.953, train_loss=0.261]\n",
      "Validating:   7%|▋         | 4/54 [00:03<00:41,  1.22it/s]\u001b[A\n",
      "Epoch 2:  97%|█████████▋| 1722/1770 [07:15<00:15,  3.04it/s, loss=0.169, v_num=7, val_loss=0.0588, val_acc=0.953, train_loss=0.261]\n",
      "Validating:  11%|█         | 6/54 [00:05<00:33,  1.45it/s]\u001b[A\n",
      "Epoch 2:  97%|█████████▋| 1724/1770 [07:16<00:15,  3.04it/s, loss=0.169, v_num=7, val_loss=0.0588, val_acc=0.953, train_loss=0.261]\n",
      "Validating:  15%|█▍        | 8/54 [00:06<00:28,  1.59it/s]\u001b[A\n",
      "Epoch 2:  98%|█████████▊| 1726/1770 [07:17<00:14,  3.03it/s, loss=0.169, v_num=7, val_loss=0.0588, val_acc=0.953, train_loss=0.261]\n",
      "Validating:  19%|█▊        | 10/54 [00:07<00:26,  1.67it/s]\u001b[A\n",
      "Epoch 2:  98%|█████████▊| 1728/1770 [07:18<00:13,  3.03it/s, loss=0.169, v_num=7, val_loss=0.0588, val_acc=0.953, train_loss=0.261]\n",
      "Validating:  22%|██▏       | 12/54 [00:08<00:24,  1.71it/s]\u001b[A\n",
      "Epoch 2:  98%|█████████▊| 1730/1770 [07:19<00:13,  3.03it/s, loss=0.169, v_num=7, val_loss=0.0588, val_acc=0.953, train_loss=0.261]\n",
      "Validating:  26%|██▌       | 14/54 [00:09<00:23,  1.73it/s]\u001b[A\n",
      "Epoch 2:  98%|█████████▊| 1732/1770 [07:20<00:12,  3.02it/s, loss=0.169, v_num=7, val_loss=0.0588, val_acc=0.953, train_loss=0.261]\n",
      "Validating:  30%|██▉       | 16/54 [00:10<00:21,  1.74it/s]\u001b[A\n",
      "Epoch 2:  98%|█████████▊| 1734/1770 [07:21<00:11,  3.02it/s, loss=0.169, v_num=7, val_loss=0.0588, val_acc=0.953, train_loss=0.261]\n",
      "Validating:  33%|███▎      | 18/54 [00:12<00:20,  1.74it/s]\u001b[A\n",
      "Epoch 2:  98%|█████████▊| 1736/1770 [07:23<00:11,  3.02it/s, loss=0.169, v_num=7, val_loss=0.0588, val_acc=0.953, train_loss=0.261]\n",
      "Validating:  37%|███▋      | 20/54 [00:13<00:19,  1.74it/s]\u001b[A\n",
      "Epoch 2:  98%|█████████▊| 1738/1770 [07:24<00:10,  3.01it/s, loss=0.169, v_num=7, val_loss=0.0588, val_acc=0.953, train_loss=0.261]\n",
      "Validating:  41%|████      | 22/54 [00:14<00:18,  1.74it/s]\u001b[A\n",
      "Epoch 2:  98%|█████████▊| 1740/1770 [07:25<00:09,  3.01it/s, loss=0.169, v_num=7, val_loss=0.0588, val_acc=0.953, train_loss=0.261]\n",
      "Validating:  44%|████▍     | 24/54 [00:15<00:17,  1.74it/s]\u001b[A\n",
      "Epoch 2:  98%|█████████▊| 1742/1770 [07:26<00:09,  3.01it/s, loss=0.169, v_num=7, val_loss=0.0588, val_acc=0.953, train_loss=0.261]\n",
      "Validating:  48%|████▊     | 26/54 [00:16<00:16,  1.74it/s]\u001b[A\n",
      "Epoch 2:  99%|█████████▊| 1744/1770 [07:27<00:08,  3.00it/s, loss=0.169, v_num=7, val_loss=0.0588, val_acc=0.953, train_loss=0.261]\n",
      "Validating:  52%|█████▏    | 28/54 [00:17<00:14,  1.74it/s]\u001b[A\n",
      "Epoch 2:  99%|█████████▊| 1746/1770 [07:28<00:07,  3.00it/s, loss=0.169, v_num=7, val_loss=0.0588, val_acc=0.953, train_loss=0.261]\n",
      "Validating:  56%|█████▌    | 30/54 [00:18<00:13,  1.74it/s]\u001b[A\n",
      "Epoch 2:  99%|█████████▉| 1748/1770 [07:29<00:07,  3.00it/s, loss=0.169, v_num=7, val_loss=0.0588, val_acc=0.953, train_loss=0.261]\n",
      "Validating:  59%|█████▉    | 32/54 [00:20<00:12,  1.74it/s]\u001b[A\n",
      "Epoch 2:  99%|█████████▉| 1750/1770 [07:31<00:06,  2.99it/s, loss=0.169, v_num=7, val_loss=0.0588, val_acc=0.953, train_loss=0.261]\n",
      "Validating:  63%|██████▎   | 34/54 [00:21<00:11,  1.74it/s]\u001b[A\n",
      "Epoch 2:  99%|█████████▉| 1752/1770 [07:32<00:06,  2.99it/s, loss=0.169, v_num=7, val_loss=0.0588, val_acc=0.953, train_loss=0.261]\n",
      "Validating:  67%|██████▋   | 36/54 [00:22<00:10,  1.74it/s]\u001b[A\n",
      "Epoch 2:  99%|█████████▉| 1754/1770 [07:33<00:05,  2.99it/s, loss=0.169, v_num=7, val_loss=0.0588, val_acc=0.953, train_loss=0.261]\n",
      "Validating:  70%|███████   | 38/54 [00:23<00:09,  1.74it/s]\u001b[A\n",
      "Epoch 2:  99%|█████████▉| 1756/1770 [07:34<00:04,  2.99it/s, loss=0.169, v_num=7, val_loss=0.0588, val_acc=0.953, train_loss=0.261]\n",
      "Validating:  74%|███████▍  | 40/54 [00:24<00:08,  1.74it/s]\u001b[A\n",
      "Epoch 2:  99%|█████████▉| 1758/1770 [07:35<00:04,  2.98it/s, loss=0.169, v_num=7, val_loss=0.0588, val_acc=0.953, train_loss=0.261]\n",
      "Validating:  78%|███████▊  | 42/54 [00:25<00:06,  1.74it/s]\u001b[A\n",
      "Epoch 2:  99%|█████████▉| 1760/1770 [07:36<00:03,  2.98it/s, loss=0.169, v_num=7, val_loss=0.0588, val_acc=0.953, train_loss=0.261]\n",
      "Validating:  81%|████████▏ | 44/54 [00:26<00:05,  1.74it/s]\u001b[A\n",
      "Epoch 2: 100%|█████████▉| 1762/1770 [07:37<00:02,  2.98it/s, loss=0.169, v_num=7, val_loss=0.0588, val_acc=0.953, train_loss=0.261]\n",
      "Validating:  85%|████████▌ | 46/54 [00:28<00:04,  1.77it/s]\u001b[A\n",
      "Epoch 2: 100%|█████████▉| 1764/1770 [07:39<00:02,  2.97it/s, loss=0.169, v_num=7, val_loss=0.0588, val_acc=0.953, train_loss=0.261]\n",
      "Validating:  89%|████████▉ | 48/54 [00:29<00:03,  1.78it/s]\u001b[A\n",
      "Epoch 2: 100%|█████████▉| 1766/1770 [07:40<00:01,  2.97it/s, loss=0.169, v_num=7, val_loss=0.0588, val_acc=0.953, train_loss=0.261]\n",
      "Validating:  93%|█████████▎| 50/54 [00:30<00:02,  1.79it/s]\u001b[A\n",
      "Epoch 2: 100%|█████████▉| 1768/1770 [07:41<00:00,  2.97it/s, loss=0.169, v_num=7, val_loss=0.0588, val_acc=0.953, train_loss=0.261]\n",
      "Validating:  96%|█████████▋| 52/54 [00:31<00:01,  1.79it/s]\u001b[A\n",
      "Epoch 2: 100%|██████████| 1770/1770 [07:42<00:00,  2.96it/s, loss=0.169, v_num=7, val_loss=0.0588, val_acc=0.953, train_loss=0.261]\n",
      "Validating: 100%|██████████| 54/54 [00:32<00:00,  2.02it/s]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2, global step 858: val_loss reached 0.05599 (best 0.05599), saving model to \"/opt/favordata/AI/Felix/kaggle-cassava/trained-models/sgd_coswarm_bnf_bitemp_smooth_weighted_t1=0.3_t2=1.0_89-53_tune/tf_efficientnet_b4_ns_bitempered_smooth=0.05_val_loss=0.056_val_acc=0.955_fold1.ckpt\" as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 14:   3%|▎         | 56/1770 [17:51<-2:30:47, -0.32it/s, loss=0.167, v_num=7, val_loss=0.0577, val_acc=0.957, train_loss=0.226]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Finding best initial lr: 100%|██████████| 100/100 [17:11<00:00, 10.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 1770/1770 [07:43<00:00,  2.96it/s, loss=0.169, v_num=7, val_loss=0.056, val_acc=0.955, train_loss=0.0448]\n",
      "Epoch 3:  97%|█████████▋| 1716/1770 [07:11<00:17,  3.05it/s, loss=0.146, v_num=7, val_loss=0.056, val_acc=0.955, train_loss=0.119]    \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 3:  97%|█████████▋| 1718/1770 [07:13<00:17,  3.04it/s, loss=0.146, v_num=7, val_loss=0.056, val_acc=0.955, train_loss=0.119]\n",
      "Validating:   4%|▎         | 2/54 [00:03<01:11,  1.38s/it]\u001b[A\n",
      "Epoch 3:  97%|█████████▋| 1720/1770 [07:14<00:16,  3.04it/s, loss=0.146, v_num=7, val_loss=0.056, val_acc=0.955, train_loss=0.119]\n",
      "Validating:   7%|▋         | 4/54 [00:04<00:43,  1.15it/s]\u001b[A\n",
      "Epoch 3:  97%|█████████▋| 1722/1770 [07:16<00:15,  3.03it/s, loss=0.146, v_num=7, val_loss=0.056, val_acc=0.955, train_loss=0.119]\n",
      "Validating:  11%|█         | 6/54 [00:05<00:33,  1.42it/s]\u001b[A\n",
      "Epoch 3:  97%|█████████▋| 1724/1770 [07:17<00:15,  3.03it/s, loss=0.146, v_num=7, val_loss=0.056, val_acc=0.955, train_loss=0.119]\n",
      "Validating:  15%|█▍        | 8/54 [00:06<00:29,  1.58it/s]\u001b[A\n",
      "Epoch 3:  98%|█████████▊| 1726/1770 [07:18<00:14,  3.03it/s, loss=0.146, v_num=7, val_loss=0.056, val_acc=0.955, train_loss=0.119]\n",
      "Validating:  19%|█▊        | 10/54 [00:07<00:26,  1.66it/s]\u001b[A\n",
      "Epoch 3:  98%|█████████▊| 1728/1770 [07:19<00:13,  3.02it/s, loss=0.146, v_num=7, val_loss=0.056, val_acc=0.955, train_loss=0.119]\n",
      "Validating:  22%|██▏       | 12/54 [00:08<00:24,  1.70it/s]\u001b[A\n",
      "Epoch 3:  98%|█████████▊| 1730/1770 [07:20<00:13,  3.02it/s, loss=0.146, v_num=7, val_loss=0.056, val_acc=0.955, train_loss=0.119]\n",
      "Validating:  26%|██▌       | 14/54 [00:10<00:23,  1.72it/s]\u001b[A\n",
      "Epoch 3:  98%|█████████▊| 1732/1770 [07:21<00:12,  3.02it/s, loss=0.146, v_num=7, val_loss=0.056, val_acc=0.955, train_loss=0.119]\n",
      "Validating:  30%|██▉       | 16/54 [00:11<00:21,  1.73it/s]\u001b[A\n",
      "Epoch 3:  98%|█████████▊| 1734/1770 [07:22<00:11,  3.01it/s, loss=0.146, v_num=7, val_loss=0.056, val_acc=0.955, train_loss=0.119]\n",
      "Validating:  33%|███▎      | 18/54 [00:12<00:20,  1.73it/s]\u001b[A\n",
      "Epoch 3:  98%|█████████▊| 1736/1770 [07:24<00:11,  3.01it/s, loss=0.146, v_num=7, val_loss=0.056, val_acc=0.955, train_loss=0.119]\n",
      "Validating:  37%|███▋      | 20/54 [00:13<00:19,  1.73it/s]\u001b[A\n",
      "Epoch 3:  98%|█████████▊| 1738/1770 [07:25<00:10,  3.01it/s, loss=0.146, v_num=7, val_loss=0.056, val_acc=0.955, train_loss=0.119]\n",
      "Validating:  41%|████      | 22/54 [00:14<00:18,  1.73it/s]\u001b[A\n",
      "Epoch 3:  98%|█████████▊| 1740/1770 [07:26<00:09,  3.00it/s, loss=0.146, v_num=7, val_loss=0.056, val_acc=0.955, train_loss=0.119]\n",
      "Validating:  44%|████▍     | 24/54 [00:15<00:17,  1.72it/s]\u001b[A\n",
      "Epoch 3:  98%|█████████▊| 1742/1770 [07:27<00:09,  3.00it/s, loss=0.146, v_num=7, val_loss=0.056, val_acc=0.955, train_loss=0.119]\n",
      "Validating:  48%|████▊     | 26/54 [00:16<00:16,  1.73it/s]\u001b[A\n",
      "Epoch 3:  99%|█████████▊| 1744/1770 [07:28<00:08,  3.00it/s, loss=0.146, v_num=7, val_loss=0.056, val_acc=0.955, train_loss=0.119]\n",
      "Validating:  52%|█████▏    | 28/54 [00:18<00:15,  1.73it/s]\u001b[A\n",
      "Epoch 3:  99%|█████████▊| 1746/1770 [07:29<00:08,  2.99it/s, loss=0.146, v_num=7, val_loss=0.056, val_acc=0.955, train_loss=0.119]\n",
      "Validating:  56%|█████▌    | 30/54 [00:19<00:13,  1.73it/s]\u001b[A\n",
      "Epoch 3:  99%|█████████▉| 1748/1770 [07:31<00:07,  2.99it/s, loss=0.146, v_num=7, val_loss=0.056, val_acc=0.955, train_loss=0.119]\n",
      "Validating:  59%|█████▉    | 32/54 [00:20<00:12,  1.74it/s]\u001b[A\n",
      "Epoch 3:  99%|█████████▉| 1750/1770 [07:32<00:06,  2.99it/s, loss=0.146, v_num=7, val_loss=0.056, val_acc=0.955, train_loss=0.119]\n",
      "Validating:  63%|██████▎   | 34/54 [00:21<00:11,  1.73it/s]\u001b[A\n",
      "Epoch 3:  99%|█████████▉| 1752/1770 [07:33<00:06,  2.98it/s, loss=0.146, v_num=7, val_loss=0.056, val_acc=0.955, train_loss=0.119]\n",
      "Validating:  67%|██████▋   | 36/54 [00:22<00:10,  1.74it/s]\u001b[A\n",
      "Epoch 3:  99%|█████████▉| 1754/1770 [07:34<00:05,  2.98it/s, loss=0.146, v_num=7, val_loss=0.056, val_acc=0.955, train_loss=0.119]\n",
      "Validating:  70%|███████   | 38/54 [00:23<00:09,  1.74it/s]\u001b[A\n",
      "Epoch 3:  99%|█████████▉| 1756/1770 [07:35<00:04,  2.98it/s, loss=0.146, v_num=7, val_loss=0.056, val_acc=0.955, train_loss=0.119]\n",
      "Validating:  74%|███████▍  | 40/54 [00:25<00:08,  1.73it/s]\u001b[A\n",
      "Epoch 3:  99%|█████████▉| 1758/1770 [07:36<00:04,  2.97it/s, loss=0.146, v_num=7, val_loss=0.056, val_acc=0.955, train_loss=0.119]\n",
      "Validating:  78%|███████▊  | 42/54 [00:26<00:06,  1.73it/s]\u001b[A\n",
      "Epoch 3:  99%|█████████▉| 1760/1770 [07:37<00:03,  2.97it/s, loss=0.146, v_num=7, val_loss=0.056, val_acc=0.955, train_loss=0.119]\n",
      "Validating:  81%|████████▏ | 44/54 [00:27<00:05,  1.74it/s]\u001b[A\n",
      "Epoch 3: 100%|█████████▉| 1762/1770 [07:39<00:02,  2.97it/s, loss=0.146, v_num=7, val_loss=0.056, val_acc=0.955, train_loss=0.119]\n",
      "Validating:  85%|████████▌ | 46/54 [00:28<00:04,  1.76it/s]\u001b[A\n",
      "Epoch 3: 100%|█████████▉| 1764/1770 [07:40<00:02,  2.97it/s, loss=0.146, v_num=7, val_loss=0.056, val_acc=0.955, train_loss=0.119]\n",
      "Validating:  89%|████████▉ | 48/54 [00:29<00:03,  1.78it/s]\u001b[A\n",
      "Epoch 3: 100%|█████████▉| 1766/1770 [07:41<00:01,  2.96it/s, loss=0.146, v_num=7, val_loss=0.056, val_acc=0.955, train_loss=0.119]\n",
      "Validating:  93%|█████████▎| 50/54 [00:30<00:02,  1.79it/s]\u001b[A\n",
      "Epoch 3: 100%|█████████▉| 1768/1770 [07:42<00:00,  2.96it/s, loss=0.146, v_num=7, val_loss=0.056, val_acc=0.955, train_loss=0.119]\n",
      "Validating:  96%|█████████▋| 52/54 [00:31<00:01,  1.79it/s]\u001b[A\n",
      "Epoch 3: 100%|██████████| 1770/1770 [07:43<00:00,  2.96it/s, loss=0.146, v_num=7, val_loss=0.056, val_acc=0.955, train_loss=0.119]\n",
      "Validating: 100%|██████████| 54/54 [00:32<00:00,  2.02it/s]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3, step 1287: val_loss was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 1770/1770 [07:44<00:00,  2.95it/s, loss=0.146, v_num=7, val_loss=0.056, val_acc=0.957, train_loss=0.146]\n",
      "Epoch 4:  97%|█████████▋| 1716/1770 [07:10<00:17,  3.06it/s, loss=0.189, v_num=7, val_loss=0.056, val_acc=0.957, train_loss=0.21]     \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 4:  97%|█████████▋| 1718/1770 [07:13<00:17,  3.04it/s, loss=0.189, v_num=7, val_loss=0.056, val_acc=0.957, train_loss=0.21]\n",
      "Validating:   4%|▎         | 2/54 [00:02<01:09,  1.33s/it]\u001b[A\n",
      "Epoch 4:  97%|█████████▋| 1720/1770 [07:14<00:16,  3.04it/s, loss=0.189, v_num=7, val_loss=0.056, val_acc=0.957, train_loss=0.21]\n",
      "Validating:   7%|▋         | 4/54 [00:04<00:41,  1.19it/s]\u001b[A\n",
      "Epoch 4:  97%|█████████▋| 1722/1770 [07:15<00:15,  3.04it/s, loss=0.189, v_num=7, val_loss=0.056, val_acc=0.957, train_loss=0.21]\n",
      "Validating:  11%|█         | 6/54 [00:05<00:32,  1.46it/s]\u001b[A\n",
      "Epoch 4:  97%|█████████▋| 1724/1770 [07:16<00:15,  3.03it/s, loss=0.189, v_num=7, val_loss=0.056, val_acc=0.957, train_loss=0.21]\n",
      "Validating:  15%|█▍        | 8/54 [00:06<00:29,  1.58it/s]\u001b[A\n",
      "Epoch 4:  98%|█████████▊| 1726/1770 [07:17<00:14,  3.03it/s, loss=0.189, v_num=7, val_loss=0.056, val_acc=0.957, train_loss=0.21]\n",
      "Validating:  19%|█▊        | 10/54 [00:07<00:26,  1.66it/s]\u001b[A\n",
      "Epoch 4:  98%|█████████▊| 1728/1770 [07:19<00:13,  3.03it/s, loss=0.189, v_num=7, val_loss=0.056, val_acc=0.957, train_loss=0.21]\n",
      "Validating:  22%|██▏       | 12/54 [00:08<00:24,  1.70it/s]\u001b[A\n",
      "Epoch 4:  98%|█████████▊| 1730/1770 [07:20<00:13,  3.02it/s, loss=0.189, v_num=7, val_loss=0.056, val_acc=0.957, train_loss=0.21]\n",
      "Validating:  26%|██▌       | 14/54 [00:09<00:23,  1.72it/s]\u001b[A\n",
      "Epoch 4:  98%|█████████▊| 1732/1770 [07:21<00:12,  3.02it/s, loss=0.189, v_num=7, val_loss=0.056, val_acc=0.957, train_loss=0.21]\n",
      "Validating:  30%|██▉       | 16/54 [00:11<00:21,  1.73it/s]\u001b[A\n",
      "Epoch 4:  98%|█████████▊| 1734/1770 [07:22<00:11,  3.02it/s, loss=0.189, v_num=7, val_loss=0.056, val_acc=0.957, train_loss=0.21]\n",
      "Validating:  33%|███▎      | 18/54 [00:12<00:20,  1.74it/s]\u001b[A\n",
      "Epoch 4:  98%|█████████▊| 1736/1770 [07:23<00:11,  3.01it/s, loss=0.189, v_num=7, val_loss=0.056, val_acc=0.957, train_loss=0.21]\n",
      "Validating:  37%|███▋      | 20/54 [00:13<00:19,  1.73it/s]\u001b[A\n",
      "Epoch 4:  98%|█████████▊| 1738/1770 [07:24<00:10,  3.01it/s, loss=0.189, v_num=7, val_loss=0.056, val_acc=0.957, train_loss=0.21]\n",
      "Validating:  41%|████      | 22/54 [00:14<00:18,  1.73it/s]\u001b[A\n",
      "Epoch 4:  98%|█████████▊| 1740/1770 [07:25<00:09,  3.01it/s, loss=0.189, v_num=7, val_loss=0.056, val_acc=0.957, train_loss=0.21]\n",
      "Validating:  44%|████▍     | 24/54 [00:15<00:17,  1.74it/s]\u001b[A\n",
      "Epoch 4:  98%|█████████▊| 1742/1770 [07:27<00:09,  3.00it/s, loss=0.189, v_num=7, val_loss=0.056, val_acc=0.957, train_loss=0.21]\n",
      "Validating:  48%|████▊     | 26/54 [00:16<00:16,  1.74it/s]\u001b[A\n",
      "Epoch 4:  99%|█████████▊| 1744/1770 [07:28<00:08,  3.00it/s, loss=0.189, v_num=7, val_loss=0.056, val_acc=0.957, train_loss=0.21]\n",
      "Validating:  52%|█████▏    | 28/54 [00:17<00:14,  1.74it/s]\u001b[A\n",
      "Epoch 4:  99%|█████████▊| 1746/1770 [07:29<00:08,  3.00it/s, loss=0.189, v_num=7, val_loss=0.056, val_acc=0.957, train_loss=0.21]\n",
      "Validating:  56%|█████▌    | 30/54 [00:19<00:13,  1.74it/s]\u001b[A\n",
      "Epoch 4:  99%|█████████▉| 1748/1770 [07:30<00:07,  2.99it/s, loss=0.189, v_num=7, val_loss=0.056, val_acc=0.957, train_loss=0.21]\n",
      "Validating:  59%|█████▉    | 32/54 [00:20<00:12,  1.74it/s]\u001b[A\n",
      "Epoch 4:  99%|█████████▉| 1750/1770 [07:31<00:06,  2.99it/s, loss=0.189, v_num=7, val_loss=0.056, val_acc=0.957, train_loss=0.21]\n",
      "Validating:  63%|██████▎   | 34/54 [00:21<00:11,  1.74it/s]\u001b[A\n",
      "Epoch 4:  99%|█████████▉| 1752/1770 [07:32<00:06,  2.99it/s, loss=0.189, v_num=7, val_loss=0.056, val_acc=0.957, train_loss=0.21]\n",
      "Validating:  67%|██████▋   | 36/54 [00:22<00:10,  1.74it/s]\u001b[A\n",
      "Epoch 4:  99%|█████████▉| 1754/1770 [07:34<00:05,  2.98it/s, loss=0.189, v_num=7, val_loss=0.056, val_acc=0.957, train_loss=0.21]\n",
      "Validating:  70%|███████   | 38/54 [00:23<00:09,  1.73it/s]\u001b[A\n",
      "Epoch 4:  99%|█████████▉| 1756/1770 [07:35<00:04,  2.98it/s, loss=0.189, v_num=7, val_loss=0.056, val_acc=0.957, train_loss=0.21]\n",
      "Validating:  74%|███████▍  | 40/54 [00:24<00:08,  1.74it/s]\u001b[A\n",
      "Epoch 4:  99%|█████████▉| 1758/1770 [07:36<00:04,  2.98it/s, loss=0.189, v_num=7, val_loss=0.056, val_acc=0.957, train_loss=0.21]\n",
      "Validating:  78%|███████▊  | 42/54 [00:26<00:06,  1.74it/s]\u001b[A\n",
      "Epoch 4:  99%|█████████▉| 1760/1770 [07:37<00:03,  2.97it/s, loss=0.189, v_num=7, val_loss=0.056, val_acc=0.957, train_loss=0.21]\n",
      "Validating:  81%|████████▏ | 44/54 [00:27<00:05,  1.74it/s]\u001b[A\n",
      "Epoch 4: 100%|█████████▉| 1762/1770 [07:38<00:02,  2.97it/s, loss=0.189, v_num=7, val_loss=0.056, val_acc=0.957, train_loss=0.21]\n",
      "Validating:  85%|████████▌ | 46/54 [00:28<00:04,  1.77it/s]\u001b[A\n",
      "Epoch 4: 100%|█████████▉| 1764/1770 [07:39<00:02,  2.97it/s, loss=0.189, v_num=7, val_loss=0.056, val_acc=0.957, train_loss=0.21]\n",
      "Validating:  89%|████████▉ | 48/54 [00:29<00:03,  1.78it/s]\u001b[A\n",
      "Epoch 4: 100%|█████████▉| 1766/1770 [07:40<00:01,  2.97it/s, loss=0.189, v_num=7, val_loss=0.056, val_acc=0.957, train_loss=0.21]\n",
      "Validating:  93%|█████████▎| 50/54 [00:30<00:02,  1.79it/s]\u001b[A\n",
      "Epoch 4: 100%|█████████▉| 1768/1770 [07:41<00:00,  2.96it/s, loss=0.189, v_num=7, val_loss=0.056, val_acc=0.957, train_loss=0.21]\n",
      "Validating:  96%|█████████▋| 52/54 [00:31<00:01,  1.79it/s]\u001b[A\n",
      "Epoch 4: 100%|██████████| 1770/1770 [07:43<00:00,  2.96it/s, loss=0.189, v_num=7, val_loss=0.056, val_acc=0.957, train_loss=0.21]\n",
      "Validating: 100%|██████████| 54/54 [00:32<00:00,  2.02it/s]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4, step 1716: val_loss was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 1770/1770 [07:43<00:00,  2.96it/s, loss=0.189, v_num=7, val_loss=0.0578, val_acc=0.954, train_loss=0.444]\n",
      "Epoch 5:  97%|█████████▋| 1716/1770 [07:10<00:17,  3.06it/s, loss=0.172, v_num=7, val_loss=0.0578, val_acc=0.954, train_loss=0.241]    \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 5:  97%|█████████▋| 1718/1770 [07:12<00:17,  3.05it/s, loss=0.172, v_num=7, val_loss=0.0578, val_acc=0.954, train_loss=0.241]\n",
      "Validating:   4%|▎         | 2/54 [00:02<01:06,  1.28s/it]\u001b[A\n",
      "Epoch 5:  97%|█████████▋| 1720/1770 [07:14<00:16,  3.04it/s, loss=0.172, v_num=7, val_loss=0.0578, val_acc=0.954, train_loss=0.241]\n",
      "Validating:   7%|▋         | 4/54 [00:04<00:42,  1.17it/s]\u001b[A\n",
      "Epoch 5:  97%|█████████▋| 1722/1770 [07:15<00:15,  3.04it/s, loss=0.172, v_num=7, val_loss=0.0578, val_acc=0.954, train_loss=0.241]\n",
      "Validating:  11%|█         | 6/54 [00:05<00:33,  1.44it/s]\u001b[A\n",
      "Epoch 5:  97%|█████████▋| 1724/1770 [07:16<00:15,  3.04it/s, loss=0.172, v_num=7, val_loss=0.0578, val_acc=0.954, train_loss=0.241]\n",
      "Validating:  15%|█▍        | 8/54 [00:06<00:28,  1.59it/s]\u001b[A\n",
      "Epoch 5:  98%|█████████▊| 1726/1770 [07:17<00:14,  3.03it/s, loss=0.172, v_num=7, val_loss=0.0578, val_acc=0.954, train_loss=0.241]\n",
      "Validating:  19%|█▊        | 10/54 [00:07<00:26,  1.66it/s]\u001b[A\n",
      "Epoch 5:  98%|█████████▊| 1728/1770 [07:18<00:13,  3.03it/s, loss=0.172, v_num=7, val_loss=0.0578, val_acc=0.954, train_loss=0.241]\n",
      "Validating:  22%|██▏       | 12/54 [00:08<00:24,  1.70it/s]\u001b[A\n",
      "Epoch 5:  98%|█████████▊| 1730/1770 [07:19<00:13,  3.03it/s, loss=0.172, v_num=7, val_loss=0.0578, val_acc=0.954, train_loss=0.241]\n",
      "Validating:  26%|██▌       | 14/54 [00:09<00:23,  1.71it/s]\u001b[A\n",
      "Epoch 5:  98%|█████████▊| 1732/1770 [07:21<00:12,  3.02it/s, loss=0.172, v_num=7, val_loss=0.0578, val_acc=0.954, train_loss=0.241]\n",
      "Validating:  30%|██▉       | 16/54 [00:11<00:22,  1.71it/s]\u001b[A\n",
      "Epoch 5:  98%|█████████▊| 1734/1770 [07:22<00:11,  3.02it/s, loss=0.172, v_num=7, val_loss=0.0578, val_acc=0.954, train_loss=0.241]\n",
      "Validating:  33%|███▎      | 18/54 [00:12<00:20,  1.73it/s]\u001b[A\n",
      "Epoch 5:  98%|█████████▊| 1736/1770 [07:23<00:11,  3.02it/s, loss=0.172, v_num=7, val_loss=0.0578, val_acc=0.954, train_loss=0.241]\n",
      "Validating:  37%|███▋      | 20/54 [00:13<00:19,  1.73it/s]\u001b[A\n",
      "Epoch 5:  98%|█████████▊| 1738/1770 [07:24<00:10,  3.01it/s, loss=0.172, v_num=7, val_loss=0.0578, val_acc=0.954, train_loss=0.241]\n",
      "Validating:  41%|████      | 22/54 [00:14<00:18,  1.74it/s]\u001b[A\n",
      "Epoch 5:  98%|█████████▊| 1740/1770 [07:25<00:09,  3.01it/s, loss=0.172, v_num=7, val_loss=0.0578, val_acc=0.954, train_loss=0.241]\n",
      "Validating:  44%|████▍     | 24/54 [00:15<00:17,  1.74it/s]\u001b[A\n",
      "Epoch 5:  98%|█████████▊| 1742/1770 [07:26<00:09,  3.01it/s, loss=0.172, v_num=7, val_loss=0.0578, val_acc=0.954, train_loss=0.241]\n",
      "Validating:  48%|████▊     | 26/54 [00:16<00:16,  1.74it/s]\u001b[A\n",
      "Epoch 5:  99%|█████████▊| 1744/1770 [07:27<00:08,  3.00it/s, loss=0.172, v_num=7, val_loss=0.0578, val_acc=0.954, train_loss=0.241]\n",
      "Validating:  52%|█████▏    | 28/54 [00:17<00:14,  1.74it/s]\u001b[A\n",
      "Epoch 5:  99%|█████████▊| 1746/1770 [07:29<00:08,  3.00it/s, loss=0.172, v_num=7, val_loss=0.0578, val_acc=0.954, train_loss=0.241]\n",
      "Validating:  56%|█████▌    | 30/54 [00:19<00:13,  1.73it/s]\u001b[A\n",
      "Epoch 5:  99%|█████████▉| 1748/1770 [07:30<00:07,  3.00it/s, loss=0.172, v_num=7, val_loss=0.0578, val_acc=0.954, train_loss=0.241]\n",
      "Validating:  59%|█████▉    | 32/54 [00:20<00:12,  1.72it/s]\u001b[A\n",
      "Epoch 5:  99%|█████████▉| 1750/1770 [07:31<00:06,  2.99it/s, loss=0.172, v_num=7, val_loss=0.0578, val_acc=0.954, train_loss=0.241]\n",
      "Validating:  63%|██████▎   | 34/54 [00:21<00:11,  1.73it/s]\u001b[A\n",
      "Epoch 5:  99%|█████████▉| 1752/1770 [07:32<00:06,  2.99it/s, loss=0.172, v_num=7, val_loss=0.0578, val_acc=0.954, train_loss=0.241]\n",
      "Validating:  67%|██████▋   | 36/54 [00:22<00:10,  1.73it/s]\u001b[A\n",
      "Epoch 5:  99%|█████████▉| 1754/1770 [07:33<00:05,  2.99it/s, loss=0.172, v_num=7, val_loss=0.0578, val_acc=0.954, train_loss=0.241]\n",
      "Validating:  70%|███████   | 38/54 [00:23<00:09,  1.74it/s]\u001b[A\n",
      "Epoch 5:  99%|█████████▉| 1756/1770 [07:34<00:04,  2.98it/s, loss=0.172, v_num=7, val_loss=0.0578, val_acc=0.954, train_loss=0.241]\n",
      "Validating:  74%|███████▍  | 40/54 [00:24<00:08,  1.74it/s]\u001b[A\n",
      "Epoch 5:  99%|█████████▉| 1758/1770 [07:36<00:04,  2.98it/s, loss=0.172, v_num=7, val_loss=0.0578, val_acc=0.954, train_loss=0.241]\n",
      "Validating:  78%|███████▊  | 42/54 [00:26<00:06,  1.74it/s]\u001b[A\n",
      "Epoch 5:  99%|█████████▉| 1760/1770 [07:37<00:03,  2.98it/s, loss=0.172, v_num=7, val_loss=0.0578, val_acc=0.954, train_loss=0.241]\n",
      "Validating:  81%|████████▏ | 44/54 [00:27<00:05,  1.73it/s]\u001b[A\n",
      "Epoch 5: 100%|█████████▉| 1762/1770 [07:38<00:02,  2.97it/s, loss=0.172, v_num=7, val_loss=0.0578, val_acc=0.954, train_loss=0.241]\n",
      "Validating:  85%|████████▌ | 46/54 [00:28<00:04,  1.76it/s]\u001b[A\n",
      "Epoch 5: 100%|█████████▉| 1764/1770 [07:39<00:02,  2.97it/s, loss=0.172, v_num=7, val_loss=0.0578, val_acc=0.954, train_loss=0.241]\n",
      "Validating:  89%|████████▉ | 48/54 [00:29<00:03,  1.78it/s]\u001b[A\n",
      "Epoch 5: 100%|█████████▉| 1766/1770 [07:40<00:01,  2.97it/s, loss=0.172, v_num=7, val_loss=0.0578, val_acc=0.954, train_loss=0.241]\n",
      "Validating:  93%|█████████▎| 50/54 [00:30<00:02,  1.79it/s]\u001b[A\n",
      "Epoch 5: 100%|█████████▉| 1768/1770 [07:41<00:00,  2.97it/s, loss=0.172, v_num=7, val_loss=0.0578, val_acc=0.954, train_loss=0.241]\n",
      "Validating:  96%|█████████▋| 52/54 [00:31<00:01,  1.79it/s]\u001b[A\n",
      "Epoch 5: 100%|██████████| 1770/1770 [07:42<00:00,  2.96it/s, loss=0.172, v_num=7, val_loss=0.0578, val_acc=0.954, train_loss=0.241]\n",
      "Validating: 100%|██████████| 54/54 [00:32<00:00,  2.02it/s]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5, step 2145: val_loss was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|██████████| 1770/1770 [07:43<00:00,  2.96it/s, loss=0.172, v_num=7, val_loss=0.059, val_acc=0.957, train_loss=0.279] \n",
      "Epoch 7:  97%|█████████▋| 1716/1770 [07:10<00:17,  3.06it/s, loss=0.163, v_num=7, val_loss=0.057, val_acc=0.955, train_loss=0.151]    \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 7:  97%|█████████▋| 1718/1770 [07:13<00:17,  3.04it/s, loss=0.163, v_num=7, val_loss=0.057, val_acc=0.955, train_loss=0.151]\n",
      "Validating:   4%|▎         | 2/54 [00:03<01:12,  1.39s/it]\u001b[A\n",
      "Epoch 7:  97%|█████████▋| 1720/1770 [07:14<00:16,  3.04it/s, loss=0.163, v_num=7, val_loss=0.057, val_acc=0.955, train_loss=0.151]\n",
      "Validating:   7%|▋         | 4/54 [00:04<00:42,  1.19it/s]\u001b[A\n",
      "Epoch 7:  97%|█████████▋| 1722/1770 [07:15<00:15,  3.04it/s, loss=0.163, v_num=7, val_loss=0.057, val_acc=0.955, train_loss=0.151]\n",
      "Validating:  11%|█         | 6/54 [00:05<00:33,  1.45it/s]\u001b[A\n",
      "Epoch 7:  97%|█████████▋| 1724/1770 [07:16<00:15,  3.03it/s, loss=0.163, v_num=7, val_loss=0.057, val_acc=0.955, train_loss=0.151]\n",
      "Validating:  15%|█▍        | 8/54 [00:06<00:28,  1.60it/s]\u001b[A\n",
      "Epoch 7:  98%|█████████▊| 1726/1770 [07:17<00:14,  3.03it/s, loss=0.163, v_num=7, val_loss=0.057, val_acc=0.955, train_loss=0.151]\n",
      "Validating:  19%|█▊        | 10/54 [00:07<00:26,  1.66it/s]\u001b[A\n",
      "Epoch 7:  98%|█████████▊| 1728/1770 [07:19<00:13,  3.03it/s, loss=0.163, v_num=7, val_loss=0.057, val_acc=0.955, train_loss=0.151]\n",
      "Validating:  22%|██▏       | 12/54 [00:08<00:24,  1.70it/s]\u001b[A\n",
      "Epoch 7:  98%|█████████▊| 1730/1770 [07:20<00:13,  3.02it/s, loss=0.163, v_num=7, val_loss=0.057, val_acc=0.955, train_loss=0.151]\n",
      "Validating:  26%|██▌       | 14/54 [00:09<00:23,  1.72it/s]\u001b[A\n",
      "Epoch 7:  98%|█████████▊| 1732/1770 [07:21<00:12,  3.02it/s, loss=0.163, v_num=7, val_loss=0.057, val_acc=0.955, train_loss=0.151]\n",
      "Validating:  30%|██▉       | 16/54 [00:11<00:21,  1.73it/s]\u001b[A\n",
      "Epoch 7:  98%|█████████▊| 1734/1770 [07:22<00:11,  3.02it/s, loss=0.163, v_num=7, val_loss=0.057, val_acc=0.955, train_loss=0.151]\n",
      "Validating:  33%|███▎      | 18/54 [00:12<00:20,  1.73it/s]\u001b[A\n",
      "Epoch 7:  98%|█████████▊| 1736/1770 [07:23<00:11,  3.01it/s, loss=0.163, v_num=7, val_loss=0.057, val_acc=0.955, train_loss=0.151]\n",
      "Validating:  37%|███▋      | 20/54 [00:13<00:19,  1.73it/s]\u001b[A\n",
      "Epoch 7:  98%|█████████▊| 1738/1770 [07:24<00:10,  3.01it/s, loss=0.163, v_num=7, val_loss=0.057, val_acc=0.955, train_loss=0.151]\n",
      "Validating:  41%|████      | 22/54 [00:14<00:18,  1.74it/s]\u001b[A\n",
      "Epoch 7:  98%|█████████▊| 1740/1770 [07:26<00:09,  3.01it/s, loss=0.163, v_num=7, val_loss=0.057, val_acc=0.955, train_loss=0.151]\n",
      "Validating:  44%|████▍     | 24/54 [00:15<00:17,  1.74it/s]\u001b[A\n",
      "Epoch 7:  98%|█████████▊| 1742/1770 [07:27<00:09,  3.00it/s, loss=0.163, v_num=7, val_loss=0.057, val_acc=0.955, train_loss=0.151]\n",
      "Validating:  48%|████▊     | 26/54 [00:16<00:16,  1.74it/s]\u001b[A\n",
      "Epoch 7:  99%|█████████▊| 1744/1770 [07:28<00:08,  3.00it/s, loss=0.163, v_num=7, val_loss=0.057, val_acc=0.955, train_loss=0.151]\n",
      "Validating:  52%|█████▏    | 28/54 [00:18<00:14,  1.74it/s]\u001b[A\n",
      "Epoch 7:  99%|█████████▊| 1746/1770 [07:29<00:08,  3.00it/s, loss=0.163, v_num=7, val_loss=0.057, val_acc=0.955, train_loss=0.151]\n",
      "Validating:  56%|█████▌    | 30/54 [00:19<00:13,  1.74it/s]\u001b[A\n",
      "Epoch 7:  99%|█████████▉| 1748/1770 [07:30<00:07,  2.99it/s, loss=0.163, v_num=7, val_loss=0.057, val_acc=0.955, train_loss=0.151]\n",
      "Validating:  59%|█████▉    | 32/54 [00:20<00:12,  1.74it/s]\u001b[A\n",
      "Epoch 7:  99%|█████████▉| 1750/1770 [07:31<00:06,  2.99it/s, loss=0.163, v_num=7, val_loss=0.057, val_acc=0.955, train_loss=0.151]\n",
      "Validating:  63%|██████▎   | 34/54 [00:21<00:11,  1.74it/s]\u001b[A\n",
      "Epoch 7:  99%|█████████▉| 1752/1770 [07:32<00:06,  2.99it/s, loss=0.163, v_num=7, val_loss=0.057, val_acc=0.955, train_loss=0.151]\n",
      "Validating:  67%|██████▋   | 36/54 [00:22<00:10,  1.74it/s]\u001b[A\n",
      "Epoch 7:  99%|█████████▉| 1754/1770 [07:34<00:05,  2.98it/s, loss=0.163, v_num=7, val_loss=0.057, val_acc=0.955, train_loss=0.151]\n",
      "Validating:  70%|███████   | 38/54 [00:23<00:09,  1.74it/s]\u001b[A\n",
      "Epoch 7:  99%|█████████▉| 1756/1770 [07:35<00:04,  2.98it/s, loss=0.163, v_num=7, val_loss=0.057, val_acc=0.955, train_loss=0.151]\n",
      "Validating:  74%|███████▍  | 40/54 [00:24<00:08,  1.74it/s]\u001b[A\n",
      "Epoch 7:  99%|█████████▉| 1758/1770 [07:36<00:04,  2.98it/s, loss=0.163, v_num=7, val_loss=0.057, val_acc=0.955, train_loss=0.151]\n",
      "Validating:  78%|███████▊  | 42/54 [00:26<00:06,  1.74it/s]\u001b[A\n",
      "Epoch 7:  99%|█████████▉| 1760/1770 [07:37<00:03,  2.97it/s, loss=0.163, v_num=7, val_loss=0.057, val_acc=0.955, train_loss=0.151]\n",
      "Validating:  81%|████████▏ | 44/54 [00:27<00:05,  1.73it/s]\u001b[A\n",
      "Epoch 7: 100%|█████████▉| 1762/1770 [07:38<00:02,  2.97it/s, loss=0.163, v_num=7, val_loss=0.057, val_acc=0.955, train_loss=0.151]\n",
      "Validating:  85%|████████▌ | 46/54 [00:28<00:04,  1.77it/s]\u001b[A\n",
      "Epoch 7: 100%|█████████▉| 1764/1770 [07:39<00:02,  2.97it/s, loss=0.163, v_num=7, val_loss=0.057, val_acc=0.955, train_loss=0.151]\n",
      "Validating:  89%|████████▉ | 48/54 [00:29<00:03,  1.78it/s]\u001b[A\n",
      "Epoch 7: 100%|█████████▉| 1766/1770 [07:40<00:01,  2.97it/s, loss=0.163, v_num=7, val_loss=0.057, val_acc=0.955, train_loss=0.151]\n",
      "Validating:  93%|█████████▎| 50/54 [00:30<00:02,  1.79it/s]\u001b[A\n",
      "Epoch 7: 100%|█████████▉| 1768/1770 [07:42<00:00,  2.96it/s, loss=0.163, v_num=7, val_loss=0.057, val_acc=0.955, train_loss=0.151]\n",
      "Validating:  96%|█████████▋| 52/54 [00:31<00:01,  1.79it/s]\u001b[A\n",
      "Epoch 7: 100%|██████████| 1770/1770 [07:43<00:00,  2.96it/s, loss=0.163, v_num=7, val_loss=0.057, val_acc=0.955, train_loss=0.151]\n",
      "Validating: 100%|██████████| 54/54 [00:32<00:00,  2.02it/s]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7, step 3003: val_loss was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7: 100%|██████████| 1770/1770 [07:43<00:00,  2.96it/s, loss=0.163, v_num=7, val_loss=0.0629, val_acc=0.95, train_loss=0.288]\n",
      "Epoch 8:  97%|█████████▋| 1716/1770 [07:11<00:17,  3.05it/s, loss=0.157, v_num=7, val_loss=0.0629, val_acc=0.95, train_loss=0.284]    \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 8:  97%|█████████▋| 1718/1770 [07:13<00:17,  3.04it/s, loss=0.157, v_num=7, val_loss=0.0629, val_acc=0.95, train_loss=0.284]\n",
      "Validating:   4%|▎         | 2/54 [00:03<01:13,  1.41s/it]\u001b[A\n",
      "Epoch 8:  97%|█████████▋| 1720/1770 [07:15<00:16,  3.04it/s, loss=0.157, v_num=7, val_loss=0.0629, val_acc=0.95, train_loss=0.284]\n",
      "Validating:   7%|▋         | 4/54 [00:04<00:42,  1.17it/s]\u001b[A\n",
      "Epoch 8:  97%|█████████▋| 1722/1770 [07:16<00:15,  3.03it/s, loss=0.157, v_num=7, val_loss=0.0629, val_acc=0.95, train_loss=0.284]\n",
      "Validating:  11%|█         | 6/54 [00:05<00:33,  1.44it/s]\u001b[A\n",
      "Epoch 8:  97%|█████████▋| 1724/1770 [07:17<00:15,  3.03it/s, loss=0.157, v_num=7, val_loss=0.0629, val_acc=0.95, train_loss=0.284]\n",
      "Validating:  15%|█▍        | 8/54 [00:06<00:29,  1.58it/s]\u001b[A\n",
      "Epoch 8:  98%|█████████▊| 1726/1770 [07:18<00:14,  3.03it/s, loss=0.157, v_num=7, val_loss=0.0629, val_acc=0.95, train_loss=0.284]\n",
      "Validating:  19%|█▊        | 10/54 [00:07<00:26,  1.66it/s]\u001b[A\n",
      "Epoch 8:  98%|█████████▊| 1728/1770 [07:19<00:13,  3.02it/s, loss=0.157, v_num=7, val_loss=0.0629, val_acc=0.95, train_loss=0.284]\n",
      "Validating:  22%|██▏       | 12/54 [00:08<00:24,  1.70it/s]\u001b[A\n",
      "Epoch 8:  98%|█████████▊| 1730/1770 [07:20<00:13,  3.02it/s, loss=0.157, v_num=7, val_loss=0.0629, val_acc=0.95, train_loss=0.284]\n",
      "Validating:  26%|██▌       | 14/54 [00:10<00:23,  1.71it/s]\u001b[A\n",
      "Epoch 8:  98%|█████████▊| 1732/1770 [07:21<00:12,  3.02it/s, loss=0.157, v_num=7, val_loss=0.0629, val_acc=0.95, train_loss=0.284]\n",
      "Validating:  30%|██▉       | 16/54 [00:11<00:21,  1.73it/s]\u001b[A\n",
      "Epoch 8:  98%|█████████▊| 1734/1770 [07:23<00:11,  3.01it/s, loss=0.157, v_num=7, val_loss=0.0629, val_acc=0.95, train_loss=0.284]\n",
      "Validating:  33%|███▎      | 18/54 [00:12<00:20,  1.73it/s]\u001b[A\n",
      "Epoch 8:  98%|█████████▊| 1736/1770 [07:24<00:11,  3.01it/s, loss=0.157, v_num=7, val_loss=0.0629, val_acc=0.95, train_loss=0.284]\n",
      "Validating:  37%|███▋      | 20/54 [00:13<00:19,  1.74it/s]\u001b[A\n",
      "Epoch 8:  98%|█████████▊| 1738/1770 [07:25<00:10,  3.01it/s, loss=0.157, v_num=7, val_loss=0.0629, val_acc=0.95, train_loss=0.284]\n",
      "Validating:  41%|████      | 22/54 [00:14<00:18,  1.74it/s]\u001b[A\n",
      "Epoch 8:  98%|█████████▊| 1740/1770 [07:26<00:09,  3.00it/s, loss=0.157, v_num=7, val_loss=0.0629, val_acc=0.95, train_loss=0.284]\n",
      "Validating:  44%|████▍     | 24/54 [00:15<00:17,  1.74it/s]\u001b[A\n",
      "Epoch 8:  98%|█████████▊| 1742/1770 [07:27<00:09,  3.00it/s, loss=0.157, v_num=7, val_loss=0.0629, val_acc=0.95, train_loss=0.284]\n",
      "Validating:  48%|████▊     | 26/54 [00:16<00:16,  1.74it/s]\u001b[A\n",
      "Epoch 8:  99%|█████████▊| 1744/1770 [07:28<00:08,  3.00it/s, loss=0.157, v_num=7, val_loss=0.0629, val_acc=0.95, train_loss=0.284]\n",
      "Validating:  52%|█████▏    | 28/54 [00:18<00:14,  1.74it/s]\u001b[A\n",
      "Epoch 8:  99%|█████████▊| 1746/1770 [07:29<00:08,  2.99it/s, loss=0.157, v_num=7, val_loss=0.0629, val_acc=0.95, train_loss=0.284]\n",
      "Validating:  56%|█████▌    | 30/54 [00:19<00:13,  1.74it/s]\u001b[A\n",
      "Epoch 8:  99%|█████████▉| 1748/1770 [07:31<00:07,  2.99it/s, loss=0.157, v_num=7, val_loss=0.0629, val_acc=0.95, train_loss=0.284]\n",
      "Validating:  59%|█████▉    | 32/54 [00:20<00:12,  1.74it/s]\u001b[A\n",
      "Epoch 8:  99%|█████████▉| 1750/1770 [07:32<00:06,  2.99it/s, loss=0.157, v_num=7, val_loss=0.0629, val_acc=0.95, train_loss=0.284]\n",
      "Validating:  63%|██████▎   | 34/54 [00:21<00:11,  1.74it/s]\u001b[A\n",
      "Epoch 8:  99%|█████████▉| 1752/1770 [07:33<00:06,  2.98it/s, loss=0.157, v_num=7, val_loss=0.0629, val_acc=0.95, train_loss=0.284]\n",
      "Validating:  67%|██████▋   | 36/54 [00:22<00:10,  1.74it/s]\u001b[A\n",
      "Epoch 8:  99%|█████████▉| 1754/1770 [07:34<00:05,  2.98it/s, loss=0.157, v_num=7, val_loss=0.0629, val_acc=0.95, train_loss=0.284]\n",
      "Validating:  70%|███████   | 38/54 [00:23<00:09,  1.73it/s]\u001b[A\n",
      "Epoch 8:  99%|█████████▉| 1756/1770 [07:35<00:04,  2.98it/s, loss=0.157, v_num=7, val_loss=0.0629, val_acc=0.95, train_loss=0.284]\n",
      "Validating:  74%|███████▍  | 40/54 [00:25<00:08,  1.74it/s]\u001b[A\n",
      "Epoch 8:  99%|█████████▉| 1758/1770 [07:36<00:04,  2.97it/s, loss=0.157, v_num=7, val_loss=0.0629, val_acc=0.95, train_loss=0.284]\n",
      "Validating:  78%|███████▊  | 42/54 [00:26<00:06,  1.74it/s]\u001b[A\n",
      "Epoch 8:  99%|█████████▉| 1760/1770 [07:38<00:03,  2.97it/s, loss=0.157, v_num=7, val_loss=0.0629, val_acc=0.95, train_loss=0.284]\n",
      "Validating:  81%|████████▏ | 44/54 [00:27<00:05,  1.74it/s]\u001b[A\n",
      "Epoch 8: 100%|█████████▉| 1762/1770 [07:39<00:02,  2.97it/s, loss=0.157, v_num=7, val_loss=0.0629, val_acc=0.95, train_loss=0.284]\n",
      "Validating:  85%|████████▌ | 46/54 [00:28<00:04,  1.77it/s]\u001b[A\n",
      "Epoch 8: 100%|█████████▉| 1764/1770 [07:40<00:02,  2.97it/s, loss=0.157, v_num=7, val_loss=0.0629, val_acc=0.95, train_loss=0.284]\n",
      "Validating:  89%|████████▉ | 48/54 [00:29<00:03,  1.78it/s]\u001b[A\n",
      "Epoch 8: 100%|█████████▉| 1766/1770 [07:41<00:01,  2.96it/s, loss=0.157, v_num=7, val_loss=0.0629, val_acc=0.95, train_loss=0.284]\n",
      "Validating:  93%|█████████▎| 50/54 [00:30<00:02,  1.79it/s]\u001b[A\n",
      "Epoch 8: 100%|█████████▉| 1768/1770 [07:42<00:00,  2.96it/s, loss=0.157, v_num=7, val_loss=0.0629, val_acc=0.95, train_loss=0.284]\n",
      "Validating:  96%|█████████▋| 52/54 [00:31<00:01,  1.79it/s]\u001b[A\n",
      "Epoch 8: 100%|██████████| 1770/1770 [07:43<00:00,  2.96it/s, loss=0.157, v_num=7, val_loss=0.0629, val_acc=0.95, train_loss=0.284]\n",
      "Validating: 100%|██████████| 54/54 [00:32<00:00,  2.02it/s]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8, global step 3432: val_loss reached 0.05466 (best 0.05466), saving model to \"/opt/favordata/AI/Felix/kaggle-cassava/trained-models/sgd_coswarm_bnf_bitemp_smooth_weighted_t1=0.3_t2=1.0_89-53_tune/tf_efficientnet_b4_ns_bitempered_smooth=0.05_val_loss=0.055_val_acc=0.959_fold1.ckpt\" as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8: 100%|██████████| 1770/1770 [07:44<00:00,  2.95it/s, loss=0.157, v_num=7, val_loss=0.0547, val_acc=0.959, train_loss=0.00386]\n",
      "Epoch 9:  97%|█████████▋| 1716/1770 [07:10<00:17,  3.06it/s, loss=0.175, v_num=7, val_loss=0.0547, val_acc=0.959, train_loss=0.0673]    \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 9:  97%|█████████▋| 1718/1770 [07:12<00:17,  3.05it/s, loss=0.175, v_num=7, val_loss=0.0547, val_acc=0.959, train_loss=0.0673]\n",
      "Validating:   4%|▎         | 2/54 [00:02<01:07,  1.29s/it]\u001b[A\n",
      "Epoch 9:  97%|█████████▋| 1720/1770 [07:14<00:16,  3.04it/s, loss=0.175, v_num=7, val_loss=0.0547, val_acc=0.959, train_loss=0.0673]\n",
      "Validating:   7%|▋         | 4/54 [00:04<00:43,  1.16it/s]\u001b[A\n",
      "Epoch 9:  97%|█████████▋| 1722/1770 [07:15<00:15,  3.04it/s, loss=0.175, v_num=7, val_loss=0.0547, val_acc=0.959, train_loss=0.0673]\n",
      "Validating:  11%|█         | 6/54 [00:05<00:33,  1.43it/s]\u001b[A\n",
      "Epoch 9:  97%|█████████▋| 1724/1770 [07:16<00:15,  3.03it/s, loss=0.175, v_num=7, val_loss=0.0547, val_acc=0.959, train_loss=0.0673]\n",
      "Validating:  15%|█▍        | 8/54 [00:06<00:29,  1.58it/s]\u001b[A\n",
      "Epoch 9:  98%|█████████▊| 1726/1770 [07:17<00:14,  3.03it/s, loss=0.175, v_num=7, val_loss=0.0547, val_acc=0.959, train_loss=0.0673]\n",
      "Validating:  19%|█▊        | 10/54 [00:07<00:26,  1.66it/s]\u001b[A\n",
      "Epoch 9:  98%|█████████▊| 1728/1770 [07:18<00:13,  3.03it/s, loss=0.175, v_num=7, val_loss=0.0547, val_acc=0.959, train_loss=0.0673]\n",
      "Validating:  22%|██▏       | 12/54 [00:08<00:24,  1.70it/s]\u001b[A\n",
      "Epoch 9:  98%|█████████▊| 1730/1770 [07:20<00:13,  3.02it/s, loss=0.175, v_num=7, val_loss=0.0547, val_acc=0.959, train_loss=0.0673]\n",
      "Validating:  26%|██▌       | 14/54 [00:09<00:23,  1.72it/s]\u001b[A\n",
      "Epoch 9:  98%|█████████▊| 1732/1770 [07:21<00:12,  3.02it/s, loss=0.175, v_num=7, val_loss=0.0547, val_acc=0.959, train_loss=0.0673]\n",
      "Validating:  30%|██▉       | 16/54 [00:11<00:21,  1.73it/s]\u001b[A\n",
      "Epoch 9:  98%|█████████▊| 1734/1770 [07:22<00:11,  3.02it/s, loss=0.175, v_num=7, val_loss=0.0547, val_acc=0.959, train_loss=0.0673]\n",
      "Validating:  33%|███▎      | 18/54 [00:12<00:20,  1.74it/s]\u001b[A\n",
      "Epoch 9:  98%|█████████▊| 1736/1770 [07:23<00:11,  3.01it/s, loss=0.175, v_num=7, val_loss=0.0547, val_acc=0.959, train_loss=0.0673]\n",
      "Validating:  37%|███▋      | 20/54 [00:13<00:19,  1.74it/s]\u001b[A\n",
      "Epoch 9:  98%|█████████▊| 1738/1770 [07:24<00:10,  3.01it/s, loss=0.175, v_num=7, val_loss=0.0547, val_acc=0.959, train_loss=0.0673]\n",
      "Validating:  41%|████      | 22/54 [00:14<00:18,  1.74it/s]\u001b[A\n",
      "Epoch 9:  98%|█████████▊| 1740/1770 [07:25<00:09,  3.01it/s, loss=0.175, v_num=7, val_loss=0.0547, val_acc=0.959, train_loss=0.0673]\n",
      "Validating:  44%|████▍     | 24/54 [00:15<00:17,  1.74it/s]\u001b[A\n",
      "Epoch 9:  98%|█████████▊| 1742/1770 [07:27<00:09,  3.00it/s, loss=0.175, v_num=7, val_loss=0.0547, val_acc=0.959, train_loss=0.0673]\n",
      "Validating:  48%|████▊     | 26/54 [00:16<00:16,  1.74it/s]\u001b[A\n",
      "Epoch 9:  99%|█████████▊| 1744/1770 [07:28<00:08,  3.00it/s, loss=0.175, v_num=7, val_loss=0.0547, val_acc=0.959, train_loss=0.0673]\n",
      "Validating:  52%|█████▏    | 28/54 [00:17<00:14,  1.74it/s]\u001b[A\n",
      "Epoch 9:  99%|█████████▊| 1746/1770 [07:29<00:08,  3.00it/s, loss=0.175, v_num=7, val_loss=0.0547, val_acc=0.959, train_loss=0.0673]\n",
      "Validating:  56%|█████▌    | 30/54 [00:19<00:13,  1.74it/s]\u001b[A\n",
      "Epoch 9:  99%|█████████▉| 1748/1770 [07:30<00:07,  2.99it/s, loss=0.175, v_num=7, val_loss=0.0547, val_acc=0.959, train_loss=0.0673]\n",
      "Validating:  59%|█████▉    | 32/54 [00:20<00:12,  1.74it/s]\u001b[A\n",
      "Epoch 9:  99%|█████████▉| 1750/1770 [07:31<00:06,  2.99it/s, loss=0.175, v_num=7, val_loss=0.0547, val_acc=0.959, train_loss=0.0673]\n",
      "Validating:  63%|██████▎   | 34/54 [00:21<00:11,  1.74it/s]\u001b[A\n",
      "Epoch 9:  99%|█████████▉| 1752/1770 [07:32<00:06,  2.99it/s, loss=0.175, v_num=7, val_loss=0.0547, val_acc=0.959, train_loss=0.0673]\n",
      "Validating:  67%|██████▋   | 36/54 [00:22<00:10,  1.72it/s]\u001b[A\n",
      "Epoch 9:  99%|█████████▉| 1754/1770 [07:33<00:05,  2.99it/s, loss=0.175, v_num=7, val_loss=0.0547, val_acc=0.959, train_loss=0.0673]\n",
      "Validating:  70%|███████   | 38/54 [00:23<00:09,  1.73it/s]\u001b[A\n",
      "Epoch 9:  99%|█████████▉| 1756/1770 [07:35<00:04,  2.98it/s, loss=0.175, v_num=7, val_loss=0.0547, val_acc=0.959, train_loss=0.0673]\n",
      "Validating:  74%|███████▍  | 40/54 [00:24<00:08,  1.73it/s]\u001b[A\n",
      "Epoch 9:  99%|█████████▉| 1758/1770 [07:36<00:04,  2.98it/s, loss=0.175, v_num=7, val_loss=0.0547, val_acc=0.959, train_loss=0.0673]\n",
      "Validating:  78%|███████▊  | 42/54 [00:26<00:06,  1.74it/s]\u001b[A\n",
      "Epoch 9:  99%|█████████▉| 1760/1770 [07:37<00:03,  2.98it/s, loss=0.175, v_num=7, val_loss=0.0547, val_acc=0.959, train_loss=0.0673]\n",
      "Validating:  81%|████████▏ | 44/54 [00:27<00:05,  1.73it/s]\u001b[A\n",
      "Epoch 9: 100%|█████████▉| 1762/1770 [07:38<00:02,  2.97it/s, loss=0.175, v_num=7, val_loss=0.0547, val_acc=0.959, train_loss=0.0673]\n",
      "Validating:  85%|████████▌ | 46/54 [00:28<00:04,  1.76it/s]\u001b[A\n",
      "Epoch 9: 100%|█████████▉| 1764/1770 [07:39<00:02,  2.97it/s, loss=0.175, v_num=7, val_loss=0.0547, val_acc=0.959, train_loss=0.0673]\n",
      "Validating:  89%|████████▉ | 48/54 [00:29<00:03,  1.78it/s]\u001b[A\n",
      "Epoch 9: 100%|█████████▉| 1766/1770 [07:40<00:01,  2.97it/s, loss=0.175, v_num=7, val_loss=0.0547, val_acc=0.959, train_loss=0.0673]\n",
      "Validating:  93%|█████████▎| 50/54 [00:30<00:02,  1.79it/s]\u001b[A\n",
      "Epoch 9: 100%|█████████▉| 1768/1770 [07:41<00:00,  2.96it/s, loss=0.175, v_num=7, val_loss=0.0547, val_acc=0.959, train_loss=0.0673]\n",
      "Validating:  96%|█████████▋| 52/54 [00:31<00:01,  1.79it/s]\u001b[A\n",
      "Epoch 9: 100%|██████████| 1770/1770 [07:42<00:00,  2.96it/s, loss=0.175, v_num=7, val_loss=0.0547, val_acc=0.959, train_loss=0.0673]\n",
      "Validating: 100%|██████████| 54/54 [00:32<00:00,  2.02it/s]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9, step 3861: val_loss was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 1770/1770 [07:43<00:00,  2.96it/s, loss=0.175, v_num=7, val_loss=0.0577, val_acc=0.955, train_loss=0.308] \n",
      "Epoch 10:  97%|█████████▋| 1716/1770 [07:11<00:17,  3.06it/s, loss=0.173, v_num=7, val_loss=0.0577, val_acc=0.955, train_loss=0.458]    \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 10:  97%|█████████▋| 1718/1770 [07:13<00:17,  3.04it/s, loss=0.173, v_num=7, val_loss=0.0577, val_acc=0.955, train_loss=0.458]\n",
      "Validating:   4%|▎         | 2/54 [00:02<01:10,  1.35s/it]\u001b[A\n",
      "Epoch 10:  97%|█████████▋| 1720/1770 [07:14<00:16,  3.04it/s, loss=0.173, v_num=7, val_loss=0.0577, val_acc=0.955, train_loss=0.458]\n",
      "Validating:   7%|▋         | 4/54 [00:04<00:43,  1.15it/s]\u001b[A\n",
      "Epoch 10:  97%|█████████▋| 1722/1770 [07:15<00:15,  3.04it/s, loss=0.173, v_num=7, val_loss=0.0577, val_acc=0.955, train_loss=0.458]\n",
      "Validating:  11%|█         | 6/54 [00:05<00:33,  1.43it/s]\u001b[A\n",
      "Epoch 10:  97%|█████████▋| 1724/1770 [07:17<00:15,  3.03it/s, loss=0.173, v_num=7, val_loss=0.0577, val_acc=0.955, train_loss=0.458]\n",
      "Validating:  15%|█▍        | 8/54 [00:06<00:29,  1.58it/s]\u001b[A\n",
      "Epoch 10:  98%|█████████▊| 1726/1770 [07:18<00:14,  3.03it/s, loss=0.173, v_num=7, val_loss=0.0577, val_acc=0.955, train_loss=0.458]\n",
      "Validating:  19%|█▊        | 10/54 [00:07<00:26,  1.66it/s]\u001b[A\n",
      "Epoch 10:  98%|█████████▊| 1728/1770 [07:19<00:13,  3.03it/s, loss=0.173, v_num=7, val_loss=0.0577, val_acc=0.955, train_loss=0.458]\n",
      "Validating:  22%|██▏       | 12/54 [00:08<00:24,  1.70it/s]\u001b[A\n",
      "Epoch 10:  98%|█████████▊| 1730/1770 [07:20<00:13,  3.02it/s, loss=0.173, v_num=7, val_loss=0.0577, val_acc=0.955, train_loss=0.458]\n",
      "Validating:  26%|██▌       | 14/54 [00:09<00:23,  1.72it/s]\u001b[A\n",
      "Epoch 10:  98%|█████████▊| 1732/1770 [07:21<00:12,  3.02it/s, loss=0.173, v_num=7, val_loss=0.0577, val_acc=0.955, train_loss=0.458]\n",
      "Validating:  30%|██▉       | 16/54 [00:11<00:21,  1.73it/s]\u001b[A\n",
      "Epoch 10:  98%|█████████▊| 1734/1770 [07:22<00:11,  3.02it/s, loss=0.173, v_num=7, val_loss=0.0577, val_acc=0.955, train_loss=0.458]\n",
      "Validating:  33%|███▎      | 18/54 [00:12<00:20,  1.74it/s]\u001b[A\n",
      "Epoch 10:  98%|█████████▊| 1736/1770 [07:23<00:11,  3.01it/s, loss=0.173, v_num=7, val_loss=0.0577, val_acc=0.955, train_loss=0.458]\n",
      "Validating:  37%|███▋      | 20/54 [00:13<00:19,  1.74it/s]\u001b[A\n",
      "Epoch 10:  98%|█████████▊| 1738/1770 [07:25<00:10,  3.01it/s, loss=0.173, v_num=7, val_loss=0.0577, val_acc=0.955, train_loss=0.458]\n",
      "Validating:  41%|████      | 22/54 [00:14<00:18,  1.74it/s]\u001b[A\n",
      "Epoch 10:  98%|█████████▊| 1740/1770 [07:26<00:09,  3.01it/s, loss=0.173, v_num=7, val_loss=0.0577, val_acc=0.955, train_loss=0.458]\n",
      "Validating:  44%|████▍     | 24/54 [00:15<00:17,  1.73it/s]\u001b[A\n",
      "Epoch 10:  98%|█████████▊| 1742/1770 [07:27<00:09,  3.00it/s, loss=0.173, v_num=7, val_loss=0.0577, val_acc=0.955, train_loss=0.458]\n",
      "Validating:  48%|████▊     | 26/54 [00:16<00:16,  1.74it/s]\u001b[A\n",
      "Epoch 10:  99%|█████████▊| 1744/1770 [07:28<00:08,  3.00it/s, loss=0.173, v_num=7, val_loss=0.0577, val_acc=0.955, train_loss=0.458]\n",
      "Validating:  52%|█████▏    | 28/54 [00:18<00:14,  1.74it/s]\u001b[A\n",
      "Epoch 10:  99%|█████████▊| 1746/1770 [07:29<00:08,  3.00it/s, loss=0.173, v_num=7, val_loss=0.0577, val_acc=0.955, train_loss=0.458]\n",
      "Validating:  56%|█████▌    | 30/54 [00:19<00:13,  1.73it/s]\u001b[A\n",
      "Epoch 10:  99%|█████████▉| 1748/1770 [07:30<00:07,  2.99it/s, loss=0.173, v_num=7, val_loss=0.0577, val_acc=0.955, train_loss=0.458]\n",
      "Validating:  59%|█████▉    | 32/54 [00:20<00:12,  1.74it/s]\u001b[A\n",
      "Epoch 10:  99%|█████████▉| 1750/1770 [07:31<00:06,  2.99it/s, loss=0.173, v_num=7, val_loss=0.0577, val_acc=0.955, train_loss=0.458]\n",
      "Validating:  63%|██████▎   | 34/54 [00:21<00:11,  1.74it/s]\u001b[A\n",
      "Epoch 10:  99%|█████████▉| 1752/1770 [07:33<00:06,  2.99it/s, loss=0.173, v_num=7, val_loss=0.0577, val_acc=0.955, train_loss=0.458]\n",
      "Validating:  67%|██████▋   | 36/54 [00:22<00:10,  1.74it/s]\u001b[A\n",
      "Epoch 10:  99%|█████████▉| 1754/1770 [07:34<00:05,  2.98it/s, loss=0.173, v_num=7, val_loss=0.0577, val_acc=0.955, train_loss=0.458]\n",
      "Validating:  70%|███████   | 38/54 [00:23<00:09,  1.74it/s]\u001b[A\n",
      "Epoch 10:  99%|█████████▉| 1756/1770 [07:35<00:04,  2.98it/s, loss=0.173, v_num=7, val_loss=0.0577, val_acc=0.955, train_loss=0.458]\n",
      "Validating:  74%|███████▍  | 40/54 [00:24<00:08,  1.74it/s]\u001b[A\n",
      "Epoch 10:  99%|█████████▉| 1758/1770 [07:36<00:04,  2.98it/s, loss=0.173, v_num=7, val_loss=0.0577, val_acc=0.955, train_loss=0.458]\n",
      "Validating:  78%|███████▊  | 42/54 [00:26<00:06,  1.74it/s]\u001b[A\n",
      "Epoch 10:  99%|█████████▉| 1760/1770 [07:37<00:03,  2.97it/s, loss=0.173, v_num=7, val_loss=0.0577, val_acc=0.955, train_loss=0.458]\n",
      "Validating:  81%|████████▏ | 44/54 [00:27<00:05,  1.74it/s]\u001b[A\n",
      "Epoch 10: 100%|█████████▉| 1762/1770 [07:38<00:02,  2.97it/s, loss=0.173, v_num=7, val_loss=0.0577, val_acc=0.955, train_loss=0.458]\n",
      "Validating:  85%|████████▌ | 46/54 [00:28<00:04,  1.76it/s]\u001b[A\n",
      "Epoch 10: 100%|█████████▉| 1764/1770 [07:39<00:02,  2.97it/s, loss=0.173, v_num=7, val_loss=0.0577, val_acc=0.955, train_loss=0.458]\n",
      "Validating:  89%|████████▉ | 48/54 [00:29<00:03,  1.78it/s]\u001b[A\n",
      "Epoch 10: 100%|█████████▉| 1766/1770 [07:41<00:01,  2.96it/s, loss=0.173, v_num=7, val_loss=0.0577, val_acc=0.955, train_loss=0.458]\n",
      "Validating:  93%|█████████▎| 50/54 [00:30<00:02,  1.79it/s]\u001b[A\n",
      "Epoch 10: 100%|█████████▉| 1768/1770 [07:42<00:00,  2.96it/s, loss=0.173, v_num=7, val_loss=0.0577, val_acc=0.955, train_loss=0.458]\n",
      "Validating:  96%|█████████▋| 52/54 [00:31<00:01,  1.79it/s]\u001b[A\n",
      "Epoch 10: 100%|██████████| 1770/1770 [07:43<00:00,  2.96it/s, loss=0.173, v_num=7, val_loss=0.0577, val_acc=0.955, train_loss=0.458]\n",
      "Validating: 100%|██████████| 54/54 [00:32<00:00,  2.02it/s]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10, step 4290: val_loss was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10: 100%|██████████| 1770/1770 [07:43<00:00,  2.96it/s, loss=0.173, v_num=7, val_loss=0.0553, val_acc=0.957, train_loss=0.172]\n",
      "Epoch 11:  97%|█████████▋| 1716/1770 [07:10<00:17,  3.06it/s, loss=0.168, v_num=7, val_loss=0.0553, val_acc=0.957, train_loss=0.122]    \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 11:  97%|█████████▋| 1718/1770 [07:12<00:17,  3.05it/s, loss=0.168, v_num=7, val_loss=0.0553, val_acc=0.957, train_loss=0.122]\n",
      "Validating:   4%|▎         | 2/54 [00:02<01:01,  1.19s/it]\u001b[A\n",
      "Epoch 11:  97%|█████████▋| 1720/1770 [07:14<00:16,  3.04it/s, loss=0.168, v_num=7, val_loss=0.0553, val_acc=0.957, train_loss=0.122]\n",
      "Validating:   7%|▋         | 4/54 [00:03<00:42,  1.18it/s]\u001b[A\n",
      "Epoch 11:  97%|█████████▋| 1722/1770 [07:15<00:15,  3.04it/s, loss=0.168, v_num=7, val_loss=0.0553, val_acc=0.957, train_loss=0.122]\n",
      "Validating:  11%|█         | 6/54 [00:05<00:33,  1.45it/s]\u001b[A\n",
      "Epoch 11:  97%|█████████▋| 1724/1770 [07:16<00:15,  3.04it/s, loss=0.168, v_num=7, val_loss=0.0553, val_acc=0.957, train_loss=0.122]\n",
      "Validating:  15%|█▍        | 8/54 [00:06<00:28,  1.60it/s]\u001b[A\n",
      "Epoch 11:  98%|█████████▊| 1726/1770 [07:17<00:14,  3.03it/s, loss=0.168, v_num=7, val_loss=0.0553, val_acc=0.957, train_loss=0.122]\n",
      "Validating:  19%|█▊        | 10/54 [00:07<00:26,  1.67it/s]\u001b[A\n",
      "Epoch 11:  98%|█████████▊| 1728/1770 [07:18<00:13,  3.03it/s, loss=0.168, v_num=7, val_loss=0.0553, val_acc=0.957, train_loss=0.122]\n",
      "Validating:  22%|██▏       | 12/54 [00:08<00:24,  1.71it/s]\u001b[A\n",
      "Epoch 11:  98%|█████████▊| 1730/1770 [07:19<00:13,  3.03it/s, loss=0.168, v_num=7, val_loss=0.0553, val_acc=0.957, train_loss=0.122]\n",
      "Validating:  26%|██▌       | 14/54 [00:09<00:23,  1.72it/s]\u001b[A\n",
      "Epoch 11:  98%|█████████▊| 1732/1770 [07:20<00:12,  3.02it/s, loss=0.168, v_num=7, val_loss=0.0553, val_acc=0.957, train_loss=0.122]\n",
      "Validating:  30%|██▉       | 16/54 [00:10<00:21,  1.73it/s]\u001b[A\n",
      "Epoch 11:  98%|█████████▊| 1734/1770 [07:22<00:11,  3.02it/s, loss=0.168, v_num=7, val_loss=0.0553, val_acc=0.957, train_loss=0.122]\n",
      "Validating:  33%|███▎      | 18/54 [00:12<00:20,  1.74it/s]\u001b[A\n",
      "Epoch 11:  98%|█████████▊| 1736/1770 [07:23<00:11,  3.02it/s, loss=0.168, v_num=7, val_loss=0.0553, val_acc=0.957, train_loss=0.122]\n",
      "Validating:  37%|███▋      | 20/54 [00:13<00:19,  1.74it/s]\u001b[A\n",
      "Epoch 11:  98%|█████████▊| 1738/1770 [07:24<00:10,  3.01it/s, loss=0.168, v_num=7, val_loss=0.0553, val_acc=0.957, train_loss=0.122]\n",
      "Validating:  41%|████      | 22/54 [00:14<00:18,  1.74it/s]\u001b[A\n",
      "Epoch 11:  98%|█████████▊| 1740/1770 [07:25<00:09,  3.01it/s, loss=0.168, v_num=7, val_loss=0.0553, val_acc=0.957, train_loss=0.122]\n",
      "Validating:  44%|████▍     | 24/54 [00:15<00:17,  1.74it/s]\u001b[A\n",
      "Epoch 11:  98%|█████████▊| 1742/1770 [07:26<00:09,  3.01it/s, loss=0.168, v_num=7, val_loss=0.0553, val_acc=0.957, train_loss=0.122]\n",
      "Validating:  48%|████▊     | 26/54 [00:16<00:16,  1.73it/s]\u001b[A\n",
      "Epoch 11:  99%|█████████▊| 1744/1770 [07:27<00:08,  3.00it/s, loss=0.168, v_num=7, val_loss=0.0553, val_acc=0.957, train_loss=0.122]\n",
      "Validating:  52%|█████▏    | 28/54 [00:17<00:15,  1.73it/s]\u001b[A\n",
      "Epoch 11:  99%|█████████▊| 1746/1770 [07:29<00:08,  3.00it/s, loss=0.168, v_num=7, val_loss=0.0553, val_acc=0.957, train_loss=0.122]\n",
      "Validating:  56%|█████▌    | 30/54 [00:18<00:13,  1.73it/s]\u001b[A\n",
      "Epoch 11:  99%|█████████▉| 1748/1770 [07:30<00:07,  3.00it/s, loss=0.168, v_num=7, val_loss=0.0553, val_acc=0.957, train_loss=0.122]\n",
      "Validating:  59%|█████▉    | 32/54 [00:20<00:12,  1.74it/s]\u001b[A\n",
      "Epoch 11:  99%|█████████▉| 1750/1770 [07:31<00:06,  2.99it/s, loss=0.168, v_num=7, val_loss=0.0553, val_acc=0.957, train_loss=0.122]\n",
      "Validating:  63%|██████▎   | 34/54 [00:21<00:11,  1.73it/s]\u001b[A\n",
      "Epoch 11:  99%|█████████▉| 1752/1770 [07:32<00:06,  2.99it/s, loss=0.168, v_num=7, val_loss=0.0553, val_acc=0.957, train_loss=0.122]\n",
      "Validating:  67%|██████▋   | 36/54 [00:22<00:10,  1.73it/s]\u001b[A\n",
      "Epoch 11:  99%|█████████▉| 1754/1770 [07:33<00:05,  2.99it/s, loss=0.168, v_num=7, val_loss=0.0553, val_acc=0.957, train_loss=0.122]\n",
      "Validating:  70%|███████   | 38/54 [00:23<00:09,  1.73it/s]\u001b[A\n",
      "Epoch 11:  99%|█████████▉| 1756/1770 [07:34<00:04,  2.98it/s, loss=0.168, v_num=7, val_loss=0.0553, val_acc=0.957, train_loss=0.122]\n",
      "Validating:  74%|███████▍  | 40/54 [00:24<00:08,  1.74it/s]\u001b[A\n",
      "Epoch 11:  99%|█████████▉| 1758/1770 [07:35<00:04,  2.98it/s, loss=0.168, v_num=7, val_loss=0.0553, val_acc=0.957, train_loss=0.122]\n",
      "Validating:  78%|███████▊  | 42/54 [00:25<00:06,  1.74it/s]\u001b[A\n",
      "Epoch 11:  99%|█████████▉| 1760/1770 [07:37<00:03,  2.98it/s, loss=0.168, v_num=7, val_loss=0.0553, val_acc=0.957, train_loss=0.122]\n",
      "Validating:  81%|████████▏ | 44/54 [00:27<00:05,  1.74it/s]\u001b[A\n",
      "Epoch 11: 100%|█████████▉| 1762/1770 [07:38<00:02,  2.97it/s, loss=0.168, v_num=7, val_loss=0.0553, val_acc=0.957, train_loss=0.122]\n",
      "Validating:  85%|████████▌ | 46/54 [00:28<00:04,  1.76it/s]\u001b[A\n",
      "Epoch 11: 100%|█████████▉| 1764/1770 [07:39<00:02,  2.97it/s, loss=0.168, v_num=7, val_loss=0.0553, val_acc=0.957, train_loss=0.122]\n",
      "Validating:  89%|████████▉ | 48/54 [00:29<00:03,  1.78it/s]\u001b[A\n",
      "Epoch 11: 100%|█████████▉| 1766/1770 [07:40<00:01,  2.97it/s, loss=0.168, v_num=7, val_loss=0.0553, val_acc=0.957, train_loss=0.122]\n",
      "Validating:  93%|█████████▎| 50/54 [00:30<00:02,  1.79it/s]\u001b[A\n",
      "Epoch 11: 100%|█████████▉| 1768/1770 [07:41<00:00,  2.97it/s, loss=0.168, v_num=7, val_loss=0.0553, val_acc=0.957, train_loss=0.122]\n",
      "Validating:  96%|█████████▋| 52/54 [00:31<00:01,  1.79it/s]\u001b[A\n",
      "Epoch 11: 100%|██████████| 1770/1770 [07:42<00:00,  2.96it/s, loss=0.168, v_num=7, val_loss=0.0553, val_acc=0.957, train_loss=0.122]\n",
      "Validating: 100%|██████████| 54/54 [00:32<00:00,  2.02it/s]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11, step 4719: val_loss was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11: 100%|██████████| 1770/1770 [07:43<00:00,  2.96it/s, loss=0.168, v_num=7, val_loss=0.0592, val_acc=0.953, train_loss=0.112]\n",
      "Epoch 12:  97%|█████████▋| 1716/1770 [07:10<00:17,  3.06it/s, loss=0.155, v_num=7, val_loss=0.0592, val_acc=0.953, train_loss=0.312]    \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 12:  97%|█████████▋| 1718/1770 [07:12<00:17,  3.05it/s, loss=0.155, v_num=7, val_loss=0.0592, val_acc=0.953, train_loss=0.312]\n",
      "Validating:   4%|▎         | 2/54 [00:02<01:02,  1.21s/it]\u001b[A\n",
      "Epoch 12:  97%|█████████▋| 1720/1770 [07:14<00:16,  3.04it/s, loss=0.155, v_num=7, val_loss=0.0592, val_acc=0.953, train_loss=0.312]\n",
      "Validating:   7%|▋         | 4/54 [00:03<00:41,  1.21it/s]\u001b[A\n",
      "Epoch 12:  97%|█████████▋| 1722/1770 [07:15<00:15,  3.04it/s, loss=0.155, v_num=7, val_loss=0.0592, val_acc=0.953, train_loss=0.312]\n",
      "Validating:  11%|█         | 6/54 [00:05<00:32,  1.46it/s]\u001b[A\n",
      "Epoch 12:  97%|█████████▋| 1724/1770 [07:16<00:15,  3.03it/s, loss=0.155, v_num=7, val_loss=0.0592, val_acc=0.953, train_loss=0.312]\n",
      "Validating:  15%|█▍        | 8/54 [00:06<00:28,  1.60it/s]\u001b[A\n",
      "Epoch 12:  98%|█████████▊| 1726/1770 [07:17<00:14,  3.03it/s, loss=0.155, v_num=7, val_loss=0.0592, val_acc=0.953, train_loss=0.312]\n",
      "Validating:  19%|█▊        | 10/54 [00:07<00:26,  1.67it/s]\u001b[A\n",
      "Epoch 12:  98%|█████████▊| 1728/1770 [07:18<00:13,  3.03it/s, loss=0.155, v_num=7, val_loss=0.0592, val_acc=0.953, train_loss=0.312]\n",
      "Validating:  22%|██▏       | 12/54 [00:08<00:24,  1.69it/s]\u001b[A\n",
      "Epoch 12:  98%|█████████▊| 1730/1770 [07:20<00:13,  3.02it/s, loss=0.155, v_num=7, val_loss=0.0592, val_acc=0.953, train_loss=0.312]\n",
      "Validating:  26%|██▌       | 14/54 [00:09<00:23,  1.72it/s]\u001b[A\n",
      "Epoch 12:  98%|█████████▊| 1732/1770 [07:21<00:12,  3.02it/s, loss=0.155, v_num=7, val_loss=0.0592, val_acc=0.953, train_loss=0.312]\n",
      "Validating:  30%|██▉       | 16/54 [00:10<00:22,  1.73it/s]\u001b[A\n",
      "Epoch 12:  98%|█████████▊| 1734/1770 [07:22<00:11,  3.02it/s, loss=0.155, v_num=7, val_loss=0.0592, val_acc=0.953, train_loss=0.312]\n",
      "Validating:  33%|███▎      | 18/54 [00:12<00:20,  1.73it/s]\u001b[A\n",
      "Epoch 12:  98%|█████████▊| 1736/1770 [07:23<00:11,  3.01it/s, loss=0.155, v_num=7, val_loss=0.0592, val_acc=0.953, train_loss=0.312]\n",
      "Validating:  37%|███▋      | 20/54 [00:13<00:19,  1.73it/s]\u001b[A\n",
      "Epoch 12:  98%|█████████▊| 1738/1770 [07:24<00:10,  3.01it/s, loss=0.155, v_num=7, val_loss=0.0592, val_acc=0.953, train_loss=0.312]\n",
      "Validating:  41%|████      | 22/54 [00:14<00:18,  1.74it/s]\u001b[A\n",
      "Epoch 12:  98%|█████████▊| 1740/1770 [07:25<00:09,  3.01it/s, loss=0.155, v_num=7, val_loss=0.0592, val_acc=0.953, train_loss=0.312]\n",
      "Validating:  44%|████▍     | 24/54 [00:15<00:17,  1.74it/s]\u001b[A\n",
      "Epoch 12:  98%|█████████▊| 1742/1770 [07:27<00:09,  3.00it/s, loss=0.155, v_num=7, val_loss=0.0592, val_acc=0.953, train_loss=0.312]\n",
      "Validating:  48%|████▊     | 26/54 [00:16<00:16,  1.74it/s]\u001b[A\n",
      "Epoch 12:  99%|█████████▊| 1744/1770 [07:28<00:08,  3.00it/s, loss=0.155, v_num=7, val_loss=0.0592, val_acc=0.953, train_loss=0.312]\n",
      "Validating:  52%|█████▏    | 28/54 [00:17<00:14,  1.74it/s]\u001b[A\n",
      "Epoch 12:  99%|█████████▊| 1746/1770 [07:29<00:08,  3.00it/s, loss=0.155, v_num=7, val_loss=0.0592, val_acc=0.953, train_loss=0.312]\n",
      "Validating:  56%|█████▌    | 30/54 [00:18<00:13,  1.74it/s]\u001b[A\n",
      "Epoch 12:  99%|█████████▉| 1748/1770 [07:30<00:07,  2.99it/s, loss=0.155, v_num=7, val_loss=0.0592, val_acc=0.953, train_loss=0.312]\n",
      "Validating:  59%|█████▉    | 32/54 [00:20<00:12,  1.73it/s]\u001b[A\n",
      "Epoch 12:  99%|█████████▉| 1750/1770 [07:31<00:06,  2.99it/s, loss=0.155, v_num=7, val_loss=0.0592, val_acc=0.953, train_loss=0.312]\n",
      "Validating:  63%|██████▎   | 34/54 [00:21<00:11,  1.73it/s]\u001b[A\n",
      "Epoch 12:  99%|█████████▉| 1752/1770 [07:32<00:06,  2.99it/s, loss=0.155, v_num=7, val_loss=0.0592, val_acc=0.953, train_loss=0.312]\n",
      "Validating:  67%|██████▋   | 36/54 [00:22<00:10,  1.73it/s]\u001b[A\n",
      "Epoch 12:  99%|█████████▉| 1754/1770 [07:33<00:05,  2.99it/s, loss=0.155, v_num=7, val_loss=0.0592, val_acc=0.953, train_loss=0.312]\n",
      "Validating:  70%|███████   | 38/54 [00:23<00:09,  1.74it/s]\u001b[A\n",
      "Epoch 12:  99%|█████████▉| 1756/1770 [07:35<00:04,  2.98it/s, loss=0.155, v_num=7, val_loss=0.0592, val_acc=0.953, train_loss=0.312]\n",
      "Validating:  74%|███████▍  | 40/54 [00:24<00:08,  1.74it/s]\u001b[A\n",
      "Epoch 12:  99%|█████████▉| 1758/1770 [07:36<00:04,  2.98it/s, loss=0.155, v_num=7, val_loss=0.0592, val_acc=0.953, train_loss=0.312]\n",
      "Validating:  78%|███████▊  | 42/54 [00:25<00:06,  1.74it/s]\u001b[A\n",
      "Epoch 12:  99%|█████████▉| 1760/1770 [07:37<00:03,  2.98it/s, loss=0.155, v_num=7, val_loss=0.0592, val_acc=0.953, train_loss=0.312]\n",
      "Validating:  81%|████████▏ | 44/54 [00:26<00:05,  1.74it/s]\u001b[A\n",
      "Epoch 12: 100%|█████████▉| 1762/1770 [07:38<00:02,  2.97it/s, loss=0.155, v_num=7, val_loss=0.0592, val_acc=0.953, train_loss=0.312]\n",
      "Validating:  85%|████████▌ | 46/54 [00:28<00:04,  1.76it/s]\u001b[A\n",
      "Epoch 12: 100%|█████████▉| 1764/1770 [07:39<00:02,  2.97it/s, loss=0.155, v_num=7, val_loss=0.0592, val_acc=0.953, train_loss=0.312]\n",
      "Validating:  89%|████████▉ | 48/54 [00:29<00:03,  1.78it/s]\u001b[A\n",
      "Epoch 12: 100%|█████████▉| 1766/1770 [07:40<00:01,  2.97it/s, loss=0.155, v_num=7, val_loss=0.0592, val_acc=0.953, train_loss=0.312]\n",
      "Validating:  93%|█████████▎| 50/54 [00:30<00:02,  1.79it/s]\u001b[A\n",
      "Epoch 12: 100%|█████████▉| 1768/1770 [07:41<00:00,  2.96it/s, loss=0.155, v_num=7, val_loss=0.0592, val_acc=0.953, train_loss=0.312]\n",
      "Validating:  96%|█████████▋| 52/54 [00:31<00:01,  1.79it/s]\u001b[A\n",
      "Epoch 12: 100%|██████████| 1770/1770 [07:42<00:00,  2.96it/s, loss=0.155, v_num=7, val_loss=0.0592, val_acc=0.953, train_loss=0.312]\n",
      "Validating: 100%|██████████| 54/54 [00:32<00:00,  2.02it/s]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12, step 5148: val_loss was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12: 100%|██████████| 1770/1770 [07:43<00:00,  2.96it/s, loss=0.155, v_num=7, val_loss=0.0555, val_acc=0.957, train_loss=0.0841]\n",
      "Epoch 13:  97%|█████████▋| 1716/1770 [07:10<00:17,  3.06it/s, loss=0.158, v_num=7, val_loss=0.0555, val_acc=0.957, train_loss=0.319]     \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 13:  97%|█████████▋| 1718/1770 [07:12<00:17,  3.05it/s, loss=0.158, v_num=7, val_loss=0.0555, val_acc=0.957, train_loss=0.319]\n",
      "Validating:   4%|▎         | 2/54 [00:02<01:00,  1.17s/it]\u001b[A\n",
      "Epoch 13:  97%|█████████▋| 1720/1770 [07:14<00:16,  3.04it/s, loss=0.158, v_num=7, val_loss=0.0555, val_acc=0.957, train_loss=0.319]\n",
      "Validating:   7%|▋         | 4/54 [00:03<00:40,  1.23it/s]\u001b[A\n",
      "Epoch 13:  97%|█████████▋| 1722/1770 [07:15<00:15,  3.04it/s, loss=0.158, v_num=7, val_loss=0.0555, val_acc=0.957, train_loss=0.319]\n",
      "Validating:  11%|█         | 6/54 [00:05<00:32,  1.48it/s]\u001b[A\n",
      "Epoch 13:  97%|█████████▋| 1724/1770 [07:16<00:15,  3.04it/s, loss=0.158, v_num=7, val_loss=0.0555, val_acc=0.957, train_loss=0.319]\n",
      "Validating:  15%|█▍        | 8/54 [00:06<00:28,  1.61it/s]\u001b[A\n",
      "Epoch 13:  98%|█████████▊| 1726/1770 [07:17<00:14,  3.03it/s, loss=0.158, v_num=7, val_loss=0.0555, val_acc=0.957, train_loss=0.319]\n",
      "Validating:  19%|█▊        | 10/54 [00:07<00:26,  1.68it/s]\u001b[A\n",
      "Epoch 13:  98%|█████████▊| 1728/1770 [07:18<00:13,  3.03it/s, loss=0.158, v_num=7, val_loss=0.0555, val_acc=0.957, train_loss=0.319]\n",
      "Validating:  22%|██▏       | 12/54 [00:08<00:24,  1.70it/s]\u001b[A\n",
      "Epoch 13:  98%|█████████▊| 1730/1770 [07:19<00:13,  3.03it/s, loss=0.158, v_num=7, val_loss=0.0555, val_acc=0.957, train_loss=0.319]\n",
      "Validating:  26%|██▌       | 14/54 [00:09<00:23,  1.72it/s]\u001b[A\n",
      "Epoch 13:  98%|█████████▊| 1732/1770 [07:21<00:12,  3.02it/s, loss=0.158, v_num=7, val_loss=0.0555, val_acc=0.957, train_loss=0.319]\n",
      "Validating:  30%|██▉       | 16/54 [00:10<00:21,  1.73it/s]\u001b[A\n",
      "Epoch 13:  98%|█████████▊| 1734/1770 [07:22<00:11,  3.02it/s, loss=0.158, v_num=7, val_loss=0.0555, val_acc=0.957, train_loss=0.319]\n",
      "Validating:  33%|███▎      | 18/54 [00:11<00:20,  1.74it/s]\u001b[A\n",
      "Epoch 13:  98%|█████████▊| 1736/1770 [07:23<00:11,  3.02it/s, loss=0.158, v_num=7, val_loss=0.0555, val_acc=0.957, train_loss=0.319]\n",
      "Validating:  37%|███▋      | 20/54 [00:13<00:19,  1.74it/s]\u001b[A\n",
      "Epoch 13:  98%|█████████▊| 1738/1770 [07:24<00:10,  3.01it/s, loss=0.158, v_num=7, val_loss=0.0555, val_acc=0.957, train_loss=0.319]\n",
      "Validating:  41%|████      | 22/54 [00:14<00:18,  1.74it/s]\u001b[A\n",
      "Epoch 13:  98%|█████████▊| 1740/1770 [07:25<00:09,  3.01it/s, loss=0.158, v_num=7, val_loss=0.0555, val_acc=0.957, train_loss=0.319]\n",
      "Validating:  44%|████▍     | 24/54 [00:15<00:17,  1.74it/s]\u001b[A\n",
      "Epoch 13:  98%|█████████▊| 1742/1770 [07:26<00:09,  3.01it/s, loss=0.158, v_num=7, val_loss=0.0555, val_acc=0.957, train_loss=0.319]\n",
      "Validating:  48%|████▊     | 26/54 [00:16<00:16,  1.74it/s]\u001b[A\n",
      "Epoch 13:  99%|█████████▊| 1744/1770 [07:27<00:08,  3.00it/s, loss=0.158, v_num=7, val_loss=0.0555, val_acc=0.957, train_loss=0.319]\n",
      "Validating:  52%|█████▏    | 28/54 [00:17<00:14,  1.74it/s]\u001b[A\n",
      "Epoch 13:  99%|█████████▊| 1746/1770 [07:29<00:08,  3.00it/s, loss=0.158, v_num=7, val_loss=0.0555, val_acc=0.957, train_loss=0.319]\n",
      "Validating:  56%|█████▌    | 30/54 [00:18<00:13,  1.74it/s]\u001b[A\n",
      "Epoch 13:  99%|█████████▉| 1748/1770 [07:30<00:07,  3.00it/s, loss=0.158, v_num=7, val_loss=0.0555, val_acc=0.957, train_loss=0.319]\n",
      "Validating:  59%|█████▉    | 32/54 [00:19<00:12,  1.74it/s]\u001b[A\n",
      "Epoch 13:  99%|█████████▉| 1750/1770 [07:31<00:06,  2.99it/s, loss=0.158, v_num=7, val_loss=0.0555, val_acc=0.957, train_loss=0.319]\n",
      "Validating:  63%|██████▎   | 34/54 [00:21<00:11,  1.74it/s]\u001b[A\n",
      "Epoch 13:  99%|█████████▉| 1752/1770 [07:32<00:06,  2.99it/s, loss=0.158, v_num=7, val_loss=0.0555, val_acc=0.957, train_loss=0.319]\n",
      "Validating:  67%|██████▋   | 36/54 [00:22<00:10,  1.74it/s]\u001b[A\n",
      "Epoch 13:  99%|█████████▉| 1754/1770 [07:33<00:05,  2.99it/s, loss=0.158, v_num=7, val_loss=0.0555, val_acc=0.957, train_loss=0.319]\n",
      "Validating:  70%|███████   | 38/54 [00:23<00:09,  1.74it/s]\u001b[A\n",
      "Epoch 13:  99%|█████████▉| 1756/1770 [07:34<00:04,  2.98it/s, loss=0.158, v_num=7, val_loss=0.0555, val_acc=0.957, train_loss=0.319]\n",
      "Validating:  74%|███████▍  | 40/54 [00:24<00:08,  1.74it/s]\u001b[A\n",
      "Epoch 13:  99%|█████████▉| 1758/1770 [07:35<00:04,  2.98it/s, loss=0.158, v_num=7, val_loss=0.0555, val_acc=0.957, train_loss=0.319]\n",
      "Validating:  78%|███████▊  | 42/54 [00:25<00:06,  1.74it/s]\u001b[A\n",
      "Epoch 13:  99%|█████████▉| 1760/1770 [07:37<00:03,  2.98it/s, loss=0.158, v_num=7, val_loss=0.0555, val_acc=0.957, train_loss=0.319]\n",
      "Validating:  81%|████████▏ | 44/54 [00:26<00:05,  1.74it/s]\u001b[A\n",
      "Epoch 13: 100%|█████████▉| 1762/1770 [07:38<00:02,  2.97it/s, loss=0.158, v_num=7, val_loss=0.0555, val_acc=0.957, train_loss=0.319]\n",
      "Validating:  85%|████████▌ | 46/54 [00:27<00:04,  1.77it/s]\u001b[A\n",
      "Epoch 13: 100%|█████████▉| 1764/1770 [07:39<00:02,  2.97it/s, loss=0.158, v_num=7, val_loss=0.0555, val_acc=0.957, train_loss=0.319]\n",
      "Validating:  89%|████████▉ | 48/54 [00:29<00:03,  1.78it/s]\u001b[A\n",
      "Epoch 13: 100%|█████████▉| 1766/1770 [07:40<00:01,  2.97it/s, loss=0.158, v_num=7, val_loss=0.0555, val_acc=0.957, train_loss=0.319]\n",
      "Validating:  93%|█████████▎| 50/54 [00:30<00:02,  1.79it/s]\u001b[A\n",
      "Epoch 13: 100%|█████████▉| 1768/1770 [07:41<00:00,  2.97it/s, loss=0.158, v_num=7, val_loss=0.0555, val_acc=0.957, train_loss=0.319]\n",
      "Validating:  96%|█████████▋| 52/54 [00:31<00:01,  1.79it/s]\u001b[A\n",
      "Epoch 13: 100%|██████████| 1770/1770 [07:42<00:00,  2.96it/s, loss=0.158, v_num=7, val_loss=0.0555, val_acc=0.957, train_loss=0.319]\n",
      "Validating: 100%|██████████| 54/54 [00:32<00:00,  2.02it/s]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13, step 5577: val_loss was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13: 100%|██████████| 1770/1770 [07:43<00:00,  2.96it/s, loss=0.158, v_num=7, val_loss=0.0568, val_acc=0.956, train_loss=0.0763]\n",
      "Epoch 14:  97%|█████████▋| 1716/1770 [07:11<00:17,  3.05it/s, loss=0.147, v_num=7, val_loss=0.0568, val_acc=0.956, train_loss=0.738]    \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 14:  97%|█████████▋| 1718/1770 [07:14<00:17,  3.04it/s, loss=0.147, v_num=7, val_loss=0.0568, val_acc=0.956, train_loss=0.738]\n",
      "Validating:   4%|▎         | 2/54 [00:03<01:13,  1.41s/it]\u001b[A\n",
      "Epoch 14:  97%|█████████▋| 1720/1770 [07:15<00:16,  3.03it/s, loss=0.147, v_num=7, val_loss=0.0568, val_acc=0.956, train_loss=0.738]\n",
      "Validating:   7%|▋         | 4/54 [00:04<00:43,  1.14it/s]\u001b[A\n",
      "Epoch 14:  97%|█████████▋| 1722/1770 [07:16<00:15,  3.03it/s, loss=0.147, v_num=7, val_loss=0.0568, val_acc=0.956, train_loss=0.738]\n",
      "Validating:  11%|█         | 6/54 [00:05<00:33,  1.42it/s]\u001b[A\n",
      "Epoch 14:  97%|█████████▋| 1724/1770 [07:17<00:15,  3.03it/s, loss=0.147, v_num=7, val_loss=0.0568, val_acc=0.956, train_loss=0.738]\n",
      "Validating:  15%|█▍        | 8/54 [00:06<00:29,  1.58it/s]\u001b[A\n",
      "Epoch 14:  98%|█████████▊| 1726/1770 [07:18<00:14,  3.02it/s, loss=0.147, v_num=7, val_loss=0.0568, val_acc=0.956, train_loss=0.738]\n",
      "Validating:  19%|█▊        | 10/54 [00:07<00:26,  1.66it/s]\u001b[A\n",
      "Epoch 14:  98%|█████████▊| 1728/1770 [07:20<00:13,  3.02it/s, loss=0.147, v_num=7, val_loss=0.0568, val_acc=0.956, train_loss=0.738]\n",
      "Validating:  22%|██▏       | 12/54 [00:08<00:24,  1.70it/s]\u001b[A\n",
      "Epoch 14:  98%|█████████▊| 1730/1770 [07:21<00:13,  3.02it/s, loss=0.147, v_num=7, val_loss=0.0568, val_acc=0.956, train_loss=0.738]\n",
      "Validating:  26%|██▌       | 14/54 [00:10<00:23,  1.72it/s]\u001b[A\n",
      "Epoch 14:  98%|█████████▊| 1732/1770 [07:22<00:12,  3.01it/s, loss=0.147, v_num=7, val_loss=0.0568, val_acc=0.956, train_loss=0.738]\n",
      "Validating:  30%|██▉       | 16/54 [00:11<00:21,  1.73it/s]\u001b[A\n",
      "Epoch 14:  98%|█████████▊| 1734/1770 [07:23<00:11,  3.01it/s, loss=0.147, v_num=7, val_loss=0.0568, val_acc=0.956, train_loss=0.738]\n",
      "Validating:  33%|███▎      | 18/54 [00:12<00:20,  1.73it/s]\u001b[A\n",
      "Epoch 14:  98%|█████████▊| 1736/1770 [07:24<00:11,  3.01it/s, loss=0.147, v_num=7, val_loss=0.0568, val_acc=0.956, train_loss=0.738]\n",
      "Validating:  37%|███▋      | 20/54 [00:13<00:19,  1.74it/s]\u001b[A\n",
      "Epoch 14:  98%|█████████▊| 1738/1770 [07:25<00:10,  3.00it/s, loss=0.147, v_num=7, val_loss=0.0568, val_acc=0.956, train_loss=0.738]\n",
      "Validating:  41%|████      | 22/54 [00:14<00:18,  1.74it/s]\u001b[A\n",
      "Epoch 14:  98%|█████████▊| 1740/1770 [07:26<00:09,  3.00it/s, loss=0.147, v_num=7, val_loss=0.0568, val_acc=0.956, train_loss=0.738]\n",
      "Validating:  44%|████▍     | 24/54 [00:15<00:17,  1.73it/s]\u001b[A\n",
      "Epoch 14:  98%|█████████▊| 1742/1770 [07:28<00:09,  3.00it/s, loss=0.147, v_num=7, val_loss=0.0568, val_acc=0.956, train_loss=0.738]\n",
      "Validating:  48%|████▊     | 26/54 [00:17<00:16,  1.73it/s]\u001b[A\n",
      "Epoch 14:  99%|█████████▊| 1744/1770 [07:29<00:08,  2.99it/s, loss=0.147, v_num=7, val_loss=0.0568, val_acc=0.956, train_loss=0.738]\n",
      "Validating:  52%|█████▏    | 28/54 [00:18<00:15,  1.73it/s]\u001b[A\n",
      "Epoch 14:  99%|█████████▊| 1746/1770 [07:30<00:08,  2.99it/s, loss=0.147, v_num=7, val_loss=0.0568, val_acc=0.956, train_loss=0.738]\n",
      "Validating:  56%|█████▌    | 30/54 [00:19<00:13,  1.73it/s]\u001b[A\n",
      "Epoch 14:  99%|█████████▉| 1748/1770 [07:31<00:07,  2.99it/s, loss=0.147, v_num=7, val_loss=0.0568, val_acc=0.956, train_loss=0.738]\n",
      "Validating:  59%|█████▉    | 32/54 [00:20<00:12,  1.74it/s]\u001b[A\n",
      "Epoch 14:  99%|█████████▉| 1750/1770 [07:32<00:06,  2.98it/s, loss=0.147, v_num=7, val_loss=0.0568, val_acc=0.956, train_loss=0.738]\n",
      "Validating:  63%|██████▎   | 34/54 [00:21<00:11,  1.74it/s]\u001b[A\n",
      "Epoch 14:  99%|█████████▉| 1752/1770 [07:33<00:06,  2.98it/s, loss=0.147, v_num=7, val_loss=0.0568, val_acc=0.956, train_loss=0.738]\n",
      "Validating:  67%|██████▋   | 36/54 [00:22<00:10,  1.74it/s]\u001b[A\n",
      "Epoch 14:  99%|█████████▉| 1754/1770 [07:35<00:05,  2.98it/s, loss=0.147, v_num=7, val_loss=0.0568, val_acc=0.956, train_loss=0.738]\n",
      "Validating:  70%|███████   | 38/54 [00:23<00:09,  1.73it/s]\u001b[A\n",
      "Epoch 14:  99%|█████████▉| 1756/1770 [07:36<00:04,  2.97it/s, loss=0.147, v_num=7, val_loss=0.0568, val_acc=0.956, train_loss=0.738]\n",
      "Validating:  74%|███████▍  | 40/54 [00:25<00:08,  1.74it/s]\u001b[A\n",
      "Epoch 14:  99%|█████████▉| 1758/1770 [07:37<00:04,  2.97it/s, loss=0.147, v_num=7, val_loss=0.0568, val_acc=0.956, train_loss=0.738]\n",
      "Validating:  78%|███████▊  | 42/54 [00:26<00:06,  1.74it/s]\u001b[A\n",
      "Epoch 14:  99%|█████████▉| 1760/1770 [07:38<00:03,  2.97it/s, loss=0.147, v_num=7, val_loss=0.0568, val_acc=0.956, train_loss=0.738]\n",
      "Validating:  81%|████████▏ | 44/54 [00:27<00:05,  1.73it/s]\u001b[A\n",
      "Epoch 14: 100%|█████████▉| 1762/1770 [07:39<00:02,  2.97it/s, loss=0.147, v_num=7, val_loss=0.0568, val_acc=0.956, train_loss=0.738]\n",
      "Validating:  85%|████████▌ | 46/54 [00:28<00:04,  1.75it/s]\u001b[A\n",
      "Epoch 14: 100%|█████████▉| 1764/1770 [07:40<00:02,  2.96it/s, loss=0.147, v_num=7, val_loss=0.0568, val_acc=0.956, train_loss=0.738]\n",
      "Validating:  89%|████████▉ | 48/54 [00:29<00:03,  1.77it/s]\u001b[A\n",
      "Epoch 14: 100%|█████████▉| 1766/1770 [07:41<00:01,  2.96it/s, loss=0.147, v_num=7, val_loss=0.0568, val_acc=0.956, train_loss=0.738]\n",
      "Validating:  93%|█████████▎| 50/54 [00:30<00:02,  1.78it/s]\u001b[A\n",
      "Epoch 14: 100%|█████████▉| 1768/1770 [07:42<00:00,  2.96it/s, loss=0.147, v_num=7, val_loss=0.0568, val_acc=0.956, train_loss=0.738]\n",
      "Validating:  96%|█████████▋| 52/54 [00:31<00:01,  1.79it/s]\u001b[A\n",
      "Epoch 14: 100%|██████████| 1770/1770 [07:44<00:00,  2.95it/s, loss=0.147, v_num=7, val_loss=0.0568, val_acc=0.956, train_loss=0.738]\n",
      "Validating: 100%|██████████| 54/54 [00:32<00:00,  2.02it/s]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14, step 6006: val_loss was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14: 100%|██████████| 1770/1770 [07:44<00:00,  2.95it/s, loss=0.147, v_num=7, val_loss=0.0586, val_acc=0.95, train_loss=0.379] \n",
      "                                                           \u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: None, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training fold 2\n",
      "Class sample counts [ 676 1381 1481 8725 1463]\n",
      "After class sample counts [2028 2762 3406 8725 3950]\n",
      "conv_stem.weight True\n",
      "bn1.weight False\n",
      "bn1.bias False\n",
      "blocks.0.0.conv_dw.weight True\n",
      "blocks.0.0.bn1.weight False\n",
      "blocks.0.0.bn1.bias False\n",
      "blocks.0.0.se.conv_reduce.weight True\n",
      "blocks.0.0.se.conv_reduce.bias True\n",
      "blocks.0.0.se.conv_expand.weight True\n",
      "blocks.0.0.se.conv_expand.bias True\n",
      "blocks.0.0.conv_pw.weight True\n",
      "blocks.0.0.bn2.weight False\n",
      "blocks.0.0.bn2.bias False\n",
      "blocks.0.1.conv_dw.weight True\n",
      "blocks.0.1.bn1.weight False\n",
      "blocks.0.1.bn1.bias False\n",
      "blocks.0.1.se.conv_reduce.weight True\n",
      "blocks.0.1.se.conv_reduce.bias True\n",
      "blocks.0.1.se.conv_expand.weight True\n",
      "blocks.0.1.se.conv_expand.bias True\n",
      "blocks.0.1.conv_pw.weight True\n",
      "blocks.0.1.bn2.weight False\n",
      "blocks.0.1.bn2.bias False\n",
      "blocks.1.0.conv_pw.weight True\n",
      "blocks.1.0.bn1.weight False\n",
      "blocks.1.0.bn1.bias False\n",
      "blocks.1.0.conv_dw.weight True\n",
      "blocks.1.0.bn2.weight False\n",
      "blocks.1.0.bn2.bias False\n",
      "blocks.1.0.se.conv_reduce.weight True\n",
      "blocks.1.0.se.conv_reduce.bias True\n",
      "blocks.1.0.se.conv_expand.weight True\n",
      "blocks.1.0.se.conv_expand.bias True\n",
      "blocks.1.0.conv_pwl.weight True\n",
      "blocks.1.0.bn3.weight False\n",
      "blocks.1.0.bn3.bias False\n",
      "blocks.1.1.conv_pw.weight True\n",
      "blocks.1.1.bn1.weight False\n",
      "blocks.1.1.bn1.bias False\n",
      "blocks.1.1.conv_dw.weight True\n",
      "blocks.1.1.bn2.weight False\n",
      "blocks.1.1.bn2.bias False\n",
      "blocks.1.1.se.conv_reduce.weight True\n",
      "blocks.1.1.se.conv_reduce.bias True\n",
      "blocks.1.1.se.conv_expand.weight True\n",
      "blocks.1.1.se.conv_expand.bias True\n",
      "blocks.1.1.conv_pwl.weight True\n",
      "blocks.1.1.bn3.weight False\n",
      "blocks.1.1.bn3.bias False\n",
      "blocks.1.2.conv_pw.weight True\n",
      "blocks.1.2.bn1.weight False\n",
      "blocks.1.2.bn1.bias False\n",
      "blocks.1.2.conv_dw.weight True\n",
      "blocks.1.2.bn2.weight False\n",
      "blocks.1.2.bn2.bias False\n",
      "blocks.1.2.se.conv_reduce.weight True\n",
      "blocks.1.2.se.conv_reduce.bias True\n",
      "blocks.1.2.se.conv_expand.weight True\n",
      "blocks.1.2.se.conv_expand.bias True\n",
      "blocks.1.2.conv_pwl.weight True\n",
      "blocks.1.2.bn3.weight False\n",
      "blocks.1.2.bn3.bias False\n",
      "blocks.1.3.conv_pw.weight True\n",
      "blocks.1.3.bn1.weight False\n",
      "blocks.1.3.bn1.bias False\n",
      "blocks.1.3.conv_dw.weight True\n",
      "blocks.1.3.bn2.weight False\n",
      "blocks.1.3.bn2.bias False\n",
      "blocks.1.3.se.conv_reduce.weight True\n",
      "blocks.1.3.se.conv_reduce.bias True\n",
      "blocks.1.3.se.conv_expand.weight True\n",
      "blocks.1.3.se.conv_expand.bias True\n",
      "blocks.1.3.conv_pwl.weight True\n",
      "blocks.1.3.bn3.weight False\n",
      "blocks.1.3.bn3.bias False\n",
      "blocks.2.0.conv_pw.weight True\n",
      "blocks.2.0.bn1.weight False\n",
      "blocks.2.0.bn1.bias False\n",
      "blocks.2.0.conv_dw.weight True\n",
      "blocks.2.0.bn2.weight False\n",
      "blocks.2.0.bn2.bias False\n",
      "blocks.2.0.se.conv_reduce.weight True\n",
      "blocks.2.0.se.conv_reduce.bias True\n",
      "blocks.2.0.se.conv_expand.weight True\n",
      "blocks.2.0.se.conv_expand.bias True\n",
      "blocks.2.0.conv_pwl.weight True\n",
      "blocks.2.0.bn3.weight False\n",
      "blocks.2.0.bn3.bias False\n",
      "blocks.2.1.conv_pw.weight True\n",
      "blocks.2.1.bn1.weight False\n",
      "blocks.2.1.bn1.bias False\n",
      "blocks.2.1.conv_dw.weight True\n",
      "blocks.2.1.bn2.weight False\n",
      "blocks.2.1.bn2.bias False\n",
      "blocks.2.1.se.conv_reduce.weight True\n",
      "blocks.2.1.se.conv_reduce.bias True\n",
      "blocks.2.1.se.conv_expand.weight True\n",
      "blocks.2.1.se.conv_expand.bias True\n",
      "blocks.2.1.conv_pwl.weight True\n",
      "blocks.2.1.bn3.weight False\n",
      "blocks.2.1.bn3.bias False\n",
      "blocks.2.2.conv_pw.weight True\n",
      "blocks.2.2.bn1.weight False\n",
      "blocks.2.2.bn1.bias False\n",
      "blocks.2.2.conv_dw.weight True\n",
      "blocks.2.2.bn2.weight False\n",
      "blocks.2.2.bn2.bias False\n",
      "blocks.2.2.se.conv_reduce.weight True\n",
      "blocks.2.2.se.conv_reduce.bias True\n",
      "blocks.2.2.se.conv_expand.weight True\n",
      "blocks.2.2.se.conv_expand.bias True\n",
      "blocks.2.2.conv_pwl.weight True\n",
      "blocks.2.2.bn3.weight False\n",
      "blocks.2.2.bn3.bias False\n",
      "blocks.2.3.conv_pw.weight True\n",
      "blocks.2.3.bn1.weight False\n",
      "blocks.2.3.bn1.bias False\n",
      "blocks.2.3.conv_dw.weight True\n",
      "blocks.2.3.bn2.weight False\n",
      "blocks.2.3.bn2.bias False\n",
      "blocks.2.3.se.conv_reduce.weight True\n",
      "blocks.2.3.se.conv_reduce.bias True\n",
      "blocks.2.3.se.conv_expand.weight True\n",
      "blocks.2.3.se.conv_expand.bias True\n",
      "blocks.2.3.conv_pwl.weight True\n",
      "blocks.2.3.bn3.weight False\n",
      "blocks.2.3.bn3.bias False\n",
      "blocks.3.0.conv_pw.weight True\n",
      "blocks.3.0.bn1.weight False\n",
      "blocks.3.0.bn1.bias False\n",
      "blocks.3.0.conv_dw.weight True\n",
      "blocks.3.0.bn2.weight False\n",
      "blocks.3.0.bn2.bias False\n",
      "blocks.3.0.se.conv_reduce.weight True\n",
      "blocks.3.0.se.conv_reduce.bias True\n",
      "blocks.3.0.se.conv_expand.weight True\n",
      "blocks.3.0.se.conv_expand.bias True\n",
      "blocks.3.0.conv_pwl.weight True\n",
      "blocks.3.0.bn3.weight False\n",
      "blocks.3.0.bn3.bias False\n",
      "blocks.3.1.conv_pw.weight True\n",
      "blocks.3.1.bn1.weight False\n",
      "blocks.3.1.bn1.bias False\n",
      "blocks.3.1.conv_dw.weight True\n",
      "blocks.3.1.bn2.weight False\n",
      "blocks.3.1.bn2.bias False\n",
      "blocks.3.1.se.conv_reduce.weight True\n",
      "blocks.3.1.se.conv_reduce.bias True\n",
      "blocks.3.1.se.conv_expand.weight True\n",
      "blocks.3.1.se.conv_expand.bias True\n",
      "blocks.3.1.conv_pwl.weight True\n",
      "blocks.3.1.bn3.weight False\n",
      "blocks.3.1.bn3.bias False\n",
      "blocks.3.2.conv_pw.weight True\n",
      "blocks.3.2.bn1.weight False\n",
      "blocks.3.2.bn1.bias False\n",
      "blocks.3.2.conv_dw.weight True\n",
      "blocks.3.2.bn2.weight False\n",
      "blocks.3.2.bn2.bias False\n",
      "blocks.3.2.se.conv_reduce.weight True\n",
      "blocks.3.2.se.conv_reduce.bias True\n",
      "blocks.3.2.se.conv_expand.weight True\n",
      "blocks.3.2.se.conv_expand.bias True\n",
      "blocks.3.2.conv_pwl.weight True\n",
      "blocks.3.2.bn3.weight False\n",
      "blocks.3.2.bn3.bias False\n",
      "blocks.3.3.conv_pw.weight True\n",
      "blocks.3.3.bn1.weight False\n",
      "blocks.3.3.bn1.bias False\n",
      "blocks.3.3.conv_dw.weight True\n",
      "blocks.3.3.bn2.weight False\n",
      "blocks.3.3.bn2.bias False\n",
      "blocks.3.3.se.conv_reduce.weight True\n",
      "blocks.3.3.se.conv_reduce.bias True\n",
      "blocks.3.3.se.conv_expand.weight True\n",
      "blocks.3.3.se.conv_expand.bias True\n",
      "blocks.3.3.conv_pwl.weight True\n",
      "blocks.3.3.bn3.weight False\n",
      "blocks.3.3.bn3.bias False\n",
      "blocks.3.4.conv_pw.weight True\n",
      "blocks.3.4.bn1.weight False\n",
      "blocks.3.4.bn1.bias False\n",
      "blocks.3.4.conv_dw.weight True\n",
      "blocks.3.4.bn2.weight False\n",
      "blocks.3.4.bn2.bias False\n",
      "blocks.3.4.se.conv_reduce.weight True\n",
      "blocks.3.4.se.conv_reduce.bias True\n",
      "blocks.3.4.se.conv_expand.weight True\n",
      "blocks.3.4.se.conv_expand.bias True\n",
      "blocks.3.4.conv_pwl.weight True\n",
      "blocks.3.4.bn3.weight False\n",
      "blocks.3.4.bn3.bias False\n",
      "blocks.3.5.conv_pw.weight True\n",
      "blocks.3.5.bn1.weight False\n",
      "blocks.3.5.bn1.bias False\n",
      "blocks.3.5.conv_dw.weight True\n",
      "blocks.3.5.bn2.weight False\n",
      "blocks.3.5.bn2.bias False\n",
      "blocks.3.5.se.conv_reduce.weight True\n",
      "blocks.3.5.se.conv_reduce.bias True\n",
      "blocks.3.5.se.conv_expand.weight True\n",
      "blocks.3.5.se.conv_expand.bias True\n",
      "blocks.3.5.conv_pwl.weight True\n",
      "blocks.3.5.bn3.weight False\n",
      "blocks.3.5.bn3.bias False\n",
      "blocks.4.0.conv_pw.weight True\n",
      "blocks.4.0.bn1.weight False\n",
      "blocks.4.0.bn1.bias False\n",
      "blocks.4.0.conv_dw.weight True\n",
      "blocks.4.0.bn2.weight False\n",
      "blocks.4.0.bn2.bias False\n",
      "blocks.4.0.se.conv_reduce.weight True\n",
      "blocks.4.0.se.conv_reduce.bias True\n",
      "blocks.4.0.se.conv_expand.weight True\n",
      "blocks.4.0.se.conv_expand.bias True\n",
      "blocks.4.0.conv_pwl.weight True\n",
      "blocks.4.0.bn3.weight False\n",
      "blocks.4.0.bn3.bias False\n",
      "blocks.4.1.conv_pw.weight True\n",
      "blocks.4.1.bn1.weight False\n",
      "blocks.4.1.bn1.bias False\n",
      "blocks.4.1.conv_dw.weight True\n",
      "blocks.4.1.bn2.weight False\n",
      "blocks.4.1.bn2.bias False\n",
      "blocks.4.1.se.conv_reduce.weight True\n",
      "blocks.4.1.se.conv_reduce.bias True\n",
      "blocks.4.1.se.conv_expand.weight True\n",
      "blocks.4.1.se.conv_expand.bias True\n",
      "blocks.4.1.conv_pwl.weight True\n",
      "blocks.4.1.bn3.weight False\n",
      "blocks.4.1.bn3.bias False\n",
      "blocks.4.2.conv_pw.weight True\n",
      "blocks.4.2.bn1.weight False\n",
      "blocks.4.2.bn1.bias False\n",
      "blocks.4.2.conv_dw.weight True\n",
      "blocks.4.2.bn2.weight False\n",
      "blocks.4.2.bn2.bias False\n",
      "blocks.4.2.se.conv_reduce.weight True\n",
      "blocks.4.2.se.conv_reduce.bias True\n",
      "blocks.4.2.se.conv_expand.weight True\n",
      "blocks.4.2.se.conv_expand.bias True\n",
      "blocks.4.2.conv_pwl.weight True\n",
      "blocks.4.2.bn3.weight False\n",
      "blocks.4.2.bn3.bias False\n",
      "blocks.4.3.conv_pw.weight True\n",
      "blocks.4.3.bn1.weight False\n",
      "blocks.4.3.bn1.bias False\n",
      "blocks.4.3.conv_dw.weight True\n",
      "blocks.4.3.bn2.weight False\n",
      "blocks.4.3.bn2.bias False\n",
      "blocks.4.3.se.conv_reduce.weight True\n",
      "blocks.4.3.se.conv_reduce.bias True\n",
      "blocks.4.3.se.conv_expand.weight True\n",
      "blocks.4.3.se.conv_expand.bias True\n",
      "blocks.4.3.conv_pwl.weight True\n",
      "blocks.4.3.bn3.weight False\n",
      "blocks.4.3.bn3.bias False\n",
      "blocks.4.4.conv_pw.weight True\n",
      "blocks.4.4.bn1.weight False\n",
      "blocks.4.4.bn1.bias False\n",
      "blocks.4.4.conv_dw.weight True\n",
      "blocks.4.4.bn2.weight False\n",
      "blocks.4.4.bn2.bias False\n",
      "blocks.4.4.se.conv_reduce.weight True\n",
      "blocks.4.4.se.conv_reduce.bias True\n",
      "blocks.4.4.se.conv_expand.weight True\n",
      "blocks.4.4.se.conv_expand.bias True\n",
      "blocks.4.4.conv_pwl.weight True\n",
      "blocks.4.4.bn3.weight False\n",
      "blocks.4.4.bn3.bias False\n",
      "blocks.4.5.conv_pw.weight True\n",
      "blocks.4.5.bn1.weight False\n",
      "blocks.4.5.bn1.bias False\n",
      "blocks.4.5.conv_dw.weight True\n",
      "blocks.4.5.bn2.weight False\n",
      "blocks.4.5.bn2.bias False\n",
      "blocks.4.5.se.conv_reduce.weight True\n",
      "blocks.4.5.se.conv_reduce.bias True\n",
      "blocks.4.5.se.conv_expand.weight True\n",
      "blocks.4.5.se.conv_expand.bias True\n",
      "blocks.4.5.conv_pwl.weight True\n",
      "blocks.4.5.bn3.weight False\n",
      "blocks.4.5.bn3.bias False\n",
      "blocks.5.0.conv_pw.weight True\n",
      "blocks.5.0.bn1.weight False\n",
      "blocks.5.0.bn1.bias False\n",
      "blocks.5.0.conv_dw.weight True\n",
      "blocks.5.0.bn2.weight False\n",
      "blocks.5.0.bn2.bias False\n",
      "blocks.5.0.se.conv_reduce.weight True\n",
      "blocks.5.0.se.conv_reduce.bias True\n",
      "blocks.5.0.se.conv_expand.weight True\n",
      "blocks.5.0.se.conv_expand.bias True\n",
      "blocks.5.0.conv_pwl.weight True\n",
      "blocks.5.0.bn3.weight False\n",
      "blocks.5.0.bn3.bias False\n",
      "blocks.5.1.conv_pw.weight True\n",
      "blocks.5.1.bn1.weight False\n",
      "blocks.5.1.bn1.bias False\n",
      "blocks.5.1.conv_dw.weight True\n",
      "blocks.5.1.bn2.weight False\n",
      "blocks.5.1.bn2.bias False\n",
      "blocks.5.1.se.conv_reduce.weight True\n",
      "blocks.5.1.se.conv_reduce.bias True\n",
      "blocks.5.1.se.conv_expand.weight True\n",
      "blocks.5.1.se.conv_expand.bias True\n",
      "blocks.5.1.conv_pwl.weight True\n",
      "blocks.5.1.bn3.weight False\n",
      "blocks.5.1.bn3.bias False\n",
      "blocks.5.2.conv_pw.weight True\n",
      "blocks.5.2.bn1.weight False\n",
      "blocks.5.2.bn1.bias False\n",
      "blocks.5.2.conv_dw.weight True\n",
      "blocks.5.2.bn2.weight False\n",
      "blocks.5.2.bn2.bias False\n",
      "blocks.5.2.se.conv_reduce.weight True\n",
      "blocks.5.2.se.conv_reduce.bias True\n",
      "blocks.5.2.se.conv_expand.weight True\n",
      "blocks.5.2.se.conv_expand.bias True\n",
      "blocks.5.2.conv_pwl.weight True\n",
      "blocks.5.2.bn3.weight False\n",
      "blocks.5.2.bn3.bias False\n",
      "blocks.5.3.conv_pw.weight True\n",
      "blocks.5.3.bn1.weight False\n",
      "blocks.5.3.bn1.bias False\n",
      "blocks.5.3.conv_dw.weight True\n",
      "blocks.5.3.bn2.weight False\n",
      "blocks.5.3.bn2.bias False\n",
      "blocks.5.3.se.conv_reduce.weight True\n",
      "blocks.5.3.se.conv_reduce.bias True\n",
      "blocks.5.3.se.conv_expand.weight True\n",
      "blocks.5.3.se.conv_expand.bias True\n",
      "blocks.5.3.conv_pwl.weight True\n",
      "blocks.5.3.bn3.weight False\n",
      "blocks.5.3.bn3.bias False\n",
      "blocks.5.4.conv_pw.weight True\n",
      "blocks.5.4.bn1.weight False\n",
      "blocks.5.4.bn1.bias False\n",
      "blocks.5.4.conv_dw.weight True\n",
      "blocks.5.4.bn2.weight False\n",
      "blocks.5.4.bn2.bias False\n",
      "blocks.5.4.se.conv_reduce.weight True\n",
      "blocks.5.4.se.conv_reduce.bias True\n",
      "blocks.5.4.se.conv_expand.weight True\n",
      "blocks.5.4.se.conv_expand.bias True\n",
      "blocks.5.4.conv_pwl.weight True\n",
      "blocks.5.4.bn3.weight False\n",
      "blocks.5.4.bn3.bias False\n",
      "blocks.5.5.conv_pw.weight True\n",
      "blocks.5.5.bn1.weight False\n",
      "blocks.5.5.bn1.bias False\n",
      "blocks.5.5.conv_dw.weight True\n",
      "blocks.5.5.bn2.weight False\n",
      "blocks.5.5.bn2.bias False\n",
      "blocks.5.5.se.conv_reduce.weight True\n",
      "blocks.5.5.se.conv_reduce.bias True\n",
      "blocks.5.5.se.conv_expand.weight True\n",
      "blocks.5.5.se.conv_expand.bias True\n",
      "blocks.5.5.conv_pwl.weight True\n",
      "blocks.5.5.bn3.weight False\n",
      "blocks.5.5.bn3.bias False\n",
      "blocks.5.6.conv_pw.weight True\n",
      "blocks.5.6.bn1.weight False\n",
      "blocks.5.6.bn1.bias False\n",
      "blocks.5.6.conv_dw.weight True\n",
      "blocks.5.6.bn2.weight False\n",
      "blocks.5.6.bn2.bias False\n",
      "blocks.5.6.se.conv_reduce.weight True\n",
      "blocks.5.6.se.conv_reduce.bias True\n",
      "blocks.5.6.se.conv_expand.weight True\n",
      "blocks.5.6.se.conv_expand.bias True\n",
      "blocks.5.6.conv_pwl.weight True\n",
      "blocks.5.6.bn3.weight False\n",
      "blocks.5.6.bn3.bias False\n",
      "blocks.5.7.conv_pw.weight True\n",
      "blocks.5.7.bn1.weight False\n",
      "blocks.5.7.bn1.bias False\n",
      "blocks.5.7.conv_dw.weight True\n",
      "blocks.5.7.bn2.weight False\n",
      "blocks.5.7.bn2.bias False\n",
      "blocks.5.7.se.conv_reduce.weight True\n",
      "blocks.5.7.se.conv_reduce.bias True\n",
      "blocks.5.7.se.conv_expand.weight True\n",
      "blocks.5.7.se.conv_expand.bias True\n",
      "blocks.5.7.conv_pwl.weight True\n",
      "blocks.5.7.bn3.weight False\n",
      "blocks.5.7.bn3.bias False\n",
      "blocks.6.0.conv_pw.weight True\n",
      "blocks.6.0.bn1.weight False\n",
      "blocks.6.0.bn1.bias False\n",
      "blocks.6.0.conv_dw.weight True\n",
      "blocks.6.0.bn2.weight False\n",
      "blocks.6.0.bn2.bias False\n",
      "blocks.6.0.se.conv_reduce.weight True\n",
      "blocks.6.0.se.conv_reduce.bias True\n",
      "blocks.6.0.se.conv_expand.weight True\n",
      "blocks.6.0.se.conv_expand.bias True\n",
      "blocks.6.0.conv_pwl.weight True\n",
      "blocks.6.0.bn3.weight False\n",
      "blocks.6.0.bn3.bias False\n",
      "blocks.6.1.conv_pw.weight True\n",
      "blocks.6.1.bn1.weight False\n",
      "blocks.6.1.bn1.bias False\n",
      "blocks.6.1.conv_dw.weight True\n",
      "blocks.6.1.bn2.weight False\n",
      "blocks.6.1.bn2.bias False\n",
      "blocks.6.1.se.conv_reduce.weight True\n",
      "blocks.6.1.se.conv_reduce.bias True\n",
      "blocks.6.1.se.conv_expand.weight True\n",
      "blocks.6.1.se.conv_expand.bias True\n",
      "blocks.6.1.conv_pwl.weight True\n",
      "blocks.6.1.bn3.weight False\n",
      "blocks.6.1.bn3.bias False\n",
      "conv_head.weight True\n",
      "bn2.weight False\n",
      "bn2.bias False\n",
      "classifier.weight True\n",
      "classifier.bias True\n",
      "EfficientNet(\n",
      "  (conv_stem): Conv2dSame(3, 48, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
      "  (bn1): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (act1): SiLU(inplace=True)\n",
      "  (blocks): Sequential(\n",
      "    (0): Sequential(\n",
      "      (0): DepthwiseSeparableConv(\n",
      "        (conv_dw): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=48, bias=False)\n",
      "        (bn1): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act1): SiLU(inplace=True)\n",
      "        (se): SqueezeExcite(\n",
      "          (conv_reduce): Conv2d(48, 12, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (act1): SiLU(inplace=True)\n",
      "          (conv_expand): Conv2d(12, 48, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "        (conv_pw): Conv2d(48, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(24, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act2): Identity()\n",
      "      )\n",
      "      (1): DepthwiseSeparableConv(\n",
      "        (conv_dw): Conv2d(24, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=24, bias=False)\n",
      "        (bn1): BatchNorm2d(24, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act1): SiLU(inplace=True)\n",
      "        (se): SqueezeExcite(\n",
      "          (conv_reduce): Conv2d(24, 6, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (act1): SiLU(inplace=True)\n",
      "          (conv_expand): Conv2d(6, 24, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "        (conv_pw): Conv2d(24, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(24, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act2): Identity()\n",
      "      )\n",
      "    )\n",
      "    (1): Sequential(\n",
      "      (0): InvertedResidual(\n",
      "        (conv_pw): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(144, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act1): SiLU(inplace=True)\n",
      "        (conv_dw): Conv2dSame(144, 144, kernel_size=(3, 3), stride=(2, 2), groups=144, bias=False)\n",
      "        (bn2): BatchNorm2d(144, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act2): SiLU(inplace=True)\n",
      "        (se): SqueezeExcite(\n",
      "          (conv_reduce): Conv2d(144, 6, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (act1): SiLU(inplace=True)\n",
      "          (conv_expand): Conv2d(6, 144, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "        (conv_pwl): Conv2d(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (1): InvertedResidual(\n",
      "        (conv_pw): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act1): SiLU(inplace=True)\n",
      "        (conv_dw): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
      "        (bn2): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act2): SiLU(inplace=True)\n",
      "        (se): SqueezeExcite(\n",
      "          (conv_reduce): Conv2d(192, 8, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (act1): SiLU(inplace=True)\n",
      "          (conv_expand): Conv2d(8, 192, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "        (conv_pwl): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (2): InvertedResidual(\n",
      "        (conv_pw): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act1): SiLU(inplace=True)\n",
      "        (conv_dw): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
      "        (bn2): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act2): SiLU(inplace=True)\n",
      "        (se): SqueezeExcite(\n",
      "          (conv_reduce): Conv2d(192, 8, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (act1): SiLU(inplace=True)\n",
      "          (conv_expand): Conv2d(8, 192, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "        (conv_pwl): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (3): InvertedResidual(\n",
      "        (conv_pw): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act1): SiLU(inplace=True)\n",
      "        (conv_dw): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
      "        (bn2): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act2): SiLU(inplace=True)\n",
      "        (se): SqueezeExcite(\n",
      "          (conv_reduce): Conv2d(192, 8, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (act1): SiLU(inplace=True)\n",
      "          (conv_expand): Conv2d(8, 192, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "        (conv_pwl): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (2): Sequential(\n",
      "      (0): InvertedResidual(\n",
      "        (conv_pw): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act1): SiLU(inplace=True)\n",
      "        (conv_dw): Conv2dSame(192, 192, kernel_size=(5, 5), stride=(2, 2), groups=192, bias=False)\n",
      "        (bn2): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act2): SiLU(inplace=True)\n",
      "        (se): SqueezeExcite(\n",
      "          (conv_reduce): Conv2d(192, 8, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (act1): SiLU(inplace=True)\n",
      "          (conv_expand): Conv2d(8, 192, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "        (conv_pwl): Conv2d(192, 56, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(56, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (1): InvertedResidual(\n",
      "        (conv_pw): Conv2d(56, 336, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(336, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act1): SiLU(inplace=True)\n",
      "        (conv_dw): Conv2d(336, 336, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=336, bias=False)\n",
      "        (bn2): BatchNorm2d(336, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act2): SiLU(inplace=True)\n",
      "        (se): SqueezeExcite(\n",
      "          (conv_reduce): Conv2d(336, 14, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (act1): SiLU(inplace=True)\n",
      "          (conv_expand): Conv2d(14, 336, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "        (conv_pwl): Conv2d(336, 56, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(56, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (2): InvertedResidual(\n",
      "        (conv_pw): Conv2d(56, 336, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(336, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act1): SiLU(inplace=True)\n",
      "        (conv_dw): Conv2d(336, 336, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=336, bias=False)\n",
      "        (bn2): BatchNorm2d(336, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act2): SiLU(inplace=True)\n",
      "        (se): SqueezeExcite(\n",
      "          (conv_reduce): Conv2d(336, 14, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (act1): SiLU(inplace=True)\n",
      "          (conv_expand): Conv2d(14, 336, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "        (conv_pwl): Conv2d(336, 56, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(56, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (3): InvertedResidual(\n",
      "        (conv_pw): Conv2d(56, 336, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(336, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act1): SiLU(inplace=True)\n",
      "        (conv_dw): Conv2d(336, 336, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=336, bias=False)\n",
      "        (bn2): BatchNorm2d(336, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act2): SiLU(inplace=True)\n",
      "        (se): SqueezeExcite(\n",
      "          (conv_reduce): Conv2d(336, 14, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (act1): SiLU(inplace=True)\n",
      "          (conv_expand): Conv2d(14, 336, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "        (conv_pwl): Conv2d(336, 56, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(56, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (3): Sequential(\n",
      "      (0): InvertedResidual(\n",
      "        (conv_pw): Conv2d(56, 336, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(336, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act1): SiLU(inplace=True)\n",
      "        (conv_dw): Conv2dSame(336, 336, kernel_size=(3, 3), stride=(2, 2), groups=336, bias=False)\n",
      "        (bn2): BatchNorm2d(336, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act2): SiLU(inplace=True)\n",
      "        (se): SqueezeExcite(\n",
      "          (conv_reduce): Conv2d(336, 14, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (act1): SiLU(inplace=True)\n",
      "          (conv_expand): Conv2d(14, 336, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "        (conv_pwl): Conv2d(336, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(112, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (1): InvertedResidual(\n",
      "        (conv_pw): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act1): SiLU(inplace=True)\n",
      "        (conv_dw): Conv2d(672, 672, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=672, bias=False)\n",
      "        (bn2): BatchNorm2d(672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act2): SiLU(inplace=True)\n",
      "        (se): SqueezeExcite(\n",
      "          (conv_reduce): Conv2d(672, 28, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (act1): SiLU(inplace=True)\n",
      "          (conv_expand): Conv2d(28, 672, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "        (conv_pwl): Conv2d(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(112, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (2): InvertedResidual(\n",
      "        (conv_pw): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act1): SiLU(inplace=True)\n",
      "        (conv_dw): Conv2d(672, 672, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=672, bias=False)\n",
      "        (bn2): BatchNorm2d(672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act2): SiLU(inplace=True)\n",
      "        (se): SqueezeExcite(\n",
      "          (conv_reduce): Conv2d(672, 28, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (act1): SiLU(inplace=True)\n",
      "          (conv_expand): Conv2d(28, 672, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "        (conv_pwl): Conv2d(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(112, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (3): InvertedResidual(\n",
      "        (conv_pw): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act1): SiLU(inplace=True)\n",
      "        (conv_dw): Conv2d(672, 672, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=672, bias=False)\n",
      "        (bn2): BatchNorm2d(672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act2): SiLU(inplace=True)\n",
      "        (se): SqueezeExcite(\n",
      "          (conv_reduce): Conv2d(672, 28, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (act1): SiLU(inplace=True)\n",
      "          (conv_expand): Conv2d(28, 672, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "        (conv_pwl): Conv2d(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(112, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (4): InvertedResidual(\n",
      "        (conv_pw): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act1): SiLU(inplace=True)\n",
      "        (conv_dw): Conv2d(672, 672, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=672, bias=False)\n",
      "        (bn2): BatchNorm2d(672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act2): SiLU(inplace=True)\n",
      "        (se): SqueezeExcite(\n",
      "          (conv_reduce): Conv2d(672, 28, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (act1): SiLU(inplace=True)\n",
      "          (conv_expand): Conv2d(28, 672, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "        (conv_pwl): Conv2d(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(112, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (5): InvertedResidual(\n",
      "        (conv_pw): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act1): SiLU(inplace=True)\n",
      "        (conv_dw): Conv2d(672, 672, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=672, bias=False)\n",
      "        (bn2): BatchNorm2d(672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act2): SiLU(inplace=True)\n",
      "        (se): SqueezeExcite(\n",
      "          (conv_reduce): Conv2d(672, 28, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (act1): SiLU(inplace=True)\n",
      "          (conv_expand): Conv2d(28, 672, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "        (conv_pwl): Conv2d(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(112, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (4): Sequential(\n",
      "      (0): InvertedResidual(\n",
      "        (conv_pw): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act1): SiLU(inplace=True)\n",
      "        (conv_dw): Conv2d(672, 672, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=672, bias=False)\n",
      "        (bn2): BatchNorm2d(672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act2): SiLU(inplace=True)\n",
      "        (se): SqueezeExcite(\n",
      "          (conv_reduce): Conv2d(672, 28, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (act1): SiLU(inplace=True)\n",
      "          (conv_expand): Conv2d(28, 672, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "        (conv_pwl): Conv2d(672, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (1): InvertedResidual(\n",
      "        (conv_pw): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(960, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act1): SiLU(inplace=True)\n",
      "        (conv_dw): Conv2d(960, 960, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=960, bias=False)\n",
      "        (bn2): BatchNorm2d(960, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act2): SiLU(inplace=True)\n",
      "        (se): SqueezeExcite(\n",
      "          (conv_reduce): Conv2d(960, 40, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (act1): SiLU(inplace=True)\n",
      "          (conv_expand): Conv2d(40, 960, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "        (conv_pwl): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (2): InvertedResidual(\n",
      "        (conv_pw): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(960, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act1): SiLU(inplace=True)\n",
      "        (conv_dw): Conv2d(960, 960, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=960, bias=False)\n",
      "        (bn2): BatchNorm2d(960, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act2): SiLU(inplace=True)\n",
      "        (se): SqueezeExcite(\n",
      "          (conv_reduce): Conv2d(960, 40, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (act1): SiLU(inplace=True)\n",
      "          (conv_expand): Conv2d(40, 960, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "        (conv_pwl): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (3): InvertedResidual(\n",
      "        (conv_pw): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(960, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act1): SiLU(inplace=True)\n",
      "        (conv_dw): Conv2d(960, 960, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=960, bias=False)\n",
      "        (bn2): BatchNorm2d(960, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act2): SiLU(inplace=True)\n",
      "        (se): SqueezeExcite(\n",
      "          (conv_reduce): Conv2d(960, 40, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (act1): SiLU(inplace=True)\n",
      "          (conv_expand): Conv2d(40, 960, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "        (conv_pwl): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (4): InvertedResidual(\n",
      "        (conv_pw): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(960, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act1): SiLU(inplace=True)\n",
      "        (conv_dw): Conv2d(960, 960, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=960, bias=False)\n",
      "        (bn2): BatchNorm2d(960, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act2): SiLU(inplace=True)\n",
      "        (se): SqueezeExcite(\n",
      "          (conv_reduce): Conv2d(960, 40, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (act1): SiLU(inplace=True)\n",
      "          (conv_expand): Conv2d(40, 960, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "        (conv_pwl): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (5): InvertedResidual(\n",
      "        (conv_pw): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(960, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act1): SiLU(inplace=True)\n",
      "        (conv_dw): Conv2d(960, 960, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=960, bias=False)\n",
      "        (bn2): BatchNorm2d(960, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act2): SiLU(inplace=True)\n",
      "        (se): SqueezeExcite(\n",
      "          (conv_reduce): Conv2d(960, 40, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (act1): SiLU(inplace=True)\n",
      "          (conv_expand): Conv2d(40, 960, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "        (conv_pwl): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (5): Sequential(\n",
      "      (0): InvertedResidual(\n",
      "        (conv_pw): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(960, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act1): SiLU(inplace=True)\n",
      "        (conv_dw): Conv2dSame(960, 960, kernel_size=(5, 5), stride=(2, 2), groups=960, bias=False)\n",
      "        (bn2): BatchNorm2d(960, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act2): SiLU(inplace=True)\n",
      "        (se): SqueezeExcite(\n",
      "          (conv_reduce): Conv2d(960, 40, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (act1): SiLU(inplace=True)\n",
      "          (conv_expand): Conv2d(40, 960, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "        (conv_pwl): Conv2d(960, 272, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(272, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (1): InvertedResidual(\n",
      "        (conv_pw): Conv2d(272, 1632, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(1632, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act1): SiLU(inplace=True)\n",
      "        (conv_dw): Conv2d(1632, 1632, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1632, bias=False)\n",
      "        (bn2): BatchNorm2d(1632, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act2): SiLU(inplace=True)\n",
      "        (se): SqueezeExcite(\n",
      "          (conv_reduce): Conv2d(1632, 68, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (act1): SiLU(inplace=True)\n",
      "          (conv_expand): Conv2d(68, 1632, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "        (conv_pwl): Conv2d(1632, 272, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(272, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (2): InvertedResidual(\n",
      "        (conv_pw): Conv2d(272, 1632, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(1632, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act1): SiLU(inplace=True)\n",
      "        (conv_dw): Conv2d(1632, 1632, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1632, bias=False)\n",
      "        (bn2): BatchNorm2d(1632, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act2): SiLU(inplace=True)\n",
      "        (se): SqueezeExcite(\n",
      "          (conv_reduce): Conv2d(1632, 68, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (act1): SiLU(inplace=True)\n",
      "          (conv_expand): Conv2d(68, 1632, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "        (conv_pwl): Conv2d(1632, 272, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(272, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (3): InvertedResidual(\n",
      "        (conv_pw): Conv2d(272, 1632, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(1632, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act1): SiLU(inplace=True)\n",
      "        (conv_dw): Conv2d(1632, 1632, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1632, bias=False)\n",
      "        (bn2): BatchNorm2d(1632, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act2): SiLU(inplace=True)\n",
      "        (se): SqueezeExcite(\n",
      "          (conv_reduce): Conv2d(1632, 68, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (act1): SiLU(inplace=True)\n",
      "          (conv_expand): Conv2d(68, 1632, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "        (conv_pwl): Conv2d(1632, 272, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(272, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (4): InvertedResidual(\n",
      "        (conv_pw): Conv2d(272, 1632, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(1632, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act1): SiLU(inplace=True)\n",
      "        (conv_dw): Conv2d(1632, 1632, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1632, bias=False)\n",
      "        (bn2): BatchNorm2d(1632, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act2): SiLU(inplace=True)\n",
      "        (se): SqueezeExcite(\n",
      "          (conv_reduce): Conv2d(1632, 68, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (act1): SiLU(inplace=True)\n",
      "          (conv_expand): Conv2d(68, 1632, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "        (conv_pwl): Conv2d(1632, 272, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(272, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (5): InvertedResidual(\n",
      "        (conv_pw): Conv2d(272, 1632, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(1632, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act1): SiLU(inplace=True)\n",
      "        (conv_dw): Conv2d(1632, 1632, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1632, bias=False)\n",
      "        (bn2): BatchNorm2d(1632, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act2): SiLU(inplace=True)\n",
      "        (se): SqueezeExcite(\n",
      "          (conv_reduce): Conv2d(1632, 68, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (act1): SiLU(inplace=True)\n",
      "          (conv_expand): Conv2d(68, 1632, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "        (conv_pwl): Conv2d(1632, 272, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(272, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (6): InvertedResidual(\n",
      "        (conv_pw): Conv2d(272, 1632, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(1632, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act1): SiLU(inplace=True)\n",
      "        (conv_dw): Conv2d(1632, 1632, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1632, bias=False)\n",
      "        (bn2): BatchNorm2d(1632, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act2): SiLU(inplace=True)\n",
      "        (se): SqueezeExcite(\n",
      "          (conv_reduce): Conv2d(1632, 68, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (act1): SiLU(inplace=True)\n",
      "          (conv_expand): Conv2d(68, 1632, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "        (conv_pwl): Conv2d(1632, 272, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(272, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (7): InvertedResidual(\n",
      "        (conv_pw): Conv2d(272, 1632, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(1632, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act1): SiLU(inplace=True)\n",
      "        (conv_dw): Conv2d(1632, 1632, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1632, bias=False)\n",
      "        (bn2): BatchNorm2d(1632, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act2): SiLU(inplace=True)\n",
      "        (se): SqueezeExcite(\n",
      "          (conv_reduce): Conv2d(1632, 68, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (act1): SiLU(inplace=True)\n",
      "          (conv_expand): Conv2d(68, 1632, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "        (conv_pwl): Conv2d(1632, 272, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(272, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (6): Sequential(\n",
      "      (0): InvertedResidual(\n",
      "        (conv_pw): Conv2d(272, 1632, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(1632, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act1): SiLU(inplace=True)\n",
      "        (conv_dw): Conv2d(1632, 1632, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1632, bias=False)\n",
      "        (bn2): BatchNorm2d(1632, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act2): SiLU(inplace=True)\n",
      "        (se): SqueezeExcite(\n",
      "          (conv_reduce): Conv2d(1632, 68, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (act1): SiLU(inplace=True)\n",
      "          (conv_expand): Conv2d(68, 1632, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "        (conv_pwl): Conv2d(1632, 448, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(448, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (1): InvertedResidual(\n",
      "        (conv_pw): Conv2d(448, 2688, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(2688, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act1): SiLU(inplace=True)\n",
      "        (conv_dw): Conv2d(2688, 2688, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2688, bias=False)\n",
      "        (bn2): BatchNorm2d(2688, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act2): SiLU(inplace=True)\n",
      "        (se): SqueezeExcite(\n",
      "          (conv_reduce): Conv2d(2688, 112, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (act1): SiLU(inplace=True)\n",
      "          (conv_expand): Conv2d(112, 2688, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "        (conv_pwl): Conv2d(2688, 448, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(448, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (conv_head): Conv2d(448, 1792, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (bn2): BatchNorm2d(1792, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (act2): SiLU(inplace=True)\n",
      "  (global_pool): SelectAdaptivePool2d (pool_type=avg, flatten=True)\n",
      "  (classifier): Linear(in_features=1792, out_features=5, bias=True)\n",
      ")\n",
      "Tuning /opt/favordata/AI/Felix/kaggle-cassava/trained-models/sgd_coswarm_bnf_bitemp_smooth_weighted_t1=0.3_t2=1.0_89-53/tf_efficientnet_b4_ns_bitempered_smooth=0.05_val_loss=0.104_val_acc=0.887_fold3.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name           | Type           | Params\n",
      "--------------------------------------------------\n",
      "0 | valid_accuracy | Accuracy       | 0     \n",
      "1 | test_accuracy  | Accuracy       | 0     \n",
      "2 | criterion      | BiTemperedLoss | 0     \n",
      "3 | model          | EfficientNet   | 17.6 M\n",
      "--------------------------------------------------\n",
      "17.4 M    Trainable params\n",
      "125 K     Non-trainable params\n",
      "17.6 M    Total params\n",
      "\n",
      "Finding best initial lr:   0%|          | 0/100 [00:00<?, ?it/s]\u001b[A\n",
      "Finding best initial lr:   1%|          | 1/100 [00:00<00:25,  3.82it/s]\u001b[A\n",
      "Finding best initial lr:   2%|▏         | 2/100 [00:01<01:07,  1.45it/s]\u001b[A\n",
      "Finding best initial lr:   3%|▎         | 3/100 [00:02<01:20,  1.21it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 14: 100%|██████████| 1770/1770 [07:55<00:00,  2.89it/s, loss=0.147, v_num=7, val_loss=0.0586, val_acc=0.95, train_loss=0.379]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Finding best initial lr:   4%|▍         | 4/100 [00:03<01:25,  1.12it/s]\u001b[A\n",
      "Finding best initial lr:   5%|▌         | 5/100 [00:04<01:28,  1.08it/s]\u001b[A\n",
      "Finding best initial lr:   6%|▌         | 6/100 [00:05<01:29,  1.05it/s]\u001b[A\n",
      "Finding best initial lr:   7%|▋         | 7/100 [00:06<01:29,  1.04it/s]\u001b[A\n",
      "Finding best initial lr:   8%|▊         | 8/100 [00:07<01:29,  1.03it/s]\u001b[A\n",
      "Finding best initial lr:   9%|▉         | 9/100 [00:08<01:28,  1.02it/s]\u001b[A\n",
      "Finding best initial lr:  10%|█         | 10/100 [00:09<01:29,  1.01it/s]\u001b[A\n",
      "Finding best initial lr:  11%|█         | 11/100 [00:10<01:28,  1.01it/s]\u001b[A\n",
      "Finding best initial lr:  12%|█▏        | 12/100 [00:11<01:27,  1.01it/s]\u001b[A\n",
      "Finding best initial lr:  13%|█▎        | 13/100 [00:12<01:26,  1.01it/s]\u001b[A\n",
      "Finding best initial lr:  14%|█▍        | 14/100 [00:13<01:25,  1.01it/s]\u001b[A\n",
      "Finding best initial lr:  15%|█▌        | 15/100 [00:14<01:24,  1.01it/s]\u001b[A\n",
      "Finding best initial lr:  16%|█▌        | 16/100 [00:15<01:23,  1.01it/s]\u001b[A\n",
      "Finding best initial lr:  17%|█▋        | 17/100 [00:16<01:22,  1.01it/s]\u001b[A\n",
      "Finding best initial lr:  18%|█▊        | 18/100 [00:17<01:21,  1.01it/s]\u001b[A\n",
      "Finding best initial lr:  19%|█▉        | 19/100 [00:18<01:20,  1.01it/s]\u001b[A\n",
      "Finding best initial lr:  20%|██        | 20/100 [00:19<01:19,  1.00it/s]\u001b[A\n",
      "Finding best initial lr:  21%|██        | 21/100 [00:20<01:18,  1.00it/s]\u001b[A\n",
      "Finding best initial lr:  22%|██▏       | 22/100 [00:21<01:17,  1.01it/s]\u001b[A\n",
      "Finding best initial lr:  23%|██▎       | 23/100 [00:22<01:16,  1.01it/s]\u001b[A\n",
      "Finding best initial lr:  24%|██▍       | 24/100 [00:23<01:15,  1.01it/s]\u001b[A\n",
      "Finding best initial lr:  25%|██▌       | 25/100 [00:24<01:14,  1.01it/s]\u001b[A\n",
      "Finding best initial lr:  26%|██▌       | 26/100 [00:25<01:13,  1.01it/s]\u001b[A\n",
      "Finding best initial lr:  27%|██▋       | 27/100 [00:26<01:12,  1.01it/s]\u001b[A\n",
      "Finding best initial lr:  28%|██▊       | 28/100 [00:27<01:11,  1.01it/s]\u001b[A\n",
      "Finding best initial lr:  29%|██▉       | 29/100 [00:28<01:10,  1.01it/s]\u001b[A\n",
      "Finding best initial lr:  30%|███       | 30/100 [00:29<01:09,  1.00it/s]\u001b[A\n",
      "Finding best initial lr:  31%|███       | 31/100 [00:30<01:08,  1.00it/s]\u001b[A\n",
      "Finding best initial lr:  32%|███▏      | 32/100 [00:31<01:07,  1.01it/s]\u001b[A\n",
      "Finding best initial lr:  33%|███▎      | 33/100 [00:32<01:06,  1.01it/s]\u001b[A\n",
      "Finding best initial lr:  34%|███▍      | 34/100 [00:33<01:05,  1.01it/s]\u001b[A\n",
      "Finding best initial lr:  35%|███▌      | 35/100 [00:34<01:04,  1.01it/s]\u001b[A\n",
      "Finding best initial lr:  36%|███▌      | 36/100 [00:35<01:03,  1.01it/s]\u001b[A\n",
      "Finding best initial lr:  37%|███▋      | 37/100 [00:35<01:02,  1.01it/s]\u001b[A\n",
      "Finding best initial lr:  38%|███▊      | 38/100 [00:36<01:01,  1.01it/s]\u001b[A\n",
      "Finding best initial lr:  39%|███▉      | 39/100 [00:37<01:00,  1.01it/s]\u001b[A\n",
      "Finding best initial lr:  40%|████      | 40/100 [00:38<00:59,  1.00it/s]\u001b[A\n",
      "Finding best initial lr:  41%|████      | 41/100 [00:39<00:58,  1.00it/s]\u001b[A\n",
      "Finding best initial lr:  42%|████▏     | 42/100 [00:40<00:57,  1.00it/s]\u001b[A\n",
      "Finding best initial lr:  43%|████▎     | 43/100 [00:41<00:56,  1.01it/s]\u001b[A\n",
      "Finding best initial lr:  44%|████▍     | 44/100 [00:42<00:55,  1.01it/s]\u001b[A\n",
      "Finding best initial lr:  45%|████▌     | 45/100 [00:43<00:54,  1.01it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 14: 100%|██████████| 1770/1770 [08:37<00:00,  2.65it/s, loss=0.147, v_num=7, val_loss=0.0586, val_acc=0.95, train_loss=0.379]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Finding best initial lr:  46%|████▌     | 46/100 [00:44<00:53,  1.01it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Finding best initial lr:  47%|████▋     | 47/100 [00:45<00:52,  1.01it/s]\u001b[A\n",
      "Finding best initial lr:  48%|████▊     | 48/100 [00:46<00:51,  1.01it/s]\u001b[A\n",
      "Finding best initial lr:  49%|████▉     | 49/100 [00:47<00:50,  1.01it/s]\u001b[A\n",
      "Finding best initial lr:  50%|█████     | 50/100 [00:48<00:49,  1.00it/s]\u001b[A\n",
      "Finding best initial lr:  51%|█████     | 51/100 [00:49<00:48,  1.00it/s]\u001b[A\n",
      "Finding best initial lr:  52%|█████▏    | 52/100 [00:50<00:47,  1.00it/s]\u001b[A\n",
      "Finding best initial lr:  53%|█████▎    | 53/100 [00:51<00:46,  1.01it/s]\u001b[A\n",
      "Finding best initial lr:  54%|█████▍    | 54/100 [00:52<00:45,  1.01it/s]\u001b[A\n",
      "Finding best initial lr:  55%|█████▌    | 55/100 [00:53<00:44,  1.01it/s]\u001b[A\n",
      "Finding best initial lr:  56%|█████▌    | 56/100 [00:54<00:43,  1.01it/s]\u001b[A\n",
      "Finding best initial lr:  57%|█████▋    | 57/100 [00:55<00:42,  1.01it/s]\u001b[A\n",
      "Finding best initial lr:  58%|█████▊    | 58/100 [00:56<00:41,  1.01it/s]\u001b[A\n",
      "Finding best initial lr:  59%|█████▉    | 59/100 [00:57<00:40,  1.01it/s]\u001b[A\n",
      "Finding best initial lr:  60%|██████    | 60/100 [00:58<00:40,  1.00s/it]\u001b[A\n",
      "Finding best initial lr:  61%|██████    | 61/100 [00:59<00:38,  1.00it/s]\u001b[A\n",
      "Finding best initial lr:  62%|██████▏   | 62/100 [01:00<00:37,  1.00it/s]\u001b[A\n",
      "Finding best initial lr:  63%|██████▎   | 63/100 [01:01<00:36,  1.01it/s]\u001b[A\n",
      "Finding best initial lr:  64%|██████▍   | 64/100 [01:02<00:35,  1.01it/s]\u001b[A\n",
      "Finding best initial lr:  65%|██████▌   | 65/100 [01:03<00:34,  1.01it/s]\u001b[A\n",
      "Finding best initial lr:  66%|██████▌   | 66/100 [01:04<00:33,  1.01it/s]\u001b[A\n",
      "Finding best initial lr:  67%|██████▋   | 67/100 [01:05<00:32,  1.01it/s]\u001b[A\n",
      "Finding best initial lr:  68%|██████▊   | 68/100 [01:06<00:31,  1.01it/s]\u001b[A\n",
      "Finding best initial lr:  69%|██████▉   | 69/100 [01:07<00:30,  1.01it/s]\u001b[A\n",
      "Finding best initial lr:  70%|███████   | 70/100 [01:08<00:29,  1.00it/s]\u001b[A\n",
      "Finding best initial lr:  71%|███████   | 71/100 [01:09<00:28,  1.00it/s]\u001b[A\n",
      "Finding best initial lr:  72%|███████▏  | 72/100 [01:10<00:27,  1.01it/s]\u001b[A\n",
      "Finding best initial lr:  73%|███████▎  | 73/100 [01:11<00:26,  1.01it/s]\u001b[A\n",
      "Finding best initial lr:  74%|███████▍  | 74/100 [01:12<00:25,  1.01it/s]\u001b[A\n",
      "Finding best initial lr:  75%|███████▌  | 75/100 [01:13<00:24,  1.01it/s]\u001b[A\n",
      "Finding best initial lr:  76%|███████▌  | 76/100 [01:14<00:23,  1.01it/s]\u001b[A\n",
      "Finding best initial lr:  77%|███████▋  | 77/100 [01:15<00:22,  1.01it/s]\u001b[A\n",
      "Finding best initial lr:  78%|███████▊  | 78/100 [01:16<00:21,  1.01it/s]\u001b[A\n",
      "Finding best initial lr:  79%|███████▉  | 79/100 [01:17<00:20,  1.01it/s]\u001b[A\n",
      "Finding best initial lr:  80%|████████  | 80/100 [01:18<00:19,  1.00it/s]\u001b[A\n",
      "Finding best initial lr:  81%|████████  | 81/100 [01:19<00:18,  1.00it/s]\u001b[A\n",
      "Finding best initial lr:  82%|████████▏ | 82/100 [01:20<00:17,  1.00it/s]\u001b[A\n",
      "Finding best initial lr:  83%|████████▎ | 83/100 [01:21<00:16,  1.01it/s]\u001b[A\n",
      "Finding best initial lr:  84%|████████▍ | 84/100 [01:22<00:15,  1.01it/s]\u001b[A\n",
      "Finding best initial lr:  85%|████████▌ | 85/100 [01:23<00:14,  1.01it/s]\u001b[A\n",
      "Finding best initial lr:  86%|████████▌ | 86/100 [01:24<00:13,  1.01it/s]\u001b[A\n",
      "Finding best initial lr:  87%|████████▋ | 87/100 [01:25<00:12,  1.01it/s]\u001b[A\n",
      "Finding best initial lr:  88%|████████▊ | 88/100 [01:26<00:11,  1.01it/s]\u001b[A\n",
      "Finding best initial lr:  89%|████████▉ | 89/100 [01:27<00:10,  1.01it/s]\u001b[A\n",
      "Finding best initial lr:  90%|█████████ | 90/100 [01:28<00:09,  1.00it/s]\u001b[A\n",
      "Finding best initial lr:  91%|█████████ | 91/100 [01:29<00:08,  1.00it/s]\u001b[A\n",
      "Finding best initial lr:  92%|█████████▏| 92/100 [01:30<00:07,  1.00it/s]\u001b[A\n",
      "Finding best initial lr:  93%|█████████▎| 93/100 [01:31<00:06,  1.00it/s]\u001b[A\n",
      "Finding best initial lr:  94%|█████████▍| 94/100 [01:32<00:05,  1.01it/s]\u001b[A\n",
      "Finding best initial lr:  95%|█████████▌| 95/100 [01:33<00:04,  1.01it/s]\u001b[A\n",
      "Finding best initial lr:  96%|█████████▌| 96/100 [01:34<00:03,  1.01it/s]\u001b[A\n",
      "Finding best initial lr:  97%|█████████▋| 97/100 [01:35<00:02,  1.01it/s]\u001b[A\n",
      "Finding best initial lr:  98%|█████████▊| 98/100 [01:36<00:01,  1.01it/s]\u001b[A\n",
      "Finding best initial lr:  99%|█████████▉| 99/100 [01:37<00:00,  1.01it/s]\u001b[A\n",
      "Finding best initial lr: 100%|██████████| 100/100 [01:38<00:00,  1.00s/it]\u001b[ARestored states from the checkpoint file at /opt/favordata/AI/Felix/kaggle-cassava/trained-models/sgd_coswarm_bnf_bitemp_smooth_weighted_t1=0.3_t2=1.0_89-53_tune/lr_find_temp_model.ckpt\n",
      "Learning rate set to 0.07585775750291836\n",
      "\n",
      "  | Name           | Type           | Params\n",
      "--------------------------------------------------\n",
      "0 | valid_accuracy | Accuracy       | 0     \n",
      "1 | test_accuracy  | Accuracy       | 0     \n",
      "2 | criterion      | BiTemperedLoss | 0     \n",
      "3 | model          | EfficientNet   | 17.6 M\n",
      "--------------------------------------------------\n",
      "17.4 M    Trainable params\n",
      "125 K     Non-trainable params\n",
      "17.6 M    Total params\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1:  97%|█████████▋| 1716/1770 [07:13<00:17,  3.04it/s, loss=0.138, v_num=7, val_loss=0.0459, val_acc=0.953, train_loss=0.261]     \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 1:  97%|█████████▋| 1718/1770 [07:15<00:17,  3.03it/s, loss=0.138, v_num=7, val_loss=0.0459, val_acc=0.953, train_loss=0.261]\n",
      "Validating:   4%|▎         | 2/54 [00:02<01:09,  1.34s/it]\u001b[A\n",
      "Epoch 1:  97%|█████████▋| 1720/1770 [07:17<00:16,  3.02it/s, loss=0.138, v_num=7, val_loss=0.0459, val_acc=0.953, train_loss=0.261]\n",
      "Validating:   7%|▋         | 4/54 [00:04<00:43,  1.15it/s]\u001b[A\n",
      "Epoch 1:  97%|█████████▋| 1722/1770 [07:18<00:15,  3.02it/s, loss=0.138, v_num=7, val_loss=0.0459, val_acc=0.953, train_loss=0.261]\n",
      "Validating:  11%|█         | 6/54 [00:05<00:33,  1.43it/s]\u001b[A\n",
      "Epoch 1:  97%|█████████▋| 1724/1770 [07:19<00:15,  3.01it/s, loss=0.138, v_num=7, val_loss=0.0459, val_acc=0.953, train_loss=0.261]\n",
      "Validating:  15%|█▍        | 8/54 [00:06<00:29,  1.57it/s]\u001b[A\n",
      "Epoch 1:  98%|█████████▊| 1726/1770 [07:20<00:14,  3.01it/s, loss=0.138, v_num=7, val_loss=0.0459, val_acc=0.953, train_loss=0.261]\n",
      "Validating:  19%|█▊        | 10/54 [00:07<00:26,  1.66it/s]\u001b[A\n",
      "Epoch 1:  98%|█████████▊| 1728/1770 [07:21<00:13,  3.01it/s, loss=0.138, v_num=7, val_loss=0.0459, val_acc=0.953, train_loss=0.261]\n",
      "Validating:  22%|██▏       | 12/54 [00:08<00:24,  1.70it/s]\u001b[A\n",
      "Epoch 1:  98%|█████████▊| 1730/1770 [07:22<00:13,  3.00it/s, loss=0.138, v_num=7, val_loss=0.0459, val_acc=0.953, train_loss=0.261]\n",
      "Validating:  26%|██▌       | 14/54 [00:10<00:23,  1.71it/s]\u001b[A\n",
      "Epoch 1:  98%|█████████▊| 1732/1770 [07:24<00:12,  3.00it/s, loss=0.138, v_num=7, val_loss=0.0459, val_acc=0.953, train_loss=0.261]\n",
      "Validating:  30%|██▉       | 16/54 [00:11<00:22,  1.72it/s]\u001b[A\n",
      "Epoch 1:  98%|█████████▊| 1734/1770 [07:25<00:12,  3.00it/s, loss=0.138, v_num=7, val_loss=0.0459, val_acc=0.953, train_loss=0.261]\n",
      "Validating:  33%|███▎      | 18/54 [00:12<00:20,  1.73it/s]\u001b[A\n",
      "Epoch 1:  98%|█████████▊| 1736/1770 [07:26<00:11,  2.99it/s, loss=0.138, v_num=7, val_loss=0.0459, val_acc=0.953, train_loss=0.261]\n",
      "Validating:  37%|███▋      | 20/54 [00:13<00:19,  1.74it/s]\u001b[A\n",
      "Epoch 1:  98%|█████████▊| 1738/1770 [07:27<00:10,  2.99it/s, loss=0.138, v_num=7, val_loss=0.0459, val_acc=0.953, train_loss=0.261]\n",
      "Validating:  41%|████      | 22/54 [00:14<00:18,  1.74it/s]\u001b[A\n",
      "Epoch 1:  98%|█████████▊| 1740/1770 [07:28<00:10,  2.99it/s, loss=0.138, v_num=7, val_loss=0.0459, val_acc=0.953, train_loss=0.261]\n",
      "Validating:  44%|████▍     | 24/54 [00:15<00:17,  1.74it/s]\u001b[A\n",
      "Epoch 1:  98%|█████████▊| 1742/1770 [07:29<00:09,  2.99it/s, loss=0.138, v_num=7, val_loss=0.0459, val_acc=0.953, train_loss=0.261]\n",
      "Validating:  48%|████▊     | 26/54 [00:16<00:16,  1.74it/s]\u001b[A\n",
      "Epoch 1:  99%|█████████▊| 1744/1770 [07:31<00:08,  2.98it/s, loss=0.138, v_num=7, val_loss=0.0459, val_acc=0.953, train_loss=0.261]\n",
      "Validating:  52%|█████▏    | 28/54 [00:18<00:14,  1.74it/s]\u001b[A\n",
      "Epoch 1:  99%|█████████▊| 1746/1770 [07:32<00:08,  2.98it/s, loss=0.138, v_num=7, val_loss=0.0459, val_acc=0.953, train_loss=0.261]\n",
      "Validating:  56%|█████▌    | 30/54 [00:19<00:13,  1.73it/s]\u001b[A\n",
      "Epoch 1:  99%|█████████▉| 1748/1770 [07:33<00:07,  2.98it/s, loss=0.138, v_num=7, val_loss=0.0459, val_acc=0.953, train_loss=0.261]\n",
      "Validating:  59%|█████▉    | 32/54 [00:20<00:12,  1.73it/s]\u001b[A\n",
      "Epoch 1:  99%|█████████▉| 1750/1770 [07:34<00:06,  2.97it/s, loss=0.138, v_num=7, val_loss=0.0459, val_acc=0.953, train_loss=0.261]\n",
      "Validating:  63%|██████▎   | 34/54 [00:21<00:11,  1.72it/s]\u001b[A\n",
      "Epoch 1:  99%|█████████▉| 1752/1770 [07:35<00:06,  2.97it/s, loss=0.138, v_num=7, val_loss=0.0459, val_acc=0.953, train_loss=0.261]\n",
      "Validating:  67%|██████▋   | 36/54 [00:22<00:10,  1.73it/s]\u001b[A\n",
      "Epoch 1:  99%|█████████▉| 1754/1770 [07:36<00:05,  2.97it/s, loss=0.138, v_num=7, val_loss=0.0459, val_acc=0.953, train_loss=0.261]\n",
      "Validating:  70%|███████   | 38/54 [00:23<00:09,  1.74it/s]\u001b[A\n",
      "Epoch 1:  99%|█████████▉| 1756/1770 [07:37<00:04,  2.96it/s, loss=0.138, v_num=7, val_loss=0.0459, val_acc=0.953, train_loss=0.261]\n",
      "Validating:  74%|███████▍  | 40/54 [00:24<00:08,  1.74it/s]\u001b[A\n",
      "Epoch 1:  99%|█████████▉| 1758/1770 [07:39<00:04,  2.96it/s, loss=0.138, v_num=7, val_loss=0.0459, val_acc=0.953, train_loss=0.261]\n",
      "Validating:  78%|███████▊  | 42/54 [00:26<00:06,  1.74it/s]\u001b[A\n",
      "Epoch 1:  99%|█████████▉| 1760/1770 [07:40<00:03,  2.96it/s, loss=0.138, v_num=7, val_loss=0.0459, val_acc=0.953, train_loss=0.261]\n",
      "Validating:  81%|████████▏ | 44/54 [00:27<00:05,  1.74it/s]\u001b[A\n",
      "Epoch 1: 100%|█████████▉| 1762/1770 [07:41<00:02,  2.95it/s, loss=0.138, v_num=7, val_loss=0.0459, val_acc=0.953, train_loss=0.261]\n",
      "Validating:  85%|████████▌ | 46/54 [00:28<00:04,  1.77it/s]\u001b[A\n",
      "Epoch 1: 100%|█████████▉| 1764/1770 [07:42<00:02,  2.95it/s, loss=0.138, v_num=7, val_loss=0.0459, val_acc=0.953, train_loss=0.261]\n",
      "Validating:  89%|████████▉ | 48/54 [00:29<00:03,  1.78it/s]\u001b[A\n",
      "Epoch 1: 100%|█████████▉| 1766/1770 [07:43<00:01,  2.95it/s, loss=0.138, v_num=7, val_loss=0.0459, val_acc=0.953, train_loss=0.261]\n",
      "Validating:  93%|█████████▎| 50/54 [00:30<00:02,  1.78it/s]\u001b[A\n",
      "Epoch 1: 100%|█████████▉| 1768/1770 [07:44<00:00,  2.95it/s, loss=0.138, v_num=7, val_loss=0.0459, val_acc=0.953, train_loss=0.261]\n",
      "Validating:  96%|█████████▋| 52/54 [00:31<00:01,  1.79it/s]\u001b[A\n",
      "Epoch 1: 100%|██████████| 1770/1770 [07:45<00:00,  2.94it/s, loss=0.138, v_num=7, val_loss=0.0459, val_acc=0.953, train_loss=0.261]\n",
      "Validating: 100%|██████████| 54/54 [00:33<00:00,  1.27it/s]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, global step 429: val_loss reached 0.05561 (best 0.05561), saving model to \"/opt/favordata/AI/Felix/kaggle-cassava/trained-models/sgd_coswarm_bnf_bitemp_smooth_weighted_t1=0.3_t2=1.0_89-53_tune/tf_efficientnet_b4_ns_bitempered_smooth=0.05_val_loss=0.056_val_acc=0.953_fold2.ckpt\" as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 1770/1770 [07:47<00:00,  2.93it/s, loss=0.138, v_num=7, val_loss=0.0556, val_acc=0.953, train_loss=0.253]\n",
      "Epoch 2:  97%|█████████▋| 1716/1770 [07:10<00:17,  3.06it/s, loss=0.133, v_num=7, val_loss=0.0556, val_acc=0.953, train_loss=0.369]    \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 2:  97%|█████████▋| 1718/1770 [07:13<00:17,  3.04it/s, loss=0.133, v_num=7, val_loss=0.0556, val_acc=0.953, train_loss=0.369]\n",
      "Validating:   4%|▎         | 2/54 [00:03<01:13,  1.42s/it]\u001b[A\n",
      "Epoch 2:  97%|█████████▋| 1720/1770 [07:14<00:16,  3.04it/s, loss=0.133, v_num=7, val_loss=0.0556, val_acc=0.953, train_loss=0.369]\n",
      "Validating:   7%|▋         | 4/54 [00:04<00:42,  1.17it/s]\u001b[A\n",
      "Epoch 2:  97%|█████████▋| 1722/1770 [07:15<00:15,  3.04it/s, loss=0.133, v_num=7, val_loss=0.0556, val_acc=0.953, train_loss=0.369]\n",
      "Validating:  11%|█         | 6/54 [00:05<00:33,  1.44it/s]\u001b[A\n",
      "Epoch 2:  97%|█████████▋| 1724/1770 [07:16<00:15,  3.03it/s, loss=0.133, v_num=7, val_loss=0.0556, val_acc=0.953, train_loss=0.369]\n",
      "Validating:  15%|█▍        | 8/54 [00:06<00:28,  1.59it/s]\u001b[A\n",
      "Epoch 2:  98%|█████████▊| 1726/1770 [07:18<00:14,  3.03it/s, loss=0.133, v_num=7, val_loss=0.0556, val_acc=0.953, train_loss=0.369]\n",
      "Validating:  19%|█▊        | 10/54 [00:07<00:26,  1.67it/s]\u001b[A\n",
      "Epoch 2:  98%|█████████▊| 1728/1770 [07:19<00:13,  3.03it/s, loss=0.133, v_num=7, val_loss=0.0556, val_acc=0.953, train_loss=0.369]\n",
      "Validating:  22%|██▏       | 12/54 [00:08<00:24,  1.70it/s]\u001b[A\n",
      "Epoch 2:  98%|█████████▊| 1730/1770 [07:20<00:13,  3.02it/s, loss=0.133, v_num=7, val_loss=0.0556, val_acc=0.953, train_loss=0.369]\n",
      "Validating:  26%|██▌       | 14/54 [00:10<00:23,  1.72it/s]\u001b[A\n",
      "Epoch 2:  98%|█████████▊| 1732/1770 [07:21<00:12,  3.02it/s, loss=0.133, v_num=7, val_loss=0.0556, val_acc=0.953, train_loss=0.369]\n",
      "Validating:  30%|██▉       | 16/54 [00:11<00:21,  1.74it/s]\u001b[A\n",
      "Epoch 2:  98%|█████████▊| 1734/1770 [07:22<00:11,  3.02it/s, loss=0.133, v_num=7, val_loss=0.0556, val_acc=0.953, train_loss=0.369]\n",
      "Validating:  33%|███▎      | 18/54 [00:12<00:20,  1.73it/s]\u001b[A\n",
      "Epoch 2:  98%|█████████▊| 1736/1770 [07:23<00:11,  3.01it/s, loss=0.133, v_num=7, val_loss=0.0556, val_acc=0.953, train_loss=0.369]\n",
      "Validating:  37%|███▋      | 20/54 [00:13<00:19,  1.74it/s]\u001b[A\n",
      "Epoch 2:  98%|█████████▊| 1738/1770 [07:24<00:10,  3.01it/s, loss=0.133, v_num=7, val_loss=0.0556, val_acc=0.953, train_loss=0.369]\n",
      "Validating:  41%|████      | 22/54 [00:14<00:18,  1.74it/s]\u001b[A\n",
      "Epoch 2:  98%|█████████▊| 1740/1770 [07:26<00:09,  3.01it/s, loss=0.133, v_num=7, val_loss=0.0556, val_acc=0.953, train_loss=0.369]\n",
      "Validating:  44%|████▍     | 24/54 [00:15<00:17,  1.74it/s]\u001b[A\n",
      "Epoch 2:  98%|█████████▊| 1742/1770 [07:27<00:09,  3.00it/s, loss=0.133, v_num=7, val_loss=0.0556, val_acc=0.953, train_loss=0.369]\n",
      "Validating:  48%|████▊     | 26/54 [00:16<00:16,  1.74it/s]\u001b[A\n",
      "Epoch 2:  99%|█████████▊| 1744/1770 [07:28<00:08,  3.00it/s, loss=0.133, v_num=7, val_loss=0.0556, val_acc=0.953, train_loss=0.369]\n",
      "Validating:  52%|█████▏    | 28/54 [00:18<00:14,  1.74it/s]\u001b[A\n",
      "Epoch 2:  99%|█████████▊| 1746/1770 [07:29<00:08,  3.00it/s, loss=0.133, v_num=7, val_loss=0.0556, val_acc=0.953, train_loss=0.369]\n",
      "Validating:  56%|█████▌    | 30/54 [00:19<00:13,  1.74it/s]\u001b[A\n",
      "Epoch 2:  99%|█████████▉| 1748/1770 [07:30<00:07,  2.99it/s, loss=0.133, v_num=7, val_loss=0.0556, val_acc=0.953, train_loss=0.369]\n",
      "Validating:  59%|█████▉    | 32/54 [00:20<00:12,  1.74it/s]\u001b[A\n",
      "Epoch 2:  99%|█████████▉| 1750/1770 [07:31<00:06,  2.99it/s, loss=0.133, v_num=7, val_loss=0.0556, val_acc=0.953, train_loss=0.369]\n",
      "Validating:  63%|██████▎   | 34/54 [00:21<00:11,  1.74it/s]\u001b[A\n",
      "Epoch 2:  99%|█████████▉| 1752/1770 [07:32<00:06,  2.99it/s, loss=0.133, v_num=7, val_loss=0.0556, val_acc=0.953, train_loss=0.369]\n",
      "Validating:  67%|██████▋   | 36/54 [00:22<00:10,  1.74it/s]\u001b[A\n",
      "Epoch 2:  99%|█████████▉| 1754/1770 [07:34<00:05,  2.98it/s, loss=0.133, v_num=7, val_loss=0.0556, val_acc=0.953, train_loss=0.369]\n",
      "Validating:  70%|███████   | 38/54 [00:23<00:09,  1.73it/s]\u001b[A\n",
      "Epoch 2:  99%|█████████▉| 1756/1770 [07:35<00:04,  2.98it/s, loss=0.133, v_num=7, val_loss=0.0556, val_acc=0.953, train_loss=0.369]\n",
      "Validating:  74%|███████▍  | 40/54 [00:24<00:08,  1.74it/s]\u001b[A\n",
      "Epoch 2:  99%|█████████▉| 1758/1770 [07:36<00:04,  2.98it/s, loss=0.133, v_num=7, val_loss=0.0556, val_acc=0.953, train_loss=0.369]\n",
      "Validating:  78%|███████▊  | 42/54 [00:26<00:06,  1.74it/s]\u001b[A\n",
      "Epoch 2:  99%|█████████▉| 1760/1770 [07:37<00:03,  2.97it/s, loss=0.133, v_num=7, val_loss=0.0556, val_acc=0.953, train_loss=0.369]\n",
      "Validating:  81%|████████▏ | 44/54 [00:27<00:05,  1.73it/s]\u001b[A\n",
      "Epoch 2: 100%|█████████▉| 1762/1770 [07:38<00:02,  2.97it/s, loss=0.133, v_num=7, val_loss=0.0556, val_acc=0.953, train_loss=0.369]\n",
      "Validating:  85%|████████▌ | 46/54 [00:28<00:04,  1.76it/s]\u001b[A\n",
      "Epoch 2: 100%|█████████▉| 1764/1770 [07:39<00:02,  2.97it/s, loss=0.133, v_num=7, val_loss=0.0556, val_acc=0.953, train_loss=0.369]\n",
      "Validating:  89%|████████▉ | 48/54 [00:29<00:03,  1.77it/s]\u001b[A\n",
      "Epoch 2: 100%|█████████▉| 1766/1770 [07:40<00:01,  2.97it/s, loss=0.133, v_num=7, val_loss=0.0556, val_acc=0.953, train_loss=0.369]\n",
      "Validating:  93%|█████████▎| 50/54 [00:30<00:02,  1.78it/s]\u001b[A\n",
      "Epoch 2: 100%|█████████▉| 1768/1770 [07:42<00:00,  2.96it/s, loss=0.133, v_num=7, val_loss=0.0556, val_acc=0.953, train_loss=0.369]\n",
      "Validating:  96%|█████████▋| 52/54 [00:31<00:01,  1.79it/s]\u001b[A\n",
      "Epoch 2: 100%|██████████| 1770/1770 [07:43<00:00,  2.96it/s, loss=0.133, v_num=7, val_loss=0.0556, val_acc=0.953, train_loss=0.369]\n",
      "Validating: 100%|██████████| 54/54 [00:32<00:00,  2.02it/s]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2, global step 858: val_loss reached 0.05152 (best 0.05152), saving model to \"/opt/favordata/AI/Felix/kaggle-cassava/trained-models/sgd_coswarm_bnf_bitemp_smooth_weighted_t1=0.3_t2=1.0_89-53_tune/tf_efficientnet_b4_ns_bitempered_smooth=0.05_val_loss=0.052_val_acc=0.959_fold2.ckpt\" as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 1770/1770 [07:43<00:00,  2.96it/s, loss=0.133, v_num=7, val_loss=0.0515, val_acc=0.959, train_loss=0.168]\n",
      "                                                           \u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Finding best initial lr: 100%|██████████| 100/100 [17:14<00:00, 10.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3:   0%|          | 0/1770 [00:00<00:00, -493520.29it/s, loss=0.133, v_num=7, val_loss=0.0515, val_acc=0.959, train_loss=0.168] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3:  97%|█████████▋| 1716/1770 [07:10<00:17,  3.06it/s, loss=0.129, v_num=7, val_loss=0.0515, val_acc=0.959, train_loss=0.0369]   \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 3:  97%|█████████▋| 1718/1770 [07:13<00:17,  3.05it/s, loss=0.129, v_num=7, val_loss=0.0515, val_acc=0.959, train_loss=0.0369]\n",
      "Validating:   4%|▎         | 2/54 [00:02<01:07,  1.30s/it]\u001b[A\n",
      "Epoch 3:  97%|█████████▋| 1720/1770 [07:14<00:16,  3.04it/s, loss=0.129, v_num=7, val_loss=0.0515, val_acc=0.959, train_loss=0.0369]\n",
      "Validating:   7%|▋         | 4/54 [00:04<00:43,  1.14it/s]\u001b[A\n",
      "Epoch 3:  97%|█████████▋| 1722/1770 [07:15<00:15,  3.04it/s, loss=0.129, v_num=7, val_loss=0.0515, val_acc=0.959, train_loss=0.0369]\n",
      "Validating:  11%|█         | 6/54 [00:05<00:33,  1.42it/s]\u001b[A\n",
      "Epoch 3:  97%|█████████▋| 1724/1770 [07:16<00:15,  3.03it/s, loss=0.129, v_num=7, val_loss=0.0515, val_acc=0.959, train_loss=0.0369]\n",
      "Validating:  15%|█▍        | 8/54 [00:06<00:29,  1.57it/s]\u001b[A\n",
      "Epoch 3:  98%|█████████▊| 1726/1770 [07:17<00:14,  3.03it/s, loss=0.129, v_num=7, val_loss=0.0515, val_acc=0.959, train_loss=0.0369]\n",
      "Validating:  19%|█▊        | 10/54 [00:07<00:26,  1.66it/s]\u001b[A\n",
      "Epoch 3:  98%|█████████▊| 1728/1770 [07:19<00:13,  3.03it/s, loss=0.129, v_num=7, val_loss=0.0515, val_acc=0.959, train_loss=0.0369]\n",
      "Validating:  22%|██▏       | 12/54 [00:08<00:24,  1.70it/s]\u001b[A\n",
      "Epoch 3:  98%|█████████▊| 1730/1770 [07:20<00:13,  3.02it/s, loss=0.129, v_num=7, val_loss=0.0515, val_acc=0.959, train_loss=0.0369]\n",
      "Validating:  26%|██▌       | 14/54 [00:09<00:23,  1.72it/s]\u001b[A\n",
      "Epoch 3:  98%|█████████▊| 1732/1770 [07:21<00:12,  3.02it/s, loss=0.129, v_num=7, val_loss=0.0515, val_acc=0.959, train_loss=0.0369]\n",
      "Validating:  30%|██▉       | 16/54 [00:11<00:21,  1.73it/s]\u001b[A\n",
      "Epoch 3:  98%|█████████▊| 1734/1770 [07:22<00:11,  3.02it/s, loss=0.129, v_num=7, val_loss=0.0515, val_acc=0.959, train_loss=0.0369]\n",
      "Validating:  33%|███▎      | 18/54 [00:12<00:20,  1.74it/s]\u001b[A\n",
      "Epoch 3:  98%|█████████▊| 1736/1770 [07:23<00:11,  3.01it/s, loss=0.129, v_num=7, val_loss=0.0515, val_acc=0.959, train_loss=0.0369]\n",
      "Validating:  37%|███▋      | 20/54 [00:13<00:19,  1.74it/s]\u001b[A\n",
      "Epoch 3:  98%|█████████▊| 1738/1770 [07:24<00:10,  3.01it/s, loss=0.129, v_num=7, val_loss=0.0515, val_acc=0.959, train_loss=0.0369]\n",
      "Validating:  41%|████      | 22/54 [00:14<00:18,  1.74it/s]\u001b[A\n",
      "Epoch 3:  98%|█████████▊| 1740/1770 [07:25<00:09,  3.01it/s, loss=0.129, v_num=7, val_loss=0.0515, val_acc=0.959, train_loss=0.0369]\n",
      "Validating:  44%|████▍     | 24/54 [00:15<00:17,  1.75it/s]\u001b[A\n",
      "Epoch 3:  98%|█████████▊| 1742/1770 [07:27<00:09,  3.00it/s, loss=0.129, v_num=7, val_loss=0.0515, val_acc=0.959, train_loss=0.0369]\n",
      "Validating:  48%|████▊     | 26/54 [00:16<00:16,  1.75it/s]\u001b[A\n",
      "Epoch 3:  99%|█████████▊| 1744/1770 [07:28<00:08,  3.00it/s, loss=0.129, v_num=7, val_loss=0.0515, val_acc=0.959, train_loss=0.0369]\n",
      "Validating:  52%|█████▏    | 28/54 [00:17<00:14,  1.75it/s]\u001b[A\n",
      "Epoch 3:  99%|█████████▊| 1746/1770 [07:29<00:08,  3.00it/s, loss=0.129, v_num=7, val_loss=0.0515, val_acc=0.959, train_loss=0.0369]\n",
      "Validating:  56%|█████▌    | 30/54 [00:19<00:13,  1.75it/s]\u001b[A\n",
      "Epoch 3:  99%|█████████▉| 1748/1770 [07:30<00:07,  2.99it/s, loss=0.129, v_num=7, val_loss=0.0515, val_acc=0.959, train_loss=0.0369]\n",
      "Validating:  59%|█████▉    | 32/54 [00:20<00:12,  1.73it/s]\u001b[A\n",
      "Epoch 3:  99%|█████████▉| 1750/1770 [07:31<00:06,  2.99it/s, loss=0.129, v_num=7, val_loss=0.0515, val_acc=0.959, train_loss=0.0369]\n",
      "Validating:  63%|██████▎   | 34/54 [00:21<00:11,  1.74it/s]\u001b[A\n",
      "Epoch 3:  99%|█████████▉| 1752/1770 [07:32<00:06,  2.99it/s, loss=0.129, v_num=7, val_loss=0.0515, val_acc=0.959, train_loss=0.0369]\n",
      "Validating:  67%|██████▋   | 36/54 [00:22<00:10,  1.74it/s]\u001b[A\n",
      "Epoch 3:  99%|█████████▉| 1754/1770 [07:34<00:05,  2.98it/s, loss=0.129, v_num=7, val_loss=0.0515, val_acc=0.959, train_loss=0.0369]\n",
      "Validating:  70%|███████   | 38/54 [00:23<00:09,  1.74it/s]\u001b[A\n",
      "Epoch 3:  99%|█████████▉| 1756/1770 [07:35<00:04,  2.98it/s, loss=0.129, v_num=7, val_loss=0.0515, val_acc=0.959, train_loss=0.0369]\n",
      "Validating:  74%|███████▍  | 40/54 [00:24<00:08,  1.74it/s]\u001b[A\n",
      "Epoch 3:  99%|█████████▉| 1758/1770 [07:36<00:04,  2.98it/s, loss=0.129, v_num=7, val_loss=0.0515, val_acc=0.959, train_loss=0.0369]\n",
      "Validating:  78%|███████▊  | 42/54 [00:26<00:06,  1.74it/s]\u001b[A\n",
      "Epoch 3:  99%|█████████▉| 1760/1770 [07:37<00:03,  2.97it/s, loss=0.129, v_num=7, val_loss=0.0515, val_acc=0.959, train_loss=0.0369]\n",
      "Validating:  81%|████████▏ | 44/54 [00:27<00:05,  1.74it/s]\u001b[A\n",
      "Epoch 3: 100%|█████████▉| 1762/1770 [07:38<00:02,  2.97it/s, loss=0.129, v_num=7, val_loss=0.0515, val_acc=0.959, train_loss=0.0369]\n",
      "Validating:  85%|████████▌ | 46/54 [00:28<00:04,  1.76it/s]\u001b[A\n",
      "Epoch 3: 100%|█████████▉| 1764/1770 [07:39<00:02,  2.97it/s, loss=0.129, v_num=7, val_loss=0.0515, val_acc=0.959, train_loss=0.0369]\n",
      "Validating:  89%|████████▉ | 48/54 [00:29<00:03,  1.78it/s]\u001b[A\n",
      "Epoch 3: 100%|█████████▉| 1766/1770 [07:40<00:01,  2.97it/s, loss=0.129, v_num=7, val_loss=0.0515, val_acc=0.959, train_loss=0.0369]\n",
      "Validating:  93%|█████████▎| 50/54 [00:30<00:02,  1.79it/s]\u001b[A\n",
      "Epoch 3: 100%|█████████▉| 1768/1770 [07:41<00:00,  2.96it/s, loss=0.129, v_num=7, val_loss=0.0515, val_acc=0.959, train_loss=0.0369]\n",
      "Validating:  96%|█████████▋| 52/54 [00:31<00:01,  1.79it/s]\u001b[A\n",
      "Epoch 3: 100%|██████████| 1770/1770 [07:43<00:00,  2.96it/s, loss=0.129, v_num=7, val_loss=0.0515, val_acc=0.959, train_loss=0.0369]\n",
      "Validating: 100%|██████████| 54/54 [00:32<00:00,  2.03it/s]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3, step 1287: val_loss was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 1770/1770 [07:43<00:00,  2.96it/s, loss=0.129, v_num=7, val_loss=0.0521, val_acc=0.958, train_loss=0.209] \n",
      "Epoch 4:  97%|█████████▋| 1716/1770 [07:10<00:17,  3.06it/s, loss=0.119, v_num=7, val_loss=0.0521, val_acc=0.958, train_loss=0.0483]    \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 4:  97%|█████████▋| 1718/1770 [07:12<00:17,  3.05it/s, loss=0.119, v_num=7, val_loss=0.0521, val_acc=0.958, train_loss=0.0483]\n",
      "Validating:   4%|▎         | 2/54 [00:02<01:09,  1.34s/it]\u001b[A\n",
      "Epoch 4:  97%|█████████▋| 1720/1770 [07:14<00:16,  3.04it/s, loss=0.119, v_num=7, val_loss=0.0521, val_acc=0.958, train_loss=0.0483]\n",
      "Validating:   7%|▋         | 4/54 [00:04<00:42,  1.17it/s]\u001b[A\n",
      "Epoch 4:  97%|█████████▋| 1722/1770 [07:15<00:15,  3.04it/s, loss=0.119, v_num=7, val_loss=0.0521, val_acc=0.958, train_loss=0.0483]\n",
      "Validating:  11%|█         | 6/54 [00:05<00:33,  1.44it/s]\u001b[A\n",
      "Epoch 4:  97%|█████████▋| 1724/1770 [07:16<00:15,  3.03it/s, loss=0.119, v_num=7, val_loss=0.0521, val_acc=0.958, train_loss=0.0483]\n",
      "Validating:  15%|█▍        | 8/54 [00:06<00:28,  1.59it/s]\u001b[A\n",
      "Epoch 4:  98%|█████████▊| 1726/1770 [07:17<00:14,  3.03it/s, loss=0.119, v_num=7, val_loss=0.0521, val_acc=0.958, train_loss=0.0483]\n",
      "Validating:  19%|█▊        | 10/54 [00:07<00:26,  1.67it/s]\u001b[A\n",
      "Epoch 4:  98%|█████████▊| 1728/1770 [07:18<00:13,  3.03it/s, loss=0.119, v_num=7, val_loss=0.0521, val_acc=0.958, train_loss=0.0483]\n",
      "Validating:  22%|██▏       | 12/54 [00:08<00:24,  1.70it/s]\u001b[A\n",
      "Epoch 4:  98%|█████████▊| 1730/1770 [07:20<00:13,  3.02it/s, loss=0.119, v_num=7, val_loss=0.0521, val_acc=0.958, train_loss=0.0483]\n",
      "Validating:  26%|██▌       | 14/54 [00:09<00:23,  1.72it/s]\u001b[A\n",
      "Epoch 4:  98%|█████████▊| 1732/1770 [07:21<00:12,  3.02it/s, loss=0.119, v_num=7, val_loss=0.0521, val_acc=0.958, train_loss=0.0483]\n",
      "Validating:  30%|██▉       | 16/54 [00:11<00:21,  1.73it/s]\u001b[A\n",
      "Epoch 4:  98%|█████████▊| 1734/1770 [07:22<00:11,  3.02it/s, loss=0.119, v_num=7, val_loss=0.0521, val_acc=0.958, train_loss=0.0483]\n",
      "Validating:  33%|███▎      | 18/54 [00:12<00:20,  1.74it/s]\u001b[A\n",
      "Epoch 4:  98%|█████████▊| 1736/1770 [07:23<00:11,  3.01it/s, loss=0.119, v_num=7, val_loss=0.0521, val_acc=0.958, train_loss=0.0483]\n",
      "Validating:  37%|███▋      | 20/54 [00:13<00:19,  1.74it/s]\u001b[A\n",
      "Epoch 4:  98%|█████████▊| 1738/1770 [07:24<00:10,  3.01it/s, loss=0.119, v_num=7, val_loss=0.0521, val_acc=0.958, train_loss=0.0483]\n",
      "Validating:  41%|████      | 22/54 [00:14<00:18,  1.74it/s]\u001b[A\n",
      "Epoch 4:  98%|█████████▊| 1740/1770 [07:25<00:09,  3.01it/s, loss=0.119, v_num=7, val_loss=0.0521, val_acc=0.958, train_loss=0.0483]\n",
      "Validating:  44%|████▍     | 24/54 [00:15<00:17,  1.74it/s]\u001b[A\n",
      "Epoch 4:  98%|█████████▊| 1742/1770 [07:26<00:09,  3.00it/s, loss=0.119, v_num=7, val_loss=0.0521, val_acc=0.958, train_loss=0.0483]\n",
      "Validating:  48%|████▊     | 26/54 [00:16<00:16,  1.74it/s]\u001b[A\n",
      "Epoch 4:  99%|█████████▊| 1744/1770 [07:28<00:08,  3.00it/s, loss=0.119, v_num=7, val_loss=0.0521, val_acc=0.958, train_loss=0.0483]\n",
      "Validating:  52%|█████▏    | 28/54 [00:17<00:14,  1.74it/s]\u001b[A\n",
      "Epoch 4:  99%|█████████▊| 1746/1770 [07:29<00:08,  3.00it/s, loss=0.119, v_num=7, val_loss=0.0521, val_acc=0.958, train_loss=0.0483]\n",
      "Validating:  56%|█████▌    | 30/54 [00:19<00:13,  1.74it/s]\u001b[A\n",
      "Epoch 4:  99%|█████████▉| 1748/1770 [07:30<00:07,  2.99it/s, loss=0.119, v_num=7, val_loss=0.0521, val_acc=0.958, train_loss=0.0483]\n",
      "Validating:  59%|█████▉    | 32/54 [00:20<00:12,  1.74it/s]\u001b[A\n",
      "Epoch 4:  99%|█████████▉| 1750/1770 [07:31<00:06,  2.99it/s, loss=0.119, v_num=7, val_loss=0.0521, val_acc=0.958, train_loss=0.0483]\n",
      "Validating:  63%|██████▎   | 34/54 [00:21<00:11,  1.74it/s]\u001b[A\n",
      "Epoch 4:  99%|█████████▉| 1752/1770 [07:32<00:06,  2.99it/s, loss=0.119, v_num=7, val_loss=0.0521, val_acc=0.958, train_loss=0.0483]\n",
      "Validating:  67%|██████▋   | 36/54 [00:22<00:10,  1.74it/s]\u001b[A\n",
      "Epoch 4:  99%|█████████▉| 1754/1770 [07:33<00:05,  2.99it/s, loss=0.119, v_num=7, val_loss=0.0521, val_acc=0.958, train_loss=0.0483]\n",
      "Validating:  70%|███████   | 38/54 [00:23<00:09,  1.74it/s]\u001b[A\n",
      "Epoch 4:  99%|█████████▉| 1756/1770 [07:35<00:04,  2.98it/s, loss=0.119, v_num=7, val_loss=0.0521, val_acc=0.958, train_loss=0.0483]\n",
      "Validating:  74%|███████▍  | 40/54 [00:24<00:08,  1.75it/s]\u001b[A\n",
      "Epoch 4:  99%|█████████▉| 1758/1770 [07:36<00:04,  2.98it/s, loss=0.119, v_num=7, val_loss=0.0521, val_acc=0.958, train_loss=0.0483]\n",
      "Validating:  78%|███████▊  | 42/54 [00:25<00:06,  1.75it/s]\u001b[A\n",
      "Epoch 4:  99%|█████████▉| 1760/1770 [07:37<00:03,  2.98it/s, loss=0.119, v_num=7, val_loss=0.0521, val_acc=0.958, train_loss=0.0483]\n",
      "Validating:  81%|████████▏ | 44/54 [00:27<00:05,  1.74it/s]\u001b[A\n",
      "Epoch 4: 100%|█████████▉| 1762/1770 [07:38<00:02,  2.97it/s, loss=0.119, v_num=7, val_loss=0.0521, val_acc=0.958, train_loss=0.0483]\n",
      "Validating:  85%|████████▌ | 46/54 [00:28<00:04,  1.77it/s]\u001b[A\n",
      "Epoch 4: 100%|█████████▉| 1764/1770 [07:39<00:02,  2.97it/s, loss=0.119, v_num=7, val_loss=0.0521, val_acc=0.958, train_loss=0.0483]\n",
      "Validating:  89%|████████▉ | 48/54 [00:29<00:03,  1.78it/s]\u001b[A\n",
      "Epoch 4: 100%|█████████▉| 1766/1770 [07:40<00:01,  2.97it/s, loss=0.119, v_num=7, val_loss=0.0521, val_acc=0.958, train_loss=0.0483]\n",
      "Validating:  93%|█████████▎| 50/54 [00:30<00:02,  1.79it/s]\u001b[A\n",
      "Epoch 4: 100%|█████████▉| 1768/1770 [07:41<00:00,  2.96it/s, loss=0.119, v_num=7, val_loss=0.0521, val_acc=0.958, train_loss=0.0483]\n",
      "Validating:  96%|█████████▋| 52/54 [00:31<00:01,  1.79it/s]\u001b[A\n",
      "Epoch 4: 100%|██████████| 1770/1770 [07:42<00:00,  2.96it/s, loss=0.119, v_num=7, val_loss=0.0521, val_acc=0.958, train_loss=0.0483]\n",
      "Validating: 100%|██████████| 54/54 [00:32<00:00,  2.03it/s]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4, step 1716: val_loss was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 1770/1770 [07:43<00:00,  2.96it/s, loss=0.119, v_num=7, val_loss=0.0545, val_acc=0.955, train_loss=0.0947]\n",
      "Epoch 8:  97%|█████████▋| 1716/1770 [07:10<00:17,  3.06it/s, loss=0.12, v_num=7, val_loss=0.0587, val_acc=0.95, train_loss=0.0706]      \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 8:  97%|█████████▋| 1718/1770 [07:12<00:17,  3.05it/s, loss=0.12, v_num=7, val_loss=0.0587, val_acc=0.95, train_loss=0.0706]\n",
      "Validating:   4%|▎         | 2/54 [00:03<01:14,  1.44s/it]\u001b[A\n",
      "Epoch 8:  97%|█████████▋| 1720/1770 [07:14<00:16,  3.04it/s, loss=0.12, v_num=7, val_loss=0.0587, val_acc=0.95, train_loss=0.0706]\n",
      "Validating:   7%|▋         | 4/54 [00:04<00:43,  1.15it/s]\u001b[A\n",
      "Epoch 8:  97%|█████████▋| 1722/1770 [07:15<00:15,  3.04it/s, loss=0.12, v_num=7, val_loss=0.0587, val_acc=0.95, train_loss=0.0706]\n",
      "Validating:  11%|█         | 6/54 [00:05<00:33,  1.43it/s]\u001b[A\n",
      "Epoch 8:  97%|█████████▋| 1724/1770 [07:16<00:15,  3.04it/s, loss=0.12, v_num=7, val_loss=0.0587, val_acc=0.95, train_loss=0.0706]\n",
      "Validating:  15%|█▍        | 8/54 [00:06<00:29,  1.58it/s]\u001b[A\n",
      "Epoch 8:  98%|█████████▊| 1726/1770 [07:17<00:14,  3.03it/s, loss=0.12, v_num=7, val_loss=0.0587, val_acc=0.95, train_loss=0.0706]\n",
      "Validating:  19%|█▊        | 10/54 [00:07<00:26,  1.66it/s]\u001b[A\n",
      "Epoch 8:  98%|█████████▊| 1728/1770 [07:18<00:13,  3.03it/s, loss=0.12, v_num=7, val_loss=0.0587, val_acc=0.95, train_loss=0.0706]\n",
      "Validating:  22%|██▏       | 12/54 [00:08<00:24,  1.70it/s]\u001b[A\n",
      "Epoch 8:  98%|█████████▊| 1730/1770 [07:19<00:13,  3.03it/s, loss=0.12, v_num=7, val_loss=0.0587, val_acc=0.95, train_loss=0.0706]\n",
      "Validating:  26%|██▌       | 14/54 [00:10<00:23,  1.72it/s]\u001b[A\n",
      "Epoch 8:  98%|█████████▊| 1732/1770 [07:20<00:12,  3.02it/s, loss=0.12, v_num=7, val_loss=0.0587, val_acc=0.95, train_loss=0.0706]\n",
      "Validating:  30%|██▉       | 16/54 [00:11<00:21,  1.73it/s]\u001b[A\n",
      "Epoch 8:  98%|█████████▊| 1734/1770 [07:22<00:11,  3.02it/s, loss=0.12, v_num=7, val_loss=0.0587, val_acc=0.95, train_loss=0.0706]\n",
      "Validating:  33%|███▎      | 18/54 [00:12<00:20,  1.73it/s]\u001b[A\n",
      "Epoch 8:  98%|█████████▊| 1736/1770 [07:23<00:11,  3.02it/s, loss=0.12, v_num=7, val_loss=0.0587, val_acc=0.95, train_loss=0.0706]\n",
      "Validating:  37%|███▋      | 20/54 [00:13<00:19,  1.74it/s]\u001b[A\n",
      "Epoch 8:  98%|█████████▊| 1738/1770 [07:24<00:10,  3.01it/s, loss=0.12, v_num=7, val_loss=0.0587, val_acc=0.95, train_loss=0.0706]\n",
      "Validating:  41%|████      | 22/54 [00:14<00:18,  1.74it/s]\u001b[A\n",
      "Epoch 8:  98%|█████████▊| 1740/1770 [07:25<00:09,  3.01it/s, loss=0.12, v_num=7, val_loss=0.0587, val_acc=0.95, train_loss=0.0706]\n",
      "Validating:  44%|████▍     | 24/54 [00:15<00:17,  1.74it/s]\u001b[A\n",
      "Epoch 8:  98%|█████████▊| 1742/1770 [07:26<00:09,  3.01it/s, loss=0.12, v_num=7, val_loss=0.0587, val_acc=0.95, train_loss=0.0706]\n",
      "Validating:  48%|████▊     | 26/54 [00:17<00:16,  1.74it/s]\u001b[A\n",
      "Epoch 8:  99%|█████████▊| 1744/1770 [07:27<00:08,  3.00it/s, loss=0.12, v_num=7, val_loss=0.0587, val_acc=0.95, train_loss=0.0706]\n",
      "Validating:  52%|█████▏    | 28/54 [00:18<00:14,  1.74it/s]\u001b[A\n",
      "Epoch 8:  99%|█████████▊| 1746/1770 [07:28<00:07,  3.00it/s, loss=0.12, v_num=7, val_loss=0.0587, val_acc=0.95, train_loss=0.0706]\n",
      "Validating:  56%|█████▌    | 30/54 [00:19<00:13,  1.74it/s]\u001b[A\n",
      "Epoch 8:  99%|█████████▉| 1748/1770 [07:30<00:07,  3.00it/s, loss=0.12, v_num=7, val_loss=0.0587, val_acc=0.95, train_loss=0.0706]\n",
      "Validating:  59%|█████▉    | 32/54 [00:20<00:12,  1.74it/s]\u001b[A\n",
      "Epoch 8:  99%|█████████▉| 1750/1770 [07:31<00:06,  2.99it/s, loss=0.12, v_num=7, val_loss=0.0587, val_acc=0.95, train_loss=0.0706]\n",
      "Validating:  63%|██████▎   | 34/54 [00:21<00:11,  1.74it/s]\u001b[A\n",
      "Epoch 8:  99%|█████████▉| 1752/1770 [07:32<00:06,  2.99it/s, loss=0.12, v_num=7, val_loss=0.0587, val_acc=0.95, train_loss=0.0706]\n",
      "Validating:  67%|██████▋   | 36/54 [00:22<00:10,  1.74it/s]\u001b[A\n",
      "Epoch 8:  99%|█████████▉| 1754/1770 [07:33<00:05,  2.99it/s, loss=0.12, v_num=7, val_loss=0.0587, val_acc=0.95, train_loss=0.0706]\n",
      "Validating:  70%|███████   | 38/54 [00:23<00:09,  1.74it/s]\u001b[A\n",
      "Epoch 8:  99%|█████████▉| 1756/1770 [07:34<00:04,  2.98it/s, loss=0.12, v_num=7, val_loss=0.0587, val_acc=0.95, train_loss=0.0706]\n",
      "Validating:  74%|███████▍  | 40/54 [00:25<00:08,  1.74it/s]\u001b[A\n",
      "Epoch 8:  99%|█████████▉| 1758/1770 [07:35<00:04,  2.98it/s, loss=0.12, v_num=7, val_loss=0.0587, val_acc=0.95, train_loss=0.0706]\n",
      "Validating:  78%|███████▊  | 42/54 [00:26<00:06,  1.74it/s]\u001b[A\n",
      "Epoch 8:  99%|█████████▉| 1760/1770 [07:37<00:03,  2.98it/s, loss=0.12, v_num=7, val_loss=0.0587, val_acc=0.95, train_loss=0.0706]\n",
      "Validating:  81%|████████▏ | 44/54 [00:27<00:05,  1.74it/s]\u001b[A\n",
      "Epoch 8: 100%|█████████▉| 1762/1770 [07:38<00:02,  2.98it/s, loss=0.12, v_num=7, val_loss=0.0587, val_acc=0.95, train_loss=0.0706]\n",
      "Validating:  85%|████████▌ | 46/54 [00:28<00:04,  1.77it/s]\u001b[A\n",
      "Epoch 8: 100%|█████████▉| 1764/1770 [07:39<00:02,  2.97it/s, loss=0.12, v_num=7, val_loss=0.0587, val_acc=0.95, train_loss=0.0706]\n",
      "Validating:  89%|████████▉ | 48/54 [00:29<00:03,  1.78it/s]\u001b[A\n",
      "Epoch 8: 100%|█████████▉| 1766/1770 [07:40<00:01,  2.97it/s, loss=0.12, v_num=7, val_loss=0.0587, val_acc=0.95, train_loss=0.0706]\n",
      "Validating:  93%|█████████▎| 50/54 [00:30<00:02,  1.79it/s]\u001b[A\n",
      "Epoch 8: 100%|█████████▉| 1768/1770 [07:41<00:00,  2.97it/s, loss=0.12, v_num=7, val_loss=0.0587, val_acc=0.95, train_loss=0.0706]\n",
      "Validating:  96%|█████████▋| 52/54 [00:31<00:01,  1.79it/s]\u001b[A\n",
      "Epoch 8: 100%|██████████| 1770/1770 [07:42<00:00,  2.96it/s, loss=0.12, v_num=7, val_loss=0.0587, val_acc=0.95, train_loss=0.0706]\n",
      "Validating: 100%|██████████| 54/54 [00:32<00:00,  2.03it/s]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8, step 3432: val_loss was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8: 100%|██████████| 1770/1770 [07:43<00:00,  2.96it/s, loss=0.12, v_num=7, val_loss=0.0572, val_acc=0.95, train_loss=0.148] \n",
      "Epoch 9:  34%|███▍      | 598/1770 [02:30<14:43,  1.33it/s, loss=0.122, v_num=7, val_loss=0.0572, val_acc=0.95, train_loss=0.0307]     "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12:  97%|█████████▋| 1716/1770 [07:10<00:17,  3.06it/s, loss=0.104, v_num=7, val_loss=0.0643, val_acc=0.949, train_loss=0.00604] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 12:  97%|█████████▋| 1718/1770 [07:12<00:17,  3.05it/s, loss=0.104, v_num=7, val_loss=0.0643, val_acc=0.949, train_loss=0.00604]\n",
      "Validating:   4%|▎         | 2/54 [00:03<01:13,  1.41s/it]\u001b[A\n",
      "Epoch 12:  97%|█████████▋| 1720/1770 [07:14<00:16,  3.04it/s, loss=0.104, v_num=7, val_loss=0.0643, val_acc=0.949, train_loss=0.00604]\n",
      "Validating:   7%|▋         | 4/54 [00:04<00:43,  1.15it/s]\u001b[A\n",
      "Epoch 12:  97%|█████████▋| 1722/1770 [07:15<00:15,  3.04it/s, loss=0.104, v_num=7, val_loss=0.0643, val_acc=0.949, train_loss=0.00604]\n",
      "Validating:  11%|█         | 6/54 [00:05<00:33,  1.43it/s]\u001b[A\n",
      "Epoch 12:  97%|█████████▋| 1724/1770 [07:16<00:15,  3.04it/s, loss=0.104, v_num=7, val_loss=0.0643, val_acc=0.949, train_loss=0.00604]\n",
      "Validating:  15%|█▍        | 8/54 [00:06<00:28,  1.59it/s]\u001b[A\n",
      "Epoch 12:  98%|█████████▊| 1726/1770 [07:17<00:14,  3.03it/s, loss=0.104, v_num=7, val_loss=0.0643, val_acc=0.949, train_loss=0.00604]\n",
      "Validating:  19%|█▊        | 10/54 [00:07<00:26,  1.67it/s]\u001b[A\n",
      "Epoch 12:  98%|█████████▊| 1728/1770 [07:18<00:13,  3.03it/s, loss=0.104, v_num=7, val_loss=0.0643, val_acc=0.949, train_loss=0.00604]\n",
      "Validating:  22%|██▏       | 12/54 [00:08<00:24,  1.71it/s]\u001b[A\n",
      "Epoch 12:  98%|█████████▊| 1730/1770 [07:19<00:13,  3.03it/s, loss=0.104, v_num=7, val_loss=0.0643, val_acc=0.949, train_loss=0.00604]\n",
      "Validating:  26%|██▌       | 14/54 [00:10<00:23,  1.72it/s]\u001b[A\n",
      "Epoch 12:  98%|█████████▊| 1732/1770 [07:20<00:12,  3.02it/s, loss=0.104, v_num=7, val_loss=0.0643, val_acc=0.949, train_loss=0.00604]\n",
      "Validating:  30%|██▉       | 16/54 [00:11<00:21,  1.73it/s]\u001b[A\n",
      "Epoch 12:  98%|█████████▊| 1734/1770 [07:22<00:11,  3.02it/s, loss=0.104, v_num=7, val_loss=0.0643, val_acc=0.949, train_loss=0.00604]\n",
      "Validating:  33%|███▎      | 18/54 [00:12<00:20,  1.73it/s]\u001b[A\n",
      "Epoch 12:  98%|█████████▊| 1736/1770 [07:23<00:11,  3.02it/s, loss=0.104, v_num=7, val_loss=0.0643, val_acc=0.949, train_loss=0.00604]\n",
      "Validating:  37%|███▋      | 20/54 [00:13<00:19,  1.74it/s]\u001b[A\n",
      "Epoch 12:  98%|█████████▊| 1738/1770 [07:24<00:10,  3.01it/s, loss=0.104, v_num=7, val_loss=0.0643, val_acc=0.949, train_loss=0.00604]\n",
      "Validating:  41%|████      | 22/54 [00:14<00:18,  1.74it/s]\u001b[A\n",
      "Epoch 12:  98%|█████████▊| 1740/1770 [07:25<00:09,  3.01it/s, loss=0.104, v_num=7, val_loss=0.0643, val_acc=0.949, train_loss=0.00604]\n",
      "Validating:  44%|████▍     | 24/54 [00:15<00:17,  1.74it/s]\u001b[A\n",
      "Epoch 12:  98%|█████████▊| 1742/1770 [07:26<00:09,  3.01it/s, loss=0.104, v_num=7, val_loss=0.0643, val_acc=0.949, train_loss=0.00604]\n",
      "Validating:  48%|████▊     | 26/54 [00:16<00:16,  1.74it/s]\u001b[A\n",
      "Epoch 12:  99%|█████████▊| 1744/1770 [07:27<00:08,  3.00it/s, loss=0.104, v_num=7, val_loss=0.0643, val_acc=0.949, train_loss=0.00604]\n",
      "Validating:  52%|█████▏    | 28/54 [00:18<00:14,  1.74it/s]\u001b[A\n",
      "Epoch 12:  99%|█████████▊| 1746/1770 [07:29<00:08,  3.00it/s, loss=0.104, v_num=7, val_loss=0.0643, val_acc=0.949, train_loss=0.00604]\n",
      "Validating:  56%|█████▌    | 30/54 [00:19<00:13,  1.74it/s]\u001b[A\n",
      "Epoch 12:  99%|█████████▉| 1748/1770 [07:30<00:07,  3.00it/s, loss=0.104, v_num=7, val_loss=0.0643, val_acc=0.949, train_loss=0.00604]\n",
      "Validating:  59%|█████▉    | 32/54 [00:20<00:12,  1.74it/s]\u001b[A\n",
      "Epoch 12:  99%|█████████▉| 1750/1770 [07:31<00:06,  2.99it/s, loss=0.104, v_num=7, val_loss=0.0643, val_acc=0.949, train_loss=0.00604]\n",
      "Validating:  63%|██████▎   | 34/54 [00:21<00:11,  1.74it/s]\u001b[A\n",
      "Epoch 12:  99%|█████████▉| 1752/1770 [07:32<00:06,  2.99it/s, loss=0.104, v_num=7, val_loss=0.0643, val_acc=0.949, train_loss=0.00604]\n",
      "Validating:  67%|██████▋   | 36/54 [00:22<00:10,  1.74it/s]\u001b[A\n",
      "Epoch 12:  99%|█████████▉| 1754/1770 [07:33<00:05,  2.99it/s, loss=0.104, v_num=7, val_loss=0.0643, val_acc=0.949, train_loss=0.00604]\n",
      "Validating:  70%|███████   | 38/54 [00:23<00:09,  1.74it/s]\u001b[A\n",
      "Epoch 12:  99%|█████████▉| 1756/1770 [07:34<00:04,  2.98it/s, loss=0.104, v_num=7, val_loss=0.0643, val_acc=0.949, train_loss=0.00604]\n",
      "Validating:  74%|███████▍  | 40/54 [00:24<00:08,  1.74it/s]\u001b[A\n",
      "Epoch 12:  99%|█████████▉| 1758/1770 [07:35<00:04,  2.98it/s, loss=0.104, v_num=7, val_loss=0.0643, val_acc=0.949, train_loss=0.00604]\n",
      "Validating:  78%|███████▊  | 42/54 [00:26<00:06,  1.74it/s]\u001b[A\n",
      "Epoch 12:  99%|█████████▉| 1760/1770 [07:37<00:03,  2.98it/s, loss=0.104, v_num=7, val_loss=0.0643, val_acc=0.949, train_loss=0.00604]\n",
      "Validating:  81%|████████▏ | 44/54 [00:27<00:05,  1.74it/s]\u001b[A\n",
      "Epoch 12: 100%|█████████▉| 1762/1770 [07:38<00:02,  2.97it/s, loss=0.104, v_num=7, val_loss=0.0643, val_acc=0.949, train_loss=0.00604]\n",
      "Validating:  85%|████████▌ | 46/54 [00:28<00:04,  1.77it/s]\u001b[A\n",
      "Epoch 12: 100%|█████████▉| 1764/1770 [07:39<00:02,  2.97it/s, loss=0.104, v_num=7, val_loss=0.0643, val_acc=0.949, train_loss=0.00604]\n",
      "Validating:  89%|████████▉ | 48/54 [00:29<00:03,  1.78it/s]\u001b[A\n",
      "Epoch 12: 100%|█████████▉| 1766/1770 [07:40<00:01,  2.97it/s, loss=0.104, v_num=7, val_loss=0.0643, val_acc=0.949, train_loss=0.00604]\n",
      "Validating:  93%|█████████▎| 50/54 [00:30<00:02,  1.79it/s]\u001b[A\n",
      "Epoch 12: 100%|█████████▉| 1768/1770 [07:41<00:00,  2.97it/s, loss=0.104, v_num=7, val_loss=0.0643, val_acc=0.949, train_loss=0.00604]\n",
      "Validating:  96%|█████████▋| 52/54 [00:31<00:01,  1.79it/s]\u001b[A\n",
      "Epoch 12: 100%|██████████| 1770/1770 [07:42<00:00,  2.96it/s, loss=0.104, v_num=7, val_loss=0.0643, val_acc=0.949, train_loss=0.00604]\n",
      "Validating: 100%|██████████| 54/54 [00:32<00:00,  2.03it/s]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12, step 5148: val_loss was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12: 100%|██████████| 1770/1770 [07:43<00:00,  2.96it/s, loss=0.104, v_num=7, val_loss=0.065, val_acc=0.948, train_loss=0.0214]  \n",
      "                                                           \u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer was signaled to stop but required minimum epochs (15) or minimum steps (None) has not been met. Training will continue...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13:   0%|          | 2/1770 [00:00<-1:59:58, -603.67it/s, loss=0.104, v_num=7, val_loss=0.065, val_acc=0.948, train_loss=0.0214] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   2%|▏         | 1/54 [00:02<01:47,  2.04s/it]\u001b[A\n",
      "Epoch 13:   0%|          | 4/1770 [00:03<-1:59:46, -118.14it/s, loss=0.104, v_num=7, val_loss=0.065, val_acc=0.948, train_loss=0.0214]\n",
      "Validating:   6%|▌         | 3/54 [00:03<00:48,  1.05it/s]\u001b[A\n",
      "Epoch 13:   0%|          | 6/1770 [00:04<-1:59:40, -85.80it/s, loss=0.104, v_num=7, val_loss=0.065, val_acc=0.948, train_loss=0.0214] \n",
      "Validating:   9%|▉         | 5/54 [00:04<00:35,  1.38it/s]\u001b[A\n",
      "Epoch 13:   0%|          | 8/1770 [00:05<-1:59:35, -68.25it/s, loss=0.104, v_num=7, val_loss=0.065, val_acc=0.948, train_loss=0.0214]\n",
      "Validating:  13%|█▎        | 7/54 [00:05<00:30,  1.56it/s]\u001b[A\n",
      "Epoch 13:   1%|          | 10/1770 [00:06<-1:59:29, -56.55it/s, loss=0.104, v_num=7, val_loss=0.065, val_acc=0.948, train_loss=0.0214]\n",
      "Validating:  17%|█▋        | 9/54 [00:06<00:27,  1.65it/s]\u001b[A\n",
      "Epoch 13:   1%|          | 12/1770 [00:08<-1:59:24, -48.19it/s, loss=0.104, v_num=7, val_loss=0.065, val_acc=0.948, train_loss=0.0214]\n",
      "Validating:  20%|██        | 11/54 [00:07<00:25,  1.69it/s]\u001b[A\n",
      "Epoch 13:   1%|          | 14/1770 [00:09<-1:59:19, -41.94it/s, loss=0.104, v_num=7, val_loss=0.065, val_acc=0.948, train_loss=0.0214]\n",
      "Validating:  24%|██▍       | 13/54 [00:09<00:23,  1.71it/s]\u001b[A\n",
      "Epoch 13:   1%|          | 16/1770 [00:10<-1:59:13, -37.06it/s, loss=0.104, v_num=7, val_loss=0.065, val_acc=0.948, train_loss=0.0214]\n",
      "Validating:  28%|██▊       | 15/54 [00:10<00:22,  1.73it/s]\u001b[A\n",
      "Epoch 13:   1%|          | 18/1770 [00:11<-1:59:08, -33.17it/s, loss=0.104, v_num=7, val_loss=0.065, val_acc=0.948, train_loss=0.0214]\n",
      "Validating:  31%|███▏      | 17/54 [00:11<00:21,  1.73it/s]\u001b[A\n",
      "Epoch 13:   1%|          | 20/1770 [00:12<-1:59:02, -29.99it/s, loss=0.104, v_num=7, val_loss=0.065, val_acc=0.948, train_loss=0.0214]\n",
      "Validating:  35%|███▌      | 19/54 [00:12<00:20,  1.73it/s]\u001b[A\n",
      "Epoch 13:   1%|          | 22/1770 [00:13<-1:58:57, -27.33it/s, loss=0.104, v_num=7, val_loss=0.065, val_acc=0.948, train_loss=0.0214]\n",
      "Validating:  39%|███▉      | 21/54 [00:13<00:19,  1.73it/s]\u001b[A\n",
      "Epoch 13:   1%|▏         | 24/1770 [00:14<-1:58:51, -25.09it/s, loss=0.104, v_num=7, val_loss=0.065, val_acc=0.948, train_loss=0.0214]\n",
      "Validating:  43%|████▎     | 23/54 [00:14<00:17,  1.73it/s]\u001b[A\n",
      "Epoch 13:   1%|▏         | 26/1770 [00:16<-1:58:45, -23.15it/s, loss=0.104, v_num=7, val_loss=0.065, val_acc=0.948, train_loss=0.0214]\n",
      "Validating:  46%|████▋     | 25/54 [00:16<00:16,  1.73it/s]\u001b[A\n",
      "Epoch 13:   2%|▏         | 28/1770 [00:17<-1:58:39, -21.49it/s, loss=0.104, v_num=7, val_loss=0.065, val_acc=0.948, train_loss=0.0214]\n",
      "Validating:  50%|█████     | 27/54 [00:17<00:15,  1.72it/s]\u001b[A\n",
      "Epoch 13:   2%|▏         | 30/1770 [00:18<-1:58:34, -20.03it/s, loss=0.104, v_num=7, val_loss=0.065, val_acc=0.948, train_loss=0.0214]\n",
      "Validating:  54%|█████▎    | 29/54 [00:18<00:14,  1.73it/s]\u001b[A\n",
      "Epoch 13:   2%|▏         | 32/1770 [00:19<-1:58:28, -18.74it/s, loss=0.104, v_num=7, val_loss=0.065, val_acc=0.948, train_loss=0.0214]\n",
      "Validating:  57%|█████▋    | 31/54 [00:19<00:13,  1.73it/s]\u001b[A\n",
      "Epoch 13:   2%|▏         | 34/1770 [00:20<-1:58:22, -17.60it/s, loss=0.104, v_num=7, val_loss=0.065, val_acc=0.948, train_loss=0.0214]\n",
      "Validating:  61%|██████    | 33/54 [00:20<00:12,  1.73it/s]\u001b[A\n",
      "Epoch 13:   2%|▏         | 36/1770 [00:21<-1:58:16, -16.58it/s, loss=0.104, v_num=7, val_loss=0.065, val_acc=0.948, train_loss=0.0214]\n",
      "Validating:  65%|██████▍   | 35/54 [00:21<00:10,  1.73it/s]\u001b[A\n",
      "Epoch 13:   2%|▏         | 38/1770 [00:23<-1:58:10, -15.66it/s, loss=0.104, v_num=7, val_loss=0.065, val_acc=0.948, train_loss=0.0214]\n",
      "Validating:  69%|██████▊   | 37/54 [00:22<00:09,  1.73it/s]\u001b[A\n",
      "Epoch 13:   2%|▏         | 40/1770 [00:24<-1:58:04, -14.83it/s, loss=0.104, v_num=7, val_loss=0.065, val_acc=0.948, train_loss=0.0214]\n",
      "Validating:  72%|███████▏  | 39/54 [00:24<00:08,  1.73it/s]\u001b[A\n",
      "Epoch 13:   2%|▏         | 42/1770 [00:25<-1:57:58, -14.08it/s, loss=0.104, v_num=7, val_loss=0.065, val_acc=0.948, train_loss=0.0214]\n",
      "Validating:  76%|███████▌  | 41/54 [00:25<00:07,  1.73it/s]\u001b[A\n",
      "Epoch 13:   2%|▏         | 44/1770 [00:26<-1:57:52, -13.39it/s, loss=0.104, v_num=7, val_loss=0.065, val_acc=0.948, train_loss=0.0214]\n",
      "Validating:  80%|███████▉  | 43/54 [00:26<00:06,  1.73it/s]\u001b[A\n",
      "Epoch 13:   3%|▎         | 46/1770 [00:27<-1:57:45, -12.76it/s, loss=0.104, v_num=7, val_loss=0.065, val_acc=0.948, train_loss=0.0214]\n",
      "Validating:  83%|████████▎ | 45/54 [00:27<00:05,  1.75it/s]\u001b[A\n",
      "Epoch 13:   3%|▎         | 48/1770 [00:28<-1:57:39, -12.19it/s, loss=0.104, v_num=7, val_loss=0.065, val_acc=0.948, train_loss=0.0214]\n",
      "Validating:  87%|████████▋ | 47/54 [00:28<00:03,  1.77it/s]\u001b[A\n",
      "Epoch 13:   3%|▎         | 50/1770 [00:29<-1:57:33, -11.67it/s, loss=0.104, v_num=7, val_loss=0.065, val_acc=0.948, train_loss=0.0214]\n",
      "Validating:  91%|█████████ | 49/54 [00:29<00:02,  1.78it/s]\u001b[A\n",
      "Epoch 13:   3%|▎         | 52/1770 [00:31<-1:57:27, -11.19it/s, loss=0.104, v_num=7, val_loss=0.065, val_acc=0.948, train_loss=0.0214]\n",
      "Validating:  94%|█████████▍| 51/54 [00:30<00:01,  1.79it/s]\u001b[A\n",
      "Epoch 13:   3%|▎         | 54/1770 [00:32<-1:57:21, -10.74it/s, loss=0.104, v_num=7, val_loss=0.065, val_acc=0.948, train_loss=0.0214]\n",
      "Validating:  98%|█████████▊| 53/54 [00:32<00:00,  1.79it/s]\u001b[A\n",
      "Epoch 13:   3%|▎         | 56/1770 [00:33<-1:57:15, -10.38it/s, loss=0.104, v_num=7, val_loss=0.065, val_acc=0.948, train_loss=0.0214]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13, step 5149: val_loss was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13:   3%|▎         | 56/1770 [00:33<-1:57:15, -10.35it/s, loss=0.104, v_num=7, val_loss=0.0668, val_acc=0.945, train_loss=0.118]\n",
      "                                                           \u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer was signaled to stop but required minimum epochs (15) or minimum steps (None) has not been met. Training will continue...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14:   0%|          | 2/1770 [00:00<-1:59:58, -589.92it/s, loss=0.104, v_num=7, val_loss=0.0668, val_acc=0.945, train_loss=0.118]  \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   2%|▏         | 1/54 [00:02<01:59,  2.25s/it]\u001b[A\n",
      "Epoch 14:   0%|          | 4/1770 [00:03<-1:59:44, -109.77it/s, loss=0.104, v_num=7, val_loss=0.0668, val_acc=0.945, train_loss=0.118]\n",
      "Validating:   6%|▌         | 3/54 [00:03<00:50,  1.01it/s]\u001b[A\n",
      "Epoch 14:   0%|          | 6/1770 [00:04<-1:59:39, -82.09it/s, loss=0.104, v_num=7, val_loss=0.0668, val_acc=0.945, train_loss=0.118] \n",
      "Validating:   9%|▉         | 5/54 [00:04<00:36,  1.35it/s]\u001b[A\n",
      "Epoch 14:   0%|          | 8/1770 [00:05<-1:59:34, -65.83it/s, loss=0.104, v_num=7, val_loss=0.0668, val_acc=0.945, train_loss=0.118]\n",
      "Validating:  13%|█▎        | 7/54 [00:05<00:30,  1.54it/s]\u001b[A\n",
      "Epoch 14:   1%|          | 10/1770 [00:07<-1:59:28, -54.87it/s, loss=0.104, v_num=7, val_loss=0.0668, val_acc=0.945, train_loss=0.118]\n",
      "Validating:  17%|█▋        | 9/54 [00:06<00:27,  1.64it/s]\u001b[A\n",
      "Epoch 14:   1%|          | 12/1770 [00:08<-1:59:23, -46.96it/s, loss=0.104, v_num=7, val_loss=0.0668, val_acc=0.945, train_loss=0.118]\n",
      "Validating:  20%|██        | 11/54 [00:08<00:25,  1.68it/s]\u001b[A\n",
      "Epoch 14:   1%|          | 14/1770 [00:09<-1:59:18, -40.96it/s, loss=0.104, v_num=7, val_loss=0.0668, val_acc=0.945, train_loss=0.118]\n",
      "Validating:  24%|██▍       | 13/54 [00:09<00:23,  1.71it/s]\u001b[A\n",
      "Epoch 14:   1%|          | 16/1770 [00:10<-1:59:12, -36.29it/s, loss=0.104, v_num=7, val_loss=0.0668, val_acc=0.945, train_loss=0.118]\n",
      "Validating:  28%|██▊       | 15/54 [00:10<00:22,  1.72it/s]\u001b[A\n",
      "Epoch 14:   1%|          | 18/1770 [00:11<-1:59:07, -32.53it/s, loss=0.104, v_num=7, val_loss=0.0668, val_acc=0.945, train_loss=0.118]\n",
      "Validating:  31%|███▏      | 17/54 [00:11<00:21,  1.73it/s]\u001b[A\n",
      "Epoch 14:   1%|          | 20/1770 [00:12<-1:59:01, -29.47it/s, loss=0.104, v_num=7, val_loss=0.0668, val_acc=0.945, train_loss=0.118]\n",
      "Validating:  35%|███▌      | 19/54 [00:12<00:20,  1.73it/s]\u001b[A\n",
      "Epoch 14:   1%|          | 22/1770 [00:14<-1:58:56, -26.91it/s, loss=0.104, v_num=7, val_loss=0.0668, val_acc=0.945, train_loss=0.118]\n",
      "Validating:  39%|███▉      | 21/54 [00:13<00:19,  1.74it/s]\u001b[A\n",
      "Epoch 14:   1%|▏         | 24/1770 [00:15<-1:58:50, -24.73it/s, loss=0.104, v_num=7, val_loss=0.0668, val_acc=0.945, train_loss=0.118]\n",
      "Validating:  43%|████▎     | 23/54 [00:15<00:17,  1.74it/s]\u001b[A\n",
      "Epoch 14:   1%|▏         | 26/1770 [00:16<-1:58:44, -22.87it/s, loss=0.104, v_num=7, val_loss=0.0668, val_acc=0.945, train_loss=0.118]\n",
      "Validating:  46%|████▋     | 25/54 [00:16<00:16,  1.74it/s]\u001b[A\n",
      "Epoch 14:   2%|▏         | 28/1770 [00:17<-1:58:38, -21.23it/s, loss=0.104, v_num=7, val_loss=0.0668, val_acc=0.945, train_loss=0.118]\n",
      "Validating:  50%|█████     | 27/54 [00:17<00:15,  1.73it/s]\u001b[A\n",
      "Epoch 14:   2%|▏         | 30/1770 [00:18<-1:58:33, -19.81it/s, loss=0.104, v_num=7, val_loss=0.0668, val_acc=0.945, train_loss=0.118]\n",
      "Validating:  54%|█████▎    | 29/54 [00:18<00:14,  1.74it/s]\u001b[A\n",
      "Epoch 14:   2%|▏         | 32/1770 [00:19<-1:58:27, -18.56it/s, loss=0.104, v_num=7, val_loss=0.0668, val_acc=0.945, train_loss=0.118]\n",
      "Validating:  57%|█████▋    | 31/54 [00:19<00:13,  1.73it/s]\u001b[A\n",
      "Epoch 14:   2%|▏         | 34/1770 [00:20<-1:58:21, -17.44it/s, loss=0.104, v_num=7, val_loss=0.0668, val_acc=0.945, train_loss=0.118]\n",
      "Validating:  61%|██████    | 33/54 [00:20<00:12,  1.74it/s]\u001b[A\n",
      "Epoch 14:   2%|▏         | 36/1770 [00:22<-1:58:15, -16.44it/s, loss=0.104, v_num=7, val_loss=0.0668, val_acc=0.945, train_loss=0.118]\n",
      "Validating:  65%|██████▍   | 35/54 [00:21<00:10,  1.73it/s]\u001b[A\n",
      "Epoch 14:   2%|▏         | 38/1770 [00:23<-1:58:09, -15.53it/s, loss=0.104, v_num=7, val_loss=0.0668, val_acc=0.945, train_loss=0.118]\n",
      "Validating:  69%|██████▊   | 37/54 [00:23<00:09,  1.73it/s]\u001b[A\n",
      "Epoch 14:   2%|▏         | 40/1770 [00:24<-1:58:03, -14.72it/s, loss=0.104, v_num=7, val_loss=0.0668, val_acc=0.945, train_loss=0.118]\n",
      "Validating:  72%|███████▏  | 39/54 [00:24<00:08,  1.73it/s]\u001b[A\n",
      "Epoch 14:   2%|▏         | 42/1770 [00:25<-1:57:57, -13.98it/s, loss=0.104, v_num=7, val_loss=0.0668, val_acc=0.945, train_loss=0.118]\n",
      "Validating:  76%|███████▌  | 41/54 [00:25<00:07,  1.74it/s]\u001b[A\n",
      "Epoch 14:   2%|▏         | 44/1770 [00:26<-1:57:51, -13.30it/s, loss=0.104, v_num=7, val_loss=0.0668, val_acc=0.945, train_loss=0.118]\n",
      "Validating:  80%|███████▉  | 43/54 [00:26<00:06,  1.74it/s]\u001b[A\n",
      "Epoch 14:   3%|▎         | 46/1770 [00:27<-1:57:45, -12.68it/s, loss=0.104, v_num=7, val_loss=0.0668, val_acc=0.945, train_loss=0.118]\n",
      "Validating:  83%|████████▎ | 45/54 [00:27<00:05,  1.75it/s]\u001b[A\n",
      "Epoch 14:   3%|▎         | 48/1770 [00:28<-1:57:38, -12.12it/s, loss=0.104, v_num=7, val_loss=0.0668, val_acc=0.945, train_loss=0.118]\n",
      "Validating:  87%|████████▋ | 47/54 [00:28<00:03,  1.77it/s]\u001b[A\n",
      "Epoch 14:   3%|▎         | 50/1770 [00:30<-1:57:32, -11.61it/s, loss=0.104, v_num=7, val_loss=0.0668, val_acc=0.945, train_loss=0.118]\n",
      "Validating:  91%|█████████ | 49/54 [00:29<00:02,  1.78it/s]\u001b[A\n",
      "Epoch 14:   3%|▎         | 52/1770 [00:31<-1:57:26, -11.13it/s, loss=0.104, v_num=7, val_loss=0.0668, val_acc=0.945, train_loss=0.118]\n",
      "Validating:  94%|█████████▍| 51/54 [00:31<00:01,  1.79it/s]\u001b[A\n",
      "Epoch 14:   3%|▎         | 54/1770 [00:32<-1:57:20, -10.68it/s, loss=0.104, v_num=7, val_loss=0.0668, val_acc=0.945, train_loss=0.118]\n",
      "Validating:  98%|█████████▊| 53/54 [00:32<00:00,  1.79it/s]\u001b[A\n",
      "Epoch 14:   3%|▎         | 56/1770 [00:33<-1:57:14, -10.30it/s, loss=0.104, v_num=7, val_loss=0.0666, val_acc=0.946, train_loss=0.00989]\n",
      "                                                           \u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: None, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training fold 3\n",
      "Class sample counts [ 675 1382 1482 8725 1462]\n",
      "After class sample counts [2025 2764 3408 8725 3947]\n",
      "conv_stem.weight True\n",
      "bn1.weight False\n",
      "bn1.bias False\n",
      "blocks.0.0.conv_dw.weight True\n",
      "blocks.0.0.bn1.weight False\n",
      "blocks.0.0.bn1.bias False\n",
      "blocks.0.0.se.conv_reduce.weight True\n",
      "blocks.0.0.se.conv_reduce.bias True\n",
      "blocks.0.0.se.conv_expand.weight True\n",
      "blocks.0.0.se.conv_expand.bias True\n",
      "blocks.0.0.conv_pw.weight True\n",
      "blocks.0.0.bn2.weight False\n",
      "blocks.0.0.bn2.bias False\n",
      "blocks.0.1.conv_dw.weight True\n",
      "blocks.0.1.bn1.weight False\n",
      "blocks.0.1.bn1.bias False\n",
      "blocks.0.1.se.conv_reduce.weight True\n",
      "blocks.0.1.se.conv_reduce.bias True\n",
      "blocks.0.1.se.conv_expand.weight True\n",
      "blocks.0.1.se.conv_expand.bias True\n",
      "blocks.0.1.conv_pw.weight True\n",
      "blocks.0.1.bn2.weight False\n",
      "blocks.0.1.bn2.bias False\n",
      "blocks.1.0.conv_pw.weight True\n",
      "blocks.1.0.bn1.weight False\n",
      "blocks.1.0.bn1.bias False\n",
      "blocks.1.0.conv_dw.weight True\n",
      "blocks.1.0.bn2.weight False\n",
      "blocks.1.0.bn2.bias False\n",
      "blocks.1.0.se.conv_reduce.weight True\n",
      "blocks.1.0.se.conv_reduce.bias True\n",
      "blocks.1.0.se.conv_expand.weight True\n",
      "blocks.1.0.se.conv_expand.bias True\n",
      "blocks.1.0.conv_pwl.weight True\n",
      "blocks.1.0.bn3.weight False\n",
      "blocks.1.0.bn3.bias False\n",
      "blocks.1.1.conv_pw.weight True\n",
      "blocks.1.1.bn1.weight False\n",
      "blocks.1.1.bn1.bias False\n",
      "blocks.1.1.conv_dw.weight True\n",
      "blocks.1.1.bn2.weight False\n",
      "blocks.1.1.bn2.bias False\n",
      "blocks.1.1.se.conv_reduce.weight True\n",
      "blocks.1.1.se.conv_reduce.bias True\n",
      "blocks.1.1.se.conv_expand.weight True\n",
      "blocks.1.1.se.conv_expand.bias True\n",
      "blocks.1.1.conv_pwl.weight True\n",
      "blocks.1.1.bn3.weight False\n",
      "blocks.1.1.bn3.bias False\n",
      "blocks.1.2.conv_pw.weight True\n",
      "blocks.1.2.bn1.weight False\n",
      "blocks.1.2.bn1.bias False\n",
      "blocks.1.2.conv_dw.weight True\n",
      "blocks.1.2.bn2.weight False\n",
      "blocks.1.2.bn2.bias False\n",
      "blocks.1.2.se.conv_reduce.weight True\n",
      "blocks.1.2.se.conv_reduce.bias True\n",
      "blocks.1.2.se.conv_expand.weight True\n",
      "blocks.1.2.se.conv_expand.bias True\n",
      "blocks.1.2.conv_pwl.weight True\n",
      "blocks.1.2.bn3.weight False\n",
      "blocks.1.2.bn3.bias False\n",
      "blocks.1.3.conv_pw.weight True\n",
      "blocks.1.3.bn1.weight False\n",
      "blocks.1.3.bn1.bias False\n",
      "blocks.1.3.conv_dw.weight True\n",
      "blocks.1.3.bn2.weight False\n",
      "blocks.1.3.bn2.bias False\n",
      "blocks.1.3.se.conv_reduce.weight True\n",
      "blocks.1.3.se.conv_reduce.bias True\n",
      "blocks.1.3.se.conv_expand.weight True\n",
      "blocks.1.3.se.conv_expand.bias True\n",
      "blocks.1.3.conv_pwl.weight True\n",
      "blocks.1.3.bn3.weight False\n",
      "blocks.1.3.bn3.bias False\n",
      "blocks.2.0.conv_pw.weight True\n",
      "blocks.2.0.bn1.weight False\n",
      "blocks.2.0.bn1.bias False\n",
      "blocks.2.0.conv_dw.weight True\n",
      "blocks.2.0.bn2.weight False\n",
      "blocks.2.0.bn2.bias False\n",
      "blocks.2.0.se.conv_reduce.weight True\n",
      "blocks.2.0.se.conv_reduce.bias True\n",
      "blocks.2.0.se.conv_expand.weight True\n",
      "blocks.2.0.se.conv_expand.bias True\n",
      "blocks.2.0.conv_pwl.weight True\n",
      "blocks.2.0.bn3.weight False\n",
      "blocks.2.0.bn3.bias False\n",
      "blocks.2.1.conv_pw.weight True\n",
      "blocks.2.1.bn1.weight False\n",
      "blocks.2.1.bn1.bias False\n",
      "blocks.2.1.conv_dw.weight True\n",
      "blocks.2.1.bn2.weight False\n",
      "blocks.2.1.bn2.bias False\n",
      "blocks.2.1.se.conv_reduce.weight True\n",
      "blocks.2.1.se.conv_reduce.bias True\n",
      "blocks.2.1.se.conv_expand.weight True\n",
      "blocks.2.1.se.conv_expand.bias True\n",
      "blocks.2.1.conv_pwl.weight True\n",
      "blocks.2.1.bn3.weight False\n",
      "blocks.2.1.bn3.bias False\n",
      "blocks.2.2.conv_pw.weight True\n",
      "blocks.2.2.bn1.weight False\n",
      "blocks.2.2.bn1.bias False\n",
      "blocks.2.2.conv_dw.weight True\n",
      "blocks.2.2.bn2.weight False\n",
      "blocks.2.2.bn2.bias False\n",
      "blocks.2.2.se.conv_reduce.weight True\n",
      "blocks.2.2.se.conv_reduce.bias True\n",
      "blocks.2.2.se.conv_expand.weight True\n",
      "blocks.2.2.se.conv_expand.bias True\n",
      "blocks.2.2.conv_pwl.weight True\n",
      "blocks.2.2.bn3.weight False\n",
      "blocks.2.2.bn3.bias False\n",
      "blocks.2.3.conv_pw.weight True\n",
      "blocks.2.3.bn1.weight False\n",
      "blocks.2.3.bn1.bias False\n",
      "blocks.2.3.conv_dw.weight True\n",
      "blocks.2.3.bn2.weight False\n",
      "blocks.2.3.bn2.bias False\n",
      "blocks.2.3.se.conv_reduce.weight True\n",
      "blocks.2.3.se.conv_reduce.bias True\n",
      "blocks.2.3.se.conv_expand.weight True\n",
      "blocks.2.3.se.conv_expand.bias True\n",
      "blocks.2.3.conv_pwl.weight True\n",
      "blocks.2.3.bn3.weight False\n",
      "blocks.2.3.bn3.bias False\n",
      "blocks.3.0.conv_pw.weight True\n",
      "blocks.3.0.bn1.weight False\n",
      "blocks.3.0.bn1.bias False\n",
      "blocks.3.0.conv_dw.weight True\n",
      "blocks.3.0.bn2.weight False\n",
      "blocks.3.0.bn2.bias False\n",
      "blocks.3.0.se.conv_reduce.weight True\n",
      "blocks.3.0.se.conv_reduce.bias True\n",
      "blocks.3.0.se.conv_expand.weight True\n",
      "blocks.3.0.se.conv_expand.bias True\n",
      "blocks.3.0.conv_pwl.weight True\n",
      "blocks.3.0.bn3.weight False\n",
      "blocks.3.0.bn3.bias False\n",
      "blocks.3.1.conv_pw.weight True\n",
      "blocks.3.1.bn1.weight False\n",
      "blocks.3.1.bn1.bias False\n",
      "blocks.3.1.conv_dw.weight True\n",
      "blocks.3.1.bn2.weight False\n",
      "blocks.3.1.bn2.bias False\n",
      "blocks.3.1.se.conv_reduce.weight True\n",
      "blocks.3.1.se.conv_reduce.bias True\n",
      "blocks.3.1.se.conv_expand.weight True\n",
      "blocks.3.1.se.conv_expand.bias True\n",
      "blocks.3.1.conv_pwl.weight True\n",
      "blocks.3.1.bn3.weight False\n",
      "blocks.3.1.bn3.bias False\n",
      "blocks.3.2.conv_pw.weight True\n",
      "blocks.3.2.bn1.weight False\n",
      "blocks.3.2.bn1.bias False\n",
      "blocks.3.2.conv_dw.weight True\n",
      "blocks.3.2.bn2.weight False\n",
      "blocks.3.2.bn2.bias False\n",
      "blocks.3.2.se.conv_reduce.weight True\n",
      "blocks.3.2.se.conv_reduce.bias True\n",
      "blocks.3.2.se.conv_expand.weight True\n",
      "blocks.3.2.se.conv_expand.bias True\n",
      "blocks.3.2.conv_pwl.weight True\n",
      "blocks.3.2.bn3.weight False\n",
      "blocks.3.2.bn3.bias False\n",
      "blocks.3.3.conv_pw.weight True\n",
      "blocks.3.3.bn1.weight False\n",
      "blocks.3.3.bn1.bias False\n",
      "blocks.3.3.conv_dw.weight True\n",
      "blocks.3.3.bn2.weight False\n",
      "blocks.3.3.bn2.bias False\n",
      "blocks.3.3.se.conv_reduce.weight True\n",
      "blocks.3.3.se.conv_reduce.bias True\n",
      "blocks.3.3.se.conv_expand.weight True\n",
      "blocks.3.3.se.conv_expand.bias True\n",
      "blocks.3.3.conv_pwl.weight True\n",
      "blocks.3.3.bn3.weight False\n",
      "blocks.3.3.bn3.bias False\n",
      "blocks.3.4.conv_pw.weight True\n",
      "blocks.3.4.bn1.weight False\n",
      "blocks.3.4.bn1.bias False\n",
      "blocks.3.4.conv_dw.weight True\n",
      "blocks.3.4.bn2.weight False\n",
      "blocks.3.4.bn2.bias False\n",
      "blocks.3.4.se.conv_reduce.weight True\n",
      "blocks.3.4.se.conv_reduce.bias True\n",
      "blocks.3.4.se.conv_expand.weight True\n",
      "blocks.3.4.se.conv_expand.bias True\n",
      "blocks.3.4.conv_pwl.weight True\n",
      "blocks.3.4.bn3.weight False\n",
      "blocks.3.4.bn3.bias False\n",
      "blocks.3.5.conv_pw.weight True\n",
      "blocks.3.5.bn1.weight False\n",
      "blocks.3.5.bn1.bias False\n",
      "blocks.3.5.conv_dw.weight True\n",
      "blocks.3.5.bn2.weight False\n",
      "blocks.3.5.bn2.bias False\n",
      "blocks.3.5.se.conv_reduce.weight True\n",
      "blocks.3.5.se.conv_reduce.bias True\n",
      "blocks.3.5.se.conv_expand.weight True\n",
      "blocks.3.5.se.conv_expand.bias True\n",
      "blocks.3.5.conv_pwl.weight True\n",
      "blocks.3.5.bn3.weight False\n",
      "blocks.3.5.bn3.bias False\n",
      "blocks.4.0.conv_pw.weight True\n",
      "blocks.4.0.bn1.weight False\n",
      "blocks.4.0.bn1.bias False\n",
      "blocks.4.0.conv_dw.weight True\n",
      "blocks.4.0.bn2.weight False\n",
      "blocks.4.0.bn2.bias False\n",
      "blocks.4.0.se.conv_reduce.weight True\n",
      "blocks.4.0.se.conv_reduce.bias True\n",
      "blocks.4.0.se.conv_expand.weight True\n",
      "blocks.4.0.se.conv_expand.bias True\n",
      "blocks.4.0.conv_pwl.weight True\n",
      "blocks.4.0.bn3.weight False\n",
      "blocks.4.0.bn3.bias False\n",
      "blocks.4.1.conv_pw.weight True\n",
      "blocks.4.1.bn1.weight False\n",
      "blocks.4.1.bn1.bias False\n",
      "blocks.4.1.conv_dw.weight True\n",
      "blocks.4.1.bn2.weight False\n",
      "blocks.4.1.bn2.bias False\n",
      "blocks.4.1.se.conv_reduce.weight True\n",
      "blocks.4.1.se.conv_reduce.bias True\n",
      "blocks.4.1.se.conv_expand.weight True\n",
      "blocks.4.1.se.conv_expand.bias True\n",
      "blocks.4.1.conv_pwl.weight True\n",
      "blocks.4.1.bn3.weight False\n",
      "blocks.4.1.bn3.bias False\n",
      "blocks.4.2.conv_pw.weight True\n",
      "blocks.4.2.bn1.weight False\n",
      "blocks.4.2.bn1.bias False\n",
      "blocks.4.2.conv_dw.weight True\n",
      "blocks.4.2.bn2.weight False\n",
      "blocks.4.2.bn2.bias False\n",
      "blocks.4.2.se.conv_reduce.weight True\n",
      "blocks.4.2.se.conv_reduce.bias True\n",
      "blocks.4.2.se.conv_expand.weight True\n",
      "blocks.4.2.se.conv_expand.bias True\n",
      "blocks.4.2.conv_pwl.weight True\n",
      "blocks.4.2.bn3.weight False\n",
      "blocks.4.2.bn3.bias False\n",
      "blocks.4.3.conv_pw.weight True\n",
      "blocks.4.3.bn1.weight False\n",
      "blocks.4.3.bn1.bias False\n",
      "blocks.4.3.conv_dw.weight True\n",
      "blocks.4.3.bn2.weight False\n",
      "blocks.4.3.bn2.bias False\n",
      "blocks.4.3.se.conv_reduce.weight True\n",
      "blocks.4.3.se.conv_reduce.bias True\n",
      "blocks.4.3.se.conv_expand.weight True\n",
      "blocks.4.3.se.conv_expand.bias True\n",
      "blocks.4.3.conv_pwl.weight True\n",
      "blocks.4.3.bn3.weight False\n",
      "blocks.4.3.bn3.bias False\n",
      "blocks.4.4.conv_pw.weight True\n",
      "blocks.4.4.bn1.weight False\n",
      "blocks.4.4.bn1.bias False\n",
      "blocks.4.4.conv_dw.weight True\n",
      "blocks.4.4.bn2.weight False\n",
      "blocks.4.4.bn2.bias False\n",
      "blocks.4.4.se.conv_reduce.weight True\n",
      "blocks.4.4.se.conv_reduce.bias True\n",
      "blocks.4.4.se.conv_expand.weight True\n",
      "blocks.4.4.se.conv_expand.bias True\n",
      "blocks.4.4.conv_pwl.weight True\n",
      "blocks.4.4.bn3.weight False\n",
      "blocks.4.4.bn3.bias False\n",
      "blocks.4.5.conv_pw.weight True\n",
      "blocks.4.5.bn1.weight False\n",
      "blocks.4.5.bn1.bias False\n",
      "blocks.4.5.conv_dw.weight True\n",
      "blocks.4.5.bn2.weight False\n",
      "blocks.4.5.bn2.bias False\n",
      "blocks.4.5.se.conv_reduce.weight True\n",
      "blocks.4.5.se.conv_reduce.bias True\n",
      "blocks.4.5.se.conv_expand.weight True\n",
      "blocks.4.5.se.conv_expand.bias True\n",
      "blocks.4.5.conv_pwl.weight True\n",
      "blocks.4.5.bn3.weight False\n",
      "blocks.4.5.bn3.bias False\n",
      "blocks.5.0.conv_pw.weight True\n",
      "blocks.5.0.bn1.weight False\n",
      "blocks.5.0.bn1.bias False\n",
      "blocks.5.0.conv_dw.weight True\n",
      "blocks.5.0.bn2.weight False\n",
      "blocks.5.0.bn2.bias False\n",
      "blocks.5.0.se.conv_reduce.weight True\n",
      "blocks.5.0.se.conv_reduce.bias True\n",
      "blocks.5.0.se.conv_expand.weight True\n",
      "blocks.5.0.se.conv_expand.bias True\n",
      "blocks.5.0.conv_pwl.weight True\n",
      "blocks.5.0.bn3.weight False\n",
      "blocks.5.0.bn3.bias False\n",
      "blocks.5.1.conv_pw.weight True\n",
      "blocks.5.1.bn1.weight False\n",
      "blocks.5.1.bn1.bias False\n",
      "blocks.5.1.conv_dw.weight True\n",
      "blocks.5.1.bn2.weight False\n",
      "blocks.5.1.bn2.bias False\n",
      "blocks.5.1.se.conv_reduce.weight True\n",
      "blocks.5.1.se.conv_reduce.bias True\n",
      "blocks.5.1.se.conv_expand.weight True\n",
      "blocks.5.1.se.conv_expand.bias True\n",
      "blocks.5.1.conv_pwl.weight True\n",
      "blocks.5.1.bn3.weight False\n",
      "blocks.5.1.bn3.bias False\n",
      "blocks.5.2.conv_pw.weight True\n",
      "blocks.5.2.bn1.weight False\n",
      "blocks.5.2.bn1.bias False\n",
      "blocks.5.2.conv_dw.weight True\n",
      "blocks.5.2.bn2.weight False\n",
      "blocks.5.2.bn2.bias False\n",
      "blocks.5.2.se.conv_reduce.weight True\n",
      "blocks.5.2.se.conv_reduce.bias True\n",
      "blocks.5.2.se.conv_expand.weight True\n",
      "blocks.5.2.se.conv_expand.bias True\n",
      "blocks.5.2.conv_pwl.weight True\n",
      "blocks.5.2.bn3.weight False\n",
      "blocks.5.2.bn3.bias False\n",
      "blocks.5.3.conv_pw.weight True\n",
      "blocks.5.3.bn1.weight False\n",
      "blocks.5.3.bn1.bias False\n",
      "blocks.5.3.conv_dw.weight True\n",
      "blocks.5.3.bn2.weight False\n",
      "blocks.5.3.bn2.bias False\n",
      "blocks.5.3.se.conv_reduce.weight True\n",
      "blocks.5.3.se.conv_reduce.bias True\n",
      "blocks.5.3.se.conv_expand.weight True\n",
      "blocks.5.3.se.conv_expand.bias True\n",
      "blocks.5.3.conv_pwl.weight True\n",
      "blocks.5.3.bn3.weight False\n",
      "blocks.5.3.bn3.bias False\n",
      "blocks.5.4.conv_pw.weight True\n",
      "blocks.5.4.bn1.weight False\n",
      "blocks.5.4.bn1.bias False\n",
      "blocks.5.4.conv_dw.weight True\n",
      "blocks.5.4.bn2.weight False\n",
      "blocks.5.4.bn2.bias False\n",
      "blocks.5.4.se.conv_reduce.weight True\n",
      "blocks.5.4.se.conv_reduce.bias True\n",
      "blocks.5.4.se.conv_expand.weight True\n",
      "blocks.5.4.se.conv_expand.bias True\n",
      "blocks.5.4.conv_pwl.weight True\n",
      "blocks.5.4.bn3.weight False\n",
      "blocks.5.4.bn3.bias False\n",
      "blocks.5.5.conv_pw.weight True\n",
      "blocks.5.5.bn1.weight False\n",
      "blocks.5.5.bn1.bias False\n",
      "blocks.5.5.conv_dw.weight True\n",
      "blocks.5.5.bn2.weight False\n",
      "blocks.5.5.bn2.bias False\n",
      "blocks.5.5.se.conv_reduce.weight True\n",
      "blocks.5.5.se.conv_reduce.bias True\n",
      "blocks.5.5.se.conv_expand.weight True\n",
      "blocks.5.5.se.conv_expand.bias True\n",
      "blocks.5.5.conv_pwl.weight True\n",
      "blocks.5.5.bn3.weight False\n",
      "blocks.5.5.bn3.bias False\n",
      "blocks.5.6.conv_pw.weight True\n",
      "blocks.5.6.bn1.weight False\n",
      "blocks.5.6.bn1.bias False\n",
      "blocks.5.6.conv_dw.weight True\n",
      "blocks.5.6.bn2.weight False\n",
      "blocks.5.6.bn2.bias False\n",
      "blocks.5.6.se.conv_reduce.weight True\n",
      "blocks.5.6.se.conv_reduce.bias True\n",
      "blocks.5.6.se.conv_expand.weight True\n",
      "blocks.5.6.se.conv_expand.bias True\n",
      "blocks.5.6.conv_pwl.weight True\n",
      "blocks.5.6.bn3.weight False\n",
      "blocks.5.6.bn3.bias False\n",
      "blocks.5.7.conv_pw.weight True\n",
      "blocks.5.7.bn1.weight False\n",
      "blocks.5.7.bn1.bias False\n",
      "blocks.5.7.conv_dw.weight True\n",
      "blocks.5.7.bn2.weight False\n",
      "blocks.5.7.bn2.bias False\n",
      "blocks.5.7.se.conv_reduce.weight True\n",
      "blocks.5.7.se.conv_reduce.bias True\n",
      "blocks.5.7.se.conv_expand.weight True\n",
      "blocks.5.7.se.conv_expand.bias True\n",
      "blocks.5.7.conv_pwl.weight True\n",
      "blocks.5.7.bn3.weight False\n",
      "blocks.5.7.bn3.bias False\n",
      "blocks.6.0.conv_pw.weight True\n",
      "blocks.6.0.bn1.weight False\n",
      "blocks.6.0.bn1.bias False\n",
      "blocks.6.0.conv_dw.weight True\n",
      "blocks.6.0.bn2.weight False\n",
      "blocks.6.0.bn2.bias False\n",
      "blocks.6.0.se.conv_reduce.weight True\n",
      "blocks.6.0.se.conv_reduce.bias True\n",
      "blocks.6.0.se.conv_expand.weight True\n",
      "blocks.6.0.se.conv_expand.bias True\n",
      "blocks.6.0.conv_pwl.weight True\n",
      "blocks.6.0.bn3.weight False\n",
      "blocks.6.0.bn3.bias False\n",
      "blocks.6.1.conv_pw.weight True\n",
      "blocks.6.1.bn1.weight False\n",
      "blocks.6.1.bn1.bias False\n",
      "blocks.6.1.conv_dw.weight True\n",
      "blocks.6.1.bn2.weight False\n",
      "blocks.6.1.bn2.bias False\n",
      "blocks.6.1.se.conv_reduce.weight True\n",
      "blocks.6.1.se.conv_reduce.bias True\n",
      "blocks.6.1.se.conv_expand.weight True\n",
      "blocks.6.1.se.conv_expand.bias True\n",
      "blocks.6.1.conv_pwl.weight True\n",
      "blocks.6.1.bn3.weight False\n",
      "blocks.6.1.bn3.bias False\n",
      "conv_head.weight True\n",
      "bn2.weight False\n",
      "bn2.bias False\n",
      "classifier.weight True\n",
      "classifier.bias True\n",
      "EfficientNet(\n",
      "  (conv_stem): Conv2dSame(3, 48, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
      "  (bn1): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (act1): SiLU(inplace=True)\n",
      "  (blocks): Sequential(\n",
      "    (0): Sequential(\n",
      "      (0): DepthwiseSeparableConv(\n",
      "        (conv_dw): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=48, bias=False)\n",
      "        (bn1): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act1): SiLU(inplace=True)\n",
      "        (se): SqueezeExcite(\n",
      "          (conv_reduce): Conv2d(48, 12, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (act1): SiLU(inplace=True)\n",
      "          (conv_expand): Conv2d(12, 48, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "        (conv_pw): Conv2d(48, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(24, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act2): Identity()\n",
      "      )\n",
      "      (1): DepthwiseSeparableConv(\n",
      "        (conv_dw): Conv2d(24, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=24, bias=False)\n",
      "        (bn1): BatchNorm2d(24, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act1): SiLU(inplace=True)\n",
      "        (se): SqueezeExcite(\n",
      "          (conv_reduce): Conv2d(24, 6, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (act1): SiLU(inplace=True)\n",
      "          (conv_expand): Conv2d(6, 24, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "        (conv_pw): Conv2d(24, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(24, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act2): Identity()\n",
      "      )\n",
      "    )\n",
      "    (1): Sequential(\n",
      "      (0): InvertedResidual(\n",
      "        (conv_pw): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(144, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act1): SiLU(inplace=True)\n",
      "        (conv_dw): Conv2dSame(144, 144, kernel_size=(3, 3), stride=(2, 2), groups=144, bias=False)\n",
      "        (bn2): BatchNorm2d(144, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act2): SiLU(inplace=True)\n",
      "        (se): SqueezeExcite(\n",
      "          (conv_reduce): Conv2d(144, 6, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (act1): SiLU(inplace=True)\n",
      "          (conv_expand): Conv2d(6, 144, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "        (conv_pwl): Conv2d(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (1): InvertedResidual(\n",
      "        (conv_pw): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act1): SiLU(inplace=True)\n",
      "        (conv_dw): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
      "        (bn2): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act2): SiLU(inplace=True)\n",
      "        (se): SqueezeExcite(\n",
      "          (conv_reduce): Conv2d(192, 8, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (act1): SiLU(inplace=True)\n",
      "          (conv_expand): Conv2d(8, 192, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "        (conv_pwl): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (2): InvertedResidual(\n",
      "        (conv_pw): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act1): SiLU(inplace=True)\n",
      "        (conv_dw): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
      "        (bn2): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act2): SiLU(inplace=True)\n",
      "        (se): SqueezeExcite(\n",
      "          (conv_reduce): Conv2d(192, 8, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (act1): SiLU(inplace=True)\n",
      "          (conv_expand): Conv2d(8, 192, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "        (conv_pwl): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (3): InvertedResidual(\n",
      "        (conv_pw): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act1): SiLU(inplace=True)\n",
      "        (conv_dw): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
      "        (bn2): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act2): SiLU(inplace=True)\n",
      "        (se): SqueezeExcite(\n",
      "          (conv_reduce): Conv2d(192, 8, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (act1): SiLU(inplace=True)\n",
      "          (conv_expand): Conv2d(8, 192, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "        (conv_pwl): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (2): Sequential(\n",
      "      (0): InvertedResidual(\n",
      "        (conv_pw): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act1): SiLU(inplace=True)\n",
      "        (conv_dw): Conv2dSame(192, 192, kernel_size=(5, 5), stride=(2, 2), groups=192, bias=False)\n",
      "        (bn2): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act2): SiLU(inplace=True)\n",
      "        (se): SqueezeExcite(\n",
      "          (conv_reduce): Conv2d(192, 8, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (act1): SiLU(inplace=True)\n",
      "          (conv_expand): Conv2d(8, 192, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "        (conv_pwl): Conv2d(192, 56, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(56, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (1): InvertedResidual(\n",
      "        (conv_pw): Conv2d(56, 336, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(336, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act1): SiLU(inplace=True)\n",
      "        (conv_dw): Conv2d(336, 336, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=336, bias=False)\n",
      "        (bn2): BatchNorm2d(336, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act2): SiLU(inplace=True)\n",
      "        (se): SqueezeExcite(\n",
      "          (conv_reduce): Conv2d(336, 14, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (act1): SiLU(inplace=True)\n",
      "          (conv_expand): Conv2d(14, 336, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "        (conv_pwl): Conv2d(336, 56, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(56, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (2): InvertedResidual(\n",
      "        (conv_pw): Conv2d(56, 336, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(336, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act1): SiLU(inplace=True)\n",
      "        (conv_dw): Conv2d(336, 336, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=336, bias=False)\n",
      "        (bn2): BatchNorm2d(336, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act2): SiLU(inplace=True)\n",
      "        (se): SqueezeExcite(\n",
      "          (conv_reduce): Conv2d(336, 14, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (act1): SiLU(inplace=True)\n",
      "          (conv_expand): Conv2d(14, 336, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "        (conv_pwl): Conv2d(336, 56, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(56, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (3): InvertedResidual(\n",
      "        (conv_pw): Conv2d(56, 336, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(336, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act1): SiLU(inplace=True)\n",
      "        (conv_dw): Conv2d(336, 336, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=336, bias=False)\n",
      "        (bn2): BatchNorm2d(336, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act2): SiLU(inplace=True)\n",
      "        (se): SqueezeExcite(\n",
      "          (conv_reduce): Conv2d(336, 14, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (act1): SiLU(inplace=True)\n",
      "          (conv_expand): Conv2d(14, 336, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "        (conv_pwl): Conv2d(336, 56, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(56, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (3): Sequential(\n",
      "      (0): InvertedResidual(\n",
      "        (conv_pw): Conv2d(56, 336, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(336, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act1): SiLU(inplace=True)\n",
      "        (conv_dw): Conv2dSame(336, 336, kernel_size=(3, 3), stride=(2, 2), groups=336, bias=False)\n",
      "        (bn2): BatchNorm2d(336, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act2): SiLU(inplace=True)\n",
      "        (se): SqueezeExcite(\n",
      "          (conv_reduce): Conv2d(336, 14, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (act1): SiLU(inplace=True)\n",
      "          (conv_expand): Conv2d(14, 336, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "        (conv_pwl): Conv2d(336, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(112, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (1): InvertedResidual(\n",
      "        (conv_pw): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act1): SiLU(inplace=True)\n",
      "        (conv_dw): Conv2d(672, 672, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=672, bias=False)\n",
      "        (bn2): BatchNorm2d(672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act2): SiLU(inplace=True)\n",
      "        (se): SqueezeExcite(\n",
      "          (conv_reduce): Conv2d(672, 28, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (act1): SiLU(inplace=True)\n",
      "          (conv_expand): Conv2d(28, 672, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "        (conv_pwl): Conv2d(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(112, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (2): InvertedResidual(\n",
      "        (conv_pw): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act1): SiLU(inplace=True)\n",
      "        (conv_dw): Conv2d(672, 672, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=672, bias=False)\n",
      "        (bn2): BatchNorm2d(672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act2): SiLU(inplace=True)\n",
      "        (se): SqueezeExcite(\n",
      "          (conv_reduce): Conv2d(672, 28, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (act1): SiLU(inplace=True)\n",
      "          (conv_expand): Conv2d(28, 672, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "        (conv_pwl): Conv2d(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(112, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (3): InvertedResidual(\n",
      "        (conv_pw): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act1): SiLU(inplace=True)\n",
      "        (conv_dw): Conv2d(672, 672, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=672, bias=False)\n",
      "        (bn2): BatchNorm2d(672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act2): SiLU(inplace=True)\n",
      "        (se): SqueezeExcite(\n",
      "          (conv_reduce): Conv2d(672, 28, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (act1): SiLU(inplace=True)\n",
      "          (conv_expand): Conv2d(28, 672, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "        (conv_pwl): Conv2d(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(112, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (4): InvertedResidual(\n",
      "        (conv_pw): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act1): SiLU(inplace=True)\n",
      "        (conv_dw): Conv2d(672, 672, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=672, bias=False)\n",
      "        (bn2): BatchNorm2d(672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act2): SiLU(inplace=True)\n",
      "        (se): SqueezeExcite(\n",
      "          (conv_reduce): Conv2d(672, 28, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (act1): SiLU(inplace=True)\n",
      "          (conv_expand): Conv2d(28, 672, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "        (conv_pwl): Conv2d(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(112, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (5): InvertedResidual(\n",
      "        (conv_pw): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act1): SiLU(inplace=True)\n",
      "        (conv_dw): Conv2d(672, 672, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=672, bias=False)\n",
      "        (bn2): BatchNorm2d(672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act2): SiLU(inplace=True)\n",
      "        (se): SqueezeExcite(\n",
      "          (conv_reduce): Conv2d(672, 28, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (act1): SiLU(inplace=True)\n",
      "          (conv_expand): Conv2d(28, 672, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "        (conv_pwl): Conv2d(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(112, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (4): Sequential(\n",
      "      (0): InvertedResidual(\n",
      "        (conv_pw): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act1): SiLU(inplace=True)\n",
      "        (conv_dw): Conv2d(672, 672, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=672, bias=False)\n",
      "        (bn2): BatchNorm2d(672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act2): SiLU(inplace=True)\n",
      "        (se): SqueezeExcite(\n",
      "          (conv_reduce): Conv2d(672, 28, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (act1): SiLU(inplace=True)\n",
      "          (conv_expand): Conv2d(28, 672, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "        (conv_pwl): Conv2d(672, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (1): InvertedResidual(\n",
      "        (conv_pw): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(960, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act1): SiLU(inplace=True)\n",
      "        (conv_dw): Conv2d(960, 960, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=960, bias=False)\n",
      "        (bn2): BatchNorm2d(960, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act2): SiLU(inplace=True)\n",
      "        (se): SqueezeExcite(\n",
      "          (conv_reduce): Conv2d(960, 40, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (act1): SiLU(inplace=True)\n",
      "          (conv_expand): Conv2d(40, 960, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "        (conv_pwl): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (2): InvertedResidual(\n",
      "        (conv_pw): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(960, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act1): SiLU(inplace=True)\n",
      "        (conv_dw): Conv2d(960, 960, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=960, bias=False)\n",
      "        (bn2): BatchNorm2d(960, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act2): SiLU(inplace=True)\n",
      "        (se): SqueezeExcite(\n",
      "          (conv_reduce): Conv2d(960, 40, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (act1): SiLU(inplace=True)\n",
      "          (conv_expand): Conv2d(40, 960, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "        (conv_pwl): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (3): InvertedResidual(\n",
      "        (conv_pw): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(960, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act1): SiLU(inplace=True)\n",
      "        (conv_dw): Conv2d(960, 960, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=960, bias=False)\n",
      "        (bn2): BatchNorm2d(960, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act2): SiLU(inplace=True)\n",
      "        (se): SqueezeExcite(\n",
      "          (conv_reduce): Conv2d(960, 40, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (act1): SiLU(inplace=True)\n",
      "          (conv_expand): Conv2d(40, 960, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "        (conv_pwl): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (4): InvertedResidual(\n",
      "        (conv_pw): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(960, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act1): SiLU(inplace=True)\n",
      "        (conv_dw): Conv2d(960, 960, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=960, bias=False)\n",
      "        (bn2): BatchNorm2d(960, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act2): SiLU(inplace=True)\n",
      "        (se): SqueezeExcite(\n",
      "          (conv_reduce): Conv2d(960, 40, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (act1): SiLU(inplace=True)\n",
      "          (conv_expand): Conv2d(40, 960, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "        (conv_pwl): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (5): InvertedResidual(\n",
      "        (conv_pw): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(960, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act1): SiLU(inplace=True)\n",
      "        (conv_dw): Conv2d(960, 960, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=960, bias=False)\n",
      "        (bn2): BatchNorm2d(960, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act2): SiLU(inplace=True)\n",
      "        (se): SqueezeExcite(\n",
      "          (conv_reduce): Conv2d(960, 40, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (act1): SiLU(inplace=True)\n",
      "          (conv_expand): Conv2d(40, 960, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "        (conv_pwl): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (5): Sequential(\n",
      "      (0): InvertedResidual(\n",
      "        (conv_pw): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(960, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act1): SiLU(inplace=True)\n",
      "        (conv_dw): Conv2dSame(960, 960, kernel_size=(5, 5), stride=(2, 2), groups=960, bias=False)\n",
      "        (bn2): BatchNorm2d(960, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act2): SiLU(inplace=True)\n",
      "        (se): SqueezeExcite(\n",
      "          (conv_reduce): Conv2d(960, 40, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (act1): SiLU(inplace=True)\n",
      "          (conv_expand): Conv2d(40, 960, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "        (conv_pwl): Conv2d(960, 272, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(272, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (1): InvertedResidual(\n",
      "        (conv_pw): Conv2d(272, 1632, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(1632, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act1): SiLU(inplace=True)\n",
      "        (conv_dw): Conv2d(1632, 1632, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1632, bias=False)\n",
      "        (bn2): BatchNorm2d(1632, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act2): SiLU(inplace=True)\n",
      "        (se): SqueezeExcite(\n",
      "          (conv_reduce): Conv2d(1632, 68, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (act1): SiLU(inplace=True)\n",
      "          (conv_expand): Conv2d(68, 1632, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "        (conv_pwl): Conv2d(1632, 272, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(272, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (2): InvertedResidual(\n",
      "        (conv_pw): Conv2d(272, 1632, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(1632, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act1): SiLU(inplace=True)\n",
      "        (conv_dw): Conv2d(1632, 1632, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1632, bias=False)\n",
      "        (bn2): BatchNorm2d(1632, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act2): SiLU(inplace=True)\n",
      "        (se): SqueezeExcite(\n",
      "          (conv_reduce): Conv2d(1632, 68, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (act1): SiLU(inplace=True)\n",
      "          (conv_expand): Conv2d(68, 1632, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "        (conv_pwl): Conv2d(1632, 272, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(272, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (3): InvertedResidual(\n",
      "        (conv_pw): Conv2d(272, 1632, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(1632, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act1): SiLU(inplace=True)\n",
      "        (conv_dw): Conv2d(1632, 1632, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1632, bias=False)\n",
      "        (bn2): BatchNorm2d(1632, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act2): SiLU(inplace=True)\n",
      "        (se): SqueezeExcite(\n",
      "          (conv_reduce): Conv2d(1632, 68, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (act1): SiLU(inplace=True)\n",
      "          (conv_expand): Conv2d(68, 1632, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "        (conv_pwl): Conv2d(1632, 272, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(272, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (4): InvertedResidual(\n",
      "        (conv_pw): Conv2d(272, 1632, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(1632, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act1): SiLU(inplace=True)\n",
      "        (conv_dw): Conv2d(1632, 1632, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1632, bias=False)\n",
      "        (bn2): BatchNorm2d(1632, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act2): SiLU(inplace=True)\n",
      "        (se): SqueezeExcite(\n",
      "          (conv_reduce): Conv2d(1632, 68, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (act1): SiLU(inplace=True)\n",
      "          (conv_expand): Conv2d(68, 1632, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "        (conv_pwl): Conv2d(1632, 272, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(272, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (5): InvertedResidual(\n",
      "        (conv_pw): Conv2d(272, 1632, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(1632, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act1): SiLU(inplace=True)\n",
      "        (conv_dw): Conv2d(1632, 1632, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1632, bias=False)\n",
      "        (bn2): BatchNorm2d(1632, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act2): SiLU(inplace=True)\n",
      "        (se): SqueezeExcite(\n",
      "          (conv_reduce): Conv2d(1632, 68, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (act1): SiLU(inplace=True)\n",
      "          (conv_expand): Conv2d(68, 1632, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "        (conv_pwl): Conv2d(1632, 272, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(272, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (6): InvertedResidual(\n",
      "        (conv_pw): Conv2d(272, 1632, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(1632, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act1): SiLU(inplace=True)\n",
      "        (conv_dw): Conv2d(1632, 1632, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1632, bias=False)\n",
      "        (bn2): BatchNorm2d(1632, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act2): SiLU(inplace=True)\n",
      "        (se): SqueezeExcite(\n",
      "          (conv_reduce): Conv2d(1632, 68, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (act1): SiLU(inplace=True)\n",
      "          (conv_expand): Conv2d(68, 1632, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "        (conv_pwl): Conv2d(1632, 272, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(272, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (7): InvertedResidual(\n",
      "        (conv_pw): Conv2d(272, 1632, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(1632, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act1): SiLU(inplace=True)\n",
      "        (conv_dw): Conv2d(1632, 1632, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1632, bias=False)\n",
      "        (bn2): BatchNorm2d(1632, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act2): SiLU(inplace=True)\n",
      "        (se): SqueezeExcite(\n",
      "          (conv_reduce): Conv2d(1632, 68, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (act1): SiLU(inplace=True)\n",
      "          (conv_expand): Conv2d(68, 1632, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "        (conv_pwl): Conv2d(1632, 272, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(272, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (6): Sequential(\n",
      "      (0): InvertedResidual(\n",
      "        (conv_pw): Conv2d(272, 1632, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(1632, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act1): SiLU(inplace=True)\n",
      "        (conv_dw): Conv2d(1632, 1632, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1632, bias=False)\n",
      "        (bn2): BatchNorm2d(1632, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act2): SiLU(inplace=True)\n",
      "        (se): SqueezeExcite(\n",
      "          (conv_reduce): Conv2d(1632, 68, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (act1): SiLU(inplace=True)\n",
      "          (conv_expand): Conv2d(68, 1632, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "        (conv_pwl): Conv2d(1632, 448, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(448, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (1): InvertedResidual(\n",
      "        (conv_pw): Conv2d(448, 2688, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(2688, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act1): SiLU(inplace=True)\n",
      "        (conv_dw): Conv2d(2688, 2688, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2688, bias=False)\n",
      "        (bn2): BatchNorm2d(2688, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act2): SiLU(inplace=True)\n",
      "        (se): SqueezeExcite(\n",
      "          (conv_reduce): Conv2d(2688, 112, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (act1): SiLU(inplace=True)\n",
      "          (conv_expand): Conv2d(112, 2688, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "        (conv_pwl): Conv2d(2688, 448, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(448, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (conv_head): Conv2d(448, 1792, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (bn2): BatchNorm2d(1792, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (act2): SiLU(inplace=True)\n",
      "  (global_pool): SelectAdaptivePool2d (pool_type=avg, flatten=True)\n",
      "  (classifier): Linear(in_features=1792, out_features=5, bias=True)\n",
      ")\n",
      "Tuning /opt/favordata/AI/Felix/kaggle-cassava/trained-models/sgd_coswarm_bnf_bitemp_smooth_weighted_t1=0.3_t2=1.0_89-53/tf_efficientnet_b4_ns_bitempered_smooth=0.05_val_loss=0.108_val_acc=0.883_fold4.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name           | Type           | Params\n",
      "--------------------------------------------------\n",
      "0 | valid_accuracy | Accuracy       | 0     \n",
      "1 | test_accuracy  | Accuracy       | 0     \n",
      "2 | criterion      | BiTemperedLoss | 0     \n",
      "3 | model          | EfficientNet   | 17.6 M\n",
      "--------------------------------------------------\n",
      "17.4 M    Trainable params\n",
      "125 K     Non-trainable params\n",
      "17.6 M    Total params\n",
      "\n",
      "Finding best initial lr:   0%|          | 0/100 [00:00<?, ?it/s]\u001b[A\n",
      "Finding best initial lr:   1%|          | 1/100 [00:00<00:26,  3.81it/s]\u001b[A\n",
      "Finding best initial lr:   2%|▏         | 2/100 [00:01<01:07,  1.45it/s]\u001b[A\n",
      "Finding best initial lr:   3%|▎         | 3/100 [00:02<01:20,  1.21it/s]\u001b[A\n",
      "Finding best initial lr:   4%|▍         | 4/100 [00:03<01:25,  1.12it/s]\u001b[A\n",
      "Finding best initial lr:   5%|▌         | 5/100 [00:04<01:28,  1.08it/s]\u001b[A\n",
      "Finding best initial lr:   6%|▌         | 6/100 [00:05<01:29,  1.06it/s]\u001b[A\n",
      "Finding best initial lr:   7%|▋         | 7/100 [00:06<01:29,  1.04it/s]\u001b[A\n",
      "Finding best initial lr:   8%|▊         | 8/100 [00:07<01:29,  1.03it/s]\u001b[A\n",
      "Finding best initial lr:   9%|▉         | 9/100 [00:08<01:28,  1.03it/s]\u001b[A\n",
      "Finding best initial lr:  10%|█         | 10/100 [00:09<01:28,  1.01it/s]\u001b[A\n",
      "Finding best initial lr:  11%|█         | 11/100 [00:10<01:27,  1.01it/s]\u001b[A\n",
      "Finding best initial lr:  12%|█▏        | 12/100 [00:11<01:26,  1.01it/s]\u001b[A\n",
      "Finding best initial lr:  13%|█▎        | 13/100 [00:12<01:25,  1.01it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 14:   3%|▎         | 56/1770 [00:52<-1:55:36, -6.49it/s, loss=0.104, v_num=7, val_loss=0.0666, val_acc=0.946, train_loss=0.00989] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Finding best initial lr:  14%|█▍        | 14/100 [00:13<01:25,  1.01it/s]\u001b[A\n",
      "Finding best initial lr:  15%|█▌        | 15/100 [00:14<01:24,  1.01it/s]\u001b[A\n",
      "Finding best initial lr:  16%|█▌        | 16/100 [00:15<01:23,  1.01it/s]\u001b[A\n",
      "Finding best initial lr:  17%|█▋        | 17/100 [00:16<01:22,  1.01it/s]\u001b[A\n",
      "Finding best initial lr:  18%|█▊        | 18/100 [00:17<01:21,  1.01it/s]\u001b[A\n",
      "Finding best initial lr:  19%|█▉        | 19/100 [00:18<01:20,  1.01it/s]\u001b[A\n",
      "Finding best initial lr:  20%|██        | 20/100 [00:19<01:19,  1.00it/s]\u001b[A\n",
      "Finding best initial lr:  21%|██        | 21/100 [00:20<01:18,  1.00it/s]\u001b[A\n",
      "Finding best initial lr:  22%|██▏       | 22/100 [00:21<01:17,  1.01it/s]\u001b[A\n",
      "Finding best initial lr:  23%|██▎       | 23/100 [00:22<01:16,  1.01it/s]\u001b[A\n",
      "Finding best initial lr:  24%|██▍       | 24/100 [00:23<01:15,  1.01it/s]\u001b[A\n",
      "Finding best initial lr:  25%|██▌       | 25/100 [00:24<01:14,  1.01it/s]\u001b[A\n",
      "Finding best initial lr:  26%|██▌       | 26/100 [00:25<01:13,  1.01it/s]\u001b[A\n",
      "Finding best initial lr:  27%|██▋       | 27/100 [00:26<01:12,  1.01it/s]\u001b[A\n",
      "Finding best initial lr:  28%|██▊       | 28/100 [00:27<01:11,  1.01it/s]\u001b[A\n",
      "Finding best initial lr:  29%|██▉       | 29/100 [00:28<01:10,  1.01it/s]\u001b[A\n",
      "Finding best initial lr:  30%|███       | 30/100 [00:29<01:09,  1.00it/s]\u001b[A\n",
      "Finding best initial lr:  31%|███       | 31/100 [00:30<01:08,  1.00it/s]\u001b[A\n",
      "Finding best initial lr:  32%|███▏      | 32/100 [00:31<01:07,  1.00it/s]\u001b[A\n",
      "Finding best initial lr:  33%|███▎      | 33/100 [00:32<01:06,  1.01it/s]\u001b[A\n",
      "Finding best initial lr:  34%|███▍      | 34/100 [00:33<01:05,  1.01it/s]\u001b[A\n",
      "Finding best initial lr:  35%|███▌      | 35/100 [00:34<01:04,  1.01it/s]\u001b[A\n",
      "Finding best initial lr:  36%|███▌      | 36/100 [00:34<01:03,  1.01it/s]\u001b[A\n",
      "Finding best initial lr:  37%|███▋      | 37/100 [00:35<01:02,  1.01it/s]\u001b[A\n",
      "Finding best initial lr:  38%|███▊      | 38/100 [00:36<01:01,  1.01it/s]\u001b[A\n",
      "Finding best initial lr:  39%|███▉      | 39/100 [00:37<01:00,  1.01it/s]\u001b[A\n",
      "Finding best initial lr:  40%|████      | 40/100 [00:38<00:59,  1.00it/s]\u001b[A\n",
      "Finding best initial lr:  41%|████      | 41/100 [00:39<00:58,  1.00it/s]\u001b[A\n",
      "Finding best initial lr:  42%|████▏     | 42/100 [00:40<00:57,  1.01it/s]\u001b[A\n",
      "Finding best initial lr:  43%|████▎     | 43/100 [00:41<00:56,  1.01it/s]\u001b[A\n",
      "Finding best initial lr:  44%|████▍     | 44/100 [00:42<00:55,  1.01it/s]\u001b[A\n",
      "Finding best initial lr:  45%|████▌     | 45/100 [00:43<00:54,  1.01it/s]\u001b[A\n",
      "Finding best initial lr:  46%|████▌     | 46/100 [00:44<00:53,  1.01it/s]\u001b[A\n",
      "Finding best initial lr:  47%|████▋     | 47/100 [00:45<00:52,  1.01it/s]\u001b[A\n",
      "Finding best initial lr:  48%|████▊     | 48/100 [00:46<00:51,  1.01it/s]\u001b[A\n",
      "Finding best initial lr:  49%|████▉     | 49/100 [00:47<00:50,  1.01it/s]\u001b[A\n",
      "Finding best initial lr:  50%|█████     | 50/100 [00:48<00:49,  1.00it/s]\u001b[A\n",
      "Finding best initial lr:  51%|█████     | 51/100 [00:49<00:48,  1.00it/s]\u001b[A\n",
      "Finding best initial lr:  52%|█████▏    | 52/100 [00:50<00:47,  1.00it/s]\u001b[A\n",
      "Finding best initial lr:  53%|█████▎    | 53/100 [00:51<00:46,  1.01it/s]\u001b[A\n",
      "Finding best initial lr:  54%|█████▍    | 54/100 [00:52<00:45,  1.01it/s]\u001b[A\n",
      "Finding best initial lr:  55%|█████▌    | 55/100 [00:53<00:44,  1.01it/s]\u001b[A\n",
      "Finding best initial lr:  56%|█████▌    | 56/100 [00:54<00:43,  1.01it/s]\u001b[A\n",
      "Finding best initial lr:  57%|█████▋    | 57/100 [00:55<00:42,  1.01it/s]\u001b[A\n",
      "Finding best initial lr:  58%|█████▊    | 58/100 [00:56<00:41,  1.01it/s]\u001b[A\n",
      "Finding best initial lr:  59%|█████▉    | 59/100 [00:57<00:40,  1.01it/s]\u001b[A\n",
      "Finding best initial lr:  60%|██████    | 60/100 [00:58<00:39,  1.00it/s]\u001b[A\n",
      "Finding best initial lr:  61%|██████    | 61/100 [00:59<00:38,  1.00it/s]\u001b[A\n",
      "Finding best initial lr:  62%|██████▏   | 62/100 [01:00<00:37,  1.00it/s]\u001b[A\n",
      "Finding best initial lr:  63%|██████▎   | 63/100 [01:01<00:36,  1.01it/s]\u001b[A\n",
      "Finding best initial lr:  64%|██████▍   | 64/100 [01:02<00:35,  1.01it/s]\u001b[A\n",
      "Finding best initial lr:  65%|██████▌   | 65/100 [01:03<00:34,  1.01it/s]\u001b[A\n",
      "Finding best initial lr:  66%|██████▌   | 66/100 [01:04<00:33,  1.01it/s]\u001b[A\n",
      "Finding best initial lr:  67%|██████▋   | 67/100 [01:05<00:32,  1.01it/s]\u001b[A\n",
      "Finding best initial lr:  68%|██████▊   | 68/100 [01:06<00:31,  1.01it/s]\u001b[A\n",
      "Finding best initial lr:  69%|██████▉   | 69/100 [01:07<00:30,  1.01it/s]\u001b[A\n",
      "Finding best initial lr:  70%|███████   | 70/100 [01:08<00:29,  1.00it/s]\u001b[A\n",
      "Finding best initial lr:  71%|███████   | 71/100 [01:09<00:28,  1.00it/s]\u001b[A\n",
      "Finding best initial lr:  72%|███████▏  | 72/100 [01:10<00:27,  1.00it/s]\u001b[A\n",
      "Finding best initial lr:  73%|███████▎  | 73/100 [01:11<00:26,  1.00it/s]\u001b[A\n",
      "Finding best initial lr:  74%|███████▍  | 74/100 [01:12<00:25,  1.00it/s]\u001b[A\n",
      "Finding best initial lr:  75%|███████▌  | 75/100 [01:13<00:24,  1.00it/s]\u001b[A\n",
      "Finding best initial lr:  76%|███████▌  | 76/100 [01:14<00:23,  1.01it/s]\u001b[A\n",
      "Finding best initial lr:  77%|███████▋  | 77/100 [01:15<00:22,  1.01it/s]\u001b[A\n",
      "Finding best initial lr:  78%|███████▊  | 78/100 [01:16<00:21,  1.01it/s]\u001b[A\n",
      "Finding best initial lr:  79%|███████▉  | 79/100 [01:17<00:20,  1.01it/s]\u001b[A\n",
      "Finding best initial lr:  80%|████████  | 80/100 [01:18<00:20,  1.00s/it]\u001b[A\n",
      "Finding best initial lr:  81%|████████  | 81/100 [01:19<00:18,  1.00it/s]\u001b[A\n",
      "Finding best initial lr:  82%|████████▏ | 82/100 [01:20<00:17,  1.00it/s]\u001b[A\n",
      "Finding best initial lr:  83%|████████▎ | 83/100 [01:21<00:16,  1.01it/s]\u001b[A\n",
      "Finding best initial lr:  84%|████████▍ | 84/100 [01:22<00:15,  1.01it/s]\u001b[A\n",
      "Finding best initial lr:  85%|████████▌ | 85/100 [01:23<00:14,  1.01it/s]\u001b[A\n",
      "Finding best initial lr:  86%|████████▌ | 86/100 [01:24<00:13,  1.01it/s]\u001b[A\n",
      "Finding best initial lr:  87%|████████▋ | 87/100 [01:25<00:12,  1.01it/s]\u001b[A\n",
      "Finding best initial lr:  88%|████████▊ | 88/100 [01:26<00:11,  1.01it/s]\u001b[A\n",
      "Finding best initial lr:  89%|████████▉ | 89/100 [01:27<00:10,  1.01it/s]\u001b[A\n",
      "Finding best initial lr:  90%|█████████ | 90/100 [01:28<00:09,  1.00it/s]\u001b[A\n",
      "Finding best initial lr:  91%|█████████ | 91/100 [01:29<00:08,  1.00it/s]\u001b[A\n",
      "Finding best initial lr:  92%|█████████▏| 92/100 [01:30<00:07,  1.00it/s]\u001b[A\n",
      "Finding best initial lr:  93%|█████████▎| 93/100 [01:31<00:06,  1.00it/s]\u001b[A\n",
      "Finding best initial lr:  94%|█████████▍| 94/100 [01:32<00:05,  1.01it/s]\u001b[A\n",
      "Finding best initial lr:  95%|█████████▌| 95/100 [01:33<00:04,  1.01it/s]\u001b[A\n",
      "Finding best initial lr:  96%|█████████▌| 96/100 [01:34<00:03,  1.01it/s]\u001b[A\n",
      "Finding best initial lr:  97%|█████████▋| 97/100 [01:35<00:02,  1.01it/s]\u001b[A\n",
      "Finding best initial lr:  98%|█████████▊| 98/100 [01:36<00:01,  1.01it/s]\u001b[A\n",
      "Finding best initial lr:  99%|█████████▉| 99/100 [01:37<00:00,  1.01it/s]\u001b[A\n",
      "Finding best initial lr: 100%|██████████| 100/100 [01:38<00:00,  1.00it/s]\u001b[ARestored states from the checkpoint file at /opt/favordata/AI/Felix/kaggle-cassava/trained-models/sgd_coswarm_bnf_bitemp_smooth_weighted_t1=0.3_t2=1.0_89-53_tune/lr_find_temp_model.ckpt\n",
      "Learning rate set to 1.0964781961431852e-07\n",
      "\n",
      "  | Name           | Type           | Params\n",
      "--------------------------------------------------\n",
      "0 | valid_accuracy | Accuracy       | 0     \n",
      "1 | test_accuracy  | Accuracy       | 0     \n",
      "2 | criterion      | BiTemperedLoss | 0     \n",
      "3 | model          | EfficientNet   | 17.6 M\n",
      "--------------------------------------------------\n",
      "17.4 M    Trainable params\n",
      "125 K     Non-trainable params\n",
      "17.6 M    Total params\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1:  51%|█████     | 903/1770 [03:47<06:30,  2.22it/s, loss=0.154, v_num=7, val_loss=0.0561, val_acc=0.945, train_loss=0.109]     "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4:  97%|█████████▋| 1716/1770 [07:10<00:17,  3.06it/s, loss=0.171, v_num=7, val_loss=0.0445, val_acc=0.967, train_loss=0.0936] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 4:  97%|█████████▋| 1718/1770 [07:13<00:17,  3.04it/s, loss=0.171, v_num=7, val_loss=0.0445, val_acc=0.967, train_loss=0.0936]\n",
      "Validating:   4%|▎         | 2/54 [00:03<01:11,  1.37s/it]\u001b[A\n",
      "Epoch 4:  97%|█████████▋| 1720/1770 [07:14<00:16,  3.04it/s, loss=0.171, v_num=7, val_loss=0.0445, val_acc=0.967, train_loss=0.0936]\n",
      "Validating:   7%|▋         | 4/54 [00:04<00:43,  1.15it/s]\u001b[A\n",
      "Epoch 4:  97%|█████████▋| 1722/1770 [07:15<00:15,  3.04it/s, loss=0.171, v_num=7, val_loss=0.0445, val_acc=0.967, train_loss=0.0936]\n",
      "Validating:  11%|█         | 6/54 [00:05<00:33,  1.43it/s]\u001b[A\n",
      "Epoch 4:  97%|█████████▋| 1724/1770 [07:16<00:15,  3.03it/s, loss=0.171, v_num=7, val_loss=0.0445, val_acc=0.967, train_loss=0.0936]\n",
      "Validating:  15%|█▍        | 8/54 [00:06<00:28,  1.59it/s]\u001b[A\n",
      "Epoch 4:  98%|█████████▊| 1726/1770 [07:18<00:14,  3.03it/s, loss=0.171, v_num=7, val_loss=0.0445, val_acc=0.967, train_loss=0.0936]\n",
      "Validating:  19%|█▊        | 10/54 [00:07<00:26,  1.67it/s]\u001b[A\n",
      "Epoch 4:  98%|█████████▊| 1728/1770 [07:19<00:13,  3.03it/s, loss=0.171, v_num=7, val_loss=0.0445, val_acc=0.967, train_loss=0.0936]\n",
      "Validating:  22%|██▏       | 12/54 [00:08<00:24,  1.70it/s]\u001b[A\n",
      "Epoch 4:  98%|█████████▊| 1730/1770 [07:20<00:13,  3.02it/s, loss=0.171, v_num=7, val_loss=0.0445, val_acc=0.967, train_loss=0.0936]\n",
      "Validating:  26%|██▌       | 14/54 [00:09<00:23,  1.72it/s]\u001b[A\n",
      "Epoch 4:  98%|█████████▊| 1732/1770 [07:21<00:12,  3.02it/s, loss=0.171, v_num=7, val_loss=0.0445, val_acc=0.967, train_loss=0.0936]\n",
      "Validating:  30%|██▉       | 16/54 [00:11<00:21,  1.73it/s]\u001b[A\n",
      "Epoch 4:  98%|█████████▊| 1734/1770 [07:22<00:11,  3.02it/s, loss=0.171, v_num=7, val_loss=0.0445, val_acc=0.967, train_loss=0.0936]\n",
      "Validating:  33%|███▎      | 18/54 [00:12<00:20,  1.74it/s]\u001b[A\n",
      "Epoch 4:  98%|█████████▊| 1736/1770 [07:23<00:11,  3.01it/s, loss=0.171, v_num=7, val_loss=0.0445, val_acc=0.967, train_loss=0.0936]\n",
      "Validating:  37%|███▋      | 20/54 [00:13<00:19,  1.74it/s]\u001b[A\n",
      "Epoch 4:  98%|█████████▊| 1738/1770 [07:24<00:10,  3.01it/s, loss=0.171, v_num=7, val_loss=0.0445, val_acc=0.967, train_loss=0.0936]\n",
      "Validating:  41%|████      | 22/54 [00:14<00:18,  1.74it/s]\u001b[A\n",
      "Epoch 4:  98%|█████████▊| 1740/1770 [07:26<00:09,  3.01it/s, loss=0.171, v_num=7, val_loss=0.0445, val_acc=0.967, train_loss=0.0936]\n",
      "Validating:  44%|████▍     | 24/54 [00:15<00:17,  1.74it/s]\u001b[A\n",
      "Epoch 4:  98%|█████████▊| 1742/1770 [07:27<00:09,  3.00it/s, loss=0.171, v_num=7, val_loss=0.0445, val_acc=0.967, train_loss=0.0936]\n",
      "Validating:  48%|████▊     | 26/54 [00:16<00:16,  1.74it/s]\u001b[A\n",
      "Epoch 4:  99%|█████████▊| 1744/1770 [07:28<00:08,  3.00it/s, loss=0.171, v_num=7, val_loss=0.0445, val_acc=0.967, train_loss=0.0936]\n",
      "Validating:  52%|█████▏    | 28/54 [00:18<00:14,  1.74it/s]\u001b[A\n",
      "Epoch 4:  99%|█████████▊| 1746/1770 [07:29<00:08,  3.00it/s, loss=0.171, v_num=7, val_loss=0.0445, val_acc=0.967, train_loss=0.0936]\n",
      "Validating:  56%|█████▌    | 30/54 [00:19<00:13,  1.75it/s]\u001b[A\n",
      "Epoch 4:  99%|█████████▉| 1748/1770 [07:30<00:07,  2.99it/s, loss=0.171, v_num=7, val_loss=0.0445, val_acc=0.967, train_loss=0.0936]\n",
      "Validating:  59%|█████▉    | 32/54 [00:20<00:12,  1.75it/s]\u001b[A\n",
      "Epoch 4:  99%|█████████▉| 1750/1770 [07:31<00:06,  2.99it/s, loss=0.171, v_num=7, val_loss=0.0445, val_acc=0.967, train_loss=0.0936]\n",
      "Validating:  63%|██████▎   | 34/54 [00:21<00:11,  1.75it/s]\u001b[A\n",
      "Epoch 4:  99%|█████████▉| 1752/1770 [07:33<00:06,  2.99it/s, loss=0.171, v_num=7, val_loss=0.0445, val_acc=0.967, train_loss=0.0936]\n",
      "Validating:  67%|██████▋   | 36/54 [00:22<00:10,  1.75it/s]\u001b[A\n",
      "Epoch 4:  99%|█████████▉| 1754/1770 [07:34<00:05,  2.98it/s, loss=0.171, v_num=7, val_loss=0.0445, val_acc=0.967, train_loss=0.0936]\n",
      "Validating:  70%|███████   | 38/54 [00:23<00:09,  1.75it/s]\u001b[A\n",
      "Epoch 4:  99%|█████████▉| 1756/1770 [07:35<00:04,  2.98it/s, loss=0.171, v_num=7, val_loss=0.0445, val_acc=0.967, train_loss=0.0936]\n",
      "Validating:  74%|███████▍  | 40/54 [00:24<00:08,  1.74it/s]\u001b[A\n",
      "Epoch 4:  99%|█████████▉| 1758/1770 [07:36<00:04,  2.98it/s, loss=0.171, v_num=7, val_loss=0.0445, val_acc=0.967, train_loss=0.0936]\n",
      "Validating:  78%|███████▊  | 42/54 [00:26<00:06,  1.75it/s]\u001b[A\n",
      "Epoch 4:  99%|█████████▉| 1760/1770 [07:37<00:03,  2.97it/s, loss=0.171, v_num=7, val_loss=0.0445, val_acc=0.967, train_loss=0.0936]\n",
      "Validating:  81%|████████▏ | 44/54 [00:27<00:05,  1.74it/s]\u001b[A\n",
      "Epoch 4: 100%|█████████▉| 1762/1770 [07:38<00:02,  2.97it/s, loss=0.171, v_num=7, val_loss=0.0445, val_acc=0.967, train_loss=0.0936]\n",
      "Validating:  85%|████████▌ | 46/54 [00:28<00:04,  1.77it/s]\u001b[A\n",
      "Epoch 4: 100%|█████████▉| 1764/1770 [07:39<00:02,  2.97it/s, loss=0.171, v_num=7, val_loss=0.0445, val_acc=0.967, train_loss=0.0936]\n",
      "Validating:  89%|████████▉ | 48/54 [00:29<00:03,  1.78it/s]\u001b[A\n",
      "Epoch 4: 100%|█████████▉| 1766/1770 [07:40<00:01,  2.97it/s, loss=0.171, v_num=7, val_loss=0.0445, val_acc=0.967, train_loss=0.0936]\n",
      "Validating:  93%|█████████▎| 50/54 [00:30<00:02,  1.79it/s]\u001b[A\n",
      "Epoch 4: 100%|█████████▉| 1768/1770 [07:42<00:00,  2.96it/s, loss=0.171, v_num=7, val_loss=0.0445, val_acc=0.967, train_loss=0.0936]\n",
      "Validating:  96%|█████████▋| 52/54 [00:31<00:01,  1.79it/s]\u001b[A\n",
      "Epoch 4: 100%|██████████| 1770/1770 [07:43<00:00,  2.96it/s, loss=0.171, v_num=7, val_loss=0.0445, val_acc=0.967, train_loss=0.0936]\n",
      "Validating: 100%|██████████| 54/54 [00:32<00:00,  2.03it/s]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4, step 1716: val_loss was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 1770/1770 [07:43<00:00,  2.96it/s, loss=0.171, v_num=7, val_loss=0.0464, val_acc=0.964, train_loss=0.182] \n",
      "Epoch 5:  97%|█████████▋| 1716/1770 [07:10<00:17,  3.06it/s, loss=0.157, v_num=7, val_loss=0.0464, val_acc=0.964, train_loss=0.227]    \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 5:  97%|█████████▋| 1718/1770 [07:12<00:17,  3.05it/s, loss=0.157, v_num=7, val_loss=0.0464, val_acc=0.964, train_loss=0.227]\n",
      "Validating:   4%|▎         | 2/54 [00:03<01:10,  1.36s/it]\u001b[A\n",
      "Epoch 5:  97%|█████████▋| 1720/1770 [07:14<00:16,  3.04it/s, loss=0.157, v_num=7, val_loss=0.0464, val_acc=0.964, train_loss=0.227]\n",
      "Validating:   7%|▋         | 4/54 [00:04<00:43,  1.16it/s]\u001b[A\n",
      "Epoch 5:  97%|█████████▋| 1722/1770 [07:15<00:15,  3.04it/s, loss=0.157, v_num=7, val_loss=0.0464, val_acc=0.964, train_loss=0.227]\n",
      "Validating:  11%|█         | 6/54 [00:05<00:33,  1.44it/s]\u001b[A\n",
      "Epoch 5:  97%|█████████▋| 1724/1770 [07:16<00:15,  3.04it/s, loss=0.157, v_num=7, val_loss=0.0464, val_acc=0.964, train_loss=0.227]\n",
      "Validating:  15%|█▍        | 8/54 [00:06<00:28,  1.59it/s]\u001b[A\n",
      "Epoch 5:  98%|█████████▊| 1726/1770 [07:17<00:14,  3.03it/s, loss=0.157, v_num=7, val_loss=0.0464, val_acc=0.964, train_loss=0.227]\n",
      "Validating:  19%|█▊        | 10/54 [00:07<00:26,  1.67it/s]\u001b[A\n",
      "Epoch 5:  98%|█████████▊| 1728/1770 [07:18<00:13,  3.03it/s, loss=0.157, v_num=7, val_loss=0.0464, val_acc=0.964, train_loss=0.227]\n",
      "Validating:  22%|██▏       | 12/54 [00:08<00:24,  1.70it/s]\u001b[A\n",
      "Epoch 5:  98%|█████████▊| 1730/1770 [07:19<00:13,  3.03it/s, loss=0.157, v_num=7, val_loss=0.0464, val_acc=0.964, train_loss=0.227]\n",
      "Validating:  26%|██▌       | 14/54 [00:09<00:23,  1.72it/s]\u001b[A\n",
      "Epoch 5:  98%|█████████▊| 1732/1770 [07:20<00:12,  3.02it/s, loss=0.157, v_num=7, val_loss=0.0464, val_acc=0.964, train_loss=0.227]\n",
      "Validating:  30%|██▉       | 16/54 [00:11<00:21,  1.73it/s]\u001b[A\n",
      "Epoch 5:  98%|█████████▊| 1734/1770 [07:22<00:11,  3.02it/s, loss=0.157, v_num=7, val_loss=0.0464, val_acc=0.964, train_loss=0.227]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 12:   3%|▎         | 52/1770 [00:31<-1:57:25, -11.06it/s, loss=0.163, v_num=7, val_loss=0.0468, val_acc=0.966, train_loss=0.253]\n",
      "Validating:  94%|█████████▍| 51/54 [00:31<00:01,  1.79it/s]\u001b[A\n",
      "Epoch 12:   3%|▎         | 54/1770 [00:32<-1:57:19, -10.62it/s, loss=0.163, v_num=7, val_loss=0.0468, val_acc=0.966, train_loss=0.253]\n",
      "Validating:  98%|█████████▊| 53/54 [00:32<00:00,  1.79it/s]\u001b[A\n",
      "Epoch 12:   3%|▎         | 56/1770 [00:33<-1:57:13, -10.24it/s, loss=0.163, v_num=7, val_loss=0.0471, val_acc=0.967, train_loss=0.0989]\n",
      "                                                           \u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer was signaled to stop but required minimum epochs (15) or minimum steps (None) has not been met. Training will continue...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13:   0%|          | 2/1770 [00:00<-1:59:58, -602.95it/s, loss=0.163, v_num=7, val_loss=0.0471, val_acc=0.967, train_loss=0.0989] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   2%|▏         | 1/54 [00:01<01:42,  1.93s/it]\u001b[A\n",
      "Epoch 13:   0%|          | 4/1770 [00:03<-1:59:46, -122.91it/s, loss=0.163, v_num=7, val_loss=0.0471, val_acc=0.967, train_loss=0.0989]\n",
      "Validating:   6%|▌         | 3/54 [00:03<00:46,  1.09it/s]\u001b[A\n",
      "Epoch 13:   0%|          | 6/1770 [00:04<-1:59:40, -86.77it/s, loss=0.163, v_num=7, val_loss=0.0471, val_acc=0.967, train_loss=0.0989] \n",
      "Validating:   9%|▉         | 5/54 [00:04<00:36,  1.34it/s]\u001b[A\n",
      "Epoch 13:   0%|          | 8/1770 [00:05<-1:59:35, -68.41it/s, loss=0.163, v_num=7, val_loss=0.0471, val_acc=0.967, train_loss=0.0989]\n",
      "Validating:  13%|█▎        | 7/54 [00:05<00:30,  1.53it/s]\u001b[A\n",
      "Epoch 13:   1%|          | 10/1770 [00:06<-1:59:29, -56.53it/s, loss=0.163, v_num=7, val_loss=0.0471, val_acc=0.967, train_loss=0.0989]\n",
      "Validating:  17%|█▋        | 9/54 [00:06<00:27,  1.63it/s]\u001b[A\n",
      "Epoch 13:   1%|          | 12/1770 [00:08<-1:59:24, -48.18it/s, loss=0.163, v_num=7, val_loss=0.0471, val_acc=0.967, train_loss=0.0989]\n",
      "Validating:  20%|██        | 11/54 [00:07<00:25,  1.68it/s]\u001b[A\n",
      "Epoch 13:   1%|          | 14/1770 [00:09<-1:59:19, -41.92it/s, loss=0.163, v_num=7, val_loss=0.0471, val_acc=0.967, train_loss=0.0989]\n",
      "Validating:  24%|██▍       | 13/54 [00:09<00:23,  1.71it/s]\u001b[A\n",
      "Epoch 13:   1%|          | 16/1770 [00:10<-1:59:13, -37.07it/s, loss=0.163, v_num=7, val_loss=0.0471, val_acc=0.967, train_loss=0.0989]\n",
      "Validating:  28%|██▊       | 15/54 [00:10<00:22,  1.72it/s]\u001b[A\n",
      "Epoch 13:   1%|          | 18/1770 [00:11<-1:59:08, -33.17it/s, loss=0.163, v_num=7, val_loss=0.0471, val_acc=0.967, train_loss=0.0989]\n",
      "Validating:  31%|███▏      | 17/54 [00:11<00:21,  1.73it/s]\u001b[A\n",
      "Epoch 13:   1%|          | 20/1770 [00:12<-1:59:02, -29.97it/s, loss=0.163, v_num=7, val_loss=0.0471, val_acc=0.967, train_loss=0.0989]\n",
      "Validating:  35%|███▌      | 19/54 [00:12<00:20,  1.72it/s]\u001b[A\n",
      "Epoch 13:   1%|          | 22/1770 [00:13<-1:58:57, -27.31it/s, loss=0.163, v_num=7, val_loss=0.0471, val_acc=0.967, train_loss=0.0989]\n",
      "Validating:  39%|███▉      | 21/54 [00:13<00:19,  1.73it/s]\u001b[A\n",
      "Epoch 13:   1%|▏         | 24/1770 [00:14<-1:58:51, -25.07it/s, loss=0.163, v_num=7, val_loss=0.0471, val_acc=0.967, train_loss=0.0989]\n",
      "Validating:  43%|████▎     | 23/54 [00:14<00:17,  1.72it/s]\u001b[A\n",
      "Epoch 13:   1%|▏         | 26/1770 [00:16<-1:58:45, -23.14it/s, loss=0.163, v_num=7, val_loss=0.0471, val_acc=0.967, train_loss=0.0989]\n",
      "Validating:  46%|████▋     | 25/54 [00:16<00:16,  1.73it/s]\u001b[A\n",
      "Epoch 13:   2%|▏         | 28/1770 [00:17<-1:58:39, -21.47it/s, loss=0.163, v_num=7, val_loss=0.0471, val_acc=0.967, train_loss=0.0989]\n",
      "Validating:  50%|█████     | 27/54 [00:17<00:15,  1.73it/s]\u001b[A\n",
      "Epoch 13:   2%|▏         | 30/1770 [00:18<-1:58:34, -20.03it/s, loss=0.163, v_num=7, val_loss=0.0471, val_acc=0.967, train_loss=0.0989]\n",
      "Validating:  54%|█████▎    | 29/54 [00:18<00:14,  1.74it/s]\u001b[A\n",
      "Epoch 13:   2%|▏         | 32/1770 [00:19<-1:58:28, -18.74it/s, loss=0.163, v_num=7, val_loss=0.0471, val_acc=0.967, train_loss=0.0989]\n",
      "Validating:  57%|█████▋    | 31/54 [00:19<00:13,  1.73it/s]\u001b[A\n",
      "Epoch 13:   2%|▏         | 34/1770 [00:20<-1:58:22, -17.61it/s, loss=0.163, v_num=7, val_loss=0.0471, val_acc=0.967, train_loss=0.0989]\n",
      "Validating:  61%|██████    | 33/54 [00:20<00:12,  1.73it/s]\u001b[A\n",
      "Epoch 13:   2%|▏         | 36/1770 [00:21<-1:58:16, -16.59it/s, loss=0.163, v_num=7, val_loss=0.0471, val_acc=0.967, train_loss=0.0989]\n",
      "Validating:  65%|██████▍   | 35/54 [00:21<00:10,  1.74it/s]\u001b[A\n",
      "Epoch 13:   2%|▏         | 38/1770 [00:23<-1:58:10, -15.67it/s, loss=0.163, v_num=7, val_loss=0.0471, val_acc=0.967, train_loss=0.0989]\n",
      "Validating:  69%|██████▊   | 37/54 [00:22<00:09,  1.74it/s]\u001b[A\n",
      "Epoch 13:   2%|▏         | 40/1770 [00:24<-1:58:04, -14.85it/s, loss=0.163, v_num=7, val_loss=0.0471, val_acc=0.967, train_loss=0.0989]\n",
      "Validating:  72%|███████▏  | 39/54 [00:24<00:08,  1.74it/s]\u001b[A\n",
      "Epoch 13:   2%|▏         | 42/1770 [00:25<-1:57:58, -14.09it/s, loss=0.163, v_num=7, val_loss=0.0471, val_acc=0.967, train_loss=0.0989]\n",
      "Validating:  76%|███████▌  | 41/54 [00:25<00:07,  1.74it/s]\u001b[A\n",
      "Epoch 13:   2%|▏         | 44/1770 [00:26<-1:57:52, -13.41it/s, loss=0.163, v_num=7, val_loss=0.0471, val_acc=0.967, train_loss=0.0989]\n",
      "Validating:  80%|███████▉  | 43/54 [00:26<00:06,  1.74it/s]\u001b[A\n",
      "Epoch 13:   3%|▎         | 46/1770 [00:27<-1:57:46, -12.78it/s, loss=0.163, v_num=7, val_loss=0.0471, val_acc=0.967, train_loss=0.0989]\n",
      "Validating:  83%|████████▎ | 45/54 [00:27<00:05,  1.76it/s]\u001b[A\n",
      "Epoch 13:   3%|▎         | 48/1770 [00:28<-1:57:40, -12.21it/s, loss=0.163, v_num=7, val_loss=0.0471, val_acc=0.967, train_loss=0.0989]\n",
      "Validating:  87%|████████▋ | 47/54 [00:28<00:03,  1.78it/s]\u001b[A\n",
      "Epoch 13:   3%|▎         | 50/1770 [00:29<-1:57:33, -11.69it/s, loss=0.163, v_num=7, val_loss=0.0471, val_acc=0.967, train_loss=0.0989]\n",
      "Validating:  91%|█████████ | 49/54 [00:29<00:02,  1.79it/s]\u001b[A\n",
      "Epoch 13:   3%|▎         | 52/1770 [00:30<-1:57:27, -11.21it/s, loss=0.163, v_num=7, val_loss=0.0471, val_acc=0.967, train_loss=0.0989]\n",
      "Validating:  94%|█████████▍| 51/54 [00:30<00:01,  1.79it/s]\u001b[A\n",
      "Epoch 13:   3%|▎         | 54/1770 [00:32<-1:57:21, -10.75it/s, loss=0.163, v_num=7, val_loss=0.0471, val_acc=0.967, train_loss=0.0989]\n",
      "Validating:  98%|█████████▊| 53/54 [00:31<00:00,  1.79it/s]\u001b[A\n",
      "Epoch 13:   3%|▎         | 56/1770 [00:33<-1:57:15, -10.37it/s, loss=0.163, v_num=7, val_loss=0.0462, val_acc=0.968, train_loss=0.0382]\n",
      "                                                           \u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer was signaled to stop but required minimum epochs (15) or minimum steps (None) has not been met. Training will continue...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14:   0%|          | 2/1770 [00:00<-1:59:57, -585.84it/s, loss=0.163, v_num=7, val_loss=0.0462, val_acc=0.968, train_loss=0.0382] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   2%|▏         | 1/54 [00:02<02:09,  2.44s/it]\u001b[A\n",
      "Epoch 14:   0%|          | 4/1770 [00:03<-1:59:44, -104.68it/s, loss=0.163, v_num=7, val_loss=0.0462, val_acc=0.968, train_loss=0.0382]\n",
      "Validating:   6%|▌         | 3/54 [00:03<00:52,  1.02s/it]\u001b[A\n",
      "Epoch 14:   0%|          | 6/1770 [00:04<-1:59:38, -79.61it/s, loss=0.163, v_num=7, val_loss=0.0462, val_acc=0.968, train_loss=0.0382] \n",
      "Validating:   9%|▉         | 5/54 [00:04<00:36,  1.33it/s]\u001b[A\n",
      "Epoch 14:   0%|          | 8/1770 [00:06<-1:59:33, -64.17it/s, loss=0.163, v_num=7, val_loss=0.0462, val_acc=0.968, train_loss=0.0382]\n",
      "Validating:  13%|█▎        | 7/54 [00:05<00:30,  1.53it/s]\u001b[A\n",
      "Epoch 14:   1%|          | 10/1770 [00:07<-1:59:28, -53.70it/s, loss=0.163, v_num=7, val_loss=0.0462, val_acc=0.968, train_loss=0.0382]\n",
      "Validating:  17%|█▋        | 9/54 [00:07<00:27,  1.63it/s]\u001b[A\n",
      "Epoch 14:   1%|          | 12/1770 [00:08<-1:59:22, -46.08it/s, loss=0.163, v_num=7, val_loss=0.0462, val_acc=0.968, train_loss=0.0382]\n",
      "Validating:  20%|██        | 11/54 [00:08<00:25,  1.68it/s]\u001b[A\n",
      "Epoch 14:   1%|          | 14/1770 [00:09<-1:59:17, -40.30it/s, loss=0.163, v_num=7, val_loss=0.0462, val_acc=0.968, train_loss=0.0382]\n",
      "Validating:  24%|██▍       | 13/54 [00:09<00:23,  1.71it/s]\u001b[A\n",
      "Epoch 14:   1%|          | 16/1770 [00:10<-1:59:11, -35.77it/s, loss=0.163, v_num=7, val_loss=0.0462, val_acc=0.968, train_loss=0.0382]\n",
      "Validating:  28%|██▊       | 15/54 [00:10<00:22,  1.72it/s]\u001b[A\n",
      "Epoch 14:   1%|          | 18/1770 [00:11<-1:59:06, -32.12it/s, loss=0.163, v_num=7, val_loss=0.0462, val_acc=0.968, train_loss=0.0382]\n",
      "Validating:  31%|███▏      | 17/54 [00:11<00:21,  1.72it/s]\u001b[A\n",
      "Epoch 14:   1%|          | 20/1770 [00:13<-1:59:00, -29.10it/s, loss=0.163, v_num=7, val_loss=0.0462, val_acc=0.968, train_loss=0.0382]\n",
      "Validating:  35%|███▌      | 19/54 [00:12<00:20,  1.72it/s]\u001b[A\n",
      "Epoch 14:   1%|          | 22/1770 [00:14<-1:58:55, -26.58it/s, loss=0.163, v_num=7, val_loss=0.0462, val_acc=0.968, train_loss=0.0382]\n",
      "Validating:  39%|███▉      | 21/54 [00:14<00:19,  1.73it/s]\u001b[A\n",
      "Epoch 14:   1%|▏         | 24/1770 [00:15<-1:58:49, -24.45it/s, loss=0.163, v_num=7, val_loss=0.0462, val_acc=0.968, train_loss=0.0382]\n",
      "Validating:  43%|████▎     | 23/54 [00:15<00:17,  1.73it/s]\u001b[A\n",
      "Epoch 14:   1%|▏         | 26/1770 [00:16<-1:58:43, -22.62it/s, loss=0.163, v_num=7, val_loss=0.0462, val_acc=0.968, train_loss=0.0382]\n",
      "Validating:  46%|████▋     | 25/54 [00:16<00:16,  1.73it/s]\u001b[A\n",
      "Epoch 14:   2%|▏         | 28/1770 [00:17<-1:58:38, -21.02it/s, loss=0.163, v_num=7, val_loss=0.0462, val_acc=0.968, train_loss=0.0382]\n",
      "Validating:  50%|█████     | 27/54 [00:17<00:15,  1.73it/s]\u001b[A\n",
      "Epoch 14:   2%|▏         | 30/1770 [00:18<-1:58:32, -19.62it/s, loss=0.163, v_num=7, val_loss=0.0462, val_acc=0.968, train_loss=0.0382]\n",
      "Validating:  54%|█████▎    | 29/54 [00:18<00:14,  1.73it/s]\u001b[A\n",
      "Epoch 14:   2%|▏         | 32/1770 [00:19<-1:58:26, -18.38it/s, loss=0.163, v_num=7, val_loss=0.0462, val_acc=0.968, train_loss=0.0382]\n",
      "Validating:  57%|█████▋    | 31/54 [00:19<00:13,  1.73it/s]\u001b[A\n",
      "Epoch 14:   2%|▏         | 34/1770 [00:21<-1:58:20, -17.28it/s, loss=0.163, v_num=7, val_loss=0.0462, val_acc=0.968, train_loss=0.0382]\n",
      "Validating:  61%|██████    | 33/54 [00:21<00:12,  1.72it/s]\u001b[A\n",
      "Epoch 14:   2%|▏         | 36/1770 [00:22<-1:58:14, -16.29it/s, loss=0.163, v_num=7, val_loss=0.0462, val_acc=0.968, train_loss=0.0382]\n",
      "Validating:  65%|██████▍   | 35/54 [00:22<00:10,  1.73it/s]\u001b[A\n",
      "Epoch 14:   2%|▏         | 38/1770 [00:23<-1:58:08, -15.40it/s, loss=0.163, v_num=7, val_loss=0.0462, val_acc=0.968, train_loss=0.0382]\n",
      "Validating:  69%|██████▊   | 37/54 [00:23<00:09,  1.73it/s]\u001b[A\n",
      "Epoch 14:   2%|▏         | 40/1770 [00:24<-1:58:02, -14.60it/s, loss=0.163, v_num=7, val_loss=0.0462, val_acc=0.968, train_loss=0.0382]\n",
      "Validating:  72%|███████▏  | 39/54 [00:24<00:08,  1.73it/s]\u001b[A\n",
      "Epoch 14:   2%|▏         | 42/1770 [00:25<-1:57:56, -13.86it/s, loss=0.163, v_num=7, val_loss=0.0462, val_acc=0.968, train_loss=0.0382]\n",
      "Validating:  76%|███████▌  | 41/54 [00:25<00:07,  1.73it/s]\u001b[A\n",
      "Epoch 14:   2%|▏         | 44/1770 [00:26<-1:57:50, -13.20it/s, loss=0.163, v_num=7, val_loss=0.0462, val_acc=0.968, train_loss=0.0382]\n",
      "Validating:  80%|███████▉  | 43/54 [00:26<00:06,  1.73it/s]\u001b[A\n",
      "Epoch 14:   3%|▎         | 46/1770 [00:28<-1:57:43, -12.58it/s, loss=0.163, v_num=7, val_loss=0.0462, val_acc=0.968, train_loss=0.0382]\n",
      "Validating:  83%|████████▎ | 45/54 [00:27<00:05,  1.75it/s]\u001b[A\n",
      "Epoch 14:   3%|▎         | 48/1770 [00:29<-1:57:37, -12.03it/s, loss=0.163, v_num=7, val_loss=0.0462, val_acc=0.968, train_loss=0.0382]\n",
      "Validating:  87%|████████▋ | 47/54 [00:29<00:03,  1.77it/s]\u001b[A\n",
      "Epoch 14:   3%|▎         | 50/1770 [00:30<-1:57:31, -11.53it/s, loss=0.163, v_num=7, val_loss=0.0462, val_acc=0.968, train_loss=0.0382]\n",
      "Validating:  91%|█████████ | 49/54 [00:30<00:02,  1.78it/s]\u001b[A\n",
      "Epoch 14:   3%|▎         | 52/1770 [00:31<-1:57:25, -11.05it/s, loss=0.163, v_num=7, val_loss=0.0462, val_acc=0.968, train_loss=0.0382]\n",
      "Validating:  94%|█████████▍| 51/54 [00:31<00:01,  1.79it/s]\u001b[A\n",
      "Epoch 14:   3%|▎         | 54/1770 [00:32<-1:57:19, -10.61it/s, loss=0.163, v_num=7, val_loss=0.0462, val_acc=0.968, train_loss=0.0382]\n",
      "Validating:  98%|█████████▊| 53/54 [00:32<00:00,  1.79it/s]\u001b[A\n",
      "Epoch 14:   3%|▎         | 56/1770 [00:33<-1:57:13, -10.24it/s, loss=0.163, v_num=7, val_loss=0.0463, val_acc=0.968, train_loss=0.0952]\n",
      "                                                           \u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: None, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training fold 4\n",
      "Class sample counts [ 675 1382 1482 8725 1462]\n",
      "After class sample counts [2025 2764 3408 8725 3947]\n",
      "conv_stem.weight True\n",
      "bn1.weight False\n",
      "bn1.bias False\n",
      "blocks.0.0.conv_dw.weight True\n",
      "blocks.0.0.bn1.weight False\n",
      "blocks.0.0.bn1.bias False\n",
      "blocks.0.0.se.conv_reduce.weight True\n",
      "blocks.0.0.se.conv_reduce.bias True\n",
      "blocks.0.0.se.conv_expand.weight True\n",
      "blocks.0.0.se.conv_expand.bias True\n",
      "blocks.0.0.conv_pw.weight True\n",
      "blocks.0.0.bn2.weight False\n",
      "blocks.0.0.bn2.bias False\n",
      "blocks.0.1.conv_dw.weight True\n",
      "blocks.0.1.bn1.weight False\n",
      "blocks.0.1.bn1.bias False\n",
      "blocks.0.1.se.conv_reduce.weight True\n",
      "blocks.0.1.se.conv_reduce.bias True\n",
      "blocks.0.1.se.conv_expand.weight True\n",
      "blocks.0.1.se.conv_expand.bias True\n",
      "blocks.0.1.conv_pw.weight True\n",
      "blocks.0.1.bn2.weight False\n",
      "blocks.0.1.bn2.bias False\n",
      "blocks.1.0.conv_pw.weight True\n",
      "blocks.1.0.bn1.weight False\n",
      "blocks.1.0.bn1.bias False\n",
      "blocks.1.0.conv_dw.weight True\n",
      "blocks.1.0.bn2.weight False\n",
      "blocks.1.0.bn2.bias False\n",
      "blocks.1.0.se.conv_reduce.weight True\n",
      "blocks.1.0.se.conv_reduce.bias True\n",
      "blocks.1.0.se.conv_expand.weight True\n",
      "blocks.1.0.se.conv_expand.bias True\n",
      "blocks.1.0.conv_pwl.weight True\n",
      "blocks.1.0.bn3.weight False\n",
      "blocks.1.0.bn3.bias False\n",
      "blocks.1.1.conv_pw.weight True\n",
      "blocks.1.1.bn1.weight False\n",
      "blocks.1.1.bn1.bias False\n",
      "blocks.1.1.conv_dw.weight True\n",
      "blocks.1.1.bn2.weight False\n",
      "blocks.1.1.bn2.bias False\n",
      "blocks.1.1.se.conv_reduce.weight True\n",
      "blocks.1.1.se.conv_reduce.bias True\n",
      "blocks.1.1.se.conv_expand.weight True\n",
      "blocks.1.1.se.conv_expand.bias True\n",
      "blocks.1.1.conv_pwl.weight True\n",
      "blocks.1.1.bn3.weight False\n",
      "blocks.1.1.bn3.bias False\n",
      "blocks.1.2.conv_pw.weight True\n",
      "blocks.1.2.bn1.weight False\n",
      "blocks.1.2.bn1.bias False\n",
      "blocks.1.2.conv_dw.weight True\n",
      "blocks.1.2.bn2.weight False\n",
      "blocks.1.2.bn2.bias False\n",
      "blocks.1.2.se.conv_reduce.weight True\n",
      "blocks.1.2.se.conv_reduce.bias True\n",
      "blocks.1.2.se.conv_expand.weight True\n",
      "blocks.1.2.se.conv_expand.bias True\n",
      "blocks.1.2.conv_pwl.weight True\n",
      "blocks.1.2.bn3.weight False\n",
      "blocks.1.2.bn3.bias False\n",
      "blocks.1.3.conv_pw.weight True\n",
      "blocks.1.3.bn1.weight False\n",
      "blocks.1.3.bn1.bias False\n",
      "blocks.1.3.conv_dw.weight True\n",
      "blocks.1.3.bn2.weight False\n",
      "blocks.1.3.bn2.bias False\n",
      "blocks.1.3.se.conv_reduce.weight True\n",
      "blocks.1.3.se.conv_reduce.bias True\n",
      "blocks.1.3.se.conv_expand.weight True\n",
      "blocks.1.3.se.conv_expand.bias True\n",
      "blocks.1.3.conv_pwl.weight True\n",
      "blocks.1.3.bn3.weight False\n",
      "blocks.1.3.bn3.bias False\n",
      "blocks.2.0.conv_pw.weight True\n",
      "blocks.2.0.bn1.weight False\n",
      "blocks.2.0.bn1.bias False\n",
      "blocks.2.0.conv_dw.weight True\n",
      "blocks.2.0.bn2.weight False\n",
      "blocks.2.0.bn2.bias False\n",
      "blocks.2.0.se.conv_reduce.weight True\n",
      "blocks.2.0.se.conv_reduce.bias True\n",
      "blocks.2.0.se.conv_expand.weight True\n",
      "blocks.2.0.se.conv_expand.bias True\n",
      "blocks.2.0.conv_pwl.weight True\n",
      "blocks.2.0.bn3.weight False\n",
      "blocks.2.0.bn3.bias False\n",
      "blocks.2.1.conv_pw.weight True\n",
      "blocks.2.1.bn1.weight False\n",
      "blocks.2.1.bn1.bias False\n",
      "blocks.2.1.conv_dw.weight True\n",
      "blocks.2.1.bn2.weight False\n",
      "blocks.2.1.bn2.bias False\n",
      "blocks.2.1.se.conv_reduce.weight True\n",
      "blocks.2.1.se.conv_reduce.bias True\n",
      "blocks.2.1.se.conv_expand.weight True\n",
      "blocks.2.1.se.conv_expand.bias True\n",
      "blocks.2.1.conv_pwl.weight True\n",
      "blocks.2.1.bn3.weight False\n",
      "blocks.2.1.bn3.bias False\n",
      "blocks.2.2.conv_pw.weight True\n",
      "blocks.2.2.bn1.weight False\n",
      "blocks.2.2.bn1.bias False\n",
      "blocks.2.2.conv_dw.weight True\n",
      "blocks.2.2.bn2.weight False\n",
      "blocks.2.2.bn2.bias False\n",
      "blocks.2.2.se.conv_reduce.weight True\n",
      "blocks.2.2.se.conv_reduce.bias True\n",
      "blocks.2.2.se.conv_expand.weight True\n",
      "blocks.2.2.se.conv_expand.bias True\n",
      "blocks.2.2.conv_pwl.weight True\n",
      "blocks.2.2.bn3.weight False\n",
      "blocks.2.2.bn3.bias False\n",
      "blocks.2.3.conv_pw.weight True\n",
      "blocks.2.3.bn1.weight False\n",
      "blocks.2.3.bn1.bias False\n",
      "blocks.2.3.conv_dw.weight True\n",
      "blocks.2.3.bn2.weight False\n",
      "blocks.2.3.bn2.bias False\n",
      "blocks.2.3.se.conv_reduce.weight True\n",
      "blocks.2.3.se.conv_reduce.bias True\n",
      "blocks.2.3.se.conv_expand.weight True\n",
      "blocks.2.3.se.conv_expand.bias True\n",
      "blocks.2.3.conv_pwl.weight True\n",
      "blocks.2.3.bn3.weight False\n",
      "blocks.2.3.bn3.bias False\n",
      "blocks.3.0.conv_pw.weight True\n",
      "blocks.3.0.bn1.weight False\n",
      "blocks.3.0.bn1.bias False\n",
      "blocks.3.0.conv_dw.weight True\n",
      "blocks.3.0.bn2.weight False\n",
      "blocks.3.0.bn2.bias False\n",
      "blocks.3.0.se.conv_reduce.weight True\n",
      "blocks.3.0.se.conv_reduce.bias True\n",
      "blocks.3.0.se.conv_expand.weight True\n",
      "blocks.3.0.se.conv_expand.bias True\n",
      "blocks.3.0.conv_pwl.weight True\n",
      "blocks.3.0.bn3.weight False\n",
      "blocks.3.0.bn3.bias False\n",
      "blocks.3.1.conv_pw.weight True\n",
      "blocks.3.1.bn1.weight False\n",
      "blocks.3.1.bn1.bias False\n",
      "blocks.3.1.conv_dw.weight True\n",
      "blocks.3.1.bn2.weight False\n",
      "blocks.3.1.bn2.bias False\n",
      "blocks.3.1.se.conv_reduce.weight True\n",
      "blocks.3.1.se.conv_reduce.bias True\n",
      "blocks.3.1.se.conv_expand.weight True\n",
      "blocks.3.1.se.conv_expand.bias True\n",
      "blocks.3.1.conv_pwl.weight True\n",
      "blocks.3.1.bn3.weight False\n",
      "blocks.3.1.bn3.bias False\n",
      "blocks.3.2.conv_pw.weight True\n",
      "blocks.3.2.bn1.weight False\n",
      "blocks.3.2.bn1.bias False\n",
      "blocks.3.2.conv_dw.weight True\n",
      "blocks.3.2.bn2.weight False\n",
      "blocks.3.2.bn2.bias False\n",
      "blocks.3.2.se.conv_reduce.weight True\n",
      "blocks.3.2.se.conv_reduce.bias True\n",
      "blocks.3.2.se.conv_expand.weight True\n",
      "blocks.3.2.se.conv_expand.bias True\n",
      "blocks.3.2.conv_pwl.weight True\n",
      "blocks.3.2.bn3.weight False\n",
      "blocks.3.2.bn3.bias False\n",
      "blocks.3.3.conv_pw.weight True\n",
      "blocks.3.3.bn1.weight False\n",
      "blocks.3.3.bn1.bias False\n",
      "blocks.3.3.conv_dw.weight True\n",
      "blocks.3.3.bn2.weight False\n",
      "blocks.3.3.bn2.bias False\n",
      "blocks.3.3.se.conv_reduce.weight True\n",
      "blocks.3.3.se.conv_reduce.bias True\n",
      "blocks.3.3.se.conv_expand.weight True\n",
      "blocks.3.3.se.conv_expand.bias True\n",
      "blocks.3.3.conv_pwl.weight True\n",
      "blocks.3.3.bn3.weight False\n",
      "blocks.3.3.bn3.bias False\n",
      "blocks.3.4.conv_pw.weight True\n",
      "blocks.3.4.bn1.weight False\n",
      "blocks.3.4.bn1.bias False\n",
      "blocks.3.4.conv_dw.weight True\n",
      "blocks.3.4.bn2.weight False\n",
      "blocks.3.4.bn2.bias False\n",
      "blocks.3.4.se.conv_reduce.weight True\n",
      "blocks.3.4.se.conv_reduce.bias True\n",
      "blocks.3.4.se.conv_expand.weight True\n",
      "blocks.3.4.se.conv_expand.bias True\n",
      "blocks.3.4.conv_pwl.weight True\n",
      "blocks.3.4.bn3.weight False\n",
      "blocks.3.4.bn3.bias False\n",
      "blocks.3.5.conv_pw.weight True\n",
      "blocks.3.5.bn1.weight False\n",
      "blocks.3.5.bn1.bias False\n",
      "blocks.3.5.conv_dw.weight True\n",
      "blocks.3.5.bn2.weight False\n",
      "blocks.3.5.bn2.bias False\n",
      "blocks.3.5.se.conv_reduce.weight True\n",
      "blocks.3.5.se.conv_reduce.bias True\n",
      "blocks.3.5.se.conv_expand.weight True\n",
      "blocks.3.5.se.conv_expand.bias True\n",
      "blocks.3.5.conv_pwl.weight True\n",
      "blocks.3.5.bn3.weight False\n",
      "blocks.3.5.bn3.bias False\n",
      "blocks.4.0.conv_pw.weight True\n",
      "blocks.4.0.bn1.weight False\n",
      "blocks.4.0.bn1.bias False\n",
      "blocks.4.0.conv_dw.weight True\n",
      "blocks.4.0.bn2.weight False\n",
      "blocks.4.0.bn2.bias False\n",
      "blocks.4.0.se.conv_reduce.weight True\n",
      "blocks.4.0.se.conv_reduce.bias True\n",
      "blocks.4.0.se.conv_expand.weight True\n",
      "blocks.4.0.se.conv_expand.bias True\n",
      "blocks.4.0.conv_pwl.weight True\n",
      "blocks.4.0.bn3.weight False\n",
      "blocks.4.0.bn3.bias False\n",
      "blocks.4.1.conv_pw.weight True\n",
      "blocks.4.1.bn1.weight False\n",
      "blocks.4.1.bn1.bias False\n",
      "blocks.4.1.conv_dw.weight True\n",
      "blocks.4.1.bn2.weight False\n",
      "blocks.4.1.bn2.bias False\n",
      "blocks.4.1.se.conv_reduce.weight True\n",
      "blocks.4.1.se.conv_reduce.bias True\n",
      "blocks.4.1.se.conv_expand.weight True\n",
      "blocks.4.1.se.conv_expand.bias True\n",
      "blocks.4.1.conv_pwl.weight True\n",
      "blocks.4.1.bn3.weight False\n",
      "blocks.4.1.bn3.bias False\n",
      "blocks.4.2.conv_pw.weight True\n",
      "blocks.4.2.bn1.weight False\n",
      "blocks.4.2.bn1.bias False\n",
      "blocks.4.2.conv_dw.weight True\n",
      "blocks.4.2.bn2.weight False\n",
      "blocks.4.2.bn2.bias False\n",
      "blocks.4.2.se.conv_reduce.weight True\n",
      "blocks.4.2.se.conv_reduce.bias True\n",
      "blocks.4.2.se.conv_expand.weight True\n",
      "blocks.4.2.se.conv_expand.bias True\n",
      "blocks.4.2.conv_pwl.weight True\n",
      "blocks.4.2.bn3.weight False\n",
      "blocks.4.2.bn3.bias False\n",
      "blocks.4.3.conv_pw.weight True\n",
      "blocks.4.3.bn1.weight False\n",
      "blocks.4.3.bn1.bias False\n",
      "blocks.4.3.conv_dw.weight True\n",
      "blocks.4.3.bn2.weight False\n",
      "blocks.4.3.bn2.bias False\n",
      "blocks.4.3.se.conv_reduce.weight True\n",
      "blocks.4.3.se.conv_reduce.bias True\n",
      "blocks.4.3.se.conv_expand.weight True\n",
      "blocks.4.3.se.conv_expand.bias True\n",
      "blocks.4.3.conv_pwl.weight True\n",
      "blocks.4.3.bn3.weight False\n",
      "blocks.4.3.bn3.bias False\n",
      "blocks.4.4.conv_pw.weight True\n",
      "blocks.4.4.bn1.weight False\n",
      "blocks.4.4.bn1.bias False\n",
      "blocks.4.4.conv_dw.weight True\n",
      "blocks.4.4.bn2.weight False\n",
      "blocks.4.4.bn2.bias False\n",
      "blocks.4.4.se.conv_reduce.weight True\n",
      "blocks.4.4.se.conv_reduce.bias True\n",
      "blocks.4.4.se.conv_expand.weight True\n",
      "blocks.4.4.se.conv_expand.bias True\n",
      "blocks.4.4.conv_pwl.weight True\n",
      "blocks.4.4.bn3.weight False\n",
      "blocks.4.4.bn3.bias False\n",
      "blocks.4.5.conv_pw.weight True\n",
      "blocks.4.5.bn1.weight False\n",
      "blocks.4.5.bn1.bias False\n",
      "blocks.4.5.conv_dw.weight True\n",
      "blocks.4.5.bn2.weight False\n",
      "blocks.4.5.bn2.bias False\n",
      "blocks.4.5.se.conv_reduce.weight True\n",
      "blocks.4.5.se.conv_reduce.bias True\n",
      "blocks.4.5.se.conv_expand.weight True\n",
      "blocks.4.5.se.conv_expand.bias True\n",
      "blocks.4.5.conv_pwl.weight True\n",
      "blocks.4.5.bn3.weight False\n",
      "blocks.4.5.bn3.bias False\n",
      "blocks.5.0.conv_pw.weight True\n",
      "blocks.5.0.bn1.weight False\n",
      "blocks.5.0.bn1.bias False\n",
      "blocks.5.0.conv_dw.weight True\n",
      "blocks.5.0.bn2.weight False\n",
      "blocks.5.0.bn2.bias False\n",
      "blocks.5.0.se.conv_reduce.weight True\n",
      "blocks.5.0.se.conv_reduce.bias True\n",
      "blocks.5.0.se.conv_expand.weight True\n",
      "blocks.5.0.se.conv_expand.bias True\n",
      "blocks.5.0.conv_pwl.weight True\n",
      "blocks.5.0.bn3.weight False\n",
      "blocks.5.0.bn3.bias False\n",
      "blocks.5.1.conv_pw.weight True\n",
      "blocks.5.1.bn1.weight False\n",
      "blocks.5.1.bn1.bias False\n",
      "blocks.5.1.conv_dw.weight True\n",
      "blocks.5.1.bn2.weight False\n",
      "blocks.5.1.bn2.bias False\n",
      "blocks.5.1.se.conv_reduce.weight True\n",
      "blocks.5.1.se.conv_reduce.bias True\n",
      "blocks.5.1.se.conv_expand.weight True\n",
      "blocks.5.1.se.conv_expand.bias True\n",
      "blocks.5.1.conv_pwl.weight True\n",
      "blocks.5.1.bn3.weight False\n",
      "blocks.5.1.bn3.bias False\n",
      "blocks.5.2.conv_pw.weight True\n",
      "blocks.5.2.bn1.weight False\n",
      "blocks.5.2.bn1.bias False\n",
      "blocks.5.2.conv_dw.weight True\n",
      "blocks.5.2.bn2.weight False\n",
      "blocks.5.2.bn2.bias False\n",
      "blocks.5.2.se.conv_reduce.weight True\n",
      "blocks.5.2.se.conv_reduce.bias True\n",
      "blocks.5.2.se.conv_expand.weight True\n",
      "blocks.5.2.se.conv_expand.bias True\n",
      "blocks.5.2.conv_pwl.weight True\n",
      "blocks.5.2.bn3.weight False\n",
      "blocks.5.2.bn3.bias False\n",
      "blocks.5.3.conv_pw.weight True\n",
      "blocks.5.3.bn1.weight False\n",
      "blocks.5.3.bn1.bias False\n",
      "blocks.5.3.conv_dw.weight True\n",
      "blocks.5.3.bn2.weight False\n",
      "blocks.5.3.bn2.bias False\n",
      "blocks.5.3.se.conv_reduce.weight True\n",
      "blocks.5.3.se.conv_reduce.bias True\n",
      "blocks.5.3.se.conv_expand.weight True\n",
      "blocks.5.3.se.conv_expand.bias True\n",
      "blocks.5.3.conv_pwl.weight True\n",
      "blocks.5.3.bn3.weight False\n",
      "blocks.5.3.bn3.bias False\n",
      "blocks.5.4.conv_pw.weight True\n",
      "blocks.5.4.bn1.weight False\n",
      "blocks.5.4.bn1.bias False\n",
      "blocks.5.4.conv_dw.weight True\n",
      "blocks.5.4.bn2.weight False\n",
      "blocks.5.4.bn2.bias False\n",
      "blocks.5.4.se.conv_reduce.weight True\n",
      "blocks.5.4.se.conv_reduce.bias True\n",
      "blocks.5.4.se.conv_expand.weight True\n",
      "blocks.5.4.se.conv_expand.bias True\n",
      "blocks.5.4.conv_pwl.weight True\n",
      "blocks.5.4.bn3.weight False\n",
      "blocks.5.4.bn3.bias False\n",
      "blocks.5.5.conv_pw.weight True\n",
      "blocks.5.5.bn1.weight False\n",
      "blocks.5.5.bn1.bias False\n",
      "blocks.5.5.conv_dw.weight True\n",
      "blocks.5.5.bn2.weight False\n",
      "blocks.5.5.bn2.bias False\n",
      "blocks.5.5.se.conv_reduce.weight True\n",
      "blocks.5.5.se.conv_reduce.bias True\n",
      "blocks.5.5.se.conv_expand.weight True\n",
      "blocks.5.5.se.conv_expand.bias True\n",
      "blocks.5.5.conv_pwl.weight True\n",
      "blocks.5.5.bn3.weight False\n",
      "blocks.5.5.bn3.bias False\n",
      "blocks.5.6.conv_pw.weight True\n",
      "blocks.5.6.bn1.weight False\n",
      "blocks.5.6.bn1.bias False\n",
      "blocks.5.6.conv_dw.weight True\n",
      "blocks.5.6.bn2.weight False\n",
      "blocks.5.6.bn2.bias False\n",
      "blocks.5.6.se.conv_reduce.weight True\n",
      "blocks.5.6.se.conv_reduce.bias True\n",
      "blocks.5.6.se.conv_expand.weight True\n",
      "blocks.5.6.se.conv_expand.bias True\n",
      "blocks.5.6.conv_pwl.weight True\n",
      "blocks.5.6.bn3.weight False\n",
      "blocks.5.6.bn3.bias False\n",
      "blocks.5.7.conv_pw.weight True\n",
      "blocks.5.7.bn1.weight False\n",
      "blocks.5.7.bn1.bias False\n",
      "blocks.5.7.conv_dw.weight True\n",
      "blocks.5.7.bn2.weight False\n",
      "blocks.5.7.bn2.bias False\n",
      "blocks.5.7.se.conv_reduce.weight True\n",
      "blocks.5.7.se.conv_reduce.bias True\n",
      "blocks.5.7.se.conv_expand.weight True\n",
      "blocks.5.7.se.conv_expand.bias True\n",
      "blocks.5.7.conv_pwl.weight True\n",
      "blocks.5.7.bn3.weight False\n",
      "blocks.5.7.bn3.bias False\n",
      "blocks.6.0.conv_pw.weight True\n",
      "blocks.6.0.bn1.weight False\n",
      "blocks.6.0.bn1.bias False\n",
      "blocks.6.0.conv_dw.weight True\n",
      "blocks.6.0.bn2.weight False\n",
      "blocks.6.0.bn2.bias False\n",
      "blocks.6.0.se.conv_reduce.weight True\n",
      "blocks.6.0.se.conv_reduce.bias True\n",
      "blocks.6.0.se.conv_expand.weight True\n",
      "blocks.6.0.se.conv_expand.bias True\n",
      "blocks.6.0.conv_pwl.weight True\n",
      "blocks.6.0.bn3.weight False\n",
      "blocks.6.0.bn3.bias False\n",
      "blocks.6.1.conv_pw.weight True\n",
      "blocks.6.1.bn1.weight False\n",
      "blocks.6.1.bn1.bias False\n",
      "blocks.6.1.conv_dw.weight True\n",
      "blocks.6.1.bn2.weight False\n",
      "blocks.6.1.bn2.bias False\n",
      "blocks.6.1.se.conv_reduce.weight True\n",
      "blocks.6.1.se.conv_reduce.bias True\n",
      "blocks.6.1.se.conv_expand.weight True\n",
      "blocks.6.1.se.conv_expand.bias True\n",
      "blocks.6.1.conv_pwl.weight True\n",
      "blocks.6.1.bn3.weight False\n",
      "blocks.6.1.bn3.bias False\n",
      "conv_head.weight True\n",
      "bn2.weight False\n",
      "bn2.bias False\n",
      "classifier.weight True\n",
      "classifier.bias True\n",
      "EfficientNet(\n",
      "  (conv_stem): Conv2dSame(3, 48, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
      "  (bn1): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (act1): SiLU(inplace=True)\n",
      "  (blocks): Sequential(\n",
      "    (0): Sequential(\n",
      "      (0): DepthwiseSeparableConv(\n",
      "        (conv_dw): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=48, bias=False)\n",
      "        (bn1): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act1): SiLU(inplace=True)\n",
      "        (se): SqueezeExcite(\n",
      "          (conv_reduce): Conv2d(48, 12, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (act1): SiLU(inplace=True)\n",
      "          (conv_expand): Conv2d(12, 48, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "        (conv_pw): Conv2d(48, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(24, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act2): Identity()\n",
      "      )\n",
      "      (1): DepthwiseSeparableConv(\n",
      "        (conv_dw): Conv2d(24, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=24, bias=False)\n",
      "        (bn1): BatchNorm2d(24, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act1): SiLU(inplace=True)\n",
      "        (se): SqueezeExcite(\n",
      "          (conv_reduce): Conv2d(24, 6, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (act1): SiLU(inplace=True)\n",
      "          (conv_expand): Conv2d(6, 24, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "        (conv_pw): Conv2d(24, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(24, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act2): Identity()\n",
      "      )\n",
      "    )\n",
      "    (1): Sequential(\n",
      "      (0): InvertedResidual(\n",
      "        (conv_pw): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(144, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act1): SiLU(inplace=True)\n",
      "        (conv_dw): Conv2dSame(144, 144, kernel_size=(3, 3), stride=(2, 2), groups=144, bias=False)\n",
      "        (bn2): BatchNorm2d(144, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act2): SiLU(inplace=True)\n",
      "        (se): SqueezeExcite(\n",
      "          (conv_reduce): Conv2d(144, 6, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (act1): SiLU(inplace=True)\n",
      "          (conv_expand): Conv2d(6, 144, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "        (conv_pwl): Conv2d(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (1): InvertedResidual(\n",
      "        (conv_pw): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act1): SiLU(inplace=True)\n",
      "        (conv_dw): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
      "        (bn2): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act2): SiLU(inplace=True)\n",
      "        (se): SqueezeExcite(\n",
      "          (conv_reduce): Conv2d(192, 8, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (act1): SiLU(inplace=True)\n",
      "          (conv_expand): Conv2d(8, 192, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "        (conv_pwl): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (2): InvertedResidual(\n",
      "        (conv_pw): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act1): SiLU(inplace=True)\n",
      "        (conv_dw): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
      "        (bn2): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act2): SiLU(inplace=True)\n",
      "        (se): SqueezeExcite(\n",
      "          (conv_reduce): Conv2d(192, 8, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (act1): SiLU(inplace=True)\n",
      "          (conv_expand): Conv2d(8, 192, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "        (conv_pwl): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (3): InvertedResidual(\n",
      "        (conv_pw): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act1): SiLU(inplace=True)\n",
      "        (conv_dw): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
      "        (bn2): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act2): SiLU(inplace=True)\n",
      "        (se): SqueezeExcite(\n",
      "          (conv_reduce): Conv2d(192, 8, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (act1): SiLU(inplace=True)\n",
      "          (conv_expand): Conv2d(8, 192, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "        (conv_pwl): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (2): Sequential(\n",
      "      (0): InvertedResidual(\n",
      "        (conv_pw): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act1): SiLU(inplace=True)\n",
      "        (conv_dw): Conv2dSame(192, 192, kernel_size=(5, 5), stride=(2, 2), groups=192, bias=False)\n",
      "        (bn2): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act2): SiLU(inplace=True)\n",
      "        (se): SqueezeExcite(\n",
      "          (conv_reduce): Conv2d(192, 8, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (act1): SiLU(inplace=True)\n",
      "          (conv_expand): Conv2d(8, 192, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "        (conv_pwl): Conv2d(192, 56, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(56, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (1): InvertedResidual(\n",
      "        (conv_pw): Conv2d(56, 336, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(336, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act1): SiLU(inplace=True)\n",
      "        (conv_dw): Conv2d(336, 336, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=336, bias=False)\n",
      "        (bn2): BatchNorm2d(336, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act2): SiLU(inplace=True)\n",
      "        (se): SqueezeExcite(\n",
      "          (conv_reduce): Conv2d(336, 14, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (act1): SiLU(inplace=True)\n",
      "          (conv_expand): Conv2d(14, 336, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "        (conv_pwl): Conv2d(336, 56, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(56, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (2): InvertedResidual(\n",
      "        (conv_pw): Conv2d(56, 336, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(336, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act1): SiLU(inplace=True)\n",
      "        (conv_dw): Conv2d(336, 336, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=336, bias=False)\n",
      "        (bn2): BatchNorm2d(336, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act2): SiLU(inplace=True)\n",
      "        (se): SqueezeExcite(\n",
      "          (conv_reduce): Conv2d(336, 14, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (act1): SiLU(inplace=True)\n",
      "          (conv_expand): Conv2d(14, 336, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "        (conv_pwl): Conv2d(336, 56, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(56, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (3): InvertedResidual(\n",
      "        (conv_pw): Conv2d(56, 336, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(336, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act1): SiLU(inplace=True)\n",
      "        (conv_dw): Conv2d(336, 336, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=336, bias=False)\n",
      "        (bn2): BatchNorm2d(336, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act2): SiLU(inplace=True)\n",
      "        (se): SqueezeExcite(\n",
      "          (conv_reduce): Conv2d(336, 14, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (act1): SiLU(inplace=True)\n",
      "          (conv_expand): Conv2d(14, 336, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "        (conv_pwl): Conv2d(336, 56, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(56, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (3): Sequential(\n",
      "      (0): InvertedResidual(\n",
      "        (conv_pw): Conv2d(56, 336, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(336, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act1): SiLU(inplace=True)\n",
      "        (conv_dw): Conv2dSame(336, 336, kernel_size=(3, 3), stride=(2, 2), groups=336, bias=False)\n",
      "        (bn2): BatchNorm2d(336, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act2): SiLU(inplace=True)\n",
      "        (se): SqueezeExcite(\n",
      "          (conv_reduce): Conv2d(336, 14, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (act1): SiLU(inplace=True)\n",
      "          (conv_expand): Conv2d(14, 336, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "        (conv_pwl): Conv2d(336, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(112, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (1): InvertedResidual(\n",
      "        (conv_pw): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act1): SiLU(inplace=True)\n",
      "        (conv_dw): Conv2d(672, 672, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=672, bias=False)\n",
      "        (bn2): BatchNorm2d(672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act2): SiLU(inplace=True)\n",
      "        (se): SqueezeExcite(\n",
      "          (conv_reduce): Conv2d(672, 28, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (act1): SiLU(inplace=True)\n",
      "          (conv_expand): Conv2d(28, 672, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "        (conv_pwl): Conv2d(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(112, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (2): InvertedResidual(\n",
      "        (conv_pw): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act1): SiLU(inplace=True)\n",
      "        (conv_dw): Conv2d(672, 672, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=672, bias=False)\n",
      "        (bn2): BatchNorm2d(672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act2): SiLU(inplace=True)\n",
      "        (se): SqueezeExcite(\n",
      "          (conv_reduce): Conv2d(672, 28, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (act1): SiLU(inplace=True)\n",
      "          (conv_expand): Conv2d(28, 672, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "        (conv_pwl): Conv2d(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(112, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (3): InvertedResidual(\n",
      "        (conv_pw): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act1): SiLU(inplace=True)\n",
      "        (conv_dw): Conv2d(672, 672, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=672, bias=False)\n",
      "        (bn2): BatchNorm2d(672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act2): SiLU(inplace=True)\n",
      "        (se): SqueezeExcite(\n",
      "          (conv_reduce): Conv2d(672, 28, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (act1): SiLU(inplace=True)\n",
      "          (conv_expand): Conv2d(28, 672, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "        (conv_pwl): Conv2d(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(112, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (4): InvertedResidual(\n",
      "        (conv_pw): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act1): SiLU(inplace=True)\n",
      "        (conv_dw): Conv2d(672, 672, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=672, bias=False)\n",
      "        (bn2): BatchNorm2d(672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act2): SiLU(inplace=True)\n",
      "        (se): SqueezeExcite(\n",
      "          (conv_reduce): Conv2d(672, 28, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (act1): SiLU(inplace=True)\n",
      "          (conv_expand): Conv2d(28, 672, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "        (conv_pwl): Conv2d(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(112, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (5): InvertedResidual(\n",
      "        (conv_pw): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act1): SiLU(inplace=True)\n",
      "        (conv_dw): Conv2d(672, 672, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=672, bias=False)\n",
      "        (bn2): BatchNorm2d(672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act2): SiLU(inplace=True)\n",
      "        (se): SqueezeExcite(\n",
      "          (conv_reduce): Conv2d(672, 28, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (act1): SiLU(inplace=True)\n",
      "          (conv_expand): Conv2d(28, 672, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "        (conv_pwl): Conv2d(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(112, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (4): Sequential(\n",
      "      (0): InvertedResidual(\n",
      "        (conv_pw): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act1): SiLU(inplace=True)\n",
      "        (conv_dw): Conv2d(672, 672, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=672, bias=False)\n",
      "        (bn2): BatchNorm2d(672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act2): SiLU(inplace=True)\n",
      "        (se): SqueezeExcite(\n",
      "          (conv_reduce): Conv2d(672, 28, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (act1): SiLU(inplace=True)\n",
      "          (conv_expand): Conv2d(28, 672, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "        (conv_pwl): Conv2d(672, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (1): InvertedResidual(\n",
      "        (conv_pw): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(960, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act1): SiLU(inplace=True)\n",
      "        (conv_dw): Conv2d(960, 960, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=960, bias=False)\n",
      "        (bn2): BatchNorm2d(960, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act2): SiLU(inplace=True)\n",
      "        (se): SqueezeExcite(\n",
      "          (conv_reduce): Conv2d(960, 40, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (act1): SiLU(inplace=True)\n",
      "          (conv_expand): Conv2d(40, 960, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "        (conv_pwl): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (2): InvertedResidual(\n",
      "        (conv_pw): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(960, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act1): SiLU(inplace=True)\n",
      "        (conv_dw): Conv2d(960, 960, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=960, bias=False)\n",
      "        (bn2): BatchNorm2d(960, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act2): SiLU(inplace=True)\n",
      "        (se): SqueezeExcite(\n",
      "          (conv_reduce): Conv2d(960, 40, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (act1): SiLU(inplace=True)\n",
      "          (conv_expand): Conv2d(40, 960, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "        (conv_pwl): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (3): InvertedResidual(\n",
      "        (conv_pw): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(960, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act1): SiLU(inplace=True)\n",
      "        (conv_dw): Conv2d(960, 960, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=960, bias=False)\n",
      "        (bn2): BatchNorm2d(960, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act2): SiLU(inplace=True)\n",
      "        (se): SqueezeExcite(\n",
      "          (conv_reduce): Conv2d(960, 40, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (act1): SiLU(inplace=True)\n",
      "          (conv_expand): Conv2d(40, 960, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "        (conv_pwl): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (4): InvertedResidual(\n",
      "        (conv_pw): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(960, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act1): SiLU(inplace=True)\n",
      "        (conv_dw): Conv2d(960, 960, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=960, bias=False)\n",
      "        (bn2): BatchNorm2d(960, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act2): SiLU(inplace=True)\n",
      "        (se): SqueezeExcite(\n",
      "          (conv_reduce): Conv2d(960, 40, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (act1): SiLU(inplace=True)\n",
      "          (conv_expand): Conv2d(40, 960, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "        (conv_pwl): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (5): InvertedResidual(\n",
      "        (conv_pw): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(960, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act1): SiLU(inplace=True)\n",
      "        (conv_dw): Conv2d(960, 960, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=960, bias=False)\n",
      "        (bn2): BatchNorm2d(960, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act2): SiLU(inplace=True)\n",
      "        (se): SqueezeExcite(\n",
      "          (conv_reduce): Conv2d(960, 40, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (act1): SiLU(inplace=True)\n",
      "          (conv_expand): Conv2d(40, 960, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "        (conv_pwl): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (5): Sequential(\n",
      "      (0): InvertedResidual(\n",
      "        (conv_pw): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(960, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act1): SiLU(inplace=True)\n",
      "        (conv_dw): Conv2dSame(960, 960, kernel_size=(5, 5), stride=(2, 2), groups=960, bias=False)\n",
      "        (bn2): BatchNorm2d(960, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act2): SiLU(inplace=True)\n",
      "        (se): SqueezeExcite(\n",
      "          (conv_reduce): Conv2d(960, 40, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (act1): SiLU(inplace=True)\n",
      "          (conv_expand): Conv2d(40, 960, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "        (conv_pwl): Conv2d(960, 272, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(272, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (1): InvertedResidual(\n",
      "        (conv_pw): Conv2d(272, 1632, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(1632, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act1): SiLU(inplace=True)\n",
      "        (conv_dw): Conv2d(1632, 1632, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1632, bias=False)\n",
      "        (bn2): BatchNorm2d(1632, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act2): SiLU(inplace=True)\n",
      "        (se): SqueezeExcite(\n",
      "          (conv_reduce): Conv2d(1632, 68, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (act1): SiLU(inplace=True)\n",
      "          (conv_expand): Conv2d(68, 1632, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "        (conv_pwl): Conv2d(1632, 272, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(272, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (2): InvertedResidual(\n",
      "        (conv_pw): Conv2d(272, 1632, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(1632, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act1): SiLU(inplace=True)\n",
      "        (conv_dw): Conv2d(1632, 1632, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1632, bias=False)\n",
      "        (bn2): BatchNorm2d(1632, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act2): SiLU(inplace=True)\n",
      "        (se): SqueezeExcite(\n",
      "          (conv_reduce): Conv2d(1632, 68, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (act1): SiLU(inplace=True)\n",
      "          (conv_expand): Conv2d(68, 1632, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "        (conv_pwl): Conv2d(1632, 272, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(272, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (3): InvertedResidual(\n",
      "        (conv_pw): Conv2d(272, 1632, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(1632, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act1): SiLU(inplace=True)\n",
      "        (conv_dw): Conv2d(1632, 1632, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1632, bias=False)\n",
      "        (bn2): BatchNorm2d(1632, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act2): SiLU(inplace=True)\n",
      "        (se): SqueezeExcite(\n",
      "          (conv_reduce): Conv2d(1632, 68, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (act1): SiLU(inplace=True)\n",
      "          (conv_expand): Conv2d(68, 1632, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "        (conv_pwl): Conv2d(1632, 272, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(272, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (4): InvertedResidual(\n",
      "        (conv_pw): Conv2d(272, 1632, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(1632, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act1): SiLU(inplace=True)\n",
      "        (conv_dw): Conv2d(1632, 1632, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1632, bias=False)\n",
      "        (bn2): BatchNorm2d(1632, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act2): SiLU(inplace=True)\n",
      "        (se): SqueezeExcite(\n",
      "          (conv_reduce): Conv2d(1632, 68, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (act1): SiLU(inplace=True)\n",
      "          (conv_expand): Conv2d(68, 1632, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "        (conv_pwl): Conv2d(1632, 272, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(272, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (5): InvertedResidual(\n",
      "        (conv_pw): Conv2d(272, 1632, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(1632, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act1): SiLU(inplace=True)\n",
      "        (conv_dw): Conv2d(1632, 1632, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1632, bias=False)\n",
      "        (bn2): BatchNorm2d(1632, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act2): SiLU(inplace=True)\n",
      "        (se): SqueezeExcite(\n",
      "          (conv_reduce): Conv2d(1632, 68, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (act1): SiLU(inplace=True)\n",
      "          (conv_expand): Conv2d(68, 1632, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "        (conv_pwl): Conv2d(1632, 272, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(272, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (6): InvertedResidual(\n",
      "        (conv_pw): Conv2d(272, 1632, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(1632, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act1): SiLU(inplace=True)\n",
      "        (conv_dw): Conv2d(1632, 1632, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1632, bias=False)\n",
      "        (bn2): BatchNorm2d(1632, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act2): SiLU(inplace=True)\n",
      "        (se): SqueezeExcite(\n",
      "          (conv_reduce): Conv2d(1632, 68, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (act1): SiLU(inplace=True)\n",
      "          (conv_expand): Conv2d(68, 1632, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "        (conv_pwl): Conv2d(1632, 272, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(272, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (7): InvertedResidual(\n",
      "        (conv_pw): Conv2d(272, 1632, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(1632, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act1): SiLU(inplace=True)\n",
      "        (conv_dw): Conv2d(1632, 1632, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1632, bias=False)\n",
      "        (bn2): BatchNorm2d(1632, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act2): SiLU(inplace=True)\n",
      "        (se): SqueezeExcite(\n",
      "          (conv_reduce): Conv2d(1632, 68, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (act1): SiLU(inplace=True)\n",
      "          (conv_expand): Conv2d(68, 1632, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "        (conv_pwl): Conv2d(1632, 272, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(272, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (6): Sequential(\n",
      "      (0): InvertedResidual(\n",
      "        (conv_pw): Conv2d(272, 1632, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(1632, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act1): SiLU(inplace=True)\n",
      "        (conv_dw): Conv2d(1632, 1632, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1632, bias=False)\n",
      "        (bn2): BatchNorm2d(1632, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act2): SiLU(inplace=True)\n",
      "        (se): SqueezeExcite(\n",
      "          (conv_reduce): Conv2d(1632, 68, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (act1): SiLU(inplace=True)\n",
      "          (conv_expand): Conv2d(68, 1632, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "        (conv_pwl): Conv2d(1632, 448, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(448, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (1): InvertedResidual(\n",
      "        (conv_pw): Conv2d(448, 2688, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(2688, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act1): SiLU(inplace=True)\n",
      "        (conv_dw): Conv2d(2688, 2688, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2688, bias=False)\n",
      "        (bn2): BatchNorm2d(2688, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act2): SiLU(inplace=True)\n",
      "        (se): SqueezeExcite(\n",
      "          (conv_reduce): Conv2d(2688, 112, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (act1): SiLU(inplace=True)\n",
      "          (conv_expand): Conv2d(112, 2688, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "        (conv_pwl): Conv2d(2688, 448, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(448, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (conv_head): Conv2d(448, 1792, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (bn2): BatchNorm2d(1792, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (act2): SiLU(inplace=True)\n",
      "  (global_pool): SelectAdaptivePool2d (pool_type=avg, flatten=True)\n",
      "  (classifier): Linear(in_features=1792, out_features=5, bias=True)\n",
      ")\n",
      "Tuning /opt/favordata/AI/Felix/kaggle-cassava/trained-models/sgd_coswarm_bnf_bitemp_smooth_weighted_t1=0.3_t2=1.0_89-53/tf_efficientnet_b4_ns_bitempered_smooth=0.05_val_loss=0.109_val_acc=0.878_fold2.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name           | Type           | Params\n",
      "--------------------------------------------------\n",
      "0 | valid_accuracy | Accuracy       | 0     \n",
      "1 | test_accuracy  | Accuracy       | 0     \n",
      "2 | criterion      | BiTemperedLoss | 0     \n",
      "3 | model          | EfficientNet   | 17.6 M\n",
      "--------------------------------------------------\n",
      "17.4 M    Trainable params\n",
      "125 K     Non-trainable params\n",
      "17.6 M    Total params\n",
      "\n",
      "Finding best initial lr:   0%|          | 0/100 [00:00<?, ?it/s]\u001b[A\n",
      "Finding best initial lr:   1%|          | 1/100 [00:00<00:25,  3.85it/s]\u001b[A\n",
      "Finding best initial lr:   2%|▏         | 2/100 [00:01<01:07,  1.45it/s]\u001b[A\n",
      "Finding best initial lr:   3%|▎         | 3/100 [00:02<01:20,  1.21it/s]\u001b[A\n",
      "Finding best initial lr:   4%|▍         | 4/100 [00:03<01:25,  1.12it/s]\u001b[A\n",
      "Finding best initial lr:   5%|▌         | 5/100 [00:04<01:27,  1.08it/s]\u001b[A\n",
      "Finding best initial lr:   6%|▌         | 6/100 [00:05<01:28,  1.06it/s]\u001b[A\n",
      "Finding best initial lr:   7%|▋         | 7/100 [00:06<01:29,  1.04it/s]\u001b[A\n",
      "Finding best initial lr:   8%|▊         | 8/100 [00:07<01:29,  1.03it/s]\u001b[A\n",
      "Finding best initial lr:   9%|▉         | 9/100 [00:08<01:28,  1.02it/s]\u001b[A\n",
      "Finding best initial lr:  10%|█         | 10/100 [00:09<01:28,  1.01it/s]\u001b[A\n",
      "Finding best initial lr:  11%|█         | 11/100 [00:10<01:27,  1.01it/s]\u001b[A\n",
      "Finding best initial lr:  12%|█▏        | 12/100 [00:11<01:27,  1.01it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 14:   3%|▎         | 56/1770 [00:52<-1:55:38, -6.52it/s, loss=0.163, v_num=7, val_loss=0.0463, val_acc=0.968, train_loss=0.0952] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Finding best initial lr:  13%|█▎        | 13/100 [00:12<01:26,  1.01it/s]\u001b[A\n",
      "Finding best initial lr:  14%|█▍        | 14/100 [00:13<01:25,  1.01it/s]\u001b[A\n",
      "Finding best initial lr:  15%|█▌        | 15/100 [00:14<01:24,  1.01it/s]\u001b[A\n",
      "Finding best initial lr:  16%|█▌        | 16/100 [00:15<01:23,  1.01it/s]\u001b[A\n",
      "Finding best initial lr:  17%|█▋        | 17/100 [00:16<01:22,  1.01it/s]\u001b[A\n",
      "Finding best initial lr:  18%|█▊        | 18/100 [00:17<01:21,  1.01it/s]\u001b[A\n",
      "Finding best initial lr:  19%|█▉        | 19/100 [00:18<01:20,  1.01it/s]\u001b[A\n",
      "Finding best initial lr:  20%|██        | 20/100 [00:19<01:19,  1.00it/s]\u001b[A\n",
      "Finding best initial lr:  21%|██        | 21/100 [00:20<01:18,  1.00it/s]\u001b[A\n",
      "Finding best initial lr:  22%|██▏       | 22/100 [00:21<01:17,  1.00it/s]\u001b[A\n",
      "Finding best initial lr:  23%|██▎       | 23/100 [00:22<01:16,  1.01it/s]\u001b[A\n",
      "Finding best initial lr:  24%|██▍       | 24/100 [00:23<01:15,  1.01it/s]\u001b[A\n",
      "Finding best initial lr:  25%|██▌       | 25/100 [00:24<01:14,  1.01it/s]\u001b[A\n",
      "Finding best initial lr:  26%|██▌       | 26/100 [00:25<01:13,  1.01it/s]\u001b[A\n",
      "Finding best initial lr:  27%|██▋       | 27/100 [00:26<01:12,  1.01it/s]\u001b[A\n",
      "Finding best initial lr:  28%|██▊       | 28/100 [00:27<01:11,  1.01it/s]\u001b[A\n",
      "Finding best initial lr:  29%|██▉       | 29/100 [00:28<01:10,  1.01it/s]\u001b[A\n",
      "Finding best initial lr:  30%|███       | 30/100 [00:29<01:09,  1.00it/s]\u001b[A\n",
      "Finding best initial lr:  31%|███       | 31/100 [00:30<01:08,  1.00it/s]\u001b[A\n",
      "Finding best initial lr:  32%|███▏      | 32/100 [00:31<01:07,  1.01it/s]\u001b[A\n",
      "Finding best initial lr:  33%|███▎      | 33/100 [00:32<01:06,  1.01it/s]\u001b[A\n",
      "Finding best initial lr:  34%|███▍      | 34/100 [00:33<01:05,  1.01it/s]\u001b[A\n",
      "Finding best initial lr:  35%|███▌      | 35/100 [00:34<01:04,  1.01it/s]\u001b[A\n",
      "Finding best initial lr:  36%|███▌      | 36/100 [00:34<01:03,  1.01it/s]\u001b[A\n",
      "Finding best initial lr:  37%|███▋      | 37/100 [00:35<01:02,  1.01it/s]\u001b[A\n",
      "Finding best initial lr:  38%|███▊      | 38/100 [00:36<01:01,  1.01it/s]\u001b[A\n",
      "Finding best initial lr:  39%|███▉      | 39/100 [00:37<01:00,  1.01it/s]\u001b[A\n",
      "Finding best initial lr:  40%|████      | 40/100 [00:38<01:00,  1.00s/it]\u001b[A\n",
      "Finding best initial lr:  41%|████      | 41/100 [00:39<00:58,  1.00it/s]\u001b[A\n",
      "Finding best initial lr:  42%|████▏     | 42/100 [00:40<00:57,  1.00it/s]\u001b[A\n",
      "Finding best initial lr:  43%|████▎     | 43/100 [00:41<00:56,  1.00it/s]\u001b[A\n",
      "Finding best initial lr:  44%|████▍     | 44/100 [00:42<00:55,  1.00it/s]\u001b[A\n",
      "Finding best initial lr:  45%|████▌     | 45/100 [00:43<00:54,  1.00it/s]\u001b[A\n",
      "Finding best initial lr:  46%|████▌     | 46/100 [00:44<00:53,  1.00it/s]\u001b[A\n",
      "Finding best initial lr:  47%|████▋     | 47/100 [00:45<00:52,  1.00it/s]\u001b[A\n",
      "Finding best initial lr:  48%|████▊     | 48/100 [00:46<00:51,  1.00it/s]\u001b[A\n",
      "Finding best initial lr:  49%|████▉     | 49/100 [00:47<00:50,  1.00it/s]\u001b[A\n",
      "Finding best initial lr:  50%|█████     | 50/100 [00:48<00:50,  1.00s/it]\u001b[A\n",
      "Finding best initial lr:  51%|█████     | 51/100 [00:49<00:49,  1.00s/it]\u001b[A\n",
      "Finding best initial lr:  52%|█████▏    | 52/100 [00:50<00:47,  1.00it/s]\u001b[A\n",
      "Finding best initial lr:  53%|█████▎    | 53/100 [00:51<00:46,  1.00it/s]\u001b[A\n",
      "Finding best initial lr:  54%|█████▍    | 54/100 [00:52<00:45,  1.00it/s]\u001b[A\n",
      "Finding best initial lr:  55%|█████▌    | 55/100 [00:53<00:44,  1.00it/s]\u001b[A\n",
      "Finding best initial lr:  56%|█████▌    | 56/100 [00:54<00:43,  1.01it/s]\u001b[A\n",
      "Finding best initial lr:  57%|█████▋    | 57/100 [00:55<00:42,  1.01it/s]\u001b[A\n",
      "Finding best initial lr:  58%|█████▊    | 58/100 [00:56<00:41,  1.01it/s]\u001b[A\n",
      "Finding best initial lr:  59%|█████▉    | 59/100 [00:57<00:40,  1.01it/s]\u001b[A\n",
      "Finding best initial lr:  60%|██████    | 60/100 [00:58<00:39,  1.00it/s]\u001b[A\n",
      "Finding best initial lr:  61%|██████    | 61/100 [00:59<00:38,  1.00it/s]\u001b[A\n",
      "Finding best initial lr:  62%|██████▏   | 62/100 [01:00<00:37,  1.00it/s]\u001b[A\n",
      "Finding best initial lr:  63%|██████▎   | 63/100 [01:01<00:36,  1.01it/s]\u001b[A\n",
      "Finding best initial lr:  64%|██████▍   | 64/100 [01:02<00:35,  1.01it/s]\u001b[A\n",
      "Finding best initial lr:  65%|██████▌   | 65/100 [01:03<00:34,  1.01it/s]\u001b[A\n",
      "Finding best initial lr:  66%|██████▌   | 66/100 [01:04<00:33,  1.01it/s]\u001b[A\n",
      "Finding best initial lr:  67%|██████▋   | 67/100 [01:05<00:32,  1.01it/s]\u001b[A\n",
      "Finding best initial lr:  68%|██████▊   | 68/100 [01:06<00:31,  1.01it/s]\u001b[A\n",
      "Finding best initial lr:  69%|██████▉   | 69/100 [01:07<00:30,  1.01it/s]\u001b[A\n",
      "Finding best initial lr:  70%|███████   | 70/100 [01:08<00:29,  1.00it/s]\u001b[A\n",
      "Finding best initial lr:  71%|███████   | 71/100 [01:09<00:28,  1.00it/s]\u001b[A\n",
      "Finding best initial lr:  72%|███████▏  | 72/100 [01:10<00:27,  1.00it/s]\u001b[A\n",
      "Finding best initial lr:  73%|███████▎  | 73/100 [01:11<00:26,  1.01it/s]\u001b[A\n",
      "Finding best initial lr:  74%|███████▍  | 74/100 [01:12<00:25,  1.01it/s]\u001b[A\n",
      "Finding best initial lr:  75%|███████▌  | 75/100 [01:13<00:24,  1.01it/s]\u001b[A\n",
      "Finding best initial lr:  76%|███████▌  | 76/100 [01:14<00:23,  1.01it/s]\u001b[A\n",
      "Finding best initial lr:  77%|███████▋  | 77/100 [01:15<00:22,  1.01it/s]\u001b[A\n",
      "Finding best initial lr:  78%|███████▊  | 78/100 [01:16<00:21,  1.01it/s]\u001b[A\n",
      "Finding best initial lr:  79%|███████▉  | 79/100 [01:17<00:20,  1.01it/s]\u001b[A\n",
      "Finding best initial lr:  80%|████████  | 80/100 [01:18<00:20,  1.00s/it]\u001b[A\n",
      "Finding best initial lr:  81%|████████  | 81/100 [01:19<00:18,  1.00it/s]\u001b[A\n",
      "Finding best initial lr:  82%|████████▏ | 82/100 [01:20<00:17,  1.00it/s]\u001b[A\n",
      "Finding best initial lr:  83%|████████▎ | 83/100 [01:21<00:16,  1.00it/s]\u001b[A\n",
      "Finding best initial lr:  84%|████████▍ | 84/100 [01:22<00:15,  1.01it/s]\u001b[A\n",
      "Finding best initial lr:  85%|████████▌ | 85/100 [01:23<00:14,  1.01it/s]\u001b[A\n",
      "Finding best initial lr:  86%|████████▌ | 86/100 [01:24<00:13,  1.01it/s]\u001b[A\n",
      "Finding best initial lr:  87%|████████▋ | 87/100 [01:25<00:12,  1.01it/s]\u001b[A\n",
      "Finding best initial lr:  88%|████████▊ | 88/100 [01:26<00:11,  1.01it/s]\u001b[A\n",
      "Finding best initial lr:  89%|████████▉ | 89/100 [01:27<00:10,  1.01it/s]\u001b[A\n",
      "Finding best initial lr:  90%|█████████ | 90/100 [01:28<00:10,  1.00s/it]\u001b[A\n",
      "Finding best initial lr:  91%|█████████ | 91/100 [01:29<00:08,  1.00it/s]\u001b[A\n",
      "Finding best initial lr:  92%|█████████▏| 92/100 [01:30<00:07,  1.00it/s]\u001b[A\n",
      "Finding best initial lr:  93%|█████████▎| 93/100 [01:31<00:06,  1.01it/s]\u001b[A\n",
      "Finding best initial lr:  94%|█████████▍| 94/100 [01:32<00:05,  1.01it/s]\u001b[A\n",
      "Finding best initial lr:  95%|█████████▌| 95/100 [01:33<00:04,  1.01it/s]\u001b[A\n",
      "Finding best initial lr:  96%|█████████▌| 96/100 [01:34<00:03,  1.01it/s]\u001b[A\n",
      "Finding best initial lr:  97%|█████████▋| 97/100 [01:35<00:02,  1.01it/s]\u001b[A\n",
      "Finding best initial lr:  98%|█████████▊| 98/100 [01:36<00:01,  1.01it/s]\u001b[A\n",
      "Finding best initial lr:  99%|█████████▉| 99/100 [01:37<00:00,  1.01it/s]\u001b[A\n",
      "Finding best initial lr: 100%|██████████| 100/100 [01:38<00:00,  1.00s/it]\u001b[ARestored states from the checkpoint file at /opt/favordata/AI/Felix/kaggle-cassava/trained-models/sgd_coswarm_bnf_bitemp_smooth_weighted_t1=0.3_t2=1.0_89-53_tune/lr_find_temp_model.ckpt\n",
      "Learning rate set to 7.585775750291837e-08\n",
      "\n",
      "  | Name           | Type           | Params\n",
      "--------------------------------------------------\n",
      "0 | valid_accuracy | Accuracy       | 0     \n",
      "1 | test_accuracy  | Accuracy       | 0     \n",
      "2 | criterion      | BiTemperedLoss | 0     \n",
      "3 | model          | EfficientNet   | 17.6 M\n",
      "--------------------------------------------------\n",
      "17.4 M    Trainable params\n",
      "125 K     Non-trainable params\n",
      "17.6 M    Total params\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1:  64%|██████▎   | 1128/1770 [04:44<04:10,  2.56it/s, loss=0.163, v_num=7, val_loss=0.0543, val_acc=0.977, train_loss=0.058]    "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4:  97%|█████████▋| 1718/1770 [07:12<00:17,  3.05it/s, loss=0.158, v_num=7, val_loss=0.0706, val_acc=0.948, train_loss=0.048]\n",
      "Validating:   4%|▎         | 2/54 [00:02<01:07,  1.29s/it]\u001b[A\n",
      "Epoch 4:  97%|█████████▋| 1720/1770 [07:13<00:16,  3.05it/s, loss=0.158, v_num=7, val_loss=0.0706, val_acc=0.948, train_loss=0.048]\n",
      "Validating:   7%|▋         | 4/54 [00:04<00:42,  1.19it/s]\u001b[A\n",
      "Epoch 4:  97%|█████████▋| 1722/1770 [07:14<00:15,  3.04it/s, loss=0.158, v_num=7, val_loss=0.0706, val_acc=0.948, train_loss=0.048]\n",
      "Validating:  11%|█         | 6/54 [00:05<00:32,  1.46it/s]\u001b[A\n",
      "Epoch 4:  97%|█████████▋| 1724/1770 [07:15<00:15,  3.04it/s, loss=0.158, v_num=7, val_loss=0.0706, val_acc=0.948, train_loss=0.048]\n",
      "Validating:  15%|█▍        | 8/54 [00:06<00:28,  1.60it/s]\u001b[A\n",
      "Epoch 4:  98%|█████████▊| 1726/1770 [07:16<00:14,  3.04it/s, loss=0.158, v_num=7, val_loss=0.0706, val_acc=0.948, train_loss=0.048]\n",
      "Validating:  19%|█▊        | 10/54 [00:07<00:26,  1.68it/s]\u001b[A\n",
      "Epoch 4:  98%|█████████▊| 1728/1770 [07:18<00:13,  3.03it/s, loss=0.158, v_num=7, val_loss=0.0706, val_acc=0.948, train_loss=0.048]\n",
      "Validating:  22%|██▏       | 12/54 [00:08<00:24,  1.72it/s]\u001b[A\n",
      "Epoch 4:  98%|█████████▊| 1730/1770 [07:19<00:13,  3.03it/s, loss=0.158, v_num=7, val_loss=0.0706, val_acc=0.948, train_loss=0.048]\n",
      "Validating:  26%|██▌       | 14/54 [00:09<00:23,  1.74it/s]\u001b[A\n",
      "Epoch 4:  98%|█████████▊| 1732/1770 [07:20<00:12,  3.03it/s, loss=0.158, v_num=7, val_loss=0.0706, val_acc=0.948, train_loss=0.048]\n",
      "Validating:  30%|██▉       | 16/54 [00:10<00:21,  1.75it/s]\u001b[A\n",
      "Epoch 4:  98%|█████████▊| 1734/1770 [07:21<00:11,  3.02it/s, loss=0.158, v_num=7, val_loss=0.0706, val_acc=0.948, train_loss=0.048]\n",
      "Validating:  33%|███▎      | 18/54 [00:12<00:20,  1.75it/s]\u001b[A\n",
      "Epoch 4:  98%|█████████▊| 1736/1770 [07:22<00:11,  3.02it/s, loss=0.158, v_num=7, val_loss=0.0706, val_acc=0.948, train_loss=0.048]\n",
      "Validating:  37%|███▋      | 20/54 [00:13<00:19,  1.76it/s]\u001b[A\n",
      "Epoch 4:  98%|█████████▊| 1738/1770 [07:23<00:10,  3.02it/s, loss=0.158, v_num=7, val_loss=0.0706, val_acc=0.948, train_loss=0.048]\n",
      "Validating:  41%|████      | 22/54 [00:14<00:18,  1.76it/s]\u001b[A\n",
      "Epoch 4:  98%|█████████▊| 1740/1770 [07:24<00:09,  3.01it/s, loss=0.158, v_num=7, val_loss=0.0706, val_acc=0.948, train_loss=0.048]\n",
      "Validating:  44%|████▍     | 24/54 [00:15<00:17,  1.75it/s]\u001b[A\n",
      "Epoch 4:  98%|█████████▊| 1742/1770 [07:25<00:09,  3.01it/s, loss=0.158, v_num=7, val_loss=0.0706, val_acc=0.948, train_loss=0.048]\n",
      "Validating:  48%|████▊     | 26/54 [00:16<00:15,  1.75it/s]\u001b[A\n",
      "Epoch 4:  99%|█████████▊| 1744/1770 [07:27<00:08,  3.01it/s, loss=0.158, v_num=7, val_loss=0.0706, val_acc=0.948, train_loss=0.048]\n",
      "Validating:  52%|█████▏    | 28/54 [00:17<00:14,  1.75it/s]\u001b[A\n",
      "Epoch 4:  99%|█████████▊| 1746/1770 [07:28<00:07,  3.00it/s, loss=0.158, v_num=7, val_loss=0.0706, val_acc=0.948, train_loss=0.048]\n",
      "Validating:  56%|█████▌    | 30/54 [00:18<00:13,  1.75it/s]\u001b[A\n",
      "Epoch 4:  99%|█████████▉| 1748/1770 [07:29<00:07,  3.00it/s, loss=0.158, v_num=7, val_loss=0.0706, val_acc=0.948, train_loss=0.048]\n",
      "Validating:  59%|█████▉    | 32/54 [00:20<00:12,  1.74it/s]\u001b[A\n",
      "Epoch 4:  99%|█████████▉| 1750/1770 [07:30<00:06,  3.00it/s, loss=0.158, v_num=7, val_loss=0.0706, val_acc=0.948, train_loss=0.048]\n",
      "Validating:  63%|██████▎   | 34/54 [00:21<00:11,  1.75it/s]\u001b[A\n",
      "Epoch 4:  99%|█████████▉| 1752/1770 [07:31<00:06,  3.00it/s, loss=0.158, v_num=7, val_loss=0.0706, val_acc=0.948, train_loss=0.048]\n",
      "Validating:  67%|██████▋   | 36/54 [00:22<00:10,  1.75it/s]\u001b[A\n",
      "Epoch 4:  99%|█████████▉| 1754/1770 [07:32<00:05,  2.99it/s, loss=0.158, v_num=7, val_loss=0.0706, val_acc=0.948, train_loss=0.048]\n",
      "Validating:  70%|███████   | 38/54 [00:23<00:09,  1.75it/s]\u001b[A\n",
      "Epoch 4:  99%|█████████▉| 1756/1770 [07:33<00:04,  2.99it/s, loss=0.158, v_num=7, val_loss=0.0706, val_acc=0.948, train_loss=0.048]\n",
      "Validating:  74%|███████▍  | 40/54 [00:24<00:07,  1.76it/s]\u001b[A\n",
      "Epoch 4:  99%|█████████▉| 1758/1770 [07:35<00:04,  2.99it/s, loss=0.158, v_num=7, val_loss=0.0706, val_acc=0.948, train_loss=0.048]\n",
      "Validating:  78%|███████▊  | 42/54 [00:25<00:06,  1.75it/s]\u001b[A\n",
      "Epoch 4:  99%|█████████▉| 1760/1770 [07:36<00:03,  2.98it/s, loss=0.158, v_num=7, val_loss=0.0706, val_acc=0.948, train_loss=0.048]\n",
      "Validating:  81%|████████▏ | 44/54 [00:26<00:05,  1.75it/s]\u001b[A\n",
      "Epoch 4: 100%|█████████▉| 1762/1770 [07:37<00:02,  2.98it/s, loss=0.158, v_num=7, val_loss=0.0706, val_acc=0.948, train_loss=0.048]\n",
      "Validating:  85%|████████▌ | 46/54 [00:28<00:04,  1.78it/s]\u001b[A\n",
      "Epoch 4: 100%|█████████▉| 1764/1770 [07:38<00:02,  2.98it/s, loss=0.158, v_num=7, val_loss=0.0706, val_acc=0.948, train_loss=0.048]\n",
      "Validating:  89%|████████▉ | 48/54 [00:29<00:03,  1.79it/s]\u001b[A\n",
      "Epoch 4: 100%|█████████▉| 1766/1770 [07:39<00:01,  2.97it/s, loss=0.158, v_num=7, val_loss=0.0706, val_acc=0.948, train_loss=0.048]\n",
      "Validating:  93%|█████████▎| 50/54 [00:30<00:02,  1.80it/s]\u001b[A\n",
      "Epoch 4: 100%|█████████▉| 1768/1770 [07:40<00:00,  2.97it/s, loss=0.158, v_num=7, val_loss=0.0706, val_acc=0.948, train_loss=0.048]\n",
      "Validating:  96%|█████████▋| 52/54 [00:31<00:01,  1.80it/s]\u001b[A\n",
      "Epoch 4: 100%|██████████| 1770/1770 [07:41<00:00,  2.97it/s, loss=0.158, v_num=7, val_loss=0.0706, val_acc=0.948, train_loss=0.048]\n",
      "Validating: 100%|██████████| 54/54 [00:32<00:00,  2.04it/s]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4, global step 1716: val_loss reached 0.06533 (best 0.06533), saving model to \"/opt/favordata/AI/Felix/kaggle-cassava/trained-models/sgd_coswarm_bnf_bitemp_smooth_weighted_t1=0.3_t2=1.0_89-53_tune/tf_efficientnet_b4_ns_bitempered_smooth=0.05_val_loss=0.065_val_acc=0.951_fold4.ckpt\" as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 1770/1770 [07:42<00:00,  2.96it/s, loss=0.158, v_num=7, val_loss=0.0653, val_acc=0.951, train_loss=0.202]\n",
      "Epoch 5:  97%|█████████▋| 1716/1770 [07:10<00:17,  3.06it/s, loss=0.191, v_num=7, val_loss=0.0653, val_acc=0.951, train_loss=0.014]    \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 5:  97%|█████████▋| 1718/1770 [07:12<00:17,  3.05it/s, loss=0.191, v_num=7, val_loss=0.0653, val_acc=0.951, train_loss=0.014]\n",
      "Validating:   4%|▎         | 2/54 [00:02<01:09,  1.34s/it]\u001b[A\n",
      "Epoch 5:  97%|█████████▋| 1720/1770 [07:14<00:16,  3.04it/s, loss=0.191, v_num=7, val_loss=0.0653, val_acc=0.951, train_loss=0.014]\n",
      "Validating:   7%|▋         | 4/54 [00:04<00:41,  1.19it/s]\u001b[A\n",
      "Epoch 5:  97%|█████████▋| 1722/1770 [07:15<00:15,  3.04it/s, loss=0.191, v_num=7, val_loss=0.0653, val_acc=0.951, train_loss=0.014]\n",
      "Validating:  11%|█         | 6/54 [00:05<00:32,  1.46it/s]\u001b[A\n",
      "Epoch 5:  97%|█████████▋| 1724/1770 [07:16<00:15,  3.04it/s, loss=0.191, v_num=7, val_loss=0.0653, val_acc=0.951, train_loss=0.014]\n",
      "Validating:  15%|█▍        | 8/54 [00:06<00:28,  1.61it/s]\u001b[A\n",
      "Epoch 5:  98%|█████████▊| 1726/1770 [07:17<00:14,  3.03it/s, loss=0.191, v_num=7, val_loss=0.0653, val_acc=0.951, train_loss=0.014]\n",
      "Validating:  19%|█▊        | 10/54 [00:07<00:26,  1.68it/s]\u001b[A\n",
      "Epoch 5:  98%|█████████▊| 1728/1770 [07:18<00:13,  3.03it/s, loss=0.191, v_num=7, val_loss=0.0653, val_acc=0.951, train_loss=0.014]\n",
      "Validating:  22%|██▏       | 12/54 [00:08<00:24,  1.72it/s]\u001b[A\n",
      "Epoch 5:  98%|█████████▊| 1730/1770 [07:19<00:13,  3.03it/s, loss=0.191, v_num=7, val_loss=0.0653, val_acc=0.951, train_loss=0.014]\n",
      "Validating:  26%|██▌       | 14/54 [00:09<00:23,  1.74it/s]\u001b[A\n",
      "Epoch 5:  98%|█████████▊| 1732/1770 [07:20<00:12,  3.02it/s, loss=0.191, v_num=7, val_loss=0.0653, val_acc=0.951, train_loss=0.014]\n",
      "Validating:  30%|██▉       | 16/54 [00:11<00:21,  1.74it/s]\u001b[A\n",
      "Epoch 5:  98%|█████████▊| 1734/1770 [07:22<00:11,  3.02it/s, loss=0.191, v_num=7, val_loss=0.0653, val_acc=0.951, train_loss=0.014]\n",
      "Validating:  33%|███▎      | 18/54 [00:12<00:20,  1.75it/s]\u001b[A\n",
      "Epoch 5:  98%|█████████▊| 1736/1770 [07:23<00:11,  3.02it/s, loss=0.191, v_num=7, val_loss=0.0653, val_acc=0.951, train_loss=0.014]\n",
      "Validating:  37%|███▋      | 20/54 [00:13<00:19,  1.75it/s]\u001b[A\n",
      "Epoch 5:  98%|█████████▊| 1738/1770 [07:24<00:10,  3.01it/s, loss=0.191, v_num=7, val_loss=0.0653, val_acc=0.951, train_loss=0.014]\n",
      "Validating:  41%|████      | 22/54 [00:14<00:18,  1.75it/s]\u001b[A\n",
      "Epoch 5:  98%|█████████▊| 1740/1770 [07:25<00:09,  3.01it/s, loss=0.191, v_num=7, val_loss=0.0653, val_acc=0.951, train_loss=0.014]\n",
      "Validating:  44%|████▍     | 24/54 [00:15<00:17,  1.75it/s]\u001b[A\n",
      "Epoch 5:  98%|█████████▊| 1742/1770 [07:26<00:09,  3.01it/s, loss=0.191, v_num=7, val_loss=0.0653, val_acc=0.951, train_loss=0.014]\n",
      "Validating:  48%|████▊     | 26/54 [00:16<00:15,  1.75it/s]\u001b[A\n",
      "Epoch 5:  99%|█████████▊| 1744/1770 [07:27<00:08,  3.00it/s, loss=0.191, v_num=7, val_loss=0.0653, val_acc=0.951, train_loss=0.014]\n",
      "Validating:  52%|█████▏    | 28/54 [00:17<00:14,  1.75it/s]\u001b[A\n",
      "Epoch 5:  99%|█████████▊| 1746/1770 [07:28<00:07,  3.00it/s, loss=0.191, v_num=7, val_loss=0.0653, val_acc=0.951, train_loss=0.014]\n",
      "Validating:  56%|█████▌    | 30/54 [00:19<00:13,  1.75it/s]\u001b[A\n",
      "Epoch 5:  99%|█████████▉| 1748/1770 [07:30<00:07,  3.00it/s, loss=0.191, v_num=7, val_loss=0.0653, val_acc=0.951, train_loss=0.014]\n",
      "Validating:  59%|█████▉    | 32/54 [00:20<00:12,  1.76it/s]\u001b[A\n",
      "Epoch 5:  99%|█████████▉| 1750/1770 [07:31<00:06,  2.99it/s, loss=0.191, v_num=7, val_loss=0.0653, val_acc=0.951, train_loss=0.014]\n",
      "Validating:  63%|██████▎   | 34/54 [00:21<00:11,  1.75it/s]\u001b[A\n",
      "Epoch 5:  99%|█████████▉| 1752/1770 [07:32<00:06,  2.99it/s, loss=0.191, v_num=7, val_loss=0.0653, val_acc=0.951, train_loss=0.014]\n",
      "Validating:  67%|██████▋   | 36/54 [00:22<00:10,  1.75it/s]\u001b[A\n",
      "Epoch 5:  99%|█████████▉| 1754/1770 [07:33<00:05,  2.99it/s, loss=0.191, v_num=7, val_loss=0.0653, val_acc=0.951, train_loss=0.014]\n",
      "Validating:  70%|███████   | 38/54 [00:23<00:09,  1.76it/s]\u001b[A\n",
      "Epoch 5:  99%|█████████▉| 1756/1770 [07:34<00:04,  2.98it/s, loss=0.191, v_num=7, val_loss=0.0653, val_acc=0.951, train_loss=0.014]\n",
      "Validating:  74%|███████▍  | 40/54 [00:24<00:07,  1.76it/s]\u001b[A\n",
      "Epoch 5:  99%|█████████▉| 1758/1770 [07:35<00:04,  2.98it/s, loss=0.191, v_num=7, val_loss=0.0653, val_acc=0.951, train_loss=0.014]\n",
      "Validating:  78%|███████▊  | 42/54 [00:25<00:06,  1.76it/s]\u001b[A\n",
      "Epoch 5:  99%|█████████▉| 1760/1770 [07:36<00:03,  2.98it/s, loss=0.191, v_num=7, val_loss=0.0653, val_acc=0.951, train_loss=0.014]\n",
      "Validating:  81%|████████▏ | 44/54 [00:26<00:05,  1.76it/s]\u001b[A\n",
      "Epoch 5: 100%|█████████▉| 1762/1770 [07:38<00:02,  2.98it/s, loss=0.191, v_num=7, val_loss=0.0653, val_acc=0.951, train_loss=0.014]\n",
      "Validating:  85%|████████▌ | 46/54 [00:28<00:04,  1.78it/s]\u001b[A\n",
      "Epoch 5: 100%|█████████▉| 1764/1770 [07:39<00:02,  2.97it/s, loss=0.191, v_num=7, val_loss=0.0653, val_acc=0.951, train_loss=0.014]\n",
      "Validating:  89%|████████▉ | 48/54 [00:29<00:03,  1.79it/s]\u001b[A\n",
      "Epoch 5: 100%|█████████▉| 1766/1770 [07:40<00:01,  2.97it/s, loss=0.191, v_num=7, val_loss=0.0653, val_acc=0.951, train_loss=0.014]\n",
      "Validating:  93%|█████████▎| 50/54 [00:30<00:02,  1.80it/s]\u001b[A\n",
      "Epoch 5: 100%|█████████▉| 1768/1770 [07:41<00:00,  2.97it/s, loss=0.191, v_num=7, val_loss=0.0653, val_acc=0.951, train_loss=0.014]\n",
      "Validating:  96%|█████████▋| 52/54 [00:31<00:01,  1.80it/s]\u001b[A\n",
      "Epoch 5: 100%|██████████| 1770/1770 [07:42<00:00,  2.96it/s, loss=0.191, v_num=7, val_loss=0.0653, val_acc=0.951, train_loss=0.014]\n",
      "Validating: 100%|██████████| 54/54 [00:32<00:00,  2.04it/s]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5, step 2145: val_loss was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|██████████| 1770/1770 [07:42<00:00,  2.96it/s, loss=0.191, v_num=7, val_loss=0.0763, val_acc=0.939, train_loss=0.0875]\n",
      "Epoch 6:   1%|          | 22/1770 [00:05<-1:59:33, -62.90it/s, loss=0.191, v_num=7, val_loss=0.0763, val_acc=0.939, train_loss=0.225]  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9:  97%|█████████▋| 1716/1770 [07:10<00:17,  3.06it/s, loss=0.2, v_num=7, val_loss=0.0677, val_acc=0.951, train_loss=0.0123]   \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 9:  97%|█████████▋| 1718/1770 [07:12<00:17,  3.05it/s, loss=0.2, v_num=7, val_loss=0.0677, val_acc=0.951, train_loss=0.0123]\n",
      "Validating:   4%|▎         | 2/54 [00:02<01:10,  1.36s/it]\u001b[A\n",
      "Epoch 9:  97%|█████████▋| 1720/1770 [07:14<00:16,  3.04it/s, loss=0.2, v_num=7, val_loss=0.0677, val_acc=0.951, train_loss=0.0123]\n",
      "Validating:   7%|▋         | 4/54 [00:04<00:43,  1.16it/s]\u001b[A\n",
      "Epoch 9:  97%|█████████▋| 1722/1770 [07:15<00:15,  3.04it/s, loss=0.2, v_num=7, val_loss=0.0677, val_acc=0.951, train_loss=0.0123]\n",
      "Validating:  11%|█         | 6/54 [00:05<00:33,  1.44it/s]\u001b[A\n",
      "Epoch 9:  97%|█████████▋| 1724/1770 [07:16<00:15,  3.03it/s, loss=0.2, v_num=7, val_loss=0.0677, val_acc=0.951, train_loss=0.0123]\n",
      "Validating:  15%|█▍        | 8/54 [00:06<00:28,  1.60it/s]\u001b[A\n",
      "Epoch 9:  98%|█████████▊| 1726/1770 [07:17<00:14,  3.03it/s, loss=0.2, v_num=7, val_loss=0.0677, val_acc=0.951, train_loss=0.0123]\n",
      "Validating:  19%|█▊        | 10/54 [00:07<00:26,  1.68it/s]\u001b[A\n",
      "Epoch 9:  98%|█████████▊| 1728/1770 [07:18<00:13,  3.03it/s, loss=0.2, v_num=7, val_loss=0.0677, val_acc=0.951, train_loss=0.0123]\n",
      "Validating:  22%|██▏       | 12/54 [00:08<00:24,  1.72it/s]\u001b[A\n",
      "Epoch 9:  98%|█████████▊| 1730/1770 [07:20<00:13,  3.02it/s, loss=0.2, v_num=7, val_loss=0.0677, val_acc=0.951, train_loss=0.0123]\n",
      "Validating:  26%|██▌       | 14/54 [00:09<00:23,  1.73it/s]\u001b[A\n",
      "Epoch 9:  98%|█████████▊| 1732/1770 [07:21<00:12,  3.02it/s, loss=0.2, v_num=7, val_loss=0.0677, val_acc=0.951, train_loss=0.0123]\n",
      "Validating:  30%|██▉       | 16/54 [00:11<00:21,  1.74it/s]\u001b[A\n",
      "Epoch 9:  98%|█████████▊| 1734/1770 [07:22<00:11,  3.02it/s, loss=0.2, v_num=7, val_loss=0.0677, val_acc=0.951, train_loss=0.0123]\n",
      "Validating:  33%|███▎      | 18/54 [00:12<00:20,  1.75it/s]\u001b[A\n",
      "Epoch 9:  98%|█████████▊| 1736/1770 [07:23<00:11,  3.01it/s, loss=0.2, v_num=7, val_loss=0.0677, val_acc=0.951, train_loss=0.0123]\n",
      "Validating:  37%|███▋      | 20/54 [00:13<00:19,  1.75it/s]\u001b[A\n",
      "Epoch 9:  98%|█████████▊| 1738/1770 [07:24<00:10,  3.01it/s, loss=0.2, v_num=7, val_loss=0.0677, val_acc=0.951, train_loss=0.0123]\n",
      "Validating:  41%|████      | 22/54 [00:14<00:18,  1.75it/s]\u001b[A\n",
      "Epoch 9:  98%|█████████▊| 1740/1770 [07:25<00:09,  3.01it/s, loss=0.2, v_num=7, val_loss=0.0677, val_acc=0.951, train_loss=0.0123]\n",
      "Validating:  44%|████▍     | 24/54 [00:15<00:17,  1.75it/s]\u001b[A\n",
      "Epoch 9:  98%|█████████▊| 1742/1770 [07:26<00:09,  3.01it/s, loss=0.2, v_num=7, val_loss=0.0677, val_acc=0.951, train_loss=0.0123]\n",
      "Validating:  48%|████▊     | 26/54 [00:16<00:15,  1.75it/s]\u001b[A\n",
      "Epoch 9:  99%|█████████▊| 1744/1770 [07:28<00:08,  3.00it/s, loss=0.2, v_num=7, val_loss=0.0677, val_acc=0.951, train_loss=0.0123]\n",
      "Validating:  52%|█████▏    | 28/54 [00:17<00:14,  1.75it/s]\u001b[A\n",
      "Epoch 9:  99%|█████████▊| 1746/1770 [07:29<00:08,  3.00it/s, loss=0.2, v_num=7, val_loss=0.0677, val_acc=0.951, train_loss=0.0123]\n",
      "Validating:  56%|█████▌    | 30/54 [00:19<00:13,  1.74it/s]\u001b[A\n",
      "Epoch 9:  99%|█████████▉| 1748/1770 [07:30<00:07,  3.00it/s, loss=0.2, v_num=7, val_loss=0.0677, val_acc=0.951, train_loss=0.0123]\n",
      "Validating:  59%|█████▉    | 32/54 [00:20<00:12,  1.75it/s]\u001b[A\n",
      "Epoch 9:  99%|█████████▉| 1750/1770 [07:31<00:06,  2.99it/s, loss=0.2, v_num=7, val_loss=0.0677, val_acc=0.951, train_loss=0.0123]\n",
      "Validating:  63%|██████▎   | 34/54 [00:21<00:11,  1.75it/s]\u001b[A\n",
      "Epoch 9:  99%|█████████▉| 1752/1770 [07:32<00:06,  2.99it/s, loss=0.2, v_num=7, val_loss=0.0677, val_acc=0.951, train_loss=0.0123]\n",
      "Validating:  67%|██████▋   | 36/54 [00:22<00:10,  1.75it/s]\u001b[A\n",
      "Epoch 9:  99%|█████████▉| 1754/1770 [07:33<00:05,  2.99it/s, loss=0.2, v_num=7, val_loss=0.0677, val_acc=0.951, train_loss=0.0123]\n",
      "Validating:  70%|███████   | 38/54 [00:23<00:09,  1.76it/s]\u001b[A\n",
      "Epoch 9:  99%|█████████▉| 1756/1770 [07:34<00:04,  2.98it/s, loss=0.2, v_num=7, val_loss=0.0677, val_acc=0.951, train_loss=0.0123]\n",
      "Validating:  74%|███████▍  | 40/54 [00:24<00:07,  1.76it/s]\u001b[A\n",
      "Epoch 9:  99%|█████████▉| 1758/1770 [07:36<00:04,  2.98it/s, loss=0.2, v_num=7, val_loss=0.0677, val_acc=0.951, train_loss=0.0123]\n",
      "Validating:  78%|███████▊  | 42/54 [00:25<00:06,  1.76it/s]\u001b[A\n",
      "Epoch 9:  99%|█████████▉| 1760/1770 [07:37<00:03,  2.98it/s, loss=0.2, v_num=7, val_loss=0.0677, val_acc=0.951, train_loss=0.0123]\n",
      "Validating:  81%|████████▏ | 44/54 [00:27<00:05,  1.75it/s]\u001b[A\n",
      "Epoch 9: 100%|█████████▉| 1762/1770 [07:38<00:02,  2.97it/s, loss=0.2, v_num=7, val_loss=0.0677, val_acc=0.951, train_loss=0.0123]\n",
      "Validating:  85%|████████▌ | 46/54 [00:28<00:04,  1.78it/s]\u001b[A\n",
      "Epoch 9: 100%|█████████▉| 1764/1770 [07:39<00:02,  2.97it/s, loss=0.2, v_num=7, val_loss=0.0677, val_acc=0.951, train_loss=0.0123]\n",
      "Validating:  89%|████████▉ | 48/54 [00:29<00:03,  1.79it/s]\u001b[A\n",
      "Epoch 9: 100%|█████████▉| 1766/1770 [07:40<00:01,  2.97it/s, loss=0.2, v_num=7, val_loss=0.0677, val_acc=0.951, train_loss=0.0123]\n",
      "Validating:  93%|█████████▎| 50/54 [00:30<00:02,  1.80it/s]\u001b[A\n",
      "Epoch 9: 100%|█████████▉| 1768/1770 [07:41<00:00,  2.97it/s, loss=0.2, v_num=7, val_loss=0.0677, val_acc=0.951, train_loss=0.0123]\n",
      "Validating:  96%|█████████▋| 52/54 [00:31<00:01,  1.80it/s]\u001b[A\n",
      "Epoch 9: 100%|██████████| 1770/1770 [07:42<00:00,  2.96it/s, loss=0.2, v_num=7, val_loss=0.0677, val_acc=0.951, train_loss=0.0123]\n",
      "Validating: 100%|██████████| 54/54 [00:32<00:00,  2.04it/s]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9, step 3861: val_loss was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 1770/1770 [07:43<00:00,  2.96it/s, loss=0.2, v_num=7, val_loss=0.0655, val_acc=0.951, train_loss=0.238] \n",
      "Epoch 10:  97%|█████████▋| 1716/1770 [07:11<00:17,  3.06it/s, loss=0.18, v_num=7, val_loss=0.0655, val_acc=0.951, train_loss=0.146]     \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 10:  97%|█████████▋| 1718/1770 [07:13<00:17,  3.05it/s, loss=0.18, v_num=7, val_loss=0.0655, val_acc=0.951, train_loss=0.146]\n",
      "Validating:   4%|▎         | 2/54 [00:02<01:03,  1.22s/it]\u001b[A\n",
      "Epoch 10:  97%|█████████▋| 1720/1770 [07:14<00:16,  3.04it/s, loss=0.18, v_num=7, val_loss=0.0655, val_acc=0.951, train_loss=0.146]\n",
      "Validating:   7%|▋         | 4/54 [00:04<00:43,  1.16it/s]\u001b[A\n",
      "Epoch 10:  97%|█████████▋| 1722/1770 [07:15<00:15,  3.04it/s, loss=0.18, v_num=7, val_loss=0.0655, val_acc=0.951, train_loss=0.146]\n",
      "Validating:  11%|█         | 6/54 [00:05<00:33,  1.44it/s]\u001b[A\n",
      "Epoch 10:  97%|█████████▋| 1724/1770 [07:16<00:15,  3.03it/s, loss=0.18, v_num=7, val_loss=0.0655, val_acc=0.951, train_loss=0.146]\n",
      "Validating:  15%|█▍        | 8/54 [00:06<00:29,  1.58it/s]\u001b[A\n",
      "Epoch 10:  98%|█████████▊| 1726/1770 [07:17<00:14,  3.03it/s, loss=0.18, v_num=7, val_loss=0.0655, val_acc=0.951, train_loss=0.146]\n",
      "Validating:  19%|█▊        | 10/54 [00:07<00:26,  1.67it/s]\u001b[A\n",
      "Epoch 10:  98%|█████████▊| 1728/1770 [07:19<00:13,  3.03it/s, loss=0.18, v_num=7, val_loss=0.0655, val_acc=0.951, train_loss=0.146]\n",
      "Validating:  22%|██▏       | 12/54 [00:08<00:24,  1.71it/s]\u001b[A\n",
      "Epoch 10:  98%|█████████▊| 1730/1770 [07:20<00:13,  3.02it/s, loss=0.18, v_num=7, val_loss=0.0655, val_acc=0.951, train_loss=0.146]\n",
      "Validating:  26%|██▌       | 14/54 [00:09<00:23,  1.73it/s]\u001b[A\n",
      "Epoch 10:  98%|█████████▊| 1732/1770 [07:21<00:12,  3.02it/s, loss=0.18, v_num=7, val_loss=0.0655, val_acc=0.951, train_loss=0.146]\n",
      "Validating:  30%|██▉       | 16/54 [00:10<00:21,  1.74it/s]\u001b[A\n",
      "Epoch 10:  98%|█████████▊| 1734/1770 [07:22<00:11,  3.02it/s, loss=0.18, v_num=7, val_loss=0.0655, val_acc=0.951, train_loss=0.146]\n",
      "Validating:  33%|███▎      | 18/54 [00:12<00:20,  1.75it/s]\u001b[A\n",
      "Epoch 10:  98%|█████████▊| 1736/1770 [07:23<00:11,  3.01it/s, loss=0.18, v_num=7, val_loss=0.0655, val_acc=0.951, train_loss=0.146]\n",
      "Validating:  37%|███▋      | 20/54 [00:13<00:19,  1.75it/s]\u001b[A\n",
      "Epoch 10:  98%|█████████▊| 1738/1770 [07:24<00:10,  3.01it/s, loss=0.18, v_num=7, val_loss=0.0655, val_acc=0.951, train_loss=0.146]\n",
      "Validating:  41%|████      | 22/54 [00:14<00:18,  1.75it/s]\u001b[A\n",
      "Epoch 10:  98%|█████████▊| 1740/1770 [07:25<00:09,  3.01it/s, loss=0.18, v_num=7, val_loss=0.0655, val_acc=0.951, train_loss=0.146]\n",
      "Validating:  44%|████▍     | 24/54 [00:15<00:17,  1.75it/s]\u001b[A\n",
      "Epoch 10:  98%|█████████▊| 1742/1770 [07:27<00:09,  3.00it/s, loss=0.18, v_num=7, val_loss=0.0655, val_acc=0.951, train_loss=0.146]\n",
      "Validating:  48%|████▊     | 26/54 [00:16<00:15,  1.75it/s]\u001b[A\n",
      "Epoch 10:  99%|█████████▊| 1744/1770 [07:28<00:08,  3.00it/s, loss=0.18, v_num=7, val_loss=0.0655, val_acc=0.951, train_loss=0.146]\n",
      "Validating:  52%|█████▏    | 28/54 [00:17<00:14,  1.74it/s]\u001b[A\n",
      "Epoch 10:  99%|█████████▊| 1746/1770 [07:29<00:08,  3.00it/s, loss=0.18, v_num=7, val_loss=0.0655, val_acc=0.951, train_loss=0.146]\n",
      "Validating:  56%|█████▌    | 30/54 [00:18<00:13,  1.74it/s]\u001b[A\n",
      "Epoch 10:  99%|█████████▉| 1748/1770 [07:30<00:07,  2.99it/s, loss=0.18, v_num=7, val_loss=0.0655, val_acc=0.951, train_loss=0.146]\n",
      "Validating:  59%|█████▉    | 32/54 [00:20<00:12,  1.75it/s]\u001b[A\n",
      "Epoch 10:  99%|█████████▉| 1750/1770 [07:31<00:06,  2.99it/s, loss=0.18, v_num=7, val_loss=0.0655, val_acc=0.951, train_loss=0.146]\n",
      "Validating:  63%|██████▎   | 34/54 [00:21<00:11,  1.75it/s]\u001b[A\n",
      "Epoch 10:  99%|█████████▉| 1752/1770 [07:32<00:06,  2.99it/s, loss=0.18, v_num=7, val_loss=0.0655, val_acc=0.951, train_loss=0.146]\n",
      "Validating:  67%|██████▋   | 36/54 [00:22<00:10,  1.75it/s]\u001b[A\n",
      "Epoch 10:  99%|█████████▉| 1754/1770 [07:33<00:05,  2.98it/s, loss=0.18, v_num=7, val_loss=0.0655, val_acc=0.951, train_loss=0.146]\n",
      "Validating:  70%|███████   | 38/54 [00:23<00:09,  1.75it/s]\u001b[A\n",
      "Epoch 10:  99%|█████████▉| 1756/1770 [07:35<00:04,  2.98it/s, loss=0.18, v_num=7, val_loss=0.0655, val_acc=0.951, train_loss=0.146]\n",
      "Validating:  74%|███████▍  | 40/54 [00:24<00:07,  1.75it/s]\u001b[A\n",
      "Epoch 10:  99%|█████████▉| 1758/1770 [07:36<00:04,  2.98it/s, loss=0.18, v_num=7, val_loss=0.0655, val_acc=0.951, train_loss=0.146]\n",
      "Validating:  78%|███████▊  | 42/54 [00:25<00:06,  1.75it/s]\u001b[A\n",
      "Epoch 10:  99%|█████████▉| 1760/1770 [07:37<00:03,  2.98it/s, loss=0.18, v_num=7, val_loss=0.0655, val_acc=0.951, train_loss=0.146]\n",
      "Validating:  81%|████████▏ | 44/54 [00:26<00:05,  1.74it/s]\u001b[A\n",
      "Epoch 10: 100%|█████████▉| 1762/1770 [07:38<00:02,  2.97it/s, loss=0.18, v_num=7, val_loss=0.0655, val_acc=0.951, train_loss=0.146]\n",
      "Validating:  85%|████████▌ | 46/54 [00:28<00:04,  1.77it/s]\u001b[A\n",
      "Epoch 10: 100%|█████████▉| 1764/1770 [07:39<00:02,  2.97it/s, loss=0.18, v_num=7, val_loss=0.0655, val_acc=0.951, train_loss=0.146]\n",
      "Validating:  89%|████████▉ | 48/54 [00:29<00:03,  1.79it/s]\u001b[A\n",
      "Epoch 10: 100%|█████████▉| 1766/1770 [07:40<00:01,  2.97it/s, loss=0.18, v_num=7, val_loss=0.0655, val_acc=0.951, train_loss=0.146]\n",
      "Validating:  93%|█████████▎| 50/54 [00:30<00:02,  1.80it/s]\u001b[A\n",
      "Epoch 10: 100%|█████████▉| 1768/1770 [07:41<00:00,  2.96it/s, loss=0.18, v_num=7, val_loss=0.0655, val_acc=0.951, train_loss=0.146]\n",
      "Validating:  96%|█████████▋| 52/54 [00:31<00:01,  1.80it/s]\u001b[A\n",
      "Epoch 10: 100%|██████████| 1770/1770 [07:42<00:00,  2.96it/s, loss=0.18, v_num=7, val_loss=0.0655, val_acc=0.951, train_loss=0.146]\n",
      "Validating: 100%|██████████| 54/54 [00:32<00:00,  2.04it/s]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10, step 4290: val_loss was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10: 100%|██████████| 1770/1770 [07:43<00:00,  2.96it/s, loss=0.18, v_num=7, val_loss=0.0747, val_acc=0.942, train_loss=0.149]\n",
      "Epoch 11:  97%|█████████▋| 1716/1770 [07:10<00:17,  3.06it/s, loss=0.188, v_num=7, val_loss=0.0747, val_acc=0.942, train_loss=0.476]    \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 11:  97%|█████████▋| 1718/1770 [07:12<00:17,  3.05it/s, loss=0.188, v_num=7, val_loss=0.0747, val_acc=0.942, train_loss=0.476]\n",
      "Validating:   4%|▎         | 2/54 [00:02<01:08,  1.32s/it]\u001b[A\n",
      "Epoch 11:  97%|█████████▋| 1720/1770 [07:14<00:16,  3.04it/s, loss=0.188, v_num=7, val_loss=0.0747, val_acc=0.942, train_loss=0.476]\n",
      "Validating:   7%|▋         | 4/54 [00:04<00:42,  1.19it/s]\u001b[A\n",
      "Epoch 11:  97%|█████████▋| 1722/1770 [07:15<00:15,  3.04it/s, loss=0.188, v_num=7, val_loss=0.0747, val_acc=0.942, train_loss=0.476]\n",
      "Validating:  11%|█         | 6/54 [00:05<00:32,  1.46it/s]\u001b[A\n",
      "Epoch 11:  97%|█████████▋| 1724/1770 [07:16<00:15,  3.04it/s, loss=0.188, v_num=7, val_loss=0.0747, val_acc=0.942, train_loss=0.476]\n",
      "Validating:  15%|█▍        | 8/54 [00:06<00:28,  1.60it/s]\u001b[A\n",
      "Epoch 11:  98%|█████████▊| 1726/1770 [07:17<00:14,  3.03it/s, loss=0.188, v_num=7, val_loss=0.0747, val_acc=0.942, train_loss=0.476]\n",
      "Validating:  19%|█▊        | 10/54 [00:07<00:26,  1.68it/s]\u001b[A\n",
      "Epoch 11:  98%|█████████▊| 1728/1770 [07:18<00:13,  3.03it/s, loss=0.188, v_num=7, val_loss=0.0747, val_acc=0.942, train_loss=0.476]\n",
      "Validating:  22%|██▏       | 12/54 [00:08<00:24,  1.72it/s]\u001b[A\n",
      "Epoch 11:  98%|█████████▊| 1730/1770 [07:19<00:13,  3.03it/s, loss=0.188, v_num=7, val_loss=0.0747, val_acc=0.942, train_loss=0.476]\n",
      "Validating:  26%|██▌       | 14/54 [00:09<00:23,  1.73it/s]\u001b[A\n",
      "Epoch 11:  98%|█████████▊| 1732/1770 [07:20<00:12,  3.02it/s, loss=0.188, v_num=7, val_loss=0.0747, val_acc=0.942, train_loss=0.476]\n",
      "Validating:  30%|██▉       | 16/54 [00:10<00:21,  1.75it/s]\u001b[A\n",
      "Epoch 11:  98%|█████████▊| 1734/1770 [07:22<00:11,  3.02it/s, loss=0.188, v_num=7, val_loss=0.0747, val_acc=0.942, train_loss=0.476]\n",
      "Validating:  33%|███▎      | 18/54 [00:12<00:20,  1.74it/s]\u001b[A\n",
      "Epoch 11:  98%|█████████▊| 1736/1770 [07:23<00:11,  3.02it/s, loss=0.188, v_num=7, val_loss=0.0747, val_acc=0.942, train_loss=0.476]\n",
      "Validating:  37%|███▋      | 20/54 [00:13<00:19,  1.75it/s]\u001b[A\n",
      "Epoch 11:  98%|█████████▊| 1738/1770 [07:24<00:10,  3.01it/s, loss=0.188, v_num=7, val_loss=0.0747, val_acc=0.942, train_loss=0.476]\n",
      "Validating:  41%|████      | 22/54 [00:14<00:18,  1.75it/s]\u001b[A\n",
      "Epoch 11:  98%|█████████▊| 1740/1770 [07:25<00:09,  3.01it/s, loss=0.188, v_num=7, val_loss=0.0747, val_acc=0.942, train_loss=0.476]\n",
      "Validating:  44%|████▍     | 24/54 [00:15<00:17,  1.75it/s]\u001b[A\n",
      "Epoch 11:  98%|█████████▊| 1742/1770 [07:26<00:09,  3.01it/s, loss=0.188, v_num=7, val_loss=0.0747, val_acc=0.942, train_loss=0.476]\n",
      "Validating:  48%|████▊     | 26/54 [00:16<00:15,  1.75it/s]\u001b[A\n",
      "Epoch 11:  99%|█████████▊| 1744/1770 [07:27<00:08,  3.00it/s, loss=0.188, v_num=7, val_loss=0.0747, val_acc=0.942, train_loss=0.476]\n",
      "Validating:  52%|█████▏    | 28/54 [00:17<00:14,  1.75it/s]\u001b[A\n",
      "Epoch 11:  99%|█████████▊| 1746/1770 [07:28<00:07,  3.00it/s, loss=0.188, v_num=7, val_loss=0.0747, val_acc=0.942, train_loss=0.476]\n",
      "Validating:  56%|█████▌    | 30/54 [00:18<00:13,  1.75it/s]\u001b[A\n",
      "Epoch 11:  99%|█████████▉| 1748/1770 [07:30<00:07,  3.00it/s, loss=0.188, v_num=7, val_loss=0.0747, val_acc=0.942, train_loss=0.476]\n",
      "Validating:  59%|█████▉    | 32/54 [00:20<00:12,  1.75it/s]\u001b[A\n",
      "Epoch 11:  99%|█████████▉| 1750/1770 [07:31<00:06,  2.99it/s, loss=0.188, v_num=7, val_loss=0.0747, val_acc=0.942, train_loss=0.476]\n",
      "Validating:  63%|██████▎   | 34/54 [00:21<00:11,  1.75it/s]\u001b[A\n",
      "Epoch 11:  99%|█████████▉| 1752/1770 [07:32<00:06,  2.99it/s, loss=0.188, v_num=7, val_loss=0.0747, val_acc=0.942, train_loss=0.476]\n",
      "Validating:  67%|██████▋   | 36/54 [00:22<00:10,  1.75it/s]\u001b[A\n",
      "Epoch 11:  99%|█████████▉| 1754/1770 [07:33<00:05,  2.99it/s, loss=0.188, v_num=7, val_loss=0.0747, val_acc=0.942, train_loss=0.476]\n",
      "Validating:  70%|███████   | 38/54 [00:23<00:09,  1.75it/s]\u001b[A\n",
      "Epoch 11:  99%|█████████▉| 1756/1770 [07:34<00:04,  2.98it/s, loss=0.188, v_num=7, val_loss=0.0747, val_acc=0.942, train_loss=0.476]\n",
      "Validating:  74%|███████▍  | 40/54 [00:24<00:08,  1.75it/s]\u001b[A\n",
      "Epoch 11:  99%|█████████▉| 1758/1770 [07:35<00:04,  2.98it/s, loss=0.188, v_num=7, val_loss=0.0747, val_acc=0.942, train_loss=0.476]\n",
      "Validating:  78%|███████▊  | 42/54 [00:25<00:06,  1.75it/s]\u001b[A\n",
      "Epoch 11:  99%|█████████▉| 1760/1770 [07:36<00:03,  2.98it/s, loss=0.188, v_num=7, val_loss=0.0747, val_acc=0.942, train_loss=0.476]\n",
      "Validating:  81%|████████▏ | 44/54 [00:26<00:05,  1.75it/s]\u001b[A\n",
      "Epoch 11: 100%|█████████▉| 1762/1770 [07:38<00:02,  2.98it/s, loss=0.188, v_num=7, val_loss=0.0747, val_acc=0.942, train_loss=0.476]\n",
      "Validating:  85%|████████▌ | 46/54 [00:28<00:04,  1.78it/s]\u001b[A\n",
      "Epoch 11: 100%|█████████▉| 1764/1770 [07:39<00:02,  2.97it/s, loss=0.188, v_num=7, val_loss=0.0747, val_acc=0.942, train_loss=0.476]\n",
      "Validating:  89%|████████▉ | 48/54 [00:29<00:03,  1.79it/s]\u001b[A\n",
      "Epoch 11: 100%|█████████▉| 1766/1770 [07:40<00:01,  2.97it/s, loss=0.188, v_num=7, val_loss=0.0747, val_acc=0.942, train_loss=0.476]\n",
      "Validating:  93%|█████████▎| 50/54 [00:30<00:02,  1.80it/s]\u001b[A\n",
      "Epoch 11: 100%|█████████▉| 1768/1770 [07:41<00:00,  2.97it/s, loss=0.188, v_num=7, val_loss=0.0747, val_acc=0.942, train_loss=0.476]\n",
      "Validating:  96%|█████████▋| 52/54 [00:31<00:01,  1.80it/s]\u001b[A\n",
      "Epoch 11: 100%|██████████| 1770/1770 [07:42<00:00,  2.96it/s, loss=0.188, v_num=7, val_loss=0.0747, val_acc=0.942, train_loss=0.476]\n",
      "Validating: 100%|██████████| 54/54 [00:32<00:00,  2.04it/s]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11, step 4719: val_loss was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11: 100%|██████████| 1770/1770 [07:42<00:00,  2.96it/s, loss=0.188, v_num=7, val_loss=0.0674, val_acc=0.949, train_loss=0.152]\n",
      "Epoch 12:  97%|█████████▋| 1716/1770 [07:11<00:17,  3.05it/s, loss=0.181, v_num=7, val_loss=0.0674, val_acc=0.949, train_loss=0.298]    \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 12:  97%|█████████▋| 1718/1770 [07:13<00:17,  3.04it/s, loss=0.181, v_num=7, val_loss=0.0674, val_acc=0.949, train_loss=0.298]\n",
      "Validating:   4%|▎         | 2/54 [00:03<01:10,  1.36s/it]\u001b[A\n",
      "Epoch 12:  97%|█████████▋| 1720/1770 [07:14<00:16,  3.04it/s, loss=0.181, v_num=7, val_loss=0.0674, val_acc=0.949, train_loss=0.298]\n",
      "Validating:   7%|▋         | 4/54 [00:04<00:41,  1.19it/s]\u001b[A\n",
      "Epoch 12:  97%|█████████▋| 1722/1770 [07:15<00:15,  3.04it/s, loss=0.181, v_num=7, val_loss=0.0674, val_acc=0.949, train_loss=0.298]\n",
      "Validating:  11%|█         | 6/54 [00:05<00:32,  1.46it/s]\u001b[A\n",
      "Epoch 12:  97%|█████████▋| 1724/1770 [07:17<00:15,  3.03it/s, loss=0.181, v_num=7, val_loss=0.0674, val_acc=0.949, train_loss=0.298]\n",
      "Validating:  15%|█▍        | 8/54 [00:06<00:28,  1.60it/s]\u001b[A\n",
      "Epoch 12:  98%|█████████▊| 1726/1770 [07:18<00:14,  3.03it/s, loss=0.181, v_num=7, val_loss=0.0674, val_acc=0.949, train_loss=0.298]\n",
      "Validating:  19%|█▊        | 10/54 [00:07<00:26,  1.67it/s]\u001b[A\n",
      "Epoch 12:  98%|█████████▊| 1728/1770 [07:19<00:13,  3.03it/s, loss=0.181, v_num=7, val_loss=0.0674, val_acc=0.949, train_loss=0.298]\n",
      "Validating:  22%|██▏       | 12/54 [00:08<00:24,  1.72it/s]\u001b[A\n",
      "Epoch 12:  98%|█████████▊| 1730/1770 [07:20<00:13,  3.02it/s, loss=0.181, v_num=7, val_loss=0.0674, val_acc=0.949, train_loss=0.298]\n",
      "Validating:  26%|██▌       | 14/54 [00:09<00:23,  1.73it/s]\u001b[A\n",
      "Epoch 12:  98%|█████████▊| 1732/1770 [07:21<00:12,  3.02it/s, loss=0.181, v_num=7, val_loss=0.0674, val_acc=0.949, train_loss=0.298]\n",
      "Validating:  30%|██▉       | 16/54 [00:11<00:21,  1.74it/s]\u001b[A\n",
      "Epoch 12:  98%|█████████▊| 1734/1770 [07:22<00:11,  3.02it/s, loss=0.181, v_num=7, val_loss=0.0674, val_acc=0.949, train_loss=0.298]\n",
      "Validating:  33%|███▎      | 18/54 [00:12<00:20,  1.75it/s]\u001b[A\n",
      "Epoch 12:  98%|█████████▊| 1736/1770 [07:23<00:11,  3.01it/s, loss=0.181, v_num=7, val_loss=0.0674, val_acc=0.949, train_loss=0.298]\n",
      "Validating:  37%|███▋      | 20/54 [00:13<00:19,  1.75it/s]\u001b[A\n",
      "Epoch 12:  98%|█████████▊| 1738/1770 [07:24<00:10,  3.01it/s, loss=0.181, v_num=7, val_loss=0.0674, val_acc=0.949, train_loss=0.298]\n",
      "Validating:  41%|████      | 22/54 [00:14<00:18,  1.75it/s]\u001b[A\n",
      "Epoch 12:  98%|█████████▊| 1740/1770 [07:26<00:09,  3.01it/s, loss=0.181, v_num=7, val_loss=0.0674, val_acc=0.949, train_loss=0.298]\n",
      "Validating:  44%|████▍     | 24/54 [00:15<00:17,  1.75it/s]\u001b[A\n",
      "Epoch 12:  98%|█████████▊| 1742/1770 [07:27<00:09,  3.00it/s, loss=0.181, v_num=7, val_loss=0.0674, val_acc=0.949, train_loss=0.298]\n",
      "Validating:  48%|████▊     | 26/54 [00:16<00:15,  1.75it/s]\u001b[A\n",
      "Epoch 12:  99%|█████████▊| 1744/1770 [07:28<00:08,  3.00it/s, loss=0.181, v_num=7, val_loss=0.0674, val_acc=0.949, train_loss=0.298]\n",
      "Validating:  52%|█████▏    | 28/54 [00:17<00:14,  1.74it/s]\u001b[A\n",
      "Epoch 12:  99%|█████████▊| 1746/1770 [07:29<00:08,  3.00it/s, loss=0.181, v_num=7, val_loss=0.0674, val_acc=0.949, train_loss=0.298]\n",
      "Validating:  56%|█████▌    | 30/54 [00:19<00:13,  1.75it/s]\u001b[A\n",
      "Epoch 12:  99%|█████████▉| 1748/1770 [07:30<00:07,  2.99it/s, loss=0.181, v_num=7, val_loss=0.0674, val_acc=0.949, train_loss=0.298]\n",
      "Validating:  59%|█████▉    | 32/54 [00:20<00:12,  1.75it/s]\u001b[A\n",
      "Epoch 12:  99%|█████████▉| 1750/1770 [07:31<00:06,  2.99it/s, loss=0.181, v_num=7, val_loss=0.0674, val_acc=0.949, train_loss=0.298]\n",
      "Validating:  63%|██████▎   | 34/54 [00:21<00:11,  1.75it/s]\u001b[A\n",
      "Epoch 12:  99%|█████████▉| 1752/1770 [07:32<00:06,  2.99it/s, loss=0.181, v_num=7, val_loss=0.0674, val_acc=0.949, train_loss=0.298]\n",
      "Validating:  67%|██████▋   | 36/54 [00:22<00:10,  1.75it/s]\u001b[A\n",
      "Epoch 12:  99%|█████████▉| 1754/1770 [07:34<00:05,  2.98it/s, loss=0.181, v_num=7, val_loss=0.0674, val_acc=0.949, train_loss=0.298]\n",
      "Validating:  70%|███████   | 38/54 [00:23<00:09,  1.75it/s]\u001b[A\n",
      "Epoch 12:  99%|█████████▉| 1756/1770 [07:35<00:04,  2.98it/s, loss=0.181, v_num=7, val_loss=0.0674, val_acc=0.949, train_loss=0.298]\n",
      "Validating:  74%|███████▍  | 40/54 [00:24<00:07,  1.75it/s]\u001b[A\n",
      "Epoch 12:  99%|█████████▉| 1758/1770 [07:36<00:04,  2.98it/s, loss=0.181, v_num=7, val_loss=0.0674, val_acc=0.949, train_loss=0.298]\n",
      "Validating:  78%|███████▊  | 42/54 [00:25<00:06,  1.75it/s]\u001b[A\n",
      "Epoch 12:  99%|█████████▉| 1760/1770 [07:37<00:03,  2.97it/s, loss=0.181, v_num=7, val_loss=0.0674, val_acc=0.949, train_loss=0.298]\n",
      "Validating:  81%|████████▏ | 44/54 [00:27<00:05,  1.75it/s]\u001b[A\n",
      "Epoch 12: 100%|█████████▉| 1762/1770 [07:38<00:02,  2.97it/s, loss=0.181, v_num=7, val_loss=0.0674, val_acc=0.949, train_loss=0.298]\n",
      "Validating:  85%|████████▌ | 46/54 [00:28<00:04,  1.78it/s]\u001b[A\n",
      "Epoch 12: 100%|█████████▉| 1764/1770 [07:39<00:02,  2.97it/s, loss=0.181, v_num=7, val_loss=0.0674, val_acc=0.949, train_loss=0.298]\n",
      "Validating:  89%|████████▉ | 48/54 [00:29<00:03,  1.79it/s]\u001b[A\n",
      "Epoch 12: 100%|█████████▉| 1766/1770 [07:40<00:01,  2.97it/s, loss=0.181, v_num=7, val_loss=0.0674, val_acc=0.949, train_loss=0.298]\n",
      "Validating:  93%|█████████▎| 50/54 [00:30<00:02,  1.80it/s]\u001b[A\n",
      "Epoch 12: 100%|█████████▉| 1768/1770 [07:42<00:00,  2.96it/s, loss=0.181, v_num=7, val_loss=0.0674, val_acc=0.949, train_loss=0.298]\n",
      "Validating:  96%|█████████▋| 52/54 [00:31<00:01,  1.80it/s]\u001b[A\n",
      "Epoch 12: 100%|██████████| 1770/1770 [07:43<00:00,  2.96it/s, loss=0.181, v_num=7, val_loss=0.0674, val_acc=0.949, train_loss=0.298]\n",
      "Validating: 100%|██████████| 54/54 [00:32<00:00,  2.04it/s]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12, step 5148: val_loss was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12: 100%|██████████| 1770/1770 [07:43<00:00,  2.96it/s, loss=0.181, v_num=7, val_loss=0.075, val_acc=0.939, train_loss=0.789] \n",
      "Epoch 13:  97%|█████████▋| 1716/1770 [07:10<00:17,  3.06it/s, loss=0.186, v_num=7, val_loss=0.075, val_acc=0.939, train_loss=0.298]    \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 13:  97%|█████████▋| 1718/1770 [07:13<00:17,  3.05it/s, loss=0.186, v_num=7, val_loss=0.075, val_acc=0.939, train_loss=0.298]\n",
      "Validating:   4%|▎         | 2/54 [00:02<01:09,  1.33s/it]\u001b[A\n",
      "Epoch 13:  97%|█████████▋| 1720/1770 [07:14<00:16,  3.04it/s, loss=0.186, v_num=7, val_loss=0.075, val_acc=0.939, train_loss=0.298]\n",
      "Validating:   7%|▋         | 4/54 [00:04<00:42,  1.18it/s]\u001b[A\n",
      "Epoch 13:  97%|█████████▋| 1722/1770 [07:15<00:15,  3.04it/s, loss=0.186, v_num=7, val_loss=0.075, val_acc=0.939, train_loss=0.298]\n",
      "Validating:  11%|█         | 6/54 [00:05<00:32,  1.46it/s]\u001b[A\n",
      "Epoch 13:  97%|█████████▋| 1724/1770 [07:16<00:15,  3.03it/s, loss=0.186, v_num=7, val_loss=0.075, val_acc=0.939, train_loss=0.298]\n",
      "Validating:  15%|█▍        | 8/54 [00:06<00:28,  1.61it/s]\u001b[A\n",
      "Epoch 13:  98%|█████████▊| 1726/1770 [07:17<00:14,  3.03it/s, loss=0.186, v_num=7, val_loss=0.075, val_acc=0.939, train_loss=0.298]\n",
      "Validating:  19%|█▊        | 10/54 [00:07<00:26,  1.68it/s]\u001b[A\n",
      "Epoch 13:  98%|█████████▊| 1728/1770 [07:18<00:13,  3.03it/s, loss=0.186, v_num=7, val_loss=0.075, val_acc=0.939, train_loss=0.298]\n",
      "Validating:  22%|██▏       | 12/54 [00:08<00:24,  1.72it/s]\u001b[A\n",
      "Epoch 13:  98%|█████████▊| 1730/1770 [07:20<00:13,  3.02it/s, loss=0.186, v_num=7, val_loss=0.075, val_acc=0.939, train_loss=0.298]\n",
      "Validating:  26%|██▌       | 14/54 [00:09<00:23,  1.74it/s]\u001b[A\n",
      "Epoch 13:  98%|█████████▊| 1732/1770 [07:21<00:12,  3.02it/s, loss=0.186, v_num=7, val_loss=0.075, val_acc=0.939, train_loss=0.298]\n",
      "Validating:  30%|██▉       | 16/54 [00:10<00:21,  1.75it/s]\u001b[A\n",
      "Epoch 13:  98%|█████████▊| 1734/1770 [07:22<00:11,  3.02it/s, loss=0.186, v_num=7, val_loss=0.075, val_acc=0.939, train_loss=0.298]\n",
      "Validating:  33%|███▎      | 18/54 [00:12<00:20,  1.75it/s]\u001b[A\n",
      "Epoch 13:  98%|█████████▊| 1736/1770 [07:23<00:11,  3.02it/s, loss=0.186, v_num=7, val_loss=0.075, val_acc=0.939, train_loss=0.298]\n",
      "Validating:  37%|███▋      | 20/54 [00:13<00:19,  1.75it/s]\u001b[A\n",
      "Epoch 13:  98%|█████████▊| 1738/1770 [07:24<00:10,  3.01it/s, loss=0.186, v_num=7, val_loss=0.075, val_acc=0.939, train_loss=0.298]\n",
      "Validating:  41%|████      | 22/54 [00:14<00:18,  1.75it/s]\u001b[A\n",
      "Epoch 13:  98%|█████████▊| 1740/1770 [07:25<00:09,  3.01it/s, loss=0.186, v_num=7, val_loss=0.075, val_acc=0.939, train_loss=0.298]\n",
      "Validating:  44%|████▍     | 24/54 [00:15<00:17,  1.75it/s]\u001b[A\n",
      "Epoch 13:  98%|█████████▊| 1742/1770 [07:26<00:09,  3.01it/s, loss=0.186, v_num=7, val_loss=0.075, val_acc=0.939, train_loss=0.298]\n",
      "Validating:  48%|████▊     | 26/54 [00:16<00:15,  1.75it/s]\u001b[A\n",
      "Epoch 13:  99%|█████████▊| 1744/1770 [07:27<00:08,  3.00it/s, loss=0.186, v_num=7, val_loss=0.075, val_acc=0.939, train_loss=0.298]\n",
      "Validating:  52%|█████▏    | 28/54 [00:17<00:14,  1.75it/s]\u001b[A\n",
      "Epoch 13:  99%|█████████▊| 1746/1770 [07:29<00:08,  3.00it/s, loss=0.186, v_num=7, val_loss=0.075, val_acc=0.939, train_loss=0.298]\n",
      "Validating:  56%|█████▌    | 30/54 [00:18<00:13,  1.75it/s]\u001b[A\n",
      "Epoch 13:  99%|█████████▉| 1748/1770 [07:30<00:07,  3.00it/s, loss=0.186, v_num=7, val_loss=0.075, val_acc=0.939, train_loss=0.298]\n",
      "Validating:  59%|█████▉    | 32/54 [00:20<00:12,  1.75it/s]\u001b[A\n",
      "Epoch 13:  99%|█████████▉| 1750/1770 [07:31<00:06,  2.99it/s, loss=0.186, v_num=7, val_loss=0.075, val_acc=0.939, train_loss=0.298]\n",
      "Validating:  63%|██████▎   | 34/54 [00:21<00:11,  1.75it/s]\u001b[A\n",
      "Epoch 13:  99%|█████████▉| 1752/1770 [07:32<00:06,  2.99it/s, loss=0.186, v_num=7, val_loss=0.075, val_acc=0.939, train_loss=0.298]\n",
      "Validating:  67%|██████▋   | 36/54 [00:22<00:10,  1.75it/s]\u001b[A\n",
      "Epoch 13:  99%|█████████▉| 1754/1770 [07:33<00:05,  2.99it/s, loss=0.186, v_num=7, val_loss=0.075, val_acc=0.939, train_loss=0.298]\n",
      "Validating:  70%|███████   | 38/54 [00:23<00:09,  1.75it/s]\u001b[A\n",
      "Epoch 13:  99%|█████████▉| 1756/1770 [07:34<00:04,  2.98it/s, loss=0.186, v_num=7, val_loss=0.075, val_acc=0.939, train_loss=0.298]\n",
      "Validating:  74%|███████▍  | 40/54 [00:24<00:07,  1.75it/s]\u001b[A\n",
      "Epoch 13:  99%|█████████▉| 1758/1770 [07:35<00:04,  2.98it/s, loss=0.186, v_num=7, val_loss=0.075, val_acc=0.939, train_loss=0.298]\n",
      "Validating:  78%|███████▊  | 42/54 [00:25<00:06,  1.75it/s]\u001b[A\n",
      "Epoch 13:  99%|█████████▉| 1760/1770 [07:37<00:03,  2.98it/s, loss=0.186, v_num=7, val_loss=0.075, val_acc=0.939, train_loss=0.298]\n",
      "Validating:  81%|████████▏ | 44/54 [00:26<00:05,  1.75it/s]\u001b[A\n",
      "Epoch 13: 100%|█████████▉| 1762/1770 [07:38<00:02,  2.97it/s, loss=0.186, v_num=7, val_loss=0.075, val_acc=0.939, train_loss=0.298]\n",
      "Validating:  85%|████████▌ | 46/54 [00:28<00:04,  1.78it/s]\u001b[A\n",
      "Epoch 13: 100%|█████████▉| 1764/1770 [07:39<00:02,  2.97it/s, loss=0.186, v_num=7, val_loss=0.075, val_acc=0.939, train_loss=0.298]\n",
      "Validating:  89%|████████▉ | 48/54 [00:29<00:03,  1.79it/s]\u001b[A\n",
      "Epoch 13: 100%|█████████▉| 1766/1770 [07:40<00:01,  2.97it/s, loss=0.186, v_num=7, val_loss=0.075, val_acc=0.939, train_loss=0.298]\n",
      "Validating:  93%|█████████▎| 50/54 [00:30<00:02,  1.80it/s]\u001b[A\n",
      "Epoch 13: 100%|█████████▉| 1768/1770 [07:41<00:00,  2.97it/s, loss=0.186, v_num=7, val_loss=0.075, val_acc=0.939, train_loss=0.298]\n",
      "Validating:  96%|█████████▋| 52/54 [00:31<00:01,  1.80it/s]\u001b[A\n",
      "Epoch 13: 100%|██████████| 1770/1770 [07:42<00:00,  2.96it/s, loss=0.186, v_num=7, val_loss=0.075, val_acc=0.939, train_loss=0.298]\n",
      "Validating: 100%|██████████| 54/54 [00:32<00:00,  2.04it/s]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13, step 5577: val_loss was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13: 100%|██████████| 1770/1770 [07:43<00:00,  2.96it/s, loss=0.186, v_num=7, val_loss=0.0743, val_acc=0.941, train_loss=0.0467]\n",
      "                                                           \u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer was signaled to stop but required minimum epochs (15) or minimum steps (None) has not been met. Training will continue...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14:   0%|          | 2/1770 [00:00<-1:59:58, -602.12it/s, loss=0.186, v_num=7, val_loss=0.0743, val_acc=0.941, train_loss=0.0467]  \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   2%|▏         | 1/54 [00:02<02:02,  2.31s/it]\u001b[A\n",
      "Epoch 14:   0%|          | 4/1770 [00:03<-1:59:44, -107.19it/s, loss=0.186, v_num=7, val_loss=0.0743, val_acc=0.941, train_loss=0.0467]\n",
      "Validating:   6%|▌         | 3/54 [00:03<00:51,  1.01s/it]\u001b[A\n",
      "Epoch 14:   0%|          | 6/1770 [00:04<-1:59:39, -81.16it/s, loss=0.186, v_num=7, val_loss=0.0743, val_acc=0.941, train_loss=0.0467] \n",
      "Validating:   9%|▉         | 5/54 [00:04<00:36,  1.35it/s]\u001b[A\n",
      "Epoch 14:   0%|          | 8/1770 [00:05<-1:59:34, -65.31it/s, loss=0.186, v_num=7, val_loss=0.0743, val_acc=0.941, train_loss=0.0467]\n",
      "Validating:  13%|█▎        | 7/54 [00:05<00:30,  1.55it/s]\u001b[A\n",
      "Epoch 14:   1%|          | 10/1770 [00:07<-1:59:28, -54.57it/s, loss=0.186, v_num=7, val_loss=0.0743, val_acc=0.941, train_loss=0.0467]\n",
      "Validating:  17%|█▋        | 9/54 [00:07<00:27,  1.65it/s]\u001b[A\n",
      "Epoch 14:   1%|          | 12/1770 [00:08<-1:59:23, -46.79it/s, loss=0.186, v_num=7, val_loss=0.0743, val_acc=0.941, train_loss=0.0467]\n",
      "Validating:  20%|██        | 11/54 [00:08<00:25,  1.70it/s]\u001b[A\n",
      "Epoch 14:   1%|          | 14/1770 [00:09<-1:59:18, -40.89it/s, loss=0.186, v_num=7, val_loss=0.0743, val_acc=0.941, train_loss=0.0467]\n",
      "Validating:  24%|██▍       | 13/54 [00:09<00:23,  1.72it/s]\u001b[A\n",
      "Epoch 14:   1%|          | 16/1770 [00:10<-1:59:12, -36.26it/s, loss=0.186, v_num=7, val_loss=0.0743, val_acc=0.941, train_loss=0.0467]\n",
      "Validating:  28%|██▊       | 15/54 [00:10<00:22,  1.73it/s]\u001b[A\n",
      "Epoch 14:   1%|          | 18/1770 [00:11<-1:59:07, -32.55it/s, loss=0.186, v_num=7, val_loss=0.0743, val_acc=0.941, train_loss=0.0467]\n",
      "Validating:  31%|███▏      | 17/54 [00:11<00:21,  1.74it/s]\u001b[A\n",
      "Epoch 14:   1%|          | 20/1770 [00:12<-1:59:01, -29.50it/s, loss=0.186, v_num=7, val_loss=0.0743, val_acc=0.941, train_loss=0.0467]\n",
      "Validating:  35%|███▌      | 19/54 [00:12<00:20,  1.74it/s]\u001b[A\n",
      "Epoch 14:   1%|          | 22/1770 [00:13<-1:58:56, -26.95it/s, loss=0.186, v_num=7, val_loss=0.0743, val_acc=0.941, train_loss=0.0467]\n",
      "Validating:  39%|███▉      | 21/54 [00:13<00:18,  1.75it/s]\u001b[A\n",
      "Epoch 14:   1%|▏         | 24/1770 [00:15<-1:58:50, -24.78it/s, loss=0.186, v_num=7, val_loss=0.0743, val_acc=0.941, train_loss=0.0467]\n",
      "Validating:  43%|████▎     | 23/54 [00:15<00:17,  1.75it/s]\u001b[A\n",
      "Epoch 14:   1%|▏         | 26/1770 [00:16<-1:58:44, -22.90it/s, loss=0.186, v_num=7, val_loss=0.0743, val_acc=0.941, train_loss=0.0467]\n",
      "Validating:  46%|████▋     | 25/54 [00:16<00:16,  1.74it/s]\u001b[A\n",
      "Epoch 14:   2%|▏         | 28/1770 [00:17<-1:58:39, -21.28it/s, loss=0.186, v_num=7, val_loss=0.0743, val_acc=0.941, train_loss=0.0467]\n",
      "Validating:  50%|█████     | 27/54 [00:17<00:15,  1.74it/s]\u001b[A\n",
      "Epoch 14:   2%|▏         | 30/1770 [00:18<-1:58:33, -19.86it/s, loss=0.186, v_num=7, val_loss=0.0743, val_acc=0.941, train_loss=0.0467]\n",
      "Validating:  54%|█████▎    | 29/54 [00:18<00:14,  1.75it/s]\u001b[A\n",
      "Epoch 14:   2%|▏         | 32/1770 [00:19<-1:58:27, -18.61it/s, loss=0.186, v_num=7, val_loss=0.0743, val_acc=0.941, train_loss=0.0467]\n",
      "Validating:  57%|█████▋    | 31/54 [00:19<00:13,  1.75it/s]\u001b[A\n",
      "Epoch 14:   2%|▏         | 34/1770 [00:20<-1:58:21, -17.49it/s, loss=0.186, v_num=7, val_loss=0.0743, val_acc=0.941, train_loss=0.0467]\n",
      "Validating:  61%|██████    | 33/54 [00:20<00:12,  1.74it/s]\u001b[A\n",
      "Epoch 14:   2%|▏         | 36/1770 [00:22<-1:58:15, -16.49it/s, loss=0.186, v_num=7, val_loss=0.0743, val_acc=0.941, train_loss=0.0467]\n",
      "Validating:  65%|██████▍   | 35/54 [00:21<00:10,  1.74it/s]\u001b[A\n",
      "Epoch 14:   2%|▏         | 38/1770 [00:23<-1:58:09, -15.58it/s, loss=0.186, v_num=7, val_loss=0.0743, val_acc=0.941, train_loss=0.0467]\n",
      "Validating:  69%|██████▊   | 37/54 [00:23<00:09,  1.73it/s]\u001b[A\n",
      "Epoch 14:   2%|▏         | 40/1770 [00:24<-1:58:03, -14.76it/s, loss=0.186, v_num=7, val_loss=0.0743, val_acc=0.941, train_loss=0.0467]\n",
      "Validating:  72%|███████▏  | 39/54 [00:24<00:08,  1.74it/s]\u001b[A\n",
      "Epoch 14:   2%|▏         | 42/1770 [00:25<-1:57:57, -14.02it/s, loss=0.186, v_num=7, val_loss=0.0743, val_acc=0.941, train_loss=0.0467]\n",
      "Validating:  76%|███████▌  | 41/54 [00:25<00:07,  1.74it/s]\u001b[A\n",
      "Epoch 14:   2%|▏         | 44/1770 [00:26<-1:57:51, -13.34it/s, loss=0.186, v_num=7, val_loss=0.0743, val_acc=0.941, train_loss=0.0467]\n",
      "Validating:  80%|███████▉  | 43/54 [00:26<00:06,  1.74it/s]\u001b[A\n",
      "Epoch 14:   3%|▎         | 46/1770 [00:27<-1:57:45, -12.72it/s, loss=0.186, v_num=7, val_loss=0.0743, val_acc=0.941, train_loss=0.0467]\n",
      "Validating:  83%|████████▎ | 45/54 [00:27<00:05,  1.76it/s]\u001b[A\n",
      "Epoch 14:   3%|▎         | 48/1770 [00:28<-1:57:39, -12.16it/s, loss=0.186, v_num=7, val_loss=0.0743, val_acc=0.941, train_loss=0.0467]\n",
      "Validating:  87%|████████▋ | 47/54 [00:28<00:03,  1.78it/s]\u001b[A\n",
      "Epoch 14:   3%|▎         | 50/1770 [00:29<-1:57:33, -11.64it/s, loss=0.186, v_num=7, val_loss=0.0743, val_acc=0.941, train_loss=0.0467]\n",
      "Validating:  91%|█████████ | 49/54 [00:29<00:02,  1.79it/s]\u001b[A\n",
      "Epoch 14:   3%|▎         | 52/1770 [00:31<-1:57:27, -11.16it/s, loss=0.186, v_num=7, val_loss=0.0743, val_acc=0.941, train_loss=0.0467]\n",
      "Validating:  94%|█████████▍| 51/54 [00:30<00:01,  1.80it/s]\u001b[A\n",
      "Epoch 14:   3%|▎         | 54/1770 [00:32<-1:57:20, -10.71it/s, loss=0.186, v_num=7, val_loss=0.0743, val_acc=0.941, train_loss=0.0467]\n",
      "Validating:  98%|█████████▊| 53/54 [00:32<00:00,  1.80it/s]\u001b[A\n",
      "Epoch 14:   3%|▎         | 56/1770 [00:33<-1:57:15, -10.36it/s, loss=0.186, v_num=7, val_loss=0.0743, val_acc=0.941, train_loss=0.0467]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14, step 5578: val_loss was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14:   3%|▎         | 56/1770 [00:33<-1:57:15, -10.33it/s, loss=0.186, v_num=7, val_loss=0.0736, val_acc=0.943, train_loss=0.394] \n",
      "                                                           \u001b[A"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    parser = argparse.ArgumentParser(description='Kaggle Cassava Disease Training')\n",
    "\n",
    "    try:\n",
    "        debug = False\n",
    "        print('Running in debug mode:', debug)\n",
    "        # fine tuned with SGD, one cycle\n",
    "        main(experiment_name='sgd_coswarm_bnf_bitemp_smooth_weighted_t1=0.3_t2=1.0_89-53', debug=debug,\n",
    "             resume=False, finetune=True, freeze_bn=True, freeze_feature_extractor=False,\n",
    "            data_csv='/train_cleaned-0.6.csv')\n",
    "    except KeyboardInterrupt:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
