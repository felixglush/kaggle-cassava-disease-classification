{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import json\n",
    "import os\n",
    "from datetime import timedelta\n",
    "import time\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pandas as pd\n",
    "import cv2\n",
    "\n",
    "# My modules\n",
    "from types import SimpleNamespace\n",
    "from utils import set_seeds\n",
    "from config import Configuration\n",
    "from train_manager import TrainManager\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, class_names):\n",
    "    \"\"\"\n",
    "    https://www.tensorflow.org/tensorboard/image_summaries#building_an_image_classifier\n",
    "    Returns a matplotlib figure containing the plotted confusion matrix.\n",
    "\n",
    "    Args:\n",
    "    cm (array, shape = [n, n]): a confusion matrix of integer classes\n",
    "    class_names (array, shape = [n]): String names of the integer classes\n",
    "    \"\"\"\n",
    "    figure = plt.figure(figsize=(8, 8))\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n",
    "    plt.title(\"Confusion matrix\")\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(class_names))\n",
    "    plt.xticks(tick_marks, class_names, rotation=45)\n",
    "    plt.yticks(tick_marks, class_names)\n",
    "\n",
    "    # Compute the labels from the normalized confusion matrix.\n",
    "    labels = np.around(cm.astype('float') / cm.sum(axis=1)[:, np.newaxis], decimals=2)\n",
    "\n",
    "    # Use white text if squares are dark; otherwise black.\n",
    "    threshold = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        color = \"white\" if cm[i, j] > threshold else \"black\"\n",
    "        plt.text(j, i, labels[i, j], horizontalalignment=\"center\", color=color)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    return figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def run_inference(experiment_name, tta, weight_avg):\n",
    "    config = Configuration()\n",
    "    experiment_dir = os.path.abspath(f'trained-models/{experiment_name}')\n",
    "\n",
    "    with open(experiment_dir + '/experiment_config.json', 'r') as f:\n",
    "        config = json.load(f, object_hook=lambda d: SimpleNamespace(**d))\n",
    "        set_seeds(config.seed)\n",
    "    df = pd.read_csv(experiment_dir + '/holdout.csv', engine='python')\n",
    "\n",
    "    if config.num_workers > 0:\n",
    "        cv2.setNumThreads(0)\n",
    "\n",
    "    inference_start = time.time()\n",
    "    print(config.model_arch)\n",
    "    # get predictions... folds = None just means ensemble inference\n",
    "    manager = TrainManager(folds_df=None, holdout_df=df, config=config,\n",
    "                           experiment_dir=experiment_dir, experiment_name=experiment_name,\n",
    "                          finetune=False, freeze_bn=False, freeze_feature_extractor=False)\n",
    "    manager.test(tta, weight_avg, mode='vote')\n",
    "    \n",
    "\n",
    "    print(f\"Inference time: {str(timedelta(seconds=time.time() - inference_start))}\")\n",
    "\n",
    "    acc = accuracy_score(y_true=df.label.values, y_pred=manager.final_test_predictions)\n",
    "    print(\"Ensemble holdout accuracy\", acc)\n",
    "    plot_confusion_matrix(manager.test_confusion_matrix.detach().cpu().numpy(), class_names=[i for i in range(config.num_classes)])\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#run_inference(experiment_name='SERESNET50_sgd_coswarm_bnf_smoothed_0.1_weighted_t1=0.8_t2=1.2_88-88',\n",
    "#              tta=0, weight_avg=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def run_inference_multiple(experiment_names, tta, weight_avg):\n",
    "    inference_start = time.time()\n",
    "\n",
    "    holdout_df = pd.read_csv('./data/holdout.csv', engine='python')\n",
    "    manager = TrainManager(holdout_df=holdout_df, experiment_name='inference_seresnet_efficientnet_1',\n",
    "                           model_names=experiment_names)\n",
    "    manager.test_multiple(tta, weight_avg, mode='vote')\n",
    "\n",
    "    print(f\"Inference time: {str(timedelta(seconds=time.time() - inference_start))}\")\n",
    "\n",
    "    acc = accuracy_score(y_true=holdout_df.label.values, y_pred=manager.final_test_predictions)\n",
    "    print(\"Ensemble holdout accuracy\", acc)\n",
    "    plot_confusion_matrix(manager.test_confusion_matrix.detach().cpu().numpy(), class_names=[i for i in range(5)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: None, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Using native 16bit precision.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/opt/favordata/AI/Felix/kaggle-cassava/trained-models/adabound_coswarm_bnf_bitemp_smooth_weighted_t1=0.3_t2=1.0_89-1\n",
      "tf_efficientnet_b4_ns\n",
      "Linear(in_features=1792, out_features=5, bias=True)\n",
      "normal inference on model 0\n",
      "Testing: 100%|██████████| 51/51 [00:26<00:00,  2.00it/s]Test epoch ended.\n",
      "Testing: 100%|██████████| 51/51 [00:26<00:00,  1.92it/s]\n",
      "--------------------------------------------------------------------------------\n",
      "DATALOADER:0 TEST RESULTS\n",
      "{'test_acc': tensor(0.8819, device='cuda:0')}\n",
      "--------------------------------------------------------------------------------\n",
      "normal inference on model 1\n",
      "Testing:  98%|█████████▊| 50/51 [00:22<00:00,  2.78it/s]Test epoch ended.\n",
      "Testing: 100%|██████████| 51/51 [00:22<00:00,  2.29it/s]\n",
      "--------------------------------------------------------------------------------\n",
      "DATALOADER:0 TEST RESULTS\n",
      "{'test_acc': tensor(0.8838, device='cuda:0')}\n",
      "--------------------------------------------------------------------------------\n",
      "normal inference on model 2\n",
      "Testing:  98%|█████████▊| 50/51 [00:22<00:00,  2.77it/s]Test epoch ended.\n",
      "Testing: 100%|██████████| 51/51 [00:22<00:00,  2.27it/s]\n",
      "--------------------------------------------------------------------------------\n",
      "DATALOADER:0 TEST RESULTS\n",
      "{'test_acc': tensor(0.8785, device='cuda:0')}\n",
      "--------------------------------------------------------------------------------\n",
      "normal inference on model 3\n",
      "Testing:  33%|███▎      | 17/51 [00:08<00:14,  2.30it/s]"
     ]
    }
   ],
   "source": [
    "run_inference_multiple(experiment_names=['adabound_coswarm_bnf_bitemp_smooth_weighted_t1=0.3_t2=1.0_89-1',\n",
    "                                         'sgd_coswarm_bnf_bitemp_smooth_weighted_t1=0.3_t2=1.0_89-53_cleaned_0.6',\n",
    "                                         'SERESNET50_sgd_coswarm_bnf_smoothed_0.1_weighted_t1=0.8_t2=1.2_88-88'],\n",
    "              tta=0, weight_avg=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
