{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter selection with Ray Tune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from datetime import datetime\n",
    "import time\n",
    "import random\n",
    "import warnings\n",
    "import joblib\n",
    "import warnings\n",
    "\n",
    "# My modules\n",
    "from config import Config\n",
    "from logger import init_logger\n",
    "from common_utils import set_seeds, read_csvs, stratify_split, setup, get_loaders\n",
    "from model import Model\n",
    "from train_loop_functions import train_epoch, valid_epoch\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.cuda.amp import GradScaler\n",
    "\n",
    "# hyperparameter tuning\n",
    "from functools import partial\n",
    "import ray\n",
    "from ray import tune\n",
    "from ray.tune import CLIReporter\n",
    "from ray.tune.schedulers import ASHAScheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_seeds(Config.seed)\n",
    "LOGGER = init_logger() # uses Python's logging framework"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all params are passed in by Tune\n",
    "def train_main(config, checkpoint_dir=None, data_dir=None):\n",
    "    assert config is not None\n",
    "    # -------- DATASETS AND LOADERS --------\n",
    "    train_df, test_df = read_csvs(data_dir, Config.debug)\n",
    "    train_folds = stratify_split(train_df, Config.fold_num, Config.seed, Config.target_col)\n",
    "    \n",
    "    # select only one of the folds (fold 0)\n",
    "    train_dataloader, valid_dataloader = get_loaders(train_folds, 0, \n",
    "                                                     config[\"batch_size\"], data_dir+'/train_images')\n",
    "    \n",
    "    # -------- MODEL --------\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model, optimizer, scheduler, criterion = setup(Config.model_arch, config[\"lr\"], \n",
    "                                                   config[\"is_amsgrad\"], train_df.label.nunique(), device)\n",
    "    \n",
    "    # The `checkpoint_dir` parameter gets passed by Ray Tune when a checkpoint should be restored.\n",
    "    if checkpoint_dir:\n",
    "        checkpoint = os.path.join(checkpoint_dir, \"checkpoint\")\n",
    "        model_state, optimizer_state = torch.load(checkpoint)\n",
    "        model.load_state_dict(model_state)\n",
    "        optimizer.load_state_dict(optimizer_state)\n",
    "        \n",
    "    # EPOCHS TRAIN\n",
    "    for e in range(10):\n",
    "        # TRAIN\n",
    "        training_losses = train_epoch(train_dataloader, model, \n",
    "                                      criterion, optimizer, \n",
    "                                      scheduler, GradScaler(), \n",
    "                                      config[\"accum_iter\"], LOGGER,\n",
    "                                      device)\n",
    "        avg_training_loss = sum(training_losses) / len(train_dataloader)\n",
    "        \n",
    "        # VALIDATE\n",
    "        validation_losses, preds = valid_epoch(valid_dataloader, model, \n",
    "                                               criterion, config[\"accum_iter\"],\n",
    "                                               LOGGER, device)\n",
    "        avg_validation_loss = sum(validation_losses) / len(valid_dataloader)\n",
    "        \n",
    "        validation_labels = valid_df[Config.target_col].values\n",
    "        accuracy = accuracy_score(y_true=validation_labels, y_pred=preds)\n",
    "        \n",
    "        # SAVE CHECKPOINT.\n",
    "        # It is automatically registered with Ray Tune and will potentially\n",
    "        # be passed as the `checkpoint_dir` parameter in future iterations.\n",
    "        with tune.checkpoint_dir(step=e) as checkpoint_dir:\n",
    "            path = os.path.join(checkpoint_dir, \"checkpoint\")\n",
    "            torch.save((model.state_dict(), optimizer.state_dict()), path)\n",
    "\n",
    "        tune.report(loss=avg_validation_loss, accuracy=accuracy)\n",
    "    print(\"Finished Training\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(num_samples=20, max_num_epochs=10, gpus_per_trial=1):\n",
    "    data_dir = os.path.abspath('./data')\n",
    "    \n",
    "    hyperconfig = {\n",
    "        \"is_amsgrad\": tune.choice([False, True]),\n",
    "        \"accum_iter\": tune.choice([1,2,4,8,16]),\n",
    "        \"lr\": tune.loguniform(1e-4, 1e-1),\n",
    "        \"batch_size\": tune.choice([4, 8, 16, 32])\n",
    "    }\n",
    "    \n",
    "    scheduler = ASHAScheduler(\n",
    "        metric=\"loss\",\n",
    "        mode=\"min\",\n",
    "        max_t=max_num_epochs,\n",
    "        grace_period=1,\n",
    "        reduction_factor=2)\n",
    "    reporter = CLIReporter(metric_columns=[\"loss\", \"accuracy\", \"training_iteration\"])\n",
    "    result = tune.run(\n",
    "        partial(train_main, data_dir=data_dir),\n",
    "        resources_per_trial={\"cpu\": 1, \"gpu\": gpus_per_trial},\n",
    "        config=hyperconfig,\n",
    "        num_samples=num_samples,\n",
    "        scheduler=scheduler,\n",
    "        progress_reporter=reporter)\n",
    "\n",
    "    best_trial = result.get_best_trial(\"loss\", \"min\", \"last\")\n",
    "    print(\"Best trial config: {}\".format(best_trial.config))\n",
    "    print(\"Best trial final validation loss: {}\".format(\n",
    "        best_trial.last_result[\"loss\"]))\n",
    "    print(\"Best trial final validation accuracy: {}\".format(\n",
    "        best_trial.last_result[\"accuracy\"]))\n",
    "\n",
    "    best_trained_model = Model(Config.model_arch, Config.num_labels, pretrained=True).to(device)\n",
    "    device = \"cpu\"\n",
    "    if torch.cuda.is_available():\n",
    "        device = \"cuda:0\"\n",
    "        if gpus_per_trial > 1:\n",
    "            best_trained_model = nn.DataParallel(best_trained_model)\n",
    "    best_trained_model.to(device)\n",
    "\n",
    "    checkpoint_path = os.path.join(best_trial.checkpoint.value, \"checkpoint\")\n",
    "\n",
    "    model_state, optimizer_state = torch.load(checkpoint_path)\n",
    "    best_trained_model.load_state_dict(model_state)\n",
    "\n",
    "    test_acc = test_accuracy(best_trained_model, device)\n",
    "    print(\"Best trial test set accuracy: {}\".format(test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-12-24 23:05:01,429\tINFO services.py:1092 -- View the Ray dashboard at \u001b[1m\u001b[32mhttp://127.0.0.1:8265\u001b[39m\u001b[22m\n",
      "2020-12-24 23:05:02,071\tWARNING experiment.py:274 -- No name detected on trainable. Using DEFAULT.\n",
      "2020-12-24 23:05:02,071\tINFO registry.py:65 -- Detected unknown callable for trainable. Converting to class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Memory usage on this node: 4.9/31.3 GiB\n",
      "Using AsyncHyperBand: num_stopped=0\n",
      "Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: None\n",
      "Resources requested: 1/8 CPUs, 1/1 GPUs, 0.0/17.63 GiB heap, 0.0/6.05 GiB objects (0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /opt/favordata/ray_results/DEFAULT_2020-12-24_23-05-02\n",
      "Number of trials: 1/20 (1 RUNNING)\n",
      "+---------------------+----------+-------+--------------+--------------+--------------+-----------+\n",
      "| Trial name          | status   | loc   |   accum_iter |   batch_size | is_amsgrad   |        lr |\n",
      "|---------------------+----------+-------+--------------+--------------+--------------+-----------|\n",
      "| DEFAULT_73dea_00000 | RUNNING  |       |            1 |           32 | False        | 0.0122859 |\n",
      "+---------------------+----------+-------+--------------+--------------+--------------+-----------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=6411)\u001b[0m Epoch     0: adjusting learning rate of group 0 to 1.2286e-02.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=6411)\u001b[0m 2020-12-24 23:05:06,153\tERROR function_runner.py:254 -- Runner Thread raised error.\n",
      "\u001b[2m\u001b[36m(pid=6411)\u001b[0m Traceback (most recent call last):\n",
      "\u001b[2m\u001b[36m(pid=6411)\u001b[0m   File \"/opt/favordata/anaconda3/envs/kaggle/lib/python3.7/site-packages/ray/tune/function_runner.py\", line 248, in run\n",
      "\u001b[2m\u001b[36m(pid=6411)\u001b[0m     self._entrypoint()\n",
      "\u001b[2m\u001b[36m(pid=6411)\u001b[0m   File \"/opt/favordata/anaconda3/envs/kaggle/lib/python3.7/site-packages/ray/tune/function_runner.py\", line 316, in entrypoint\n",
      "\u001b[2m\u001b[36m(pid=6411)\u001b[0m     self._status_reporter.get_checkpoint())\n",
      "\u001b[2m\u001b[36m(pid=6411)\u001b[0m   File \"/opt/favordata/anaconda3/envs/kaggle/lib/python3.7/site-packages/ray/tune/function_runner.py\", line 575, in _trainable_func\n",
      "\u001b[2m\u001b[36m(pid=6411)\u001b[0m     output = fn()\n",
      "\u001b[2m\u001b[36m(pid=6411)\u001b[0m   File \"<ipython-input-4-85c201a07a96>\", line 31, in train_main\n",
      "\u001b[2m\u001b[36m(pid=6411)\u001b[0m   File \"/opt/favordata/AI/Felix/kaggle-cassava/train_loop_functions.py\", line 21, in train_epoch\n",
      "\u001b[2m\u001b[36m(pid=6411)\u001b[0m     predictions = model(images)\n",
      "\u001b[2m\u001b[36m(pid=6411)\u001b[0m   File \"/opt/favordata/anaconda3/envs/kaggle/lib/python3.7/site-packages/torch/nn/modules/module.py\", line 727, in _call_impl\n",
      "\u001b[2m\u001b[36m(pid=6411)\u001b[0m     result = self.forward(*input, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=6411)\u001b[0m   File \"/opt/favordata/AI/Felix/kaggle-cassava/model.py\", line 17, in forward\n",
      "\u001b[2m\u001b[36m(pid=6411)\u001b[0m     return self.model(x)\n",
      "\u001b[2m\u001b[36m(pid=6411)\u001b[0m   File \"/opt/favordata/anaconda3/envs/kaggle/lib/python3.7/site-packages/torch/nn/modules/module.py\", line 727, in _call_impl\n",
      "\u001b[2m\u001b[36m(pid=6411)\u001b[0m     result = self.forward(*input, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=6411)\u001b[0m   File \"../pytorch-image-models/timm/models/efficientnet.py\", line 391, in forward\n",
      "\u001b[2m\u001b[36m(pid=6411)\u001b[0m     x = self.forward_features(x)\n",
      "\u001b[2m\u001b[36m(pid=6411)\u001b[0m   File \"../pytorch-image-models/timm/models/efficientnet.py\", line 384, in forward_features\n",
      "\u001b[2m\u001b[36m(pid=6411)\u001b[0m     x = self.blocks(x)\n",
      "\u001b[2m\u001b[36m(pid=6411)\u001b[0m   File \"/opt/favordata/anaconda3/envs/kaggle/lib/python3.7/site-packages/torch/nn/modules/module.py\", line 727, in _call_impl\n",
      "\u001b[2m\u001b[36m(pid=6411)\u001b[0m     result = self.forward(*input, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=6411)\u001b[0m   File \"/opt/favordata/anaconda3/envs/kaggle/lib/python3.7/site-packages/torch/nn/modules/container.py\", line 117, in forward\n",
      "\u001b[2m\u001b[36m(pid=6411)\u001b[0m     input = module(input)\n",
      "\u001b[2m\u001b[36m(pid=6411)\u001b[0m   File \"/opt/favordata/anaconda3/envs/kaggle/lib/python3.7/site-packages/torch/nn/modules/module.py\", line 727, in _call_impl\n",
      "\u001b[2m\u001b[36m(pid=6411)\u001b[0m     result = self.forward(*input, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=6411)\u001b[0m   File \"/opt/favordata/anaconda3/envs/kaggle/lib/python3.7/site-packages/torch/nn/modules/container.py\", line 117, in forward\n",
      "\u001b[2m\u001b[36m(pid=6411)\u001b[0m     input = module(input)\n",
      "\u001b[2m\u001b[36m(pid=6411)\u001b[0m   File \"/opt/favordata/anaconda3/envs/kaggle/lib/python3.7/site-packages/torch/nn/modules/module.py\", line 727, in _call_impl\n",
      "\u001b[2m\u001b[36m(pid=6411)\u001b[0m     result = self.forward(*input, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=6411)\u001b[0m   File \"../pytorch-image-models/timm/models/efficientnet_blocks.py\", line 259, in forward\n",
      "\u001b[2m\u001b[36m(pid=6411)\u001b[0m     x = self.act1(x)\n",
      "\u001b[2m\u001b[36m(pid=6411)\u001b[0m   File \"/opt/favordata/anaconda3/envs/kaggle/lib/python3.7/site-packages/torch/nn/modules/module.py\", line 727, in _call_impl\n",
      "\u001b[2m\u001b[36m(pid=6411)\u001b[0m     result = self.forward(*input, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=6411)\u001b[0m   File \"/opt/favordata/anaconda3/envs/kaggle/lib/python3.7/site-packages/torch/nn/modules/activation.py\", line 394, in forward\n",
      "\u001b[2m\u001b[36m(pid=6411)\u001b[0m     return F.silu(input, inplace=self.inplace)\n",
      "\u001b[2m\u001b[36m(pid=6411)\u001b[0m   File \"/opt/favordata/anaconda3/envs/kaggle/lib/python3.7/site-packages/torch/nn/functional.py\", line 1740, in silu\n",
      "\u001b[2m\u001b[36m(pid=6411)\u001b[0m     return torch._C._nn.silu_(input)\n",
      "\u001b[2m\u001b[36m(pid=6411)\u001b[0m RuntimeError: CUDA out of memory. Tried to allocate 84.00 MiB (GPU 0; 10.76 GiB total capacity; 9.66 GiB already allocated; 39.44 MiB free; 9.84 GiB reserved in total by PyTorch)\n",
      "\u001b[2m\u001b[36m(pid=6411)\u001b[0m Exception in thread Thread-2:\n",
      "\u001b[2m\u001b[36m(pid=6411)\u001b[0m Traceback (most recent call last):\n",
      "\u001b[2m\u001b[36m(pid=6411)\u001b[0m   File \"/opt/favordata/anaconda3/envs/kaggle/lib/python3.7/threading.py\", line 926, in _bootstrap_inner\n",
      "\u001b[2m\u001b[36m(pid=6411)\u001b[0m     self.run()\n",
      "\u001b[2m\u001b[36m(pid=6411)\u001b[0m   File \"/opt/favordata/anaconda3/envs/kaggle/lib/python3.7/site-packages/ray/tune/function_runner.py\", line 267, in run\n",
      "\u001b[2m\u001b[36m(pid=6411)\u001b[0m     raise e\n",
      "\u001b[2m\u001b[36m(pid=6411)\u001b[0m   File \"/opt/favordata/anaconda3/envs/kaggle/lib/python3.7/site-packages/ray/tune/function_runner.py\", line 248, in run\n",
      "\u001b[2m\u001b[36m(pid=6411)\u001b[0m     self._entrypoint()\n",
      "\u001b[2m\u001b[36m(pid=6411)\u001b[0m   File \"/opt/favordata/anaconda3/envs/kaggle/lib/python3.7/site-packages/ray/tune/function_runner.py\", line 316, in entrypoint\n",
      "\u001b[2m\u001b[36m(pid=6411)\u001b[0m     self._status_reporter.get_checkpoint())\n",
      "\u001b[2m\u001b[36m(pid=6411)\u001b[0m   File \"/opt/favordata/anaconda3/envs/kaggle/lib/python3.7/site-packages/ray/tune/function_runner.py\", line 575, in _trainable_func\n",
      "\u001b[2m\u001b[36m(pid=6411)\u001b[0m     output = fn()\n",
      "\u001b[2m\u001b[36m(pid=6411)\u001b[0m   File \"<ipython-input-4-85c201a07a96>\", line 31, in train_main\n",
      "\u001b[2m\u001b[36m(pid=6411)\u001b[0m   File \"/opt/favordata/AI/Felix/kaggle-cassava/train_loop_functions.py\", line 21, in train_epoch\n",
      "\u001b[2m\u001b[36m(pid=6411)\u001b[0m     predictions = model(images)\n",
      "\u001b[2m\u001b[36m(pid=6411)\u001b[0m   File \"/opt/favordata/anaconda3/envs/kaggle/lib/python3.7/site-packages/torch/nn/modules/module.py\", line 727, in _call_impl\n",
      "\u001b[2m\u001b[36m(pid=6411)\u001b[0m     result = self.forward(*input, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=6411)\u001b[0m   File \"/opt/favordata/AI/Felix/kaggle-cassava/model.py\", line 17, in forward\n",
      "\u001b[2m\u001b[36m(pid=6411)\u001b[0m     return self.model(x)\n",
      "\u001b[2m\u001b[36m(pid=6411)\u001b[0m   File \"/opt/favordata/anaconda3/envs/kaggle/lib/python3.7/site-packages/torch/nn/modules/module.py\", line 727, in _call_impl\n",
      "\u001b[2m\u001b[36m(pid=6411)\u001b[0m     result = self.forward(*input, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=6411)\u001b[0m   File \"../pytorch-image-models/timm/models/efficientnet.py\", line 391, in forward\n",
      "\u001b[2m\u001b[36m(pid=6411)\u001b[0m     x = self.forward_features(x)\n",
      "\u001b[2m\u001b[36m(pid=6411)\u001b[0m   File \"../pytorch-image-models/timm/models/efficientnet.py\", line 384, in forward_features\n",
      "\u001b[2m\u001b[36m(pid=6411)\u001b[0m     x = self.blocks(x)\n",
      "\u001b[2m\u001b[36m(pid=6411)\u001b[0m   File \"/opt/favordata/anaconda3/envs/kaggle/lib/python3.7/site-packages/torch/nn/modules/module.py\", line 727, in _call_impl\n",
      "\u001b[2m\u001b[36m(pid=6411)\u001b[0m     result = self.forward(*input, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=6411)\u001b[0m   File \"/opt/favordata/anaconda3/envs/kaggle/lib/python3.7/site-packages/torch/nn/modules/container.py\", line 117, in forward\n",
      "\u001b[2m\u001b[36m(pid=6411)\u001b[0m     input = module(input)\n",
      "\u001b[2m\u001b[36m(pid=6411)\u001b[0m   File \"/opt/favordata/anaconda3/envs/kaggle/lib/python3.7/site-packages/torch/nn/modules/module.py\", line 727, in _call_impl\n",
      "\u001b[2m\u001b[36m(pid=6411)\u001b[0m     result = self.forward(*input, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=6411)\u001b[0m   File \"/opt/favordata/anaconda3/envs/kaggle/lib/python3.7/site-packages/torch/nn/modules/container.py\", line 117, in forward\n",
      "\u001b[2m\u001b[36m(pid=6411)\u001b[0m     input = module(input)\n",
      "\u001b[2m\u001b[36m(pid=6411)\u001b[0m   File \"/opt/favordata/anaconda3/envs/kaggle/lib/python3.7/site-packages/torch/nn/modules/module.py\", line 727, in _call_impl\n",
      "\u001b[2m\u001b[36m(pid=6411)\u001b[0m     result = self.forward(*input, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=6411)\u001b[0m   File \"../pytorch-image-models/timm/models/efficientnet_blocks.py\", line 259, in forward\n",
      "\u001b[2m\u001b[36m(pid=6411)\u001b[0m     x = self.act1(x)\n",
      "\u001b[2m\u001b[36m(pid=6411)\u001b[0m   File \"/opt/favordata/anaconda3/envs/kaggle/lib/python3.7/site-packages/torch/nn/modules/module.py\", line 727, in _call_impl\n",
      "\u001b[2m\u001b[36m(pid=6411)\u001b[0m     result = self.forward(*input, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=6411)\u001b[0m   File \"/opt/favordata/anaconda3/envs/kaggle/lib/python3.7/site-packages/torch/nn/modules/activation.py\", line 394, in forward\n",
      "\u001b[2m\u001b[36m(pid=6411)\u001b[0m     return F.silu(input, inplace=self.inplace)\n",
      "\u001b[2m\u001b[36m(pid=6411)\u001b[0m   File \"/opt/favordata/anaconda3/envs/kaggle/lib/python3.7/site-packages/torch/nn/functional.py\", line 1740, in silu\n",
      "\u001b[2m\u001b[36m(pid=6411)\u001b[0m     return torch._C._nn.silu_(input)\n",
      "\u001b[2m\u001b[36m(pid=6411)\u001b[0m RuntimeError: CUDA out of memory. Tried to allocate 84.00 MiB (GPU 0; 10.76 GiB total capacity; 9.66 GiB already allocated; 39.44 MiB free; 9.84 GiB reserved in total by PyTorch)\n",
      "\u001b[2m\u001b[36m(pid=6411)\u001b[0m \n",
      "2020-12-24 23:05:06,225\tERROR trial_runner.py:793 -- Trial DEFAULT_73dea_00000: Error processing event.\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/favordata/anaconda3/envs/kaggle/lib/python3.7/site-packages/ray/tune/trial_runner.py\", line 726, in _process_trial\n",
      "    result = self.trial_executor.fetch_result(trial)\n",
      "  File \"/opt/favordata/anaconda3/envs/kaggle/lib/python3.7/site-packages/ray/tune/ray_trial_executor.py\", line 489, in fetch_result\n",
      "    result = ray.get(trial_future[0], timeout=DEFAULT_GET_TIMEOUT)\n",
      "  File \"/opt/favordata/anaconda3/envs/kaggle/lib/python3.7/site-packages/ray/worker.py\", line 1452, in get\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(TuneError): \u001b[36mray::ImplicitFunc.train()\u001b[39m (pid=6411, ip=10.0.0.200)\n",
      "  File \"python/ray/_raylet.pyx\", line 482, in ray._raylet.execute_task\n",
      "  File \"python/ray/_raylet.pyx\", line 436, in ray._raylet.execute_task.function_executor\n",
      "  File \"/opt/favordata/anaconda3/envs/kaggle/lib/python3.7/site-packages/ray/tune/trainable.py\", line 336, in train\n",
      "    result = self.step()\n",
      "  File \"/opt/favordata/anaconda3/envs/kaggle/lib/python3.7/site-packages/ray/tune/function_runner.py\", line 366, in step\n",
      "    self._report_thread_runner_error(block=True)\n",
      "  File \"/opt/favordata/anaconda3/envs/kaggle/lib/python3.7/site-packages/ray/tune/function_runner.py\", line 513, in _report_thread_runner_error\n",
      "    .format(err_tb_str)))\n",
      "ray.tune.error.TuneError: Trial raised an exception. Traceback:\n",
      "\u001b[36mray::ImplicitFunc.train()\u001b[39m (pid=6411, ip=10.0.0.200)\n",
      "  File \"/opt/favordata/anaconda3/envs/kaggle/lib/python3.7/site-packages/ray/tune/function_runner.py\", line 248, in run\n",
      "    self._entrypoint()\n",
      "  File \"/opt/favordata/anaconda3/envs/kaggle/lib/python3.7/site-packages/ray/tune/function_runner.py\", line 316, in entrypoint\n",
      "    self._status_reporter.get_checkpoint())\n",
      "  File \"/opt/favordata/anaconda3/envs/kaggle/lib/python3.7/site-packages/ray/tune/function_runner.py\", line 575, in _trainable_func\n",
      "    output = fn()\n",
      "  File \"<ipython-input-4-85c201a07a96>\", line 31, in train_main\n",
      "  File \"/opt/favordata/AI/Felix/kaggle-cassava/train_loop_functions.py\", line 21, in train_epoch\n",
      "    predictions = model(images)\n",
      "  File \"/opt/favordata/anaconda3/envs/kaggle/lib/python3.7/site-packages/torch/nn/modules/module.py\", line 727, in _call_impl\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"/opt/favordata/AI/Felix/kaggle-cassava/model.py\", line 17, in forward\n",
      "    return self.model(x)\n",
      "  File \"/opt/favordata/anaconda3/envs/kaggle/lib/python3.7/site-packages/torch/nn/modules/module.py\", line 727, in _call_impl\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"../pytorch-image-models/timm/models/efficientnet.py\", line 391, in forward\n",
      "    x = self.forward_features(x)\n",
      "  File \"../pytorch-image-models/timm/models/efficientnet.py\", line 384, in forward_features\n",
      "    x = self.blocks(x)\n",
      "  File \"/opt/favordata/anaconda3/envs/kaggle/lib/python3.7/site-packages/torch/nn/modules/module.py\", line 727, in _call_impl\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"/opt/favordata/anaconda3/envs/kaggle/lib/python3.7/site-packages/torch/nn/modules/container.py\", line 117, in forward\n",
      "    input = module(input)\n",
      "  File \"/opt/favordata/anaconda3/envs/kaggle/lib/python3.7/site-packages/torch/nn/modules/module.py\", line 727, in _call_impl\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"/opt/favordata/anaconda3/envs/kaggle/lib/python3.7/site-packages/torch/nn/modules/container.py\", line 117, in forward\n",
      "    input = module(input)\n",
      "  File \"/opt/favordata/anaconda3/envs/kaggle/lib/python3.7/site-packages/torch/nn/modules/module.py\", line 727, in _call_impl\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"../pytorch-image-models/timm/models/efficientnet_blocks.py\", line 259, in forward\n",
      "    x = self.act1(x)\n",
      "  File \"/opt/favordata/anaconda3/envs/kaggle/lib/python3.7/site-packages/torch/nn/modules/module.py\", line 727, in _call_impl\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"/opt/favordata/anaconda3/envs/kaggle/lib/python3.7/site-packages/torch/nn/modules/activation.py\", line 394, in forward\n",
      "    return F.silu(input, inplace=self.inplace)\n",
      "  File \"/opt/favordata/anaconda3/envs/kaggle/lib/python3.7/site-packages/torch/nn/functional.py\", line 1740, in silu\n",
      "    return torch._C._nn.silu_(input)\n",
      "RuntimeError: CUDA out of memory. Tried to allocate 84.00 MiB (GPU 0; 10.76 GiB total capacity; 9.66 GiB already allocated; 39.44 MiB free; 9.84 GiB reserved in total by PyTorch)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=6410)\u001b[0m Epoch     0: adjusting learning rate of group 0 to 4.7924e-04.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=6410)\u001b[0m 2020-12-24 23:05:14,125\tERROR function_runner.py:254 -- Runner Thread raised error.\n",
      "\u001b[2m\u001b[36m(pid=6410)\u001b[0m Traceback (most recent call last):\n",
      "\u001b[2m\u001b[36m(pid=6410)\u001b[0m   File \"/opt/favordata/anaconda3/envs/kaggle/lib/python3.7/site-packages/ray/tune/function_runner.py\", line 248, in run\n",
      "\u001b[2m\u001b[36m(pid=6410)\u001b[0m     self._entrypoint()\n",
      "\u001b[2m\u001b[36m(pid=6410)\u001b[0m   File \"/opt/favordata/anaconda3/envs/kaggle/lib/python3.7/site-packages/ray/tune/function_runner.py\", line 316, in entrypoint\n",
      "\u001b[2m\u001b[36m(pid=6410)\u001b[0m     self._status_reporter.get_checkpoint())\n",
      "\u001b[2m\u001b[36m(pid=6410)\u001b[0m   File \"/opt/favordata/anaconda3/envs/kaggle/lib/python3.7/site-packages/ray/tune/function_runner.py\", line 575, in _trainable_func\n",
      "\u001b[2m\u001b[36m(pid=6410)\u001b[0m     output = fn()\n",
      "\u001b[2m\u001b[36m(pid=6410)\u001b[0m   File \"<ipython-input-4-85c201a07a96>\", line 31, in train_main\n",
      "\u001b[2m\u001b[36m(pid=6410)\u001b[0m   File \"/opt/favordata/AI/Felix/kaggle-cassava/train_loop_functions.py\", line 60, in train_epoch\n",
      "\u001b[2m\u001b[36m(pid=6410)\u001b[0m     LOGGER.info(f'[TRAIN] batch {batch_idx+1}/{len(dataloader)} loss: {loss} | grad: {total_norm}')\n",
      "\u001b[2m\u001b[36m(pid=6410)\u001b[0m NameError: name 'LOGGER' is not defined\n",
      "\u001b[2m\u001b[36m(pid=6410)\u001b[0m Exception in thread Thread-2:\n",
      "\u001b[2m\u001b[36m(pid=6410)\u001b[0m Traceback (most recent call last):\n",
      "\u001b[2m\u001b[36m(pid=6410)\u001b[0m   File \"/opt/favordata/anaconda3/envs/kaggle/lib/python3.7/threading.py\", line 926, in _bootstrap_inner\n",
      "\u001b[2m\u001b[36m(pid=6410)\u001b[0m     self.run()\n",
      "\u001b[2m\u001b[36m(pid=6410)\u001b[0m   File \"/opt/favordata/anaconda3/envs/kaggle/lib/python3.7/site-packages/ray/tune/function_runner.py\", line 267, in run\n",
      "\u001b[2m\u001b[36m(pid=6410)\u001b[0m     raise e\n",
      "\u001b[2m\u001b[36m(pid=6410)\u001b[0m   File \"/opt/favordata/anaconda3/envs/kaggle/lib/python3.7/site-packages/ray/tune/function_runner.py\", line 248, in run\n",
      "\u001b[2m\u001b[36m(pid=6410)\u001b[0m     self._entrypoint()\n",
      "\u001b[2m\u001b[36m(pid=6410)\u001b[0m   File \"/opt/favordata/anaconda3/envs/kaggle/lib/python3.7/site-packages/ray/tune/function_runner.py\", line 316, in entrypoint\n",
      "\u001b[2m\u001b[36m(pid=6410)\u001b[0m     self._status_reporter.get_checkpoint())\n",
      "\u001b[2m\u001b[36m(pid=6410)\u001b[0m   File \"/opt/favordata/anaconda3/envs/kaggle/lib/python3.7/site-packages/ray/tune/function_runner.py\", line 575, in _trainable_func\n",
      "\u001b[2m\u001b[36m(pid=6410)\u001b[0m     output = fn()\n",
      "\u001b[2m\u001b[36m(pid=6410)\u001b[0m   File \"<ipython-input-4-85c201a07a96>\", line 31, in train_main\n",
      "\u001b[2m\u001b[36m(pid=6410)\u001b[0m   File \"/opt/favordata/AI/Felix/kaggle-cassava/train_loop_functions.py\", line 60, in train_epoch\n",
      "\u001b[2m\u001b[36m(pid=6410)\u001b[0m     LOGGER.info(f'[TRAIN] batch {batch_idx+1}/{len(dataloader)} loss: {loss} | grad: {total_norm}')\n",
      "\u001b[2m\u001b[36m(pid=6410)\u001b[0m NameError: name 'LOGGER' is not defined\n",
      "\u001b[2m\u001b[36m(pid=6410)\u001b[0m \n",
      "2020-12-24 23:05:14,197\tERROR trial_runner.py:793 -- Trial DEFAULT_73dea_00001: Error processing event.\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/favordata/anaconda3/envs/kaggle/lib/python3.7/site-packages/ray/tune/trial_runner.py\", line 726, in _process_trial\n",
      "    result = self.trial_executor.fetch_result(trial)\n",
      "  File \"/opt/favordata/anaconda3/envs/kaggle/lib/python3.7/site-packages/ray/tune/ray_trial_executor.py\", line 489, in fetch_result\n",
      "    result = ray.get(trial_future[0], timeout=DEFAULT_GET_TIMEOUT)\n",
      "  File \"/opt/favordata/anaconda3/envs/kaggle/lib/python3.7/site-packages/ray/worker.py\", line 1452, in get\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(TuneError): \u001b[36mray::ImplicitFunc.train()\u001b[39m (pid=6410, ip=10.0.0.200)\n",
      "  File \"python/ray/_raylet.pyx\", line 482, in ray._raylet.execute_task\n",
      "  File \"python/ray/_raylet.pyx\", line 436, in ray._raylet.execute_task.function_executor\n",
      "  File \"/opt/favordata/anaconda3/envs/kaggle/lib/python3.7/site-packages/ray/tune/trainable.py\", line 336, in train\n",
      "    result = self.step()\n",
      "  File \"/opt/favordata/anaconda3/envs/kaggle/lib/python3.7/site-packages/ray/tune/function_runner.py\", line 366, in step\n",
      "    self._report_thread_runner_error(block=True)\n",
      "  File \"/opt/favordata/anaconda3/envs/kaggle/lib/python3.7/site-packages/ray/tune/function_runner.py\", line 513, in _report_thread_runner_error\n",
      "    .format(err_tb_str)))\n",
      "ray.tune.error.TuneError: Trial raised an exception. Traceback:\n",
      "\u001b[36mray::ImplicitFunc.train()\u001b[39m (pid=6410, ip=10.0.0.200)\n",
      "  File \"/opt/favordata/anaconda3/envs/kaggle/lib/python3.7/site-packages/ray/tune/function_runner.py\", line 248, in run\n",
      "    self._entrypoint()\n",
      "  File \"/opt/favordata/anaconda3/envs/kaggle/lib/python3.7/site-packages/ray/tune/function_runner.py\", line 316, in entrypoint\n",
      "    self._status_reporter.get_checkpoint())\n",
      "  File \"/opt/favordata/anaconda3/envs/kaggle/lib/python3.7/site-packages/ray/tune/function_runner.py\", line 575, in _trainable_func\n",
      "    output = fn()\n",
      "  File \"<ipython-input-4-85c201a07a96>\", line 31, in train_main\n",
      "  File \"/opt/favordata/AI/Felix/kaggle-cassava/train_loop_functions.py\", line 60, in train_epoch\n",
      "    LOGGER.info(f'[TRAIN] batch {batch_idx+1}/{len(dataloader)} loss: {loss} | grad: {total_norm}')\n",
      "NameError: name 'LOGGER' is not defined\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Memory usage on this node: 7.1/31.3 GiB\n",
      "Using AsyncHyperBand: num_stopped=0\n",
      "Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: None\n",
      "Resources requested: 0/8 CPUs, 0/1 GPUs, 0.0/17.63 GiB heap, 0.0/6.05 GiB objects (0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /opt/favordata/ray_results/DEFAULT_2020-12-24_23-05-02\n",
      "Number of trials: 3/20 (2 ERROR, 1 PENDING)\n",
      "+---------------------+----------+-------+--------------+--------------+--------------+-------------+\n",
      "| Trial name          | status   | loc   |   accum_iter |   batch_size | is_amsgrad   |          lr |\n",
      "|---------------------+----------+-------+--------------+--------------+--------------+-------------|\n",
      "| DEFAULT_73dea_00002 | PENDING  |       |            1 |            8 | True         | 0.0144015   |\n",
      "| DEFAULT_73dea_00000 | ERROR    |       |            1 |           32 | False        | 0.0122859   |\n",
      "| DEFAULT_73dea_00001 | ERROR    |       |            4 |            8 | False        | 0.000479241 |\n",
      "+---------------------+----------+-------+--------------+--------------+--------------+-------------+\n",
      "Number of errored trials: 2\n",
      "+---------------------+--------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "| Trial name          |   # failures | error file                                                                                                                                                          |\n",
      "|---------------------+--------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n",
      "| DEFAULT_73dea_00000 |            1 | /opt/favordata/ray_results/DEFAULT_2020-12-24_23-05-02/DEFAULT_73dea_00000_0_accum_iter=1,batch_size=32,is_amsgrad=False,lr=0.012286_2020-12-24_23-05-02/error.txt  |\n",
      "| DEFAULT_73dea_00001 |            1 | /opt/favordata/ray_results/DEFAULT_2020-12-24_23-05-02/DEFAULT_73dea_00001_1_accum_iter=4,batch_size=8,is_amsgrad=False,lr=0.00047924_2020-12-24_23-05-06/error.txt |\n",
      "+---------------------+--------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=6406)\u001b[0m Epoch     0: adjusting learning rate of group 0 to 1.4401e-02.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=6406)\u001b[0m 2020-12-24 23:05:22,318\tERROR function_runner.py:254 -- Runner Thread raised error.\n",
      "\u001b[2m\u001b[36m(pid=6406)\u001b[0m Traceback (most recent call last):\n",
      "\u001b[2m\u001b[36m(pid=6406)\u001b[0m   File \"/opt/favordata/anaconda3/envs/kaggle/lib/python3.7/site-packages/ray/tune/function_runner.py\", line 248, in run\n",
      "\u001b[2m\u001b[36m(pid=6406)\u001b[0m     self._entrypoint()\n",
      "\u001b[2m\u001b[36m(pid=6406)\u001b[0m   File \"/opt/favordata/anaconda3/envs/kaggle/lib/python3.7/site-packages/ray/tune/function_runner.py\", line 316, in entrypoint\n",
      "\u001b[2m\u001b[36m(pid=6406)\u001b[0m     self._status_reporter.get_checkpoint())\n",
      "\u001b[2m\u001b[36m(pid=6406)\u001b[0m   File \"/opt/favordata/anaconda3/envs/kaggle/lib/python3.7/site-packages/ray/tune/function_runner.py\", line 575, in _trainable_func\n",
      "\u001b[2m\u001b[36m(pid=6406)\u001b[0m     output = fn()\n",
      "\u001b[2m\u001b[36m(pid=6406)\u001b[0m   File \"<ipython-input-4-85c201a07a96>\", line 31, in train_main\n",
      "\u001b[2m\u001b[36m(pid=6406)\u001b[0m   File \"/opt/favordata/AI/Felix/kaggle-cassava/train_loop_functions.py\", line 60, in train_epoch\n",
      "\u001b[2m\u001b[36m(pid=6406)\u001b[0m     LOGGER.info(f'[TRAIN] batch {batch_idx+1}/{len(dataloader)} loss: {loss} | grad: {total_norm}')\n",
      "\u001b[2m\u001b[36m(pid=6406)\u001b[0m NameError: name 'LOGGER' is not defined\n",
      "\u001b[2m\u001b[36m(pid=6406)\u001b[0m Exception in thread Thread-2:\n",
      "\u001b[2m\u001b[36m(pid=6406)\u001b[0m Traceback (most recent call last):\n",
      "\u001b[2m\u001b[36m(pid=6406)\u001b[0m   File \"/opt/favordata/anaconda3/envs/kaggle/lib/python3.7/threading.py\", line 926, in _bootstrap_inner\n",
      "\u001b[2m\u001b[36m(pid=6406)\u001b[0m     self.run()\n",
      "\u001b[2m\u001b[36m(pid=6406)\u001b[0m   File \"/opt/favordata/anaconda3/envs/kaggle/lib/python3.7/site-packages/ray/tune/function_runner.py\", line 267, in run\n",
      "\u001b[2m\u001b[36m(pid=6406)\u001b[0m     raise e\n",
      "\u001b[2m\u001b[36m(pid=6406)\u001b[0m   File \"/opt/favordata/anaconda3/envs/kaggle/lib/python3.7/site-packages/ray/tune/function_runner.py\", line 248, in run\n",
      "\u001b[2m\u001b[36m(pid=6406)\u001b[0m     self._entrypoint()\n",
      "\u001b[2m\u001b[36m(pid=6406)\u001b[0m   File \"/opt/favordata/anaconda3/envs/kaggle/lib/python3.7/site-packages/ray/tune/function_runner.py\", line 316, in entrypoint\n",
      "\u001b[2m\u001b[36m(pid=6406)\u001b[0m     self._status_reporter.get_checkpoint())\n",
      "\u001b[2m\u001b[36m(pid=6406)\u001b[0m   File \"/opt/favordata/anaconda3/envs/kaggle/lib/python3.7/site-packages/ray/tune/function_runner.py\", line 575, in _trainable_func\n",
      "\u001b[2m\u001b[36m(pid=6406)\u001b[0m     output = fn()\n",
      "\u001b[2m\u001b[36m(pid=6406)\u001b[0m   File \"<ipython-input-4-85c201a07a96>\", line 31, in train_main\n",
      "\u001b[2m\u001b[36m(pid=6406)\u001b[0m   File \"/opt/favordata/AI/Felix/kaggle-cassava/train_loop_functions.py\", line 60, in train_epoch\n",
      "\u001b[2m\u001b[36m(pid=6406)\u001b[0m     LOGGER.info(f'[TRAIN] batch {batch_idx+1}/{len(dataloader)} loss: {loss} | grad: {total_norm}')\n",
      "\u001b[2m\u001b[36m(pid=6406)\u001b[0m NameError: name 'LOGGER' is not defined\n",
      "\u001b[2m\u001b[36m(pid=6406)\u001b[0m \n",
      "2020-12-24 23:05:22,386\tERROR trial_runner.py:793 -- Trial DEFAULT_73dea_00002: Error processing event.\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/favordata/anaconda3/envs/kaggle/lib/python3.7/site-packages/ray/tune/trial_runner.py\", line 726, in _process_trial\n",
      "    result = self.trial_executor.fetch_result(trial)\n",
      "  File \"/opt/favordata/anaconda3/envs/kaggle/lib/python3.7/site-packages/ray/tune/ray_trial_executor.py\", line 489, in fetch_result\n",
      "    result = ray.get(trial_future[0], timeout=DEFAULT_GET_TIMEOUT)\n",
      "  File \"/opt/favordata/anaconda3/envs/kaggle/lib/python3.7/site-packages/ray/worker.py\", line 1452, in get\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(TuneError): \u001b[36mray::ImplicitFunc.train()\u001b[39m (pid=6406, ip=10.0.0.200)\n",
      "  File \"python/ray/_raylet.pyx\", line 482, in ray._raylet.execute_task\n",
      "  File \"python/ray/_raylet.pyx\", line 436, in ray._raylet.execute_task.function_executor\n",
      "  File \"/opt/favordata/anaconda3/envs/kaggle/lib/python3.7/site-packages/ray/tune/trainable.py\", line 336, in train\n",
      "    result = self.step()\n",
      "  File \"/opt/favordata/anaconda3/envs/kaggle/lib/python3.7/site-packages/ray/tune/function_runner.py\", line 366, in step\n",
      "    self._report_thread_runner_error(block=True)\n",
      "  File \"/opt/favordata/anaconda3/envs/kaggle/lib/python3.7/site-packages/ray/tune/function_runner.py\", line 513, in _report_thread_runner_error\n",
      "    .format(err_tb_str)))\n",
      "ray.tune.error.TuneError: Trial raised an exception. Traceback:\n",
      "\u001b[36mray::ImplicitFunc.train()\u001b[39m (pid=6406, ip=10.0.0.200)\n",
      "  File \"/opt/favordata/anaconda3/envs/kaggle/lib/python3.7/site-packages/ray/tune/function_runner.py\", line 248, in run\n",
      "    self._entrypoint()\n",
      "  File \"/opt/favordata/anaconda3/envs/kaggle/lib/python3.7/site-packages/ray/tune/function_runner.py\", line 316, in entrypoint\n",
      "    self._status_reporter.get_checkpoint())\n",
      "  File \"/opt/favordata/anaconda3/envs/kaggle/lib/python3.7/site-packages/ray/tune/function_runner.py\", line 575, in _trainable_func\n",
      "    output = fn()\n",
      "  File \"<ipython-input-4-85c201a07a96>\", line 31, in train_main\n",
      "  File \"/opt/favordata/AI/Felix/kaggle-cassava/train_loop_functions.py\", line 60, in train_epoch\n",
      "    LOGGER.info(f'[TRAIN] batch {batch_idx+1}/{len(dataloader)} loss: {loss} | grad: {total_norm}')\n",
      "NameError: name 'LOGGER' is not defined\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Memory usage on this node: 7.0/31.3 GiB\n",
      "Using AsyncHyperBand: num_stopped=0\n",
      "Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: None\n",
      "Resources requested: 0/8 CPUs, 0/1 GPUs, 0.0/17.63 GiB heap, 0.0/6.05 GiB objects (0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /opt/favordata/ray_results/DEFAULT_2020-12-24_23-05-02\n",
      "Number of trials: 4/20 (3 ERROR, 1 PENDING)\n",
      "+---------------------+----------+-------+--------------+--------------+--------------+-------------+\n",
      "| Trial name          | status   | loc   |   accum_iter |   batch_size | is_amsgrad   |          lr |\n",
      "|---------------------+----------+-------+--------------+--------------+--------------+-------------|\n",
      "| DEFAULT_73dea_00003 | PENDING  |       |            2 |            4 | False        | 0.0875573   |\n",
      "| DEFAULT_73dea_00000 | ERROR    |       |            1 |           32 | False        | 0.0122859   |\n",
      "| DEFAULT_73dea_00001 | ERROR    |       |            4 |            8 | False        | 0.000479241 |\n",
      "| DEFAULT_73dea_00002 | ERROR    |       |            1 |            8 | True         | 0.0144015   |\n",
      "+---------------------+----------+-------+--------------+--------------+--------------+-------------+\n",
      "Number of errored trials: 3\n",
      "+---------------------+--------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "| Trial name          |   # failures | error file                                                                                                                                                          |\n",
      "|---------------------+--------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n",
      "| DEFAULT_73dea_00000 |            1 | /opt/favordata/ray_results/DEFAULT_2020-12-24_23-05-02/DEFAULT_73dea_00000_0_accum_iter=1,batch_size=32,is_amsgrad=False,lr=0.012286_2020-12-24_23-05-02/error.txt  |\n",
      "| DEFAULT_73dea_00001 |            1 | /opt/favordata/ray_results/DEFAULT_2020-12-24_23-05-02/DEFAULT_73dea_00001_1_accum_iter=4,batch_size=8,is_amsgrad=False,lr=0.00047924_2020-12-24_23-05-06/error.txt |\n",
      "| DEFAULT_73dea_00002 |            1 | /opt/favordata/ray_results/DEFAULT_2020-12-24_23-05-02/DEFAULT_73dea_00002_2_accum_iter=1,batch_size=8,is_amsgrad=True,lr=0.014401_2020-12-24_23-05-14/error.txt    |\n",
      "+---------------------+--------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=6416)\u001b[0m Epoch     0: adjusting learning rate of group 0 to 8.7557e-02.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=6416)\u001b[0m 2020-12-24 23:05:31,207\tERROR function_runner.py:254 -- Runner Thread raised error.\n",
      "\u001b[2m\u001b[36m(pid=6416)\u001b[0m Traceback (most recent call last):\n",
      "\u001b[2m\u001b[36m(pid=6416)\u001b[0m   File \"/opt/favordata/anaconda3/envs/kaggle/lib/python3.7/site-packages/ray/tune/function_runner.py\", line 248, in run\n",
      "\u001b[2m\u001b[36m(pid=6416)\u001b[0m     self._entrypoint()\n",
      "\u001b[2m\u001b[36m(pid=6416)\u001b[0m   File \"/opt/favordata/anaconda3/envs/kaggle/lib/python3.7/site-packages/ray/tune/function_runner.py\", line 316, in entrypoint\n",
      "\u001b[2m\u001b[36m(pid=6416)\u001b[0m     self._status_reporter.get_checkpoint())\n",
      "\u001b[2m\u001b[36m(pid=6416)\u001b[0m   File \"/opt/favordata/anaconda3/envs/kaggle/lib/python3.7/site-packages/ray/tune/function_runner.py\", line 575, in _trainable_func\n",
      "\u001b[2m\u001b[36m(pid=6416)\u001b[0m     output = fn()\n",
      "\u001b[2m\u001b[36m(pid=6416)\u001b[0m   File \"<ipython-input-4-85c201a07a96>\", line 31, in train_main\n",
      "\u001b[2m\u001b[36m(pid=6416)\u001b[0m   File \"/opt/favordata/AI/Felix/kaggle-cassava/train_loop_functions.py\", line 60, in train_epoch\n",
      "\u001b[2m\u001b[36m(pid=6416)\u001b[0m     LOGGER.info(f'[TRAIN] batch {batch_idx+1}/{len(dataloader)} loss: {loss} | grad: {total_norm}')\n",
      "\u001b[2m\u001b[36m(pid=6416)\u001b[0m NameError: name 'LOGGER' is not defined\n",
      "\u001b[2m\u001b[36m(pid=6416)\u001b[0m Exception in thread Thread-2:\n",
      "\u001b[2m\u001b[36m(pid=6416)\u001b[0m Traceback (most recent call last):\n",
      "\u001b[2m\u001b[36m(pid=6416)\u001b[0m   File \"/opt/favordata/anaconda3/envs/kaggle/lib/python3.7/threading.py\", line 926, in _bootstrap_inner\n",
      "\u001b[2m\u001b[36m(pid=6416)\u001b[0m     self.run()\n",
      "\u001b[2m\u001b[36m(pid=6416)\u001b[0m   File \"/opt/favordata/anaconda3/envs/kaggle/lib/python3.7/site-packages/ray/tune/function_runner.py\", line 267, in run\n",
      "\u001b[2m\u001b[36m(pid=6416)\u001b[0m     raise e\n",
      "\u001b[2m\u001b[36m(pid=6416)\u001b[0m   File \"/opt/favordata/anaconda3/envs/kaggle/lib/python3.7/site-packages/ray/tune/function_runner.py\", line 248, in run\n",
      "\u001b[2m\u001b[36m(pid=6416)\u001b[0m     self._entrypoint()\n",
      "\u001b[2m\u001b[36m(pid=6416)\u001b[0m   File \"/opt/favordata/anaconda3/envs/kaggle/lib/python3.7/site-packages/ray/tune/function_runner.py\", line 316, in entrypoint\n",
      "\u001b[2m\u001b[36m(pid=6416)\u001b[0m     self._status_reporter.get_checkpoint())\n",
      "\u001b[2m\u001b[36m(pid=6416)\u001b[0m   File \"/opt/favordata/anaconda3/envs/kaggle/lib/python3.7/site-packages/ray/tune/function_runner.py\", line 575, in _trainable_func\n",
      "\u001b[2m\u001b[36m(pid=6416)\u001b[0m     output = fn()\n",
      "\u001b[2m\u001b[36m(pid=6416)\u001b[0m   File \"<ipython-input-4-85c201a07a96>\", line 31, in train_main\n",
      "\u001b[2m\u001b[36m(pid=6416)\u001b[0m   File \"/opt/favordata/AI/Felix/kaggle-cassava/train_loop_functions.py\", line 60, in train_epoch\n",
      "\u001b[2m\u001b[36m(pid=6416)\u001b[0m     LOGGER.info(f'[TRAIN] batch {batch_idx+1}/{len(dataloader)} loss: {loss} | grad: {total_norm}')\n",
      "\u001b[2m\u001b[36m(pid=6416)\u001b[0m NameError: name 'LOGGER' is not defined\n",
      "\u001b[2m\u001b[36m(pid=6416)\u001b[0m \n",
      "2020-12-24 23:05:31,356\tERROR trial_runner.py:793 -- Trial DEFAULT_73dea_00003: Error processing event.\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/favordata/anaconda3/envs/kaggle/lib/python3.7/site-packages/ray/tune/trial_runner.py\", line 726, in _process_trial\n",
      "    result = self.trial_executor.fetch_result(trial)\n",
      "  File \"/opt/favordata/anaconda3/envs/kaggle/lib/python3.7/site-packages/ray/tune/ray_trial_executor.py\", line 489, in fetch_result\n",
      "    result = ray.get(trial_future[0], timeout=DEFAULT_GET_TIMEOUT)\n",
      "  File \"/opt/favordata/anaconda3/envs/kaggle/lib/python3.7/site-packages/ray/worker.py\", line 1452, in get\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(TuneError): \u001b[36mray::ImplicitFunc.train()\u001b[39m (pid=6416, ip=10.0.0.200)\n",
      "  File \"python/ray/_raylet.pyx\", line 482, in ray._raylet.execute_task\n",
      "  File \"python/ray/_raylet.pyx\", line 436, in ray._raylet.execute_task.function_executor\n",
      "  File \"/opt/favordata/anaconda3/envs/kaggle/lib/python3.7/site-packages/ray/tune/trainable.py\", line 336, in train\n",
      "    result = self.step()\n",
      "  File \"/opt/favordata/anaconda3/envs/kaggle/lib/python3.7/site-packages/ray/tune/function_runner.py\", line 366, in step\n",
      "    self._report_thread_runner_error(block=True)\n",
      "  File \"/opt/favordata/anaconda3/envs/kaggle/lib/python3.7/site-packages/ray/tune/function_runner.py\", line 513, in _report_thread_runner_error\n",
      "    .format(err_tb_str)))\n",
      "ray.tune.error.TuneError: Trial raised an exception. Traceback:\n",
      "\u001b[36mray::ImplicitFunc.train()\u001b[39m (pid=6416, ip=10.0.0.200)\n",
      "  File \"/opt/favordata/anaconda3/envs/kaggle/lib/python3.7/site-packages/ray/tune/function_runner.py\", line 248, in run\n",
      "    self._entrypoint()\n",
      "  File \"/opt/favordata/anaconda3/envs/kaggle/lib/python3.7/site-packages/ray/tune/function_runner.py\", line 316, in entrypoint\n",
      "    self._status_reporter.get_checkpoint())\n",
      "  File \"/opt/favordata/anaconda3/envs/kaggle/lib/python3.7/site-packages/ray/tune/function_runner.py\", line 575, in _trainable_func\n",
      "    output = fn()\n",
      "  File \"<ipython-input-4-85c201a07a96>\", line 31, in train_main\n",
      "  File \"/opt/favordata/AI/Felix/kaggle-cassava/train_loop_functions.py\", line 60, in train_epoch\n",
      "    LOGGER.info(f'[TRAIN] batch {batch_idx+1}/{len(dataloader)} loss: {loss} | grad: {total_norm}')\n",
      "NameError: name 'LOGGER' is not defined\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Memory usage on this node: 6.9/31.3 GiB\n",
      "Using AsyncHyperBand: num_stopped=0\n",
      "Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: None\n",
      "Resources requested: 0/8 CPUs, 0/1 GPUs, 0.0/17.63 GiB heap, 0.0/6.05 GiB objects (0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /opt/favordata/ray_results/DEFAULT_2020-12-24_23-05-02\n",
      "Number of trials: 5/20 (4 ERROR, 1 PENDING)\n",
      "+---------------------+----------+-------+--------------+--------------+--------------+-------------+\n",
      "| Trial name          | status   | loc   |   accum_iter |   batch_size | is_amsgrad   |          lr |\n",
      "|---------------------+----------+-------+--------------+--------------+--------------+-------------|\n",
      "| DEFAULT_73dea_00004 | PENDING  |       |            1 |           16 | False        | 0.00277202  |\n",
      "| DEFAULT_73dea_00000 | ERROR    |       |            1 |           32 | False        | 0.0122859   |\n",
      "| DEFAULT_73dea_00001 | ERROR    |       |            4 |            8 | False        | 0.000479241 |\n",
      "| DEFAULT_73dea_00002 | ERROR    |       |            1 |            8 | True         | 0.0144015   |\n",
      "| DEFAULT_73dea_00003 | ERROR    |       |            2 |            4 | False        | 0.0875573   |\n",
      "+---------------------+----------+-------+--------------+--------------+--------------+-------------+\n",
      "Number of errored trials: 4\n",
      "+---------------------+--------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "| Trial name          |   # failures | error file                                                                                                                                                          |\n",
      "|---------------------+--------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n",
      "| DEFAULT_73dea_00000 |            1 | /opt/favordata/ray_results/DEFAULT_2020-12-24_23-05-02/DEFAULT_73dea_00000_0_accum_iter=1,batch_size=32,is_amsgrad=False,lr=0.012286_2020-12-24_23-05-02/error.txt  |\n",
      "| DEFAULT_73dea_00001 |            1 | /opt/favordata/ray_results/DEFAULT_2020-12-24_23-05-02/DEFAULT_73dea_00001_1_accum_iter=4,batch_size=8,is_amsgrad=False,lr=0.00047924_2020-12-24_23-05-06/error.txt |\n",
      "| DEFAULT_73dea_00002 |            1 | /opt/favordata/ray_results/DEFAULT_2020-12-24_23-05-02/DEFAULT_73dea_00002_2_accum_iter=1,batch_size=8,is_amsgrad=True,lr=0.014401_2020-12-24_23-05-14/error.txt    |\n",
      "| DEFAULT_73dea_00003 |            1 | /opt/favordata/ray_results/DEFAULT_2020-12-24_23-05-02/DEFAULT_73dea_00003_3_accum_iter=2,batch_size=4,is_amsgrad=False,lr=0.087557_2020-12-24_23-05-22/error.txt   |\n",
      "+---------------------+--------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=6408)\u001b[0m Epoch     0: adjusting learning rate of group 0 to 2.7720e-03.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=6408)\u001b[0m 2020-12-24 23:05:39,759\tERROR function_runner.py:254 -- Runner Thread raised error.\n",
      "\u001b[2m\u001b[36m(pid=6408)\u001b[0m Traceback (most recent call last):\n",
      "\u001b[2m\u001b[36m(pid=6408)\u001b[0m   File \"/opt/favordata/anaconda3/envs/kaggle/lib/python3.7/site-packages/ray/tune/function_runner.py\", line 248, in run\n",
      "\u001b[2m\u001b[36m(pid=6408)\u001b[0m     self._entrypoint()\n",
      "\u001b[2m\u001b[36m(pid=6408)\u001b[0m   File \"/opt/favordata/anaconda3/envs/kaggle/lib/python3.7/site-packages/ray/tune/function_runner.py\", line 316, in entrypoint\n",
      "\u001b[2m\u001b[36m(pid=6408)\u001b[0m     self._status_reporter.get_checkpoint())\n",
      "\u001b[2m\u001b[36m(pid=6408)\u001b[0m   File \"/opt/favordata/anaconda3/envs/kaggle/lib/python3.7/site-packages/ray/tune/function_runner.py\", line 575, in _trainable_func\n",
      "\u001b[2m\u001b[36m(pid=6408)\u001b[0m     output = fn()\n",
      "\u001b[2m\u001b[36m(pid=6408)\u001b[0m   File \"<ipython-input-4-85c201a07a96>\", line 31, in train_main\n",
      "\u001b[2m\u001b[36m(pid=6408)\u001b[0m   File \"/opt/favordata/AI/Felix/kaggle-cassava/train_loop_functions.py\", line 60, in train_epoch\n",
      "\u001b[2m\u001b[36m(pid=6408)\u001b[0m     LOGGER.info(f'[TRAIN] batch {batch_idx+1}/{len(dataloader)} loss: {loss} | grad: {total_norm}')\n",
      "\u001b[2m\u001b[36m(pid=6408)\u001b[0m NameError: name 'LOGGER' is not defined\n",
      "\u001b[2m\u001b[36m(pid=6408)\u001b[0m Exception in thread Thread-2:\n",
      "\u001b[2m\u001b[36m(pid=6408)\u001b[0m Traceback (most recent call last):\n",
      "\u001b[2m\u001b[36m(pid=6408)\u001b[0m   File \"/opt/favordata/anaconda3/envs/kaggle/lib/python3.7/threading.py\", line 926, in _bootstrap_inner\n",
      "\u001b[2m\u001b[36m(pid=6408)\u001b[0m     self.run()\n",
      "\u001b[2m\u001b[36m(pid=6408)\u001b[0m   File \"/opt/favordata/anaconda3/envs/kaggle/lib/python3.7/site-packages/ray/tune/function_runner.py\", line 267, in run\n",
      "\u001b[2m\u001b[36m(pid=6408)\u001b[0m     raise e\n",
      "\u001b[2m\u001b[36m(pid=6408)\u001b[0m   File \"/opt/favordata/anaconda3/envs/kaggle/lib/python3.7/site-packages/ray/tune/function_runner.py\", line 248, in run\n",
      "\u001b[2m\u001b[36m(pid=6408)\u001b[0m     self._entrypoint()\n",
      "\u001b[2m\u001b[36m(pid=6408)\u001b[0m   File \"/opt/favordata/anaconda3/envs/kaggle/lib/python3.7/site-packages/ray/tune/function_runner.py\", line 316, in entrypoint\n",
      "\u001b[2m\u001b[36m(pid=6408)\u001b[0m     self._status_reporter.get_checkpoint())\n",
      "\u001b[2m\u001b[36m(pid=6408)\u001b[0m   File \"/opt/favordata/anaconda3/envs/kaggle/lib/python3.7/site-packages/ray/tune/function_runner.py\", line 575, in _trainable_func\n",
      "\u001b[2m\u001b[36m(pid=6408)\u001b[0m     output = fn()\n",
      "\u001b[2m\u001b[36m(pid=6408)\u001b[0m   File \"<ipython-input-4-85c201a07a96>\", line 31, in train_main\n",
      "\u001b[2m\u001b[36m(pid=6408)\u001b[0m   File \"/opt/favordata/AI/Felix/kaggle-cassava/train_loop_functions.py\", line 60, in train_epoch\n",
      "\u001b[2m\u001b[36m(pid=6408)\u001b[0m     LOGGER.info(f'[TRAIN] batch {batch_idx+1}/{len(dataloader)} loss: {loss} | grad: {total_norm}')\n",
      "\u001b[2m\u001b[36m(pid=6408)\u001b[0m NameError: name 'LOGGER' is not defined\n",
      "\u001b[2m\u001b[36m(pid=6408)\u001b[0m \n",
      "2020-12-24 23:05:39,922\tERROR trial_runner.py:793 -- Trial DEFAULT_73dea_00004: Error processing event.\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/favordata/anaconda3/envs/kaggle/lib/python3.7/site-packages/ray/tune/trial_runner.py\", line 726, in _process_trial\n",
      "    result = self.trial_executor.fetch_result(trial)\n",
      "  File \"/opt/favordata/anaconda3/envs/kaggle/lib/python3.7/site-packages/ray/tune/ray_trial_executor.py\", line 489, in fetch_result\n",
      "    result = ray.get(trial_future[0], timeout=DEFAULT_GET_TIMEOUT)\n",
      "  File \"/opt/favordata/anaconda3/envs/kaggle/lib/python3.7/site-packages/ray/worker.py\", line 1452, in get\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(TuneError): \u001b[36mray::ImplicitFunc.train()\u001b[39m (pid=6408, ip=10.0.0.200)\n",
      "  File \"python/ray/_raylet.pyx\", line 482, in ray._raylet.execute_task\n",
      "  File \"python/ray/_raylet.pyx\", line 436, in ray._raylet.execute_task.function_executor\n",
      "  File \"/opt/favordata/anaconda3/envs/kaggle/lib/python3.7/site-packages/ray/tune/trainable.py\", line 336, in train\n",
      "    result = self.step()\n",
      "  File \"/opt/favordata/anaconda3/envs/kaggle/lib/python3.7/site-packages/ray/tune/function_runner.py\", line 366, in step\n",
      "    self._report_thread_runner_error(block=True)\n",
      "  File \"/opt/favordata/anaconda3/envs/kaggle/lib/python3.7/site-packages/ray/tune/function_runner.py\", line 513, in _report_thread_runner_error\n",
      "    .format(err_tb_str)))\n",
      "ray.tune.error.TuneError: Trial raised an exception. Traceback:\n",
      "\u001b[36mray::ImplicitFunc.train()\u001b[39m (pid=6408, ip=10.0.0.200)\n",
      "  File \"/opt/favordata/anaconda3/envs/kaggle/lib/python3.7/site-packages/ray/tune/function_runner.py\", line 248, in run\n",
      "    self._entrypoint()\n",
      "  File \"/opt/favordata/anaconda3/envs/kaggle/lib/python3.7/site-packages/ray/tune/function_runner.py\", line 316, in entrypoint\n",
      "    self._status_reporter.get_checkpoint())\n",
      "  File \"/opt/favordata/anaconda3/envs/kaggle/lib/python3.7/site-packages/ray/tune/function_runner.py\", line 575, in _trainable_func\n",
      "    output = fn()\n",
      "  File \"<ipython-input-4-85c201a07a96>\", line 31, in train_main\n",
      "  File \"/opt/favordata/AI/Felix/kaggle-cassava/train_loop_functions.py\", line 60, in train_epoch\n",
      "    LOGGER.info(f'[TRAIN] batch {batch_idx+1}/{len(dataloader)} loss: {loss} | grad: {total_norm}')\n",
      "NameError: name 'LOGGER' is not defined\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Memory usage on this node: 6.9/31.3 GiB\n",
      "Using AsyncHyperBand: num_stopped=0\n",
      "Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: None\n",
      "Resources requested: 0/8 CPUs, 0/1 GPUs, 0.0/17.63 GiB heap, 0.0/6.05 GiB objects (0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /opt/favordata/ray_results/DEFAULT_2020-12-24_23-05-02\n",
      "Number of trials: 6/20 (5 ERROR, 1 PENDING)\n",
      "+---------------------+----------+-------+--------------+--------------+--------------+-------------+\n",
      "| Trial name          | status   | loc   |   accum_iter |   batch_size | is_amsgrad   |          lr |\n",
      "|---------------------+----------+-------+--------------+--------------+--------------+-------------|\n",
      "| DEFAULT_73dea_00005 | PENDING  |       |            2 |            8 | False        | 0.00107037  |\n",
      "| DEFAULT_73dea_00000 | ERROR    |       |            1 |           32 | False        | 0.0122859   |\n",
      "| DEFAULT_73dea_00001 | ERROR    |       |            4 |            8 | False        | 0.000479241 |\n",
      "| DEFAULT_73dea_00002 | ERROR    |       |            1 |            8 | True         | 0.0144015   |\n",
      "| DEFAULT_73dea_00003 | ERROR    |       |            2 |            4 | False        | 0.0875573   |\n",
      "| DEFAULT_73dea_00004 | ERROR    |       |            1 |           16 | False        | 0.00277202  |\n",
      "+---------------------+----------+-------+--------------+--------------+--------------+-------------+\n",
      "Number of errored trials: 5\n",
      "+---------------------+--------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "| Trial name          |   # failures | error file                                                                                                                                                          |\n",
      "|---------------------+--------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n",
      "| DEFAULT_73dea_00000 |            1 | /opt/favordata/ray_results/DEFAULT_2020-12-24_23-05-02/DEFAULT_73dea_00000_0_accum_iter=1,batch_size=32,is_amsgrad=False,lr=0.012286_2020-12-24_23-05-02/error.txt  |\n",
      "| DEFAULT_73dea_00001 |            1 | /opt/favordata/ray_results/DEFAULT_2020-12-24_23-05-02/DEFAULT_73dea_00001_1_accum_iter=4,batch_size=8,is_amsgrad=False,lr=0.00047924_2020-12-24_23-05-06/error.txt |\n",
      "| DEFAULT_73dea_00002 |            1 | /opt/favordata/ray_results/DEFAULT_2020-12-24_23-05-02/DEFAULT_73dea_00002_2_accum_iter=1,batch_size=8,is_amsgrad=True,lr=0.014401_2020-12-24_23-05-14/error.txt    |\n",
      "| DEFAULT_73dea_00003 |            1 | /opt/favordata/ray_results/DEFAULT_2020-12-24_23-05-02/DEFAULT_73dea_00003_3_accum_iter=2,batch_size=4,is_amsgrad=False,lr=0.087557_2020-12-24_23-05-22/error.txt   |\n",
      "| DEFAULT_73dea_00004 |            1 | /opt/favordata/ray_results/DEFAULT_2020-12-24_23-05-02/DEFAULT_73dea_00004_4_accum_iter=1,batch_size=16,is_amsgrad=False,lr=0.002772_2020-12-24_23-05-31/error.txt  |\n",
      "+---------------------+--------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=6409)\u001b[0m Epoch     0: adjusting learning rate of group 0 to 1.0704e-03.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=6409)\u001b[0m 2020-12-24 23:05:47,775\tERROR function_runner.py:254 -- Runner Thread raised error.\n",
      "\u001b[2m\u001b[36m(pid=6409)\u001b[0m Traceback (most recent call last):\n",
      "\u001b[2m\u001b[36m(pid=6409)\u001b[0m   File \"/opt/favordata/anaconda3/envs/kaggle/lib/python3.7/site-packages/ray/tune/function_runner.py\", line 248, in run\n",
      "\u001b[2m\u001b[36m(pid=6409)\u001b[0m     self._entrypoint()\n",
      "\u001b[2m\u001b[36m(pid=6409)\u001b[0m   File \"/opt/favordata/anaconda3/envs/kaggle/lib/python3.7/site-packages/ray/tune/function_runner.py\", line 316, in entrypoint\n",
      "\u001b[2m\u001b[36m(pid=6409)\u001b[0m     self._status_reporter.get_checkpoint())\n",
      "\u001b[2m\u001b[36m(pid=6409)\u001b[0m   File \"/opt/favordata/anaconda3/envs/kaggle/lib/python3.7/site-packages/ray/tune/function_runner.py\", line 575, in _trainable_func\n",
      "\u001b[2m\u001b[36m(pid=6409)\u001b[0m     output = fn()\n",
      "\u001b[2m\u001b[36m(pid=6409)\u001b[0m   File \"<ipython-input-4-85c201a07a96>\", line 31, in train_main\n",
      "\u001b[2m\u001b[36m(pid=6409)\u001b[0m   File \"/opt/favordata/AI/Felix/kaggle-cassava/train_loop_functions.py\", line 60, in train_epoch\n",
      "\u001b[2m\u001b[36m(pid=6409)\u001b[0m     LOGGER.info(f'[TRAIN] batch {batch_idx+1}/{len(dataloader)} loss: {loss} | grad: {total_norm}')\n",
      "\u001b[2m\u001b[36m(pid=6409)\u001b[0m NameError: name 'LOGGER' is not defined\n",
      "\u001b[2m\u001b[36m(pid=6409)\u001b[0m Exception in thread Thread-2:\n",
      "\u001b[2m\u001b[36m(pid=6409)\u001b[0m Traceback (most recent call last):\n",
      "\u001b[2m\u001b[36m(pid=6409)\u001b[0m   File \"/opt/favordata/anaconda3/envs/kaggle/lib/python3.7/threading.py\", line 926, in _bootstrap_inner\n",
      "\u001b[2m\u001b[36m(pid=6409)\u001b[0m     self.run()\n",
      "\u001b[2m\u001b[36m(pid=6409)\u001b[0m   File \"/opt/favordata/anaconda3/envs/kaggle/lib/python3.7/site-packages/ray/tune/function_runner.py\", line 267, in run\n",
      "\u001b[2m\u001b[36m(pid=6409)\u001b[0m     raise e\n",
      "\u001b[2m\u001b[36m(pid=6409)\u001b[0m   File \"/opt/favordata/anaconda3/envs/kaggle/lib/python3.7/site-packages/ray/tune/function_runner.py\", line 248, in run\n",
      "\u001b[2m\u001b[36m(pid=6409)\u001b[0m     self._entrypoint()\n",
      "\u001b[2m\u001b[36m(pid=6409)\u001b[0m   File \"/opt/favordata/anaconda3/envs/kaggle/lib/python3.7/site-packages/ray/tune/function_runner.py\", line 316, in entrypoint\n",
      "\u001b[2m\u001b[36m(pid=6409)\u001b[0m     self._status_reporter.get_checkpoint())\n",
      "\u001b[2m\u001b[36m(pid=6409)\u001b[0m   File \"/opt/favordata/anaconda3/envs/kaggle/lib/python3.7/site-packages/ray/tune/function_runner.py\", line 575, in _trainable_func\n",
      "\u001b[2m\u001b[36m(pid=6409)\u001b[0m     output = fn()\n",
      "\u001b[2m\u001b[36m(pid=6409)\u001b[0m   File \"<ipython-input-4-85c201a07a96>\", line 31, in train_main\n",
      "\u001b[2m\u001b[36m(pid=6409)\u001b[0m   File \"/opt/favordata/AI/Felix/kaggle-cassava/train_loop_functions.py\", line 60, in train_epoch\n",
      "\u001b[2m\u001b[36m(pid=6409)\u001b[0m     LOGGER.info(f'[TRAIN] batch {batch_idx+1}/{len(dataloader)} loss: {loss} | grad: {total_norm}')\n",
      "\u001b[2m\u001b[36m(pid=6409)\u001b[0m NameError: name 'LOGGER' is not defined\n",
      "\u001b[2m\u001b[36m(pid=6409)\u001b[0m \n",
      "2020-12-24 23:05:47,914\tERROR trial_runner.py:793 -- Trial DEFAULT_73dea_00005: Error processing event.\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/favordata/anaconda3/envs/kaggle/lib/python3.7/site-packages/ray/tune/trial_runner.py\", line 726, in _process_trial\n",
      "    result = self.trial_executor.fetch_result(trial)\n",
      "  File \"/opt/favordata/anaconda3/envs/kaggle/lib/python3.7/site-packages/ray/tune/ray_trial_executor.py\", line 489, in fetch_result\n",
      "    result = ray.get(trial_future[0], timeout=DEFAULT_GET_TIMEOUT)\n",
      "  File \"/opt/favordata/anaconda3/envs/kaggle/lib/python3.7/site-packages/ray/worker.py\", line 1452, in get\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(TuneError): \u001b[36mray::ImplicitFunc.train()\u001b[39m (pid=6409, ip=10.0.0.200)\n",
      "  File \"python/ray/_raylet.pyx\", line 482, in ray._raylet.execute_task\n",
      "  File \"python/ray/_raylet.pyx\", line 436, in ray._raylet.execute_task.function_executor\n",
      "  File \"/opt/favordata/anaconda3/envs/kaggle/lib/python3.7/site-packages/ray/tune/trainable.py\", line 336, in train\n",
      "    result = self.step()\n",
      "  File \"/opt/favordata/anaconda3/envs/kaggle/lib/python3.7/site-packages/ray/tune/function_runner.py\", line 366, in step\n",
      "    self._report_thread_runner_error(block=True)\n",
      "  File \"/opt/favordata/anaconda3/envs/kaggle/lib/python3.7/site-packages/ray/tune/function_runner.py\", line 513, in _report_thread_runner_error\n",
      "    .format(err_tb_str)))\n",
      "ray.tune.error.TuneError: Trial raised an exception. Traceback:\n",
      "\u001b[36mray::ImplicitFunc.train()\u001b[39m (pid=6409, ip=10.0.0.200)\n",
      "  File \"/opt/favordata/anaconda3/envs/kaggle/lib/python3.7/site-packages/ray/tune/function_runner.py\", line 248, in run\n",
      "    self._entrypoint()\n",
      "  File \"/opt/favordata/anaconda3/envs/kaggle/lib/python3.7/site-packages/ray/tune/function_runner.py\", line 316, in entrypoint\n",
      "    self._status_reporter.get_checkpoint())\n",
      "  File \"/opt/favordata/anaconda3/envs/kaggle/lib/python3.7/site-packages/ray/tune/function_runner.py\", line 575, in _trainable_func\n",
      "    output = fn()\n",
      "  File \"<ipython-input-4-85c201a07a96>\", line 31, in train_main\n",
      "  File \"/opt/favordata/AI/Felix/kaggle-cassava/train_loop_functions.py\", line 60, in train_epoch\n",
      "    LOGGER.info(f'[TRAIN] batch {batch_idx+1}/{len(dataloader)} loss: {loss} | grad: {total_norm}')\n",
      "NameError: name 'LOGGER' is not defined\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Memory usage on this node: 6.9/31.3 GiB\n",
      "Using AsyncHyperBand: num_stopped=0\n",
      "Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: None\n",
      "Resources requested: 0/8 CPUs, 0/1 GPUs, 0.0/17.63 GiB heap, 0.0/6.05 GiB objects (0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /opt/favordata/ray_results/DEFAULT_2020-12-24_23-05-02\n",
      "Number of trials: 7/20 (6 ERROR, 1 PENDING)\n",
      "+---------------------+----------+-------+--------------+--------------+--------------+-------------+\n",
      "| Trial name          | status   | loc   |   accum_iter |   batch_size | is_amsgrad   |          lr |\n",
      "|---------------------+----------+-------+--------------+--------------+--------------+-------------|\n",
      "| DEFAULT_73dea_00006 | PENDING  |       |            1 |            4 | True         | 0.00206879  |\n",
      "| DEFAULT_73dea_00000 | ERROR    |       |            1 |           32 | False        | 0.0122859   |\n",
      "| DEFAULT_73dea_00001 | ERROR    |       |            4 |            8 | False        | 0.000479241 |\n",
      "| DEFAULT_73dea_00002 | ERROR    |       |            1 |            8 | True         | 0.0144015   |\n",
      "| DEFAULT_73dea_00003 | ERROR    |       |            2 |            4 | False        | 0.0875573   |\n",
      "| DEFAULT_73dea_00004 | ERROR    |       |            1 |           16 | False        | 0.00277202  |\n",
      "| DEFAULT_73dea_00005 | ERROR    |       |            2 |            8 | False        | 0.00107037  |\n",
      "+---------------------+----------+-------+--------------+--------------+--------------+-------------+\n",
      "Number of errored trials: 6\n",
      "+---------------------+--------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "| Trial name          |   # failures | error file                                                                                                                                                          |\n",
      "|---------------------+--------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n",
      "| DEFAULT_73dea_00000 |            1 | /opt/favordata/ray_results/DEFAULT_2020-12-24_23-05-02/DEFAULT_73dea_00000_0_accum_iter=1,batch_size=32,is_amsgrad=False,lr=0.012286_2020-12-24_23-05-02/error.txt  |\n",
      "| DEFAULT_73dea_00001 |            1 | /opt/favordata/ray_results/DEFAULT_2020-12-24_23-05-02/DEFAULT_73dea_00001_1_accum_iter=4,batch_size=8,is_amsgrad=False,lr=0.00047924_2020-12-24_23-05-06/error.txt |\n",
      "| DEFAULT_73dea_00002 |            1 | /opt/favordata/ray_results/DEFAULT_2020-12-24_23-05-02/DEFAULT_73dea_00002_2_accum_iter=1,batch_size=8,is_amsgrad=True,lr=0.014401_2020-12-24_23-05-14/error.txt    |\n",
      "| DEFAULT_73dea_00003 |            1 | /opt/favordata/ray_results/DEFAULT_2020-12-24_23-05-02/DEFAULT_73dea_00003_3_accum_iter=2,batch_size=4,is_amsgrad=False,lr=0.087557_2020-12-24_23-05-22/error.txt   |\n",
      "| DEFAULT_73dea_00004 |            1 | /opt/favordata/ray_results/DEFAULT_2020-12-24_23-05-02/DEFAULT_73dea_00004_4_accum_iter=1,batch_size=16,is_amsgrad=False,lr=0.002772_2020-12-24_23-05-31/error.txt  |\n",
      "| DEFAULT_73dea_00005 |            1 | /opt/favordata/ray_results/DEFAULT_2020-12-24_23-05-02/DEFAULT_73dea_00005_5_accum_iter=2,batch_size=8,is_amsgrad=False,lr=0.0010704_2020-12-24_23-05-39/error.txt  |\n",
      "+---------------------+--------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=6407)\u001b[0m Epoch     0: adjusting learning rate of group 0 to 2.0688e-03.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=6407)\u001b[0m 2020-12-24 23:05:56,717\tERROR function_runner.py:254 -- Runner Thread raised error.\n",
      "\u001b[2m\u001b[36m(pid=6407)\u001b[0m Traceback (most recent call last):\n",
      "\u001b[2m\u001b[36m(pid=6407)\u001b[0m   File \"/opt/favordata/anaconda3/envs/kaggle/lib/python3.7/site-packages/ray/tune/function_runner.py\", line 248, in run\n",
      "\u001b[2m\u001b[36m(pid=6407)\u001b[0m     self._entrypoint()\n",
      "\u001b[2m\u001b[36m(pid=6407)\u001b[0m   File \"/opt/favordata/anaconda3/envs/kaggle/lib/python3.7/site-packages/ray/tune/function_runner.py\", line 316, in entrypoint\n",
      "\u001b[2m\u001b[36m(pid=6407)\u001b[0m     self._status_reporter.get_checkpoint())\n",
      "\u001b[2m\u001b[36m(pid=6407)\u001b[0m   File \"/opt/favordata/anaconda3/envs/kaggle/lib/python3.7/site-packages/ray/tune/function_runner.py\", line 575, in _trainable_func\n",
      "\u001b[2m\u001b[36m(pid=6407)\u001b[0m     output = fn()\n",
      "\u001b[2m\u001b[36m(pid=6407)\u001b[0m   File \"<ipython-input-4-85c201a07a96>\", line 31, in train_main\n",
      "\u001b[2m\u001b[36m(pid=6407)\u001b[0m   File \"/opt/favordata/AI/Felix/kaggle-cassava/train_loop_functions.py\", line 60, in train_epoch\n",
      "\u001b[2m\u001b[36m(pid=6407)\u001b[0m     LOGGER.info(f'[TRAIN] batch {batch_idx+1}/{len(dataloader)} loss: {loss} | grad: {total_norm}')\n",
      "\u001b[2m\u001b[36m(pid=6407)\u001b[0m NameError: name 'LOGGER' is not defined\n",
      "\u001b[2m\u001b[36m(pid=6407)\u001b[0m Exception in thread Thread-2:\n",
      "\u001b[2m\u001b[36m(pid=6407)\u001b[0m Traceback (most recent call last):\n",
      "\u001b[2m\u001b[36m(pid=6407)\u001b[0m   File \"/opt/favordata/anaconda3/envs/kaggle/lib/python3.7/threading.py\", line 926, in _bootstrap_inner\n",
      "\u001b[2m\u001b[36m(pid=6407)\u001b[0m     self.run()\n",
      "\u001b[2m\u001b[36m(pid=6407)\u001b[0m   File \"/opt/favordata/anaconda3/envs/kaggle/lib/python3.7/site-packages/ray/tune/function_runner.py\", line 267, in run\n",
      "\u001b[2m\u001b[36m(pid=6407)\u001b[0m     raise e\n",
      "\u001b[2m\u001b[36m(pid=6407)\u001b[0m   File \"/opt/favordata/anaconda3/envs/kaggle/lib/python3.7/site-packages/ray/tune/function_runner.py\", line 248, in run\n",
      "\u001b[2m\u001b[36m(pid=6407)\u001b[0m     self._entrypoint()\n",
      "\u001b[2m\u001b[36m(pid=6407)\u001b[0m   File \"/opt/favordata/anaconda3/envs/kaggle/lib/python3.7/site-packages/ray/tune/function_runner.py\", line 316, in entrypoint\n",
      "\u001b[2m\u001b[36m(pid=6407)\u001b[0m     self._status_reporter.get_checkpoint())\n",
      "\u001b[2m\u001b[36m(pid=6407)\u001b[0m   File \"/opt/favordata/anaconda3/envs/kaggle/lib/python3.7/site-packages/ray/tune/function_runner.py\", line 575, in _trainable_func\n",
      "\u001b[2m\u001b[36m(pid=6407)\u001b[0m     output = fn()\n",
      "\u001b[2m\u001b[36m(pid=6407)\u001b[0m   File \"<ipython-input-4-85c201a07a96>\", line 31, in train_main\n",
      "\u001b[2m\u001b[36m(pid=6407)\u001b[0m   File \"/opt/favordata/AI/Felix/kaggle-cassava/train_loop_functions.py\", line 60, in train_epoch\n",
      "\u001b[2m\u001b[36m(pid=6407)\u001b[0m     LOGGER.info(f'[TRAIN] batch {batch_idx+1}/{len(dataloader)} loss: {loss} | grad: {total_norm}')\n",
      "\u001b[2m\u001b[36m(pid=6407)\u001b[0m NameError: name 'LOGGER' is not defined\n",
      "\u001b[2m\u001b[36m(pid=6407)\u001b[0m \n",
      "2020-12-24 23:05:56,889\tERROR trial_runner.py:793 -- Trial DEFAULT_73dea_00006: Error processing event.\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/favordata/anaconda3/envs/kaggle/lib/python3.7/site-packages/ray/tune/trial_runner.py\", line 726, in _process_trial\n",
      "    result = self.trial_executor.fetch_result(trial)\n",
      "  File \"/opt/favordata/anaconda3/envs/kaggle/lib/python3.7/site-packages/ray/tune/ray_trial_executor.py\", line 489, in fetch_result\n",
      "    result = ray.get(trial_future[0], timeout=DEFAULT_GET_TIMEOUT)\n",
      "  File \"/opt/favordata/anaconda3/envs/kaggle/lib/python3.7/site-packages/ray/worker.py\", line 1452, in get\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(TuneError): \u001b[36mray::ImplicitFunc.train()\u001b[39m (pid=6407, ip=10.0.0.200)\n",
      "  File \"python/ray/_raylet.pyx\", line 482, in ray._raylet.execute_task\n",
      "  File \"python/ray/_raylet.pyx\", line 436, in ray._raylet.execute_task.function_executor\n",
      "  File \"/opt/favordata/anaconda3/envs/kaggle/lib/python3.7/site-packages/ray/tune/trainable.py\", line 336, in train\n",
      "    result = self.step()\n",
      "  File \"/opt/favordata/anaconda3/envs/kaggle/lib/python3.7/site-packages/ray/tune/function_runner.py\", line 366, in step\n",
      "    self._report_thread_runner_error(block=True)\n",
      "  File \"/opt/favordata/anaconda3/envs/kaggle/lib/python3.7/site-packages/ray/tune/function_runner.py\", line 513, in _report_thread_runner_error\n",
      "    .format(err_tb_str)))\n",
      "ray.tune.error.TuneError: Trial raised an exception. Traceback:\n",
      "\u001b[36mray::ImplicitFunc.train()\u001b[39m (pid=6407, ip=10.0.0.200)\n",
      "  File \"/opt/favordata/anaconda3/envs/kaggle/lib/python3.7/site-packages/ray/tune/function_runner.py\", line 248, in run\n",
      "    self._entrypoint()\n",
      "  File \"/opt/favordata/anaconda3/envs/kaggle/lib/python3.7/site-packages/ray/tune/function_runner.py\", line 316, in entrypoint\n",
      "    self._status_reporter.get_checkpoint())\n",
      "  File \"/opt/favordata/anaconda3/envs/kaggle/lib/python3.7/site-packages/ray/tune/function_runner.py\", line 575, in _trainable_func\n",
      "    output = fn()\n",
      "  File \"<ipython-input-4-85c201a07a96>\", line 31, in train_main\n",
      "  File \"/opt/favordata/AI/Felix/kaggle-cassava/train_loop_functions.py\", line 60, in train_epoch\n",
      "    LOGGER.info(f'[TRAIN] batch {batch_idx+1}/{len(dataloader)} loss: {loss} | grad: {total_norm}')\n",
      "NameError: name 'LOGGER' is not defined\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Memory usage on this node: 6.8/31.3 GiB\n",
      "Using AsyncHyperBand: num_stopped=0\n",
      "Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: None\n",
      "Resources requested: 0/8 CPUs, 0/1 GPUs, 0.0/17.63 GiB heap, 0.0/6.05 GiB objects (0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /opt/favordata/ray_results/DEFAULT_2020-12-24_23-05-02\n",
      "Number of trials: 8/20 (7 ERROR, 1 PENDING)\n",
      "+---------------------+----------+-------+--------------+--------------+--------------+-------------+\n",
      "| Trial name          | status   | loc   |   accum_iter |   batch_size | is_amsgrad   |          lr |\n",
      "|---------------------+----------+-------+--------------+--------------+--------------+-------------|\n",
      "| DEFAULT_73dea_00007 | PENDING  |       |            1 |           32 | True         | 0.00156363  |\n",
      "| DEFAULT_73dea_00000 | ERROR    |       |            1 |           32 | False        | 0.0122859   |\n",
      "| DEFAULT_73dea_00001 | ERROR    |       |            4 |            8 | False        | 0.000479241 |\n",
      "| DEFAULT_73dea_00002 | ERROR    |       |            1 |            8 | True         | 0.0144015   |\n",
      "| DEFAULT_73dea_00003 | ERROR    |       |            2 |            4 | False        | 0.0875573   |\n",
      "| DEFAULT_73dea_00004 | ERROR    |       |            1 |           16 | False        | 0.00277202  |\n",
      "| DEFAULT_73dea_00005 | ERROR    |       |            2 |            8 | False        | 0.00107037  |\n",
      "| DEFAULT_73dea_00006 | ERROR    |       |            1 |            4 | True         | 0.00206879  |\n",
      "+---------------------+----------+-------+--------------+--------------+--------------+-------------+\n",
      "Number of errored trials: 7\n",
      "+---------------------+--------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "| Trial name          |   # failures | error file                                                                                                                                                          |\n",
      "|---------------------+--------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n",
      "| DEFAULT_73dea_00000 |            1 | /opt/favordata/ray_results/DEFAULT_2020-12-24_23-05-02/DEFAULT_73dea_00000_0_accum_iter=1,batch_size=32,is_amsgrad=False,lr=0.012286_2020-12-24_23-05-02/error.txt  |\n",
      "| DEFAULT_73dea_00001 |            1 | /opt/favordata/ray_results/DEFAULT_2020-12-24_23-05-02/DEFAULT_73dea_00001_1_accum_iter=4,batch_size=8,is_amsgrad=False,lr=0.00047924_2020-12-24_23-05-06/error.txt |\n",
      "| DEFAULT_73dea_00002 |            1 | /opt/favordata/ray_results/DEFAULT_2020-12-24_23-05-02/DEFAULT_73dea_00002_2_accum_iter=1,batch_size=8,is_amsgrad=True,lr=0.014401_2020-12-24_23-05-14/error.txt    |\n",
      "| DEFAULT_73dea_00003 |            1 | /opt/favordata/ray_results/DEFAULT_2020-12-24_23-05-02/DEFAULT_73dea_00003_3_accum_iter=2,batch_size=4,is_amsgrad=False,lr=0.087557_2020-12-24_23-05-22/error.txt   |\n",
      "| DEFAULT_73dea_00004 |            1 | /opt/favordata/ray_results/DEFAULT_2020-12-24_23-05-02/DEFAULT_73dea_00004_4_accum_iter=1,batch_size=16,is_amsgrad=False,lr=0.002772_2020-12-24_23-05-31/error.txt  |\n",
      "| DEFAULT_73dea_00005 |            1 | /opt/favordata/ray_results/DEFAULT_2020-12-24_23-05-02/DEFAULT_73dea_00005_5_accum_iter=2,batch_size=8,is_amsgrad=False,lr=0.0010704_2020-12-24_23-05-39/error.txt  |\n",
      "| DEFAULT_73dea_00006 |            1 | /opt/favordata/ray_results/DEFAULT_2020-12-24_23-05-02/DEFAULT_73dea_00006_6_accum_iter=1,batch_size=4,is_amsgrad=True,lr=0.0020688_2020-12-24_23-05-47/error.txt   |\n",
      "+---------------------+--------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=6405)\u001b[0m Epoch     0: adjusting learning rate of group 0 to 1.5636e-03.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=6405)\u001b[0m 2020-12-24 23:06:00,929\tERROR function_runner.py:254 -- Runner Thread raised error.\n",
      "\u001b[2m\u001b[36m(pid=6405)\u001b[0m Traceback (most recent call last):\n",
      "\u001b[2m\u001b[36m(pid=6405)\u001b[0m   File \"/opt/favordata/anaconda3/envs/kaggle/lib/python3.7/site-packages/ray/tune/function_runner.py\", line 248, in run\n",
      "\u001b[2m\u001b[36m(pid=6405)\u001b[0m     self._entrypoint()\n",
      "\u001b[2m\u001b[36m(pid=6405)\u001b[0m   File \"/opt/favordata/anaconda3/envs/kaggle/lib/python3.7/site-packages/ray/tune/function_runner.py\", line 316, in entrypoint\n",
      "\u001b[2m\u001b[36m(pid=6405)\u001b[0m     self._status_reporter.get_checkpoint())\n",
      "\u001b[2m\u001b[36m(pid=6405)\u001b[0m   File \"/opt/favordata/anaconda3/envs/kaggle/lib/python3.7/site-packages/ray/tune/function_runner.py\", line 575, in _trainable_func\n",
      "\u001b[2m\u001b[36m(pid=6405)\u001b[0m     output = fn()\n",
      "\u001b[2m\u001b[36m(pid=6405)\u001b[0m   File \"<ipython-input-4-85c201a07a96>\", line 31, in train_main\n",
      "\u001b[2m\u001b[36m(pid=6405)\u001b[0m   File \"/opt/favordata/AI/Felix/kaggle-cassava/train_loop_functions.py\", line 21, in train_epoch\n",
      "\u001b[2m\u001b[36m(pid=6405)\u001b[0m     predictions = model(images)\n",
      "\u001b[2m\u001b[36m(pid=6405)\u001b[0m   File \"/opt/favordata/anaconda3/envs/kaggle/lib/python3.7/site-packages/torch/nn/modules/module.py\", line 727, in _call_impl\n",
      "\u001b[2m\u001b[36m(pid=6405)\u001b[0m     result = self.forward(*input, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=6405)\u001b[0m   File \"/opt/favordata/AI/Felix/kaggle-cassava/model.py\", line 17, in forward\n",
      "\u001b[2m\u001b[36m(pid=6405)\u001b[0m     return self.model(x)\n",
      "\u001b[2m\u001b[36m(pid=6405)\u001b[0m   File \"/opt/favordata/anaconda3/envs/kaggle/lib/python3.7/site-packages/torch/nn/modules/module.py\", line 727, in _call_impl\n",
      "\u001b[2m\u001b[36m(pid=6405)\u001b[0m     result = self.forward(*input, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=6405)\u001b[0m   File \"../pytorch-image-models/timm/models/efficientnet.py\", line 391, in forward\n",
      "\u001b[2m\u001b[36m(pid=6405)\u001b[0m     x = self.forward_features(x)\n",
      "\u001b[2m\u001b[36m(pid=6405)\u001b[0m   File \"../pytorch-image-models/timm/models/efficientnet.py\", line 384, in forward_features\n",
      "\u001b[2m\u001b[36m(pid=6405)\u001b[0m     x = self.blocks(x)\n",
      "\u001b[2m\u001b[36m(pid=6405)\u001b[0m   File \"/opt/favordata/anaconda3/envs/kaggle/lib/python3.7/site-packages/torch/nn/modules/module.py\", line 727, in _call_impl\n",
      "\u001b[2m\u001b[36m(pid=6405)\u001b[0m     result = self.forward(*input, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=6405)\u001b[0m   File \"/opt/favordata/anaconda3/envs/kaggle/lib/python3.7/site-packages/torch/nn/modules/container.py\", line 117, in forward\n",
      "\u001b[2m\u001b[36m(pid=6405)\u001b[0m     input = module(input)\n",
      "\u001b[2m\u001b[36m(pid=6405)\u001b[0m   File \"/opt/favordata/anaconda3/envs/kaggle/lib/python3.7/site-packages/torch/nn/modules/module.py\", line 727, in _call_impl\n",
      "\u001b[2m\u001b[36m(pid=6405)\u001b[0m     result = self.forward(*input, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=6405)\u001b[0m   File \"/opt/favordata/anaconda3/envs/kaggle/lib/python3.7/site-packages/torch/nn/modules/container.py\", line 117, in forward\n",
      "\u001b[2m\u001b[36m(pid=6405)\u001b[0m     input = module(input)\n",
      "\u001b[2m\u001b[36m(pid=6405)\u001b[0m   File \"/opt/favordata/anaconda3/envs/kaggle/lib/python3.7/site-packages/torch/nn/modules/module.py\", line 727, in _call_impl\n",
      "\u001b[2m\u001b[36m(pid=6405)\u001b[0m     result = self.forward(*input, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=6405)\u001b[0m   File \"../pytorch-image-models/timm/models/efficientnet_blocks.py\", line 259, in forward\n",
      "\u001b[2m\u001b[36m(pid=6405)\u001b[0m     x = self.act1(x)\n",
      "\u001b[2m\u001b[36m(pid=6405)\u001b[0m   File \"/opt/favordata/anaconda3/envs/kaggle/lib/python3.7/site-packages/torch/nn/modules/module.py\", line 727, in _call_impl\n",
      "\u001b[2m\u001b[36m(pid=6405)\u001b[0m     result = self.forward(*input, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=6405)\u001b[0m   File \"/opt/favordata/anaconda3/envs/kaggle/lib/python3.7/site-packages/torch/nn/modules/activation.py\", line 394, in forward\n",
      "\u001b[2m\u001b[36m(pid=6405)\u001b[0m     return F.silu(input, inplace=self.inplace)\n",
      "\u001b[2m\u001b[36m(pid=6405)\u001b[0m   File \"/opt/favordata/anaconda3/envs/kaggle/lib/python3.7/site-packages/torch/nn/functional.py\", line 1740, in silu\n",
      "\u001b[2m\u001b[36m(pid=6405)\u001b[0m     return torch._C._nn.silu_(input)\n",
      "\u001b[2m\u001b[36m(pid=6405)\u001b[0m RuntimeError: CUDA out of memory. Tried to allocate 84.00 MiB (GPU 0; 10.76 GiB total capacity; 9.66 GiB already allocated; 39.44 MiB free; 9.84 GiB reserved in total by PyTorch)\n",
      "\u001b[2m\u001b[36m(pid=6405)\u001b[0m Exception in thread Thread-2:\n",
      "\u001b[2m\u001b[36m(pid=6405)\u001b[0m Traceback (most recent call last):\n",
      "\u001b[2m\u001b[36m(pid=6405)\u001b[0m   File \"/opt/favordata/anaconda3/envs/kaggle/lib/python3.7/threading.py\", line 926, in _bootstrap_inner\n",
      "\u001b[2m\u001b[36m(pid=6405)\u001b[0m     self.run()\n",
      "\u001b[2m\u001b[36m(pid=6405)\u001b[0m   File \"/opt/favordata/anaconda3/envs/kaggle/lib/python3.7/site-packages/ray/tune/function_runner.py\", line 267, in run\n",
      "\u001b[2m\u001b[36m(pid=6405)\u001b[0m     raise e\n",
      "\u001b[2m\u001b[36m(pid=6405)\u001b[0m   File \"/opt/favordata/anaconda3/envs/kaggle/lib/python3.7/site-packages/ray/tune/function_runner.py\", line 248, in run\n",
      "\u001b[2m\u001b[36m(pid=6405)\u001b[0m     self._entrypoint()\n",
      "\u001b[2m\u001b[36m(pid=6405)\u001b[0m   File \"/opt/favordata/anaconda3/envs/kaggle/lib/python3.7/site-packages/ray/tune/function_runner.py\", line 316, in entrypoint\n",
      "\u001b[2m\u001b[36m(pid=6405)\u001b[0m     self._status_reporter.get_checkpoint())\n",
      "\u001b[2m\u001b[36m(pid=6405)\u001b[0m   File \"/opt/favordata/anaconda3/envs/kaggle/lib/python3.7/site-packages/ray/tune/function_runner.py\", line 575, in _trainable_func\n",
      "\u001b[2m\u001b[36m(pid=6405)\u001b[0m     output = fn()\n",
      "\u001b[2m\u001b[36m(pid=6405)\u001b[0m   File \"<ipython-input-4-85c201a07a96>\", line 31, in train_main\n",
      "\u001b[2m\u001b[36m(pid=6405)\u001b[0m   File \"/opt/favordata/AI/Felix/kaggle-cassava/train_loop_functions.py\", line 21, in train_epoch\n",
      "\u001b[2m\u001b[36m(pid=6405)\u001b[0m     predictions = model(images)\n",
      "\u001b[2m\u001b[36m(pid=6405)\u001b[0m   File \"/opt/favordata/anaconda3/envs/kaggle/lib/python3.7/site-packages/torch/nn/modules/module.py\", line 727, in _call_impl\n",
      "\u001b[2m\u001b[36m(pid=6405)\u001b[0m     result = self.forward(*input, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=6405)\u001b[0m   File \"/opt/favordata/AI/Felix/kaggle-cassava/model.py\", line 17, in forward\n",
      "\u001b[2m\u001b[36m(pid=6405)\u001b[0m     return self.model(x)\n",
      "\u001b[2m\u001b[36m(pid=6405)\u001b[0m   File \"/opt/favordata/anaconda3/envs/kaggle/lib/python3.7/site-packages/torch/nn/modules/module.py\", line 727, in _call_impl\n",
      "\u001b[2m\u001b[36m(pid=6405)\u001b[0m     result = self.forward(*input, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=6405)\u001b[0m   File \"../pytorch-image-models/timm/models/efficientnet.py\", line 391, in forward\n",
      "\u001b[2m\u001b[36m(pid=6405)\u001b[0m     x = self.forward_features(x)\n",
      "\u001b[2m\u001b[36m(pid=6405)\u001b[0m   File \"../pytorch-image-models/timm/models/efficientnet.py\", line 384, in forward_features\n",
      "\u001b[2m\u001b[36m(pid=6405)\u001b[0m     x = self.blocks(x)\n",
      "\u001b[2m\u001b[36m(pid=6405)\u001b[0m   File \"/opt/favordata/anaconda3/envs/kaggle/lib/python3.7/site-packages/torch/nn/modules/module.py\", line 727, in _call_impl\n",
      "\u001b[2m\u001b[36m(pid=6405)\u001b[0m     result = self.forward(*input, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=6405)\u001b[0m   File \"/opt/favordata/anaconda3/envs/kaggle/lib/python3.7/site-packages/torch/nn/modules/container.py\", line 117, in forward\n",
      "\u001b[2m\u001b[36m(pid=6405)\u001b[0m     input = module(input)\n",
      "\u001b[2m\u001b[36m(pid=6405)\u001b[0m   File \"/opt/favordata/anaconda3/envs/kaggle/lib/python3.7/site-packages/torch/nn/modules/module.py\", line 727, in _call_impl\n",
      "\u001b[2m\u001b[36m(pid=6405)\u001b[0m     result = self.forward(*input, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=6405)\u001b[0m   File \"/opt/favordata/anaconda3/envs/kaggle/lib/python3.7/site-packages/torch/nn/modules/container.py\", line 117, in forward\n",
      "\u001b[2m\u001b[36m(pid=6405)\u001b[0m     input = module(input)\n",
      "\u001b[2m\u001b[36m(pid=6405)\u001b[0m   File \"/opt/favordata/anaconda3/envs/kaggle/lib/python3.7/site-packages/torch/nn/modules/module.py\", line 727, in _call_impl\n",
      "\u001b[2m\u001b[36m(pid=6405)\u001b[0m     result = self.forward(*input, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=6405)\u001b[0m   File \"../pytorch-image-models/timm/models/efficientnet_blocks.py\", line 259, in forward\n",
      "\u001b[2m\u001b[36m(pid=6405)\u001b[0m     x = self.act1(x)\n",
      "\u001b[2m\u001b[36m(pid=6405)\u001b[0m   File \"/opt/favordata/anaconda3/envs/kaggle/lib/python3.7/site-packages/torch/nn/modules/module.py\", line 727, in _call_impl\n",
      "\u001b[2m\u001b[36m(pid=6405)\u001b[0m     result = self.forward(*input, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=6405)\u001b[0m   File \"/opt/favordata/anaconda3/envs/kaggle/lib/python3.7/site-packages/torch/nn/modules/activation.py\", line 394, in forward\n",
      "\u001b[2m\u001b[36m(pid=6405)\u001b[0m     return F.silu(input, inplace=self.inplace)\n",
      "\u001b[2m\u001b[36m(pid=6405)\u001b[0m   File \"/opt/favordata/anaconda3/envs/kaggle/lib/python3.7/site-packages/torch/nn/functional.py\", line 1740, in silu\n",
      "\u001b[2m\u001b[36m(pid=6405)\u001b[0m     return torch._C._nn.silu_(input)\n",
      "\u001b[2m\u001b[36m(pid=6405)\u001b[0m RuntimeError: CUDA out of memory. Tried to allocate 84.00 MiB (GPU 0; 10.76 GiB total capacity; 9.66 GiB already allocated; 39.44 MiB free; 9.84 GiB reserved in total by PyTorch)\n",
      "\u001b[2m\u001b[36m(pid=6405)\u001b[0m \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-263240bbee7e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-5-9830309e70ff>\u001b[0m in \u001b[0;36mmain\u001b[0;34m(num_samples, max_num_epochs, gpus_per_trial)\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0mnum_samples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_samples\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0mscheduler\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscheduler\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m         progress_reporter=reporter)\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0mbest_trial\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_best_trial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"loss\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"min\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"last\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/favordata/anaconda3/envs/kaggle/lib/python3.7/site-packages/ray/tune/tune.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(run_or_experiment, name, metric, mode, stop, time_budget_s, config, resources_per_trial, num_samples, local_dir, search_alg, scheduler, keep_checkpoints_num, checkpoint_score_attr, checkpoint_freq, checkpoint_at_end, verbose, progress_reporter, loggers, log_to_file, trial_name_creator, trial_dirname_creator, sync_config, export_formats, max_failures, fail_fast, restore, server_port, resume, queue_trials, reuse_actors, trial_executor, raise_on_failed_trial, callbacks, ray_auto_init, run_errored_only, global_checkpoint_period, with_server, upload_dir, sync_to_cloud, sync_to_driver, sync_on_checkpoint)\u001b[0m\n\u001b[1;32m    409\u001b[0m     \u001b[0mtune_start\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    410\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mrunner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_finished\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 411\u001b[0;31m         \u001b[0mrunner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    412\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    413\u001b[0m             \u001b[0m_report_progress\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrunner\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprogress_reporter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/favordata/anaconda3/envs/kaggle/lib/python3.7/site-packages/ray/tune/trial_runner.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    568\u001b[0m                     trial=next_trial)\n\u001b[1;32m    569\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrial_executor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_running_trials\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 570\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process_events\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# blocking\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    571\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    572\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrial_executor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_no_available_trials\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/favordata/anaconda3/envs/kaggle/lib/python3.7/site-packages/ray/tune/trial_runner.py\u001b[0m in \u001b[0;36m_process_events\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    674\u001b[0m             \u001b[0;31m# TODO(ujvl): Consider combining get_next_available_trial and\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    675\u001b[0m             \u001b[0;31m#  fetch_result functionality so that we don't timeout on fetch.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 676\u001b[0;31m             \u001b[0mtrial\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrial_executor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_next_available_trial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# blocking\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    677\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtrial\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_restoring\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    678\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mwarn_if_slow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"process_trial_restore\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/favordata/anaconda3/envs/kaggle/lib/python3.7/site-packages/ray/tune/ray_trial_executor.py\u001b[0m in \u001b[0;36mget_next_available_trial\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    462\u001b[0m         \u001b[0;31m# See https://github.com/ray-project/ray/issues/4211 for details.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    463\u001b[0m         \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 464\u001b[0;31m         \u001b[0;34m[\u001b[0m\u001b[0mresult_id\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshuffled_results\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    465\u001b[0m         \u001b[0mwait_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    466\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mwait_time\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mNONTRIVIAL_WAIT_TIME_THRESHOLD_S\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/favordata/anaconda3/envs/kaggle/lib/python3.7/site-packages/ray/worker.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(object_refs, num_returns, timeout)\u001b[0m\n\u001b[1;32m   1580\u001b[0m             \u001b[0mnum_returns\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1581\u001b[0m             \u001b[0mtimeout_milliseconds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1582\u001b[0;31m             \u001b[0mworker\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcurrent_task_id\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1583\u001b[0m         )\n\u001b[1;32m   1584\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mready_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mremaining_ids\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpython/ray/_raylet.pyx\u001b[0m in \u001b[0;36mray._raylet.CoreWorker.wait\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpython/ray/_raylet.pyx\u001b[0m in \u001b[0;36mray._raylet.check_status\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
